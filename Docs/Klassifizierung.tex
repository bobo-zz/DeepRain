\section{Klassifizierung}
Statt die genaue Regenmenge vorherzusagen, stellten wir drei Kategorien auf: kein Regen ($= 0mm$), wenig Regen ($\leq 8mm$) und viel Regen ($> 8mm$). Diese Kategorien haben wir als One-Hot-Vector kodiert. `[1, 0, 0]` entspricht hierbei kein Regen, sodass man aus der ersten Dimension der Vorhersage einfach ein Vorschaubild generieren kann aus dem man gleich feststellen kann, ob es am jeweiligen Pixel regnet oder nicht.

Für das Training mit Kategorien kann man nicht mehr den MSE verwenden, hier würde selbst nach 80 Epochen nur "kein Regen" vorhergesagt. Stattdessen wurde als Loss-Funktion die \enquote{Categorical Crossentropy} von Keras verwendet; die binäre Crossentropy können wir nicht verwenden, weil wir mehr als zwei Kategorien verwenden. Die \enquote{Categorical Crossentropy} funktioniert relativ gut, aber es wird ein Blob vorhersagt, der etwas über den Bereich ragt, in dem es eigentlich regnet.

Danach wurde noch die Aktivierungsfunktion für den Output-Layer Sigmoid durch Softmax ersetzt. Dadurch erscheint das Vorschaubild etwas verwaschener, aber der Blob um das Regengebiet wird kleiner und die Differenz zum Referenzbild wird kleiner.

Wenn man die Aktivierungsfunktion der Hidden-Layer (von ReLu) zu Tanh verändert, verbessert sich auch die Kategorisierung: der Blob nähert sich weiter dem Regengebiet aus dem zu vorhersagendem Bild an, ist aber immer noch merkbar größer und franst an den kanten aus.

Als nächstes wird die Metrik "categorical\_accuracy" verwendet, um die Vorhersage zu überwachen. Dadurch kann der Fortschritt beim Trainieren besser überwacht werden.


\subsection{Training}
Für das Training wurden alle Daten der 18 Jahre verwendet, partitioniert in Trainings- und Evaluationsdaten. Als Lossfunktion wurde der MSE verwendet, der den Unterschied über alle Pixel kumuliert, weswegen so hohe Werte in den Abbildungen vorkommen (1100x900 Pixel). Da das Training auf der GPU weniger al 10~Sekunden pro Epoche dauert, wurden gleich 3072 Epochen trainiert.

In Abbildung~\ref{fig:lernkurven} sind die Lernkurven des Trainings nebeneinander dargestellt, links steht das Training des Netzes mit Softmax als Aktivierungsfunktion des Hidden Layer und rechts ist das selbe Netz mit TanH als Aktivierungsfunktion. Man sieht jedoch, dass es ab etwa 1500~Epochen (x-Achse) keine Verbesserungen mehr gibt.

\begin{figure}[ht]
\centering
\begin{subfigure}{0.5\textwidth}
\centering
\includegraphics[width=\linewidth]{pics/lernkurve_activationHidden-softmax_activationOutput-softmax}
\caption{Lernkurve (Hidden layer: Softmax)}
\label{fig:lernkurveSoftmax}
\end{subfigure}%
\begin{subfigure}{0.5\textwidth}
\centering
\includegraphics[width=\linewidth]{pics/lernkurve_activationHidden-tanh_activationOutput-softmax}
\caption{Lernkurve (Hidden layer: Tanh)}
\label{fig:lernkurveTanh}
\end{subfigure}%
\caption{Lernkurven von den Aktivierungsfunktionen der Hidden-Layer}
\label{fig:lernkurven}
\end{figure}



\subsection{Auswertung}
Zu den Netzen mit den verschiedenen Aktivierungsfunktionen wurden jeweils eine Confustion-Matrix stellt (siehe Tabellen~\ref{tab:confusionSoftmax} und~\ref{tab:confusionTanh}). An beiden Matrizen kann man sehen, dass beide Aktivierungsfunktionen für einzelne Pixel statistisch ähnliche Ergebnisse liefern.

Bei beiden Matrizen ist gleich, dass, falls kein Regen vorhergesagt wird, in 96,1\% respektive 96,3\% auch tatsächlich kein Regen eintrifft. Wird wenig Regen vorhergesagt, ist die Unsicherheit recht groß: zu rund 20\% regnet es gar nicht oder zu etwa 16\% regnet es stark. Zu einem Fünftel kann es also sein, dass hier die Vorhersage \enquote{Regen} nicht eintrifft. Wird starker Regen vorausgesagt, trifft zu gut 68\% auch starker Regen ein, zu fast 26\% wenig Regen oder gut 5\% kein Regen. Hier trifft die Vorhersage \enquote{Regen} also zu 95\% ein.

\begin{table}[ht]
\centering
\begin{tabular}{lr|rrr}
    &                      & \multicolumn{3}{c}{Vorhersage}\\
    &                      & \textbf{Kein Regen} & \textbf{Wenig Regen} & \textbf{Viel Regen}\\\hline
\multirow{3}{*}{\rotatebox{90}{Daten}}
    & \textbf{Kein Regen}  & 2227245 (96,1\%)    & 33383 (19,9\%)       & 3762 (05,7\%)\\
    & \textbf{Wenig Regen} & 81116 (03,5\%)      & 106434 (63,4\%)      & 17077 (25,9\%)\\
    & \textbf{Viel Regen}  & 9695 (00,4\%)       & 27930 (16,7\%)       & 45166 (68,4\%)\\
\end{tabular}
\caption{Confustion-Matrix (Aktivierungsfunktion Hidden Layer: Softmax)}
\label{tab:confusionSoftmax}
\end{table}

\begin{table}[ht]
\centering
\begin{tabular}{lr|rrr}
    &                      & \multicolumn{3}{c}{Vorhersage}\\
    &                      & \textbf{Kein Regen} & \textbf{Wenig Regen} & \textbf{Viel Regen}\\\hline
\multirow{3}{*}{\rotatebox{90}{Daten}}
    & \textbf{Kein Regen}  & 2225229 (96,3\%)    & 35527 (20,4\%)       & 3634 (05,4\%)\\
    & \textbf{Wenig Regen} & 76988 (03,3\%)      & 110399 (63,5\%)      & 17240 (25,8\%)\\
    & \textbf{Viel Regen}  & 8849 (00,4\%)       & 27969 (16,1\%)       & 45973 (68,8\%)\\
\end{tabular}
\caption{Confustion-Matrix (Aktivierungsfunktion Hidden Layer: Tanh)}
\label{tab:confusionTanh}
\end{table}

Bei der Vorhersage von zusammenhängenden Niederschlagsmengen auf einer Karte gibt es Unterschiede zwischen den Aktivierungsfunktionen der Hidden Layer, während es auf die Wahrscheinlichkeit der einzelnen Pixel kaum unterschiede gab.
Das UNet mit TanH als Aktivierungsfunktion der Hidden Layer erzeugt größere (und leicht rundere) Blobs (Abbildung~\ref{fig:hiddenActivationTanh}). Bei Softmax werden schräge Kanten besser vorhergesagt (Abbildung~\ref{fig:hiddenActivationSoftmax}).
\begin{figure}[ht]
\centering
\begin{subfigure}{0.5\textwidth}
\centering
\includegraphics[width=\linewidth]{pics/categorical_crossentropy_hidden-softmax_output-softmax_above_3072}
\caption{Hidden layer activation: Softmax}
\label{fig:hiddenActivationSoftmax}
\end{subfigure}%
\begin{subfigure}{0.5\textwidth}
\centering
\includegraphics[width=\linewidth]{pics/categorical_crossentropy_hidden-tanh_output-softmax_above_3072}
\caption{Hidden layer activation: Tanh}
\label{fig:hiddenActivationTanh}
\end{subfigure}%
\caption{Vergleich von Aktivierungsfunktionen der Hidden-Layer}
\label{fig:activatinHidden}
\end{figure}


\subsubsection{Zwei Kategorien}
Daraufhin versuchten wir die Vorhersage mit nur zwei Kategorien (Regen / Kein Regen) durchzuführen um festzustellen, ob die Vorhersage ob es regnet oder nicht besser funktioniert als die mit keinem, wenig oder starkem Regen. Dazu erstellen noch einmal die Confusion Matrix auf (siehe Tabelle~\ref{tab:confusionTwoCategoriesTresholdZero}). Bei einem Treshold von 0 erhält man fast gleiche Wahrscheinlichkeiten wie bei 3 Kategorien für Regen und Kein Regen: Falls kein Regen vorhergesagt wurde, regnet es zu 96\% nicht; und falls Regen vorhergesagt wurde regnet es zu gut 80\%.

\begin{table}[ht]
\centering
\begin{tabular}{lr|rr}
    &                      & \multicolumn{2}{c}{Vorhersage}\\
    &                      & \textbf{Kein Regen} & \textbf{Regen}\\\hline
\multirow{3}{*}{\rotatebox{90}{Daten}}
    & \textbf{Kein Regen}  & 2218754 (96,3\%)    & 45636 (18,4\%)\\
    & \textbf{Regen}       & 85427 (03,7\%)      & 201991 (81,6\%)\\
\end{tabular}
\caption{Confustion-Matrix (Zwei Kategorien, Treshold: 0)}
\label{tab:confusionTwoCategoriesTresholdZero}
\end{table}

\begin{table}[ht]
\centering
\begin{tabular}{lr|rr}
    &                      & \multicolumn{2}{c}{Vorhersage}\\
    &                      & \textbf{Kein Regen} & \textbf{Regen}\\\hline
\multirow{3}{*}{\rotatebox{90}{Daten}}
    & \textbf{Kein Regen}  & 2272947 (96,7\%)    & 39276 (19,6\%)\\
    & \textbf{Regen}       & 78475 (03,3\%)      & 161110 (80,4\%)\\
\end{tabular}
\caption{Confustion-Matrix (Zwei Kategorien, Treshold: 2)}
\label{tab:confusionTwoCategoriesTresholdTwo}
\end{table}



\subsection{Herausforderungen in diesem Kapitel}
\begin{itemize}
\item Richtige Kategorien finden
\item Training mit richtiger Aktivierungsfunktion / Optimizer
\end{itemize}
