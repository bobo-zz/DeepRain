\section{Klassifizierung}
Statt die genaue Regenmenge in 35 Minuten vorherzusagen, stellten wir drei Kategorien auf: kein Regen ($= 0mm$), wenig Regen ($\leq 8mm$) und viel Regen ($> 8mm$). Diese Kategorien haben wir als One-Hot-Vector kodiert. `[1, 0, 0]` entspricht hierbei kein Regen, sodass man aus der ersten Dimension der Vorhersage einfach ein Vorschaubild generieren kann aus dem man gleich feststellen kann, ob es am jeweiligen Pixel regnet oder nicht.

Für das Training mit Kategorien kann man nicht mehr den MSE verwenden, hier würde selbst nach 80 Epochen nur \gqq{kein Regen} vorhergesagt. Stattdessen wurde als Loss-Funktion die \gqq{Categorical Crossentropy} von Keras verwendet; die binäre Crossentropy können wir nicht verwenden, weil wir mehr als zwei Kategorien verwenden. Die \gqq{Categorical Crossentropy} funktioniert relativ gut, aber es wird ein Blob vorhersagt, der etwas über den Bereich ragt, in dem es eigentlich regnet.

Danach wurde noch die Aktivierungsfunktion für den Output-Layer Sigmoid durch Softmax ersetzt. Dadurch erscheint das Vorschaubild etwas verwaschener, aber der Blob um das Regengebiet wird kleiner und die Differenz zum Referenzbild wird kleiner.

Wenn man die Aktivierungsfunktion der Hidden-Layer (von ReLu) zu Tanh verändert, verbessert sich auch die Kategorisierung: der Blob nähert sich weiter dem Regengebiet aus dem zu vorhersagendem Bild an, ist aber immer noch merkbar größer und franst an den kanten aus.

Als nächstes wird die Metrik \gqq{categorical\_accuracy} verwendet, um die Vorhersage zu überwachen. Dadurch kann der Fortschritt beim Trainieren besser überwacht werden.


\subsection{Training}
Für das Training wurden alle Daten der 18 Jahre verwendet, partitioniert in Trainings- und Evaluationsdaten. Als Lossfunktion wurde der MSE verwendet, der den Unterschied über alle Pixel kumuliert, weswegen so hohe Werte in den Abbildungen vorkommen (1100x900 Pixel). Da das Training auf der GPU weniger al 10~Sekunden pro Epoche dauert, wurden gleich 3072 Epochen trainiert.

In Abbildung~\ref{fig:lernkurven} sind die Lernkurven des Trainings nebeneinander dargestellt, links steht das Training des Netzes mit Softmax als Aktivierungsfunktion des Hidden Layer und rechts ist das selbe Netz mit TanH als Aktivierungsfunktion. Man sieht jedoch, dass es ab etwa 1500~Epochen (x-Achse) keine Verbesserungen mehr gibt.

\begin{figure}[ht]
\centering
\begin{subfigure}{0.5\textwidth}
\centering
\includegraphics[width=\linewidth]{pics/lernkurve_activationHidden-softmax_activationOutput-softmax}
\caption{Lernkurve (Hidden layer: Softmax)}
\label{fig:lernkurveSoftmax}
\end{subfigure}%
\begin{subfigure}{0.5\textwidth}
\centering
\includegraphics[width=\linewidth]{pics/lernkurve_activationHidden-tanh_activationOutput-softmax}
\caption{Lernkurve (Hidden layer: Tanh)}
\label{fig:lernkurveTanh}
\end{subfigure}%
\caption[Lernkurven verschiedener Aktivierungsfkt. der Hidden Layer]{Gegenüberstellung zweier Lernkurven von verschiedenen Aktivierungsfunktionen der Hidden Layer. Auf der Y-Achse ist der kumulierte MSE über alle Pixel. Ab etwa der tausendsten Epoche gibt es kaum noch eine Verbesserung. Bei Tanh flacht die Kurve schneler ab.}
\label{fig:lernkurven}
\end{figure}



\subsection{Auswertung}
Zu den Netzen mit den verschiedenen Aktivierungsfunktionen wurden jeweils eine Confustion-Matrix erstellt (siehe Tabellen~\ref{tab:confusionSoftmax} und~\ref{tab:confusionTanh}). An beiden Matrizen kann man sehen, dass beide Aktivierungsfunktionen für einzelne Pixel statistisch ähnliche Ergebnisse liefern.

Bei beiden Matrizen ist gleich, dass, falls kein Regen vorhergesagt wird, in 96,1\% respektive 96,3\% auch tatsächlich kein Regen eintrifft. Wird wenig Regen vorhergesagt, ist die Unsicherheit recht groß: zu rund 20\% regnet es gar nicht oder zu etwa 16\% regnet es stark. Zu einem Fünftel kann es also sein, dass hier die Vorhersage \gqq{Regen} nicht eintrifft. Wird starker Regen vorausgesagt, trifft zu gut 68\% auch starker Regen ein, zu fast 26\% wenig Regen oder gut 5\% kein Regen. Hier trifft die Vorhersage \gqq{Regen} also zu 95\% ein.

\begin{table}[ht]
\centering
\begin{tabular}{lr|rrr}
    &                      & \multicolumn{3}{c}{Vorhersage}\\
    &                      & \textbf{Kein Regen} & \textbf{Wenig Regen} & \textbf{Viel Regen}\\\hline
\multirow{3}{*}{\rotatebox{90}{Daten}}
    & \textbf{Kein Regen}  & 2227245 (96,1\%)    & 33383 (19,9\%)       & 3762 (5,7\%)\\
    & \textbf{Wenig Regen} & 81116 (3,5\%)       & 106434 (63,4\%)      & 17077 (25,9\%)\\
    & \textbf{Viel Regen}  & 9695 (0,4\%)        & 27930 (16,7\%)       & 45166 (68,4\%)\\
\end{tabular}
\caption[Confustion-Matrix (Drei Kategorien, Hidden Layer: Softmax)]{Confustion-Matrix zur 35 minuten Regenvorhersage (Drei Kategorien, Aktivierungsfunktion der Hidden Layer: Softmax), Vorhersage für kein Regen sehr gut, die für wenig und viel Regen sind unsicherer.}
\label{tab:confusionSoftmax}
\end{table}

\begin{table}[ht]
\centering
\begin{tabular}{lr|rrr}
    &                      & \multicolumn{3}{c}{Vorhersage}\\
    &                      & \textbf{Kein Regen} & \textbf{Wenig Regen} & \textbf{Viel Regen}\\\hline
\multirow{3}{*}{\rotatebox{90}{Daten}}
    & \textbf{Kein Regen}  & 2225229 (96,3\%)    & 35527 (20,4\%)       & 3634 (5,4\%)\\
    & \textbf{Wenig Regen} & 76988 (3,3\%)       & 110399 (63,5\%)      & 17240 (25,8\%)\\
    & \textbf{Viel Regen}  & 8849 (0,4\%)        & 27969 (16,1\%)       & 45973 (68,8\%)\\
\end{tabular}
\caption[Confustion-Matrix (Drei Kategorien, Hidden Layer: Tanh)]{Confustion-Matrix zur 35 minuten Regenvorhersage (Drei Kategorien, Aktivierungsfunktion Hidden Layer: Tanh), die Werte sind ähnlich wie die der Aktivierungsfunktion Softmax (Tabelle~\ref{tab:confusionSoftmax}).}
\label{tab:confusionTanh}
\end{table}

Bei der Vorhersage von zusammenhängenden Niederschlagsmengen auf einer Karte gibt es Unterschiede zwischen den Aktivierungsfunktionen der Hidden Layer, während es auf die Wahrscheinlichkeit der einzelnen Pixel kaum Unterschiede gab.
Das UNet mit TanH als Aktivierungsfunktion der Hidden Layer erzeugt größere (und leicht rundere) Blobs (Abbildung~\ref{fig:hiddenActivationTanh}). Bei Softmax werden schräge Kanten besser vorhergesagt (Abbildung~\ref{fig:hiddenActivationSoftmax}).
\begin{figure}[ht]
\centering
\begin{subfigure}{0.5\textwidth}
\centering
\includegraphics[width=\linewidth]{pics/categorical_crossentropy_hidden-softmax_output-softmax_above_3072}
\caption{Hidden layer activation: Softmax}
\label{fig:hiddenActivationSoftmax}
\end{subfigure}%
\begin{subfigure}{0.5\textwidth}
\centering
\includegraphics[width=\linewidth]{pics/categorical_crossentropy_hidden-tanh_output-softmax_above_3072}
\caption{Hidden layer activation: Tanh}
\label{fig:hiddenActivationTanh}
\end{subfigure}%
\caption[Vergleich von Aktivierungsfunktionen der Hidden-Layer]{Vergleich von Aktivierungsfunktionen der Hidden-Layer nach je 3072 Epochen. Aktivierungsfunktion der Output Layer ist jedes mal Softmax. Bei Tanh sind die Blobs rundlicher und haben härtere Kanten.}
\label{fig:activatinHidden}
\end{figure}


\subsubsection{Training mit zwei Kategorien}
Daraufhin versuchten wir die Vorhersage mit nur zwei Kategorien (Regen / Kein Regen) durchzuführen um festzustellen, ob die Vorhersage auf diese Weise besser funktioniert als die mit den drei bisherigen Kategorien. Dazu trainierten wir noch einmal das Netz mit zwei Kategorien und stellen die Confusion Matrix auf (siehe Tabelle~\ref{tab:confusionTwoCategoriesThresholdZero}). Bei einem Threshold von 0 erhält man fast gleiche Wahrscheinlichkeiten wie bei 3 Kategorien für Regen und Kein Regen: Falls kein Regen vorhergesagt wurde, regnet es zu 96\% nicht; und falls Regen vorhergesagt wurde regnet es zu gut 80\%.

\begin{table}[ht]
\centering
\begin{tabular}{lr|rr}
    &                      & \multicolumn{2}{c}{Vorhersage}\\
    &                      & \textbf{Kein Regen} & \textbf{Regen}\\\hline
\multirow{3}{*}{\rotatebox{90}{Daten}}
    & \textbf{Kein Regen}  & 2218754 (96,3\%)    & 45636 (18,4\%)\\
    & \textbf{Regen}       & 85427 (3,7\%)       & 201991 (81,6\%)\\
\end{tabular}
\caption[Confustion-Matrix (Zwei Kategorien, Threshold: 0, Softmax)]{Confustion-Matrix (Zwei Kategorien, Threshold: 0, Softmax), die Vorhersage von keinem Regen ist genau so gut wie bei drei Kategorien, die Kategorie für Regen wird besser vorhergesagt, als die einzelnen Kategorien für wenig oder viel Regen (vgl. Tabelle~\ref{tab:confusionTanh}).}
\label{tab:confusionTwoCategoriesThresholdZero}
\end{table}

Verwendet man einen Threshold von 2 (mm) für die Generierung der Kategorien, verschlechtern sich die Wahrscheinlichkeiten leicht (siehe Tabelle~\ref{tab:confusionTwoCategoriesThresholdTwo}). Falls Regen vorhergesagt wurde, ist die Kein-Regen-Wahrscheinlichkeit nun 19,6\%, statt 18,4\%. Die Wahrscheinlichkeit von Regen, falls kein Regen vorhergesagt wurde, wird dafür minimal besser: 3,3\% statt 3,7\%.
%\begin{table}[ht]
%\centering
%\begin{tabular}{lr|rr}
%    &                      & \multicolumn{2}{c}{Vorhersage}\\
%    &                      & \textbf{Kein Regen} & \textbf{Regen}\\\hline
%\multirow{3}{*}{\rotatebox{90}{Daten}}
%    & \textbf{Kein Regen}  & 2323398 (99,7\%)    & 163631 (73,9\%)\\
%    & \textbf{Regen}       & 7068 (0,3\%)        & 57711 (26,1\%)\\
%\end{tabular}
%\caption{Confustion-Matrix (Zwei Kategorien, Threshold: 1, Softmax)}
%\label{tab:confusionTwoCategoriesThresholdOne}
%\end{table}

\begin{table}[ht]
\centering
\begin{tabular}{lr|rr}
    &                      & \multicolumn{2}{c}{Vorhersage}\\
    &                      & \textbf{Kein Regen} & \textbf{Regen}\\\hline
\multirow{3}{*}{\rotatebox{90}{Daten}}
    & \textbf{Kein Regen}  & 2272947 (96,7\%)    & 39276 (19,6\%)\\
    & \textbf{Regen}       & 78475 (3,3\%)       & 161110 (80,4\%)\\
\end{tabular}
\caption[Confustion-Matrix (Zwei Kategorien, Threshold: 2, Softmax)]{Confustion-Matrix (Zwei Kategorien, Threshold: 2, Softmax), die Kategorie \gqq{kein Regen} wird leicht besser vorhergesagt, Regen etwas schlechter (vgl. Tabelle~\ref{tab:confusionTwoCategoriesThresholdZero}).}
\label{tab:confusionTwoCategoriesThresholdTwo}
\end{table}

%\begin{table}[ht]
%\centering
%\begin{tabular}{lr|rr}
%    &                      & \multicolumn{2}{c}{Vorhersage}\\
%    &                      & \textbf{Kein Regen} & \textbf{Regen}\\\hline
%\multirow{3}{*}{\rotatebox{90}{Daten}}
%    & \textbf{Kein Regen}  & 2365886 (99,6\%)    & 121143 (69,1\%)\\
%    & \textbf{Regen}       & 10664 (0,4\%)       & 54115 (30,9\%)\\
%\end{tabular}
%\caption{Confustion-Matrix (Zwei Kategorien, Threshold: 3, Softmax)}
%\label{tab:confusionTwoCategoriesThresholdThree}
%\end{table}

Erhöht man den Threshold weiter auf 4, verdeutlicht sich der Trend aus der letzten Confusion Matrix (siehe Tabelle~\ref{tab:confusionTwoCategoriesThresholdFour}): die Wahrscheinlichkeit, dass für Regen \gqq{kein Regen} vorhergesagt wird, sinkt auf 2,7\%, die Wahrscheinlichkeit, dass Regen vorhergesagt wird und nicht eintrifft, steigt auf 23,2\%.
\begin{table}[ht]
\centering
\begin{tabular}{lr|rr}
    &                      & \multicolumn{2}{c}{Vorhersage}\\
    &                      & \textbf{Kein Regen} & \textbf{Regen}\\\hline
\multirow{3}{*}{\rotatebox{90}{Daten}}
    & \textbf{Kein Regen}  & 2376736 (97,3\%)    & 25441 (23,2\%)\\
    & \textbf{Regen}       & 65381 (2,7\%)       & 84250 (77,8\%)\\
\end{tabular}
\caption[Confustion-Matrix (Zwei Kategorien, Threshold: 4, Softmax)]{Confustion-Matrix (Zwei Kategorien, Threshold: 4, Softmax), die Kategorie \gqq{kein Regen} wird wieder etwas besser vorhergesagt, Regen schlechter (vgl. Tabelle~\ref{tab:confusionTwoCategoriesThresholdTwo}).}
\label{tab:confusionTwoCategoriesThresholdFour}
\end{table}

%\begin{table}[ht]
%\centering
%\begin{tabular}{lr|rr}
%    &                      & \multicolumn{2}{c}{Vorhersage}\\
%    &                      & \textbf{Kein Regen} & \textbf{Regen}\\\hline
%\multirow{3}{*}{\rotatebox{90}{Daten}}
%    & \textbf{Kein Regen}  & 2436225 (99,3\%)    & 50804 (51,9\%)\\
%    & \textbf{Regen}       & 17672 (0,7\%)       & 47107 (48,1\%)\\
%\end{tabular}
%\caption{Confustion-Matrix (Zwei Kategorien, Threshold: 5, Softmax)}
%\label{tab:confusionTwoCategoriesThresholdFive}
%\end{table}

%\begin{table}[ht]
%\centering
%\begin{tabular}{lr|rr}
%    &                      & \multicolumn{2}{c}{Vorhersage}\\
%    &                      & \textbf{Kein Regen} & \textbf{Regen}\\\hline
%\multirow{3}{*}{\rotatebox{90}{Daten}}
%    & \textbf{Kein Regen}  & 2445930 (99,2\%)    & 41099 (48,1\%)\\
%    & \textbf{Regen}       & 20450 (0,8\%)       & 44329 (51,9\%)\\
%\end{tabular}
%\caption{Confustion-Matrix (Zwei Kategorien, Threshold: 6, Softmax)}
%\label{tab:confusionTwoCategoriesThresholdSix}
%\end{table}

%\begin{table}[ht]
%\centering
%\begin{tabular}{lr|rr}
%    &                      & \multicolumn{2}{c}{Vorhersage}\\
%    &                      & \textbf{Kein Regen} & \textbf{Regen}\\\hline
%\multirow{3}{*}{\rotatebox{90}{Daten}}
%    & \textbf{Kein Regen}  & 2475815 (98,5\%)    & 11214 (28,6\%)\\
%    & \textbf{Regen}       & 36827 (1,5\%)       & 27952 (71,4\%)\\
%\end{tabular}
%\caption{Confustion-Matrix (Zwei Kategorien, Threshold: 10, Softmax)}
%\label{tab:confusionTwoCategoriesThresholdTen}
%\end{table}

Man sieht also, dass die Vorhersage ob Regen eintrifft oder nicht, bei drei Kategorien und zwei Kategorien (bei einem Threshold von 0) fast gleich ausfällt und  die Erhöhung des Thresholds die Genauigkeit senkt. Die genaue Regenmenge vorauszusagen hat sich als schwierig herausgestellt, aber man weiß zumindest (fast) sicher, dass man, wenn kein Regen vorhergesagt wird, nicht nass wird.
Da das Datenset sehr unbalanciert ist ist die Trefferquote nur bedingt aussagekräftig. Auch ein Klassifikator, welcher immer nur kein Regen vorhersagt hätte eine gute Trefferrate. Um dieser Eingenschaft entgegen zu wirken, wird auch ein ROC analyse durchgeführt.

\subsection{ROC-Kurve bei zwei Kategorien}
Zur Überprüfung des Verhaltens der Genauigkeit bei Anpassung des Thresholds wird eine Receiver Operating Characteristic-Kurve (ROC) verwendet (siehe Abbildung~\ref{roc}). Diese dient zum Vergleich der Confusion Matrizen mit verschiedenen Thresholds und damit der Performance des Netzes.

Auf der X-Achse wird die True Positive Rate (Sensitivität) abgebildet. Diese beschreibt die Rate der richtig kategorisierten positiven Ereignisse (In unserem Fall: Kein Regen vorhergesagt und es regnet tatsächlich nicht).

\begin{align*}
  TPR \quad	 {=} \quad True Positives \quad / \quad(True Positive + False Negatives)
\end{align*}

Auf der Y-Achse wird die False Positive Rate abgebildet. Diese beschreibt die Rate der falsch kategorisierten negativen Ereignisse (In unserem Fall: Kein Regen vorhergesagt aber es regnet tatsächlich) und der Gesamtanzahl der negativen Ereignisse.

\begin{align*}
  FPR \quad	 {=} \quad False Positives \quad / \quad(False Positive + True Negatives)
\end{align*}

In einem Optimalen Szenario wäre der Wert der TPR gleich eins und der Wert der FPR gleich Null. 


\subsubsection{ROC-Kurve bei verschieden Trainierten Netzen}
In diesem Beispiel wird der Threshhold der Daten angepasst, ab wann ein Pixel als Regen zählt. Die daraus entstehende Confusion Matrix wird dann in der ROC verwendet. Dies soll zur Veranschaulichung dienen, welcher Schwellwert auf den Label am sinnvollsten ist.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.6\textwidth]{pics/roc}
	\caption[ROC-Kurve verschiedener Thresholds]{ROC-Kurve verschiedener Thresholds. Die Vorhersage wird schlechter mit steigendem Threshold.}
	\label{roc}
\end{figure}

Wie bereits vermutet, verschlechtert sich die Genauigkeit mit einer Erhöhung eines Thresholds, der mit Null daher den bestmöglichen Wert hat.
Außerdem kann dadurch nachgewiesen werden, dass die Genauigkeit höher als beim zufälligen Auswählen ist.

\subsubsection{ROC-Kurve bezüglich dem beste Netz}
Da sich gezeigt hat, dass der Threshold 0 sich am besten Eignet, wird nun die ROC auf die Ausgabe des Netzes, welches mit einem Threshold von 0 trainiert wurde, angewandt. Hierzu wird jeweils die Wahrscheinlichkeit, für die Klasse \gqq{Regen} ausgewertet. Pixel welche als Regen klassifiziert sind haben hier ideal einen Wert nahe bei 1, regenfreie Pixel idealerweise einen Wert nahe bei 0. Wenn die beiden Klassen fehlerfrei voneinander zu trennen sind, ergibt sich daraus eine Area under the Curve (AUC) von 1. Bei einem Klassifikator, welcher die Klassen nicht trennen kann, erreicht eine AUC von 0,5. in unserem Fall (Abbildung~\ref{roc2}) wird eine AUC von 0,955 erreicht, was auf ein recht gutes unterteilen der Klassen hinweist. Unser Klassifikator ist nicht ganz ideal, aber für eine 35 Minuten vorhersage doch recht zuverlässig.

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.6\textwidth]{pics/ROC-curve}
	\caption{ROC-Kurve für den Threshold 0}
	\label{roc2}
\end{figure}



\subsection{Vergleich zu einfacher Klassifizierung mittels CNN}
Ein sehr ähnlicher Test wurde auch mit einem einfachen CNN durchgeführt. Hierbei wurden die selben Eingangsdaten verwendet. Als Label wurde allerdings nur eine einfache Klassifizierung für den 'Konstanzpixel' vorgenommen. Im Gegensatz zu dem UNet muss das CNN also lediglich für einen Pixel eine Klassifizierung vornehmen. Das Ergebnis dieses Versuchs zeigt, dass das CNN für eine vergleichsweise einfachere Aufgabe eine ähnliches bzw. leicht schlechteres Ergebnis liefert. Die Auswertung ist in Tabelle~\ref{tab:confusionCNNkonstanz} abgebildet. Es zeigt sich, eine deutliche Schwäche bei der vorhersage von Regen, hier sind lediglich 55\% der vorhersagen korrekt. auch bei der Klasse \gqq{kein Regen} ist das UNet zuverlässiger.

\begin{table}[ht]
\centering
\begin{tabular}{lr|rr}
	&                      & \multicolumn{2}{c}{Vorhersage}\\
	&                      & \textbf{Kein Regen} & \textbf{Regen}\\\hline
	\multirow{3}{*}{\rotatebox{90}{Daten}}
	& \textbf{Kein Regen}  & 410 (92\%)          & 80 (45\%)\\
	& \textbf{Regen}       & 35 (8\%)            & 98 (55\%)\\
\end{tabular}
\caption[Confusion Matrix der Vorhersage des Konstanzpixels mit CNN]{Confusion Matrix der Vorhersage des Konstanzpixels mit CNN. Die Sicherheit der Vorhersage von \gqq{kein Regen} ist genau so gut wie beim UNet, die der Regenvorhersage deutlich schlechter.}
\label{tab:confusionCNNkonstanz}
\end{table}


\subsection{Herausforderungen in diesem Kapitel}
In diesem Kapitel gab es zwei große Herausforderungen: zum einen war es schwierig die richtigen Kategorien zu finden, und zum anderen musste sich herausstellen, wie sich die verschiedenen Aktivierungsfunktionen auswirken.

Die drei Kategorien haben sich als suboptimal herausgestellt, da vor allem die dritte Klasse deutlich zu wenig Samples für ein sinnvolles Training besitzt. Mit zwei Kategorien hingegen können wir zuverlässige Vorhersagen bezüglich Regen oder kein Regen geben.

Die Aktivierungsfunktionen haben sich nur auf die Form der Blobs der Niederschlagsmengen ausgewirkt (Abbildung~\ref{fig:activatinHidden}), aber weniger auf die Regen-Wahrscheinlichkeit der einzelnen Punkte (siehe Tabellen~\ref{tab:confusionSoftmax} und \ref{tab:confusionTanh}).
