# Deep Learning
## Local short-term precipitation prediction through machine learning

```Thomas Gnädig, Etienne Gramlich, Tim Hardenacke, Merle Wolff and Oliver Dürr```

#### Abstract
We try to predict precipitation for a range of 35 minutes in an area around Constance.
Therefore we are using machine learning techniques and train a UNet on radar data images. 
Here we present the result of precipitation prediction as well with regression as with classification. 
Both approaches provide good results.

#### Data
We are using radar Data from the [Climate Data Center of the DWD](https://www.dwd.de/DE/klimaumwelt/cdc/cdc_node.html). Here are radarimages since 2004. 
This data has to be Downloaded and converted to png this is done by our [Crawler](https://github.com/thgnaedi/DeepRain/tree/master/DWD_Crawler) and [Converter](https://github.com/thgnaedi/DeepRain/blob/master/Data/DWDtoPngScript.py).
The rainfall images then are tailored and scaled. resulting unattraktiv images are then rejected that only interessting images are used for the training.
The images are grayscales png's as Network input five temporally consecutive of them are combined to a 3D Tensor as input. The Label consits of seven of them.

#### Architecture
To predict precipitation either with regression or classification we are using a UNet.
This Architecture is a convolutional neural network that was at first developed for biomedical image segmentation. 

![Image of an UNet](https://github.com/thgnaedi/DeepRain/blob/master/Docs/pics/UNet_Biomedical.PNG)
The image is taken from the [university of freiburg](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/)

The input images have a shape of 64x64 pixels. They are pooled until the shape reaches a minimum of 8x8 features. Then they are upsampled and concatenated with the downsampling part.
This yields into an u-shaped architecture and is the reason for its Name.
For regression we use the MSE as lossfunction. The result is shown in the following graphics.

The input is a 64x64x5 Tesnor with the following content:
![input date](https://github.com/thgnaedi/DeepRain/blob/master/Docs/pics/dt5.png)

The Labels are seven timesteps to predict, from 5 minutes till 35 minutes into the future. The result is shown here:
![labels and output](https://github.com/thgnaedi/DeepRain/blob/master/Docs/pics/t5.png)

In the upper row we can see the seven timesteps in the Labels. White means a lot rainfall while black is no rainfall.
The prediction of our network trained on the radar data from 2005 till 2017 is shown in the second row.
The predicted values are verry close to the label for a difference of only 5 minutes to the input data. the further the time progresses, the worse the prediction becomes.
In the last image it looks like the resolution of the output has been drastically decreased compared to the first output. 
In fact the resolution is the same we can say that this is an indication of uncertainty in the Network.
Over the time, the movement of the rainfall is well predicted. even the tiny spot in the top left of Images can be predicted.
Even if the area of rainfall increases much faster than in the labels, the center is still well predicted and close to the center of the label.

The second approach is to predict the precipitation by classification. Here we try to classify into either three classes (no rain, rain, heavy rain) or two classes (no rain, rain) for each pixel.
Herefor the Unets output is modified to three classes per pixel and an additional softmax layer at the output to provide propabilities. The labels are generated by a threshold for each class and the predictionimage after 35 minutes.
to show the output of the pixelwise classification the class heavy rainfall has been plotted to the following image.

![classification output](https://github.com/thgnaedi/DeepRain/blob/master/Docs/pics/categorical_crossentropy_hidden-softmax_output-softmax_above_3072.png)
in the left image the prediction of the first class (no rainfall) is plotted. the white spots are 100% no rainfall. the black spots are 0% no rainfall.
the gray spots can be rainfall or not depending on the propabilitiey of the other two classes. The right image (difference) shows us the absolute difference between the prediction and the label.
Here we can see that the big black spots (no difference between prediction and label) are at the no rainfall labels. This can be explained later. 
The network has a high accuracy by predicting rainfree pixels. this can be shown in the follwing ROC-image. 
By evaluating the confusion matrix for three class classification, you can recognize that the last class (heavy rainfall) is higly undersampled. 
There are much more rainfall pixels and even more no rainfall pixels in the Dataset. To increase the the performance we tried over and undersampling, but both tecniques didnt work well for our scenario.
Finally we changed the problem to a two clas classification with a threshold of 0, so the classes are 'no rainfall' and 'rainfall'.
To show the performance you can take a lock at the ROC. The calculated AUC is close to 96%, wich means, that the model has a good class separation.

![ROC](https://github.com/thgnaedi/DeepRain/blob/master/Docs/pics/ROC-curve.png)

#### Conclusion and Future Work
In summary, this paper argued that short term precipitation prediction can be done by only observing radar data and without any other source of information.
The accuracy could still be imporved as well at the regression, were another lossfunction may could help, as at the classification were the rainfall class is still undersampled and worse accurate than the 'no rain' class.


