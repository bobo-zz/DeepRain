Epoch: 0	max: 0.62266576/1.0	min: 0.3773342	loss: 36189.02734375	train_loss: 36478.739120273596	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1
Epoch: 1	max: 0.700289/1.0	min: 0.299711	loss: 35821.6640625	train_loss: 36044.35336393302	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_2
Epoch: 2	max: 0.7589017/1.0	min: 0.24109834	loss: 35586.99609375	train_loss: 35758.74237185294	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_3
Epoch: 3	max: 0.8019949/1.0	min: 0.19800508	loss: 35441.60546875	train_loss: 35583.203147741704	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_4
Epoch: 4	max: 0.833432/1.0	min: 0.16656804	loss: 35351.1640625	train_loss: 35477.491518313356	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_5
Epoch: 5	max: 0.8560577/1.0	min: 0.14394225	loss: 35295.85546875	train_loss: 35414.623596788675	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_6
Epoch: 6	max: 0.8724423/1.0	min: 0.12755767	loss: 35261.8671875	train_loss: 35377.74003478028	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_7
Epoch: 7	max: 0.8845842/1.0	min: 0.11541584	loss: 35240.58984375	train_loss: 35356.25999860647	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_8
Epoch: 8	max: 0.8931424/1.0	min: 0.10685759	loss: 35227.6875	train_loss: 35343.910536568656	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_9
Epoch: 9	max: 0.8993782/1.0	min: 0.100621834	loss: 35219.44140625	train_loss: 35336.87462210067	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_10
Epoch: 10	max: 0.90337586/1.0	min: 0.096624166	loss: 35214.4765625	train_loss: 35332.44431186517	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_11
Epoch: 11	max: 0.9061273/1.0	min: 0.09387279	loss: 35211.03515625	train_loss: 35329.349913484766	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_12
Epoch: 12	max: 0.90799606/1.0	min: 0.092003934	loss: 35208.44140625	train_loss: 35326.766966276475	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_13
Epoch: 13	max: 0.9093812/1.0	min: 0.09061879	loss: 35206.203125	train_loss: 35324.2566492862	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_14
Epoch: 14	max: 0.91031605/1.0	min: 0.08968394	loss: 35204.19921875	train_loss: 35321.62736223368	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_15
Epoch: 15	max: 0.9107731/1.0	min: 0.089226976	loss: 35202.36328125	train_loss: 35318.77205606265	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_16
Epoch: 16	max: 0.91102153/1.0	min: 0.088978484	loss: 35200.4765625	train_loss: 35315.59669867924	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_17
Epoch: 17	max: 0.9113741/1.0	min: 0.08862595	loss: 35198.28515625	train_loss: 35312.01321728292	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_18
Epoch: 18	max: 0.911612/1.0	min: 0.08838798	loss: 35195.88671875	train_loss: 35307.97099126719	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_19
Epoch: 19	max: 0.9119015/1.0	min: 0.088098556	loss: 35193.1328125	train_loss: 35303.33122851635	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_20
Epoch: 20	max: 0.9122584/1.0	min: 0.08774166	loss: 35189.921875	train_loss: 35297.9547730475	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_21
Epoch: 21	max: 0.9126823/1.0	min: 0.08731768	loss: 35186.125	train_loss: 35291.719581281744	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_22
Epoch: 22	max: 0.91292375/1.0	min: 0.08707622	loss: 35181.7265625	train_loss: 35284.30523426855	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_23
Epoch: 23	max: 0.91357446/1.0	min: 0.086425565	loss: 35176.1796875	train_loss: 35275.46300022064	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_24
Epoch: 24	max: 0.91426975/1.0	min: 0.085730284	loss: 35169.34375	train_loss: 35264.84852285396	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_25
Epoch: 25	max: 0.9154022/1.0	min: 0.08459786	loss: 35160.4765625	train_loss: 35251.86004660597	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_26
Epoch: 26	max: 0.91662145/1.0	min: 0.08337851	loss: 35148.19921875	train_loss: 35235.05410347377	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_27
Epoch: 27	max: 0.9181945/1.0	min: 0.08180551	loss: 35129.71875	train_loss: 35211.326084053326	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_28
Epoch: 28	max: 0.9224575/1.0	min: 0.07754252	loss: 35101.69140625	train_loss: 35176.87715610678	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_29
Epoch: 29	max: 0.9300009/1.0	min: 0.0699991	loss: 35063.35546875	train_loss: 35130.22229093119	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_30
Epoch: 30	max: 0.93994987/1.0	min: 0.06005009	loss: 35015.46484375	train_loss: 35071.983459041716	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_31
Epoch: 31	max: 0.9520405/1.0	min: 0.04795952	loss: 34963.65234375	train_loss: 35008.13756261225	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_32
Epoch: 32	max: 0.9637875/1.0	min: 0.036212496	loss: 34915.01171875	train_loss: 34947.019698667624	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_33
Epoch: 33	max: 0.97308743/1.0	min: 0.026912538	loss: 34879.9296875	train_loss: 34898.25860410473	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_34
Epoch: 34	max: 0.9788179/1.0	min: 0.021182202	loss: 34859.609375	train_loss: 34867.688590150035	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_35
Epoch: 35	max: 0.98233193/1.0	min: 0.017668104	loss: 34847.9609375	train_loss: 34850.73103971185	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_36
Epoch: 36	max: 0.9843374/1.0	min: 0.015662655	loss: 34837.62109375	train_loss: 34839.44472750604	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_37
Epoch: 37	max: 0.98571044/1.0	min: 0.014289548	loss: 34828.390625	train_loss: 34830.673620304566	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_38
Epoch: 38	max: 0.9868645/1.0	min: 0.013135448	loss: 34821.38671875	train_loss: 34823.40747853571	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_39
Epoch: 39	max: 0.9877555/1.0	min: 0.012244603	loss: 34815.00390625	train_loss: 34817.24218846773	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_40
Epoch: 40	max: 0.98833185/1.0	min: 0.011668179	loss: 34808.0703125	train_loss: 34811.71702840487	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_41
Epoch: 41	max: 0.98900175/1.0	min: 0.010998207	loss: 34803.0	train_loss: 34806.76371324554	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_42
Epoch: 42	max: 0.98955554/1.0	min: 0.010444386	loss: 34798.28125	train_loss: 34802.13835470085	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_43
Epoch: 43	max: 0.989995/1.0	min: 0.010005009	loss: 34793.28125	train_loss: 34797.74978903444	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_44
Epoch: 44	max: 0.990422/1.0	min: 0.00957794	loss: 34788.84375	train_loss: 34793.56072179255	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_45
Epoch: 45	max: 0.99083686/1.0	min: 0.009163187	loss: 34784.71875	train_loss: 34789.42491029125	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_46
Epoch: 46	max: 0.9912697/1.0	min: 0.008730267	loss: 34781.2265625	train_loss: 34785.437969349994	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_47
Epoch: 47	max: 0.9917698/1.0	min: 0.008230266	loss: 34778.78125	train_loss: 34781.48697481187	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_48
Epoch: 48	max: 0.9919463/1.0	min: 0.00805369	loss: 34773.55078125	train_loss: 34777.50876426437	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_49
Epoch: 49	max: 0.9921631/1.0	min: 0.007836928	loss: 34768.953125	train_loss: 34773.59685738728	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_50
Epoch: 50	max: 0.9924596/1.0	min: 0.0075403685	loss: 34765.16796875	train_loss: 34769.68269375929	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_51
Epoch: 51	max: 0.99260837/1.0	min: 0.0073916214	loss: 34760.265625	train_loss: 34765.7230288268	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_52
Epoch: 52	max: 0.9928705/1.0	min: 0.007129464	loss: 34756.625	train_loss: 34761.8097540606	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_53
Epoch: 53	max: 0.99313605/1.0	min: 0.0068639037	loss: 34753.15625	train_loss: 34757.830815778674	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_54
Epoch: 54	max: 0.993382/1.0	min: 0.006618085	loss: 34749.81640625	train_loss: 34753.82316247058	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_55
Epoch: 55	max: 0.99347806/1.0	min: 0.006521934	loss: 34745.359375	train_loss: 34749.76744046513	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_56
Epoch: 56	max: 0.9936494/1.0	min: 0.006350634	loss: 34741.73828125	train_loss: 34745.670724850585	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_57
Epoch: 57	max: 0.9936666/1.0	min: 0.0063334187	loss: 34736.625	train_loss: 34741.49041074415	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_58
Epoch: 58	max: 0.99387276/1.0	min: 0.006127219	loss: 34733.390625	train_loss: 34737.27744100706	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_59
Epoch: 59	max: 0.993832/1.0	min: 0.006168013	loss: 34728.31640625	train_loss: 34733.05032786758	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_60
Epoch: 60	max: 0.9942154/1.0	min: 0.005784622	loss: 34726.6015625	train_loss: 34728.76073456661	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_61
Epoch: 61	max: 0.9941466/1.0	min: 0.0058534504	loss: 34721.3359375	train_loss: 34724.42827703069	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_62
Epoch: 62	max: 0.9941493/1.0	min: 0.005850665	loss: 34716.703125	train_loss: 34720.02204735306	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_63
Epoch: 63	max: 0.9943369/1.0	min: 0.005663049	loss: 34713.56640625	train_loss: 34715.78648446209	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_64
Epoch: 64	max: 0.9944352/1.0	min: 0.0055647534	loss: 34709.8515625	train_loss: 34711.643798676916	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_65
Epoch: 65	max: 0.9945253/1.0	min: 0.005474696	loss: 34705.62109375	train_loss: 34707.67430449105	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_66
Epoch: 66	max: 0.99491984/1.0	min: 0.0050801747	loss: 34702.828125	train_loss: 34703.760719566766	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_67
Epoch: 67	max: 0.9952421/1.0	min: 0.0047579403	loss: 34699.66015625	train_loss: 34699.956711898456	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_68
Epoch: 68	max: 0.9955651/1.0	min: 0.0044348096	loss: 34696.984375	train_loss: 34696.30681360709	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_69
Epoch: 69	max: 0.9956994/1.0	min: 0.0043006497	loss: 34692.75	train_loss: 34692.67025888765	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_70
Epoch: 70	max: 0.9960608/1.0	min: 0.003939239	loss: 34690.85546875	train_loss: 34689.358439203206	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_71
Epoch: 71	max: 0.9962722/1.0	min: 0.0037278172	loss: 34688.14453125	train_loss: 34686.32412971866	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_72
Epoch: 72	max: 0.9965814/1.0	min: 0.003418614	loss: 34687.16015625	train_loss: 34683.60891242413	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_73
Epoch: 73	max: 0.99664515/1.0	min: 0.0033548563	loss: 34683.38671875	train_loss: 34681.07907821597	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_74
Epoch: 74	max: 0.9968533/1.0	min: 0.0031467418	loss: 34681.78125	train_loss: 34678.68355310526	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_75
Epoch: 75	max: 0.99701035/1.0	min: 0.0029896137	loss: 34679.890625	train_loss: 34676.42573528273	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_76
Epoch: 76	max: 0.9970795/1.0	min: 0.0029204974	loss: 34677.18359375	train_loss: 34674.271940902545	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_77
Epoch: 77	max: 0.9972114/1.0	min: 0.0027886396	loss: 34675.49609375	train_loss: 34672.20472998343	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_78
Epoch: 78	max: 0.9973259/1.0	min: 0.0026741414	loss: 34673.92578125	train_loss: 34670.21886080531	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_79
Epoch: 79	max: 0.9974087/1.0	min: 0.002591312	loss: 34672.078125	train_loss: 34668.29624887743	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_80
Epoch: 80	max: 0.9975243/1.0	min: 0.002475664	loss: 34671.1640625	train_loss: 34666.40445195405	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_81
Epoch: 81	max: 0.99755955/1.0	min: 0.0024404665	loss: 34668.92578125	train_loss: 34664.59469402251	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_82
Epoch: 82	max: 0.99763215/1.0	min: 0.002367891	loss: 34667.44921875	train_loss: 34662.75492236854	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_83
Epoch: 83	max: 0.9975969/1.0	min: 0.0024030712	loss: 34664.48046875	train_loss: 34661.02869421993	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_84
Epoch: 84	max: 0.99758875/1.0	min: 0.0024112517	loss: 34662.328125	train_loss: 34659.252326427595	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_85
Epoch: 85	max: 0.9976145/1.0	min: 0.0023855167	loss: 34660.65234375	train_loss: 34657.507206699804	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_86
Epoch: 86	max: 0.9977023/1.0	min: 0.002297691	loss: 34659.83984375	train_loss: 34655.747834699774	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_87
Epoch: 87	max: 0.9977151/1.0	min: 0.0022848654	loss: 34658.1484375	train_loss: 34653.95419869859	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_88
Epoch: 88	max: 0.997741/1.0	min: 0.0022590454	loss: 34656.73046875	train_loss: 34652.21422730475	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_89
Epoch: 89	max: 0.99782526/1.0	min: 0.0021747074	loss: 34656.19921875	train_loss: 34650.524712970706	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_90
Epoch: 90	max: 0.9976884/1.0	min: 0.0023115438	loss: 34652.703125	train_loss: 34648.79088667472	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_91
Epoch: 91	max: 0.99769515/1.0	min: 0.0023048797	loss: 34651.2890625	train_loss: 34647.11150981667	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_92
Epoch: 92	max: 0.9976726/1.0	min: 0.002327406	loss: 34649.55859375	train_loss: 34645.413433474234	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_93
Epoch: 93	max: 0.9977545/1.0	min: 0.002245469	loss: 34648.94140625	train_loss: 34643.60175120773	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_94
Epoch: 94	max: 0.9976419/1.0	min: 0.00235813	loss: 34646.37890625	train_loss: 34641.867367014274	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_95
Epoch: 95	max: 0.9975349/1.0	min: 0.0024651191	loss: 34644.36328125	train_loss: 34640.155510652796	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_96
Epoch: 96	max: 0.9975157/1.0	min: 0.0024842739	loss: 34642.8125	train_loss: 34638.60529310665	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_97
Epoch: 97	max: 0.9978161/1.0	min: 0.0021839296	loss: 34644.7734375	train_loss: 34636.78774299749	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_98
Epoch: 98	max: 0.99765754/1.0	min: 0.0023424078	loss: 34641.6015625	train_loss: 34635.15825804379	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_99
Epoch: 99	max: 0.9976749/1.0	min: 0.0023251371	loss: 34640.890625	train_loss: 34633.43732532438	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_100
Epoch: 100	max: 0.9975188/1.0	min: 0.002481298	loss: 34638.14453125	train_loss: 34631.854525211354	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_101
Epoch: 101	max: 0.99744093/1.0	min: 0.0025590078	loss: 34636.37109375	train_loss: 34630.21946854097	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_102
Epoch: 102	max: 0.9973571/1.0	min: 0.002642854	loss: 34634.76171875	train_loss: 34628.634715544875	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_103
Epoch: 103	max: 0.9974068/1.0	min: 0.002593207	loss: 34634.09375	train_loss: 34627.03898362985	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_104
Epoch: 104	max: 0.997431/1.0	min: 0.0025690552	loss: 34633.62109375	train_loss: 34625.57504519308	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_105
Epoch: 105	max: 0.99728346/1.0	min: 0.002716487	loss: 34631.4296875	train_loss: 34624.17349837034	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_106
Epoch: 106	max: 0.99722856/1.0	min: 0.0027714665	loss: 34630.1484375	train_loss: 34622.73615465905	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_107
Epoch: 107	max: 0.99705195/1.0	min: 0.002948078	loss: 34628.22265625	train_loss: 34621.36644428186	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_108
Epoch: 108	max: 0.99714655/1.0	min: 0.0028534322	loss: 34628.12109375	train_loss: 34620.01149520392	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_109
Epoch: 109	max: 0.9968213/1.0	min: 0.003178689	loss: 34625.296875	train_loss: 34618.729526179086	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_110
Epoch: 110	max: 0.9966453/1.0	min: 0.0033546549	loss: 34623.578125	train_loss: 34617.49341700344	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_111
Epoch: 111	max: 0.9969633/1.0	min: 0.0030366322	loss: 34623.52734375	train_loss: 34616.36094562895	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_112
Epoch: 112	max: 0.99696726/1.0	min: 0.0030327763	loss: 34622.38671875	train_loss: 34615.15022344931	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_113
Epoch: 113	max: 0.9969183/1.0	min: 0.0030816447	loss: 34620.9296875	train_loss: 34614.04492018147	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_114
Epoch: 114	max: 0.99711096/1.0	min: 0.0028890136	loss: 34620.63671875	train_loss: 34612.97692878654	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_115
Epoch: 115	max: 0.9970848/1.0	min: 0.002915162	loss: 34619.3359375	train_loss: 34611.92728704091	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_116
Epoch: 116	max: 0.9970342/1.0	min: 0.0029658559	loss: 34617.84375	train_loss: 34610.94094754506	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_117
Epoch: 117	max: 0.997171/1.0	min: 0.0028290206	loss: 34617.515625	train_loss: 34610.00831475288	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_118
Epoch: 118	max: 0.9971547/1.0	min: 0.0028453318	loss: 34616.2890625	train_loss: 34609.01867625883	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_119
Epoch: 119	max: 0.99706584/1.0	min: 0.0029341984	loss: 34614.80859375	train_loss: 34608.09675432383	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_120
Epoch: 120	max: 0.9972759/1.0	min: 0.0027241155	loss: 34614.859375	train_loss: 34607.20200968893	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_121
Epoch: 121	max: 0.9971591/1.0	min: 0.002840899	loss: 34613.25390625	train_loss: 34606.31978121516	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_122
Epoch: 122	max: 0.99724185/1.0	min: 0.0027581335	loss: 34612.69921875	train_loss: 34605.513117606526	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_123
Epoch: 123	max: 0.99729675/1.0	min: 0.0027032255	loss: 34612.11328125	train_loss: 34604.782392407564	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_124
Epoch: 124	max: 0.9973048/1.0	min: 0.0026951479	loss: 34611.17578125	train_loss: 34603.86411785427	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_125
Epoch: 125	max: 0.99737585/1.0	min: 0.002624215	loss: 34610.75	train_loss: 34603.054225891865	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_126
Epoch: 126	max: 0.9972063/1.0	min: 0.0027937205	loss: 34608.8984375	train_loss: 34602.34241065899	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_127
Epoch: 127	max: 0.9970571/1.0	min: 0.0029429246	loss: 34607.3984375	train_loss: 34601.53074581166	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_128
Epoch: 128	max: 0.99730575/1.0	min: 0.002694188	loss: 34607.453125	train_loss: 34600.809219388706	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_129
Epoch: 129	max: 0.9975242/1.0	min: 0.0024757485	loss: 34607.921875	train_loss: 34600.15259729577	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_130
Epoch: 130	max: 0.99730396/1.0	min: 0.0026960724	loss: 34605.78515625	train_loss: 34599.394392864335	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_131
Epoch: 131	max: 0.9974771/1.0	min: 0.0025228926	loss: 34605.609375	train_loss: 34598.6808961972	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_132
Epoch: 132	max: 0.99757713/1.0	min: 0.0024228676	loss: 34605.55859375	train_loss: 34597.99645810108	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_133
Epoch: 133	max: 0.9974974/1.0	min: 0.0025025536	loss: 34604.05078125	train_loss: 34597.36199561811	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_134
Epoch: 134	max: 0.9974648/1.0	min: 0.0025352414	loss: 34603.04296875	train_loss: 34596.682950208255	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_135
Epoch: 135	max: 0.9973418/1.0	min: 0.00265814	loss: 34601.74609375	train_loss: 34596.10927145268	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_136
Epoch: 136	max: 0.99743193/1.0	min: 0.0025680363	loss: 34601.30078125	train_loss: 34595.387312453546	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_137
Epoch: 137	max: 0.99735117/1.0	min: 0.0026488448	loss: 34600.19921875	train_loss: 34594.745983428555	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_138
Epoch: 138	max: 0.9975139/1.0	min: 0.0024860778	loss: 34600.1953125	train_loss: 34594.13592762913	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_139
Epoch: 139	max: 0.9975182/1.0	min: 0.0024817924	loss: 34599.48046875	train_loss: 34593.53514318562	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_140
Epoch: 140	max: 0.9976695/1.0	min: 0.0023304294	loss: 34599.50390625	train_loss: 34592.92835832017	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_141
Epoch: 141	max: 0.99755704/1.0	min: 0.0024429522	loss: 34598.1015625	train_loss: 34592.380001722566	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_142
Epoch: 142	max: 0.9974515/1.0	min: 0.0025485235	loss: 34596.984375	train_loss: 34591.768504486405	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_143
Epoch: 143	max: 0.997624/1.0	min: 0.0023760784	loss: 34597.0546875	train_loss: 34591.301308180045	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_144
Epoch: 144	max: 0.99758923/1.0	min: 0.002410763	loss: 34596.39453125	train_loss: 34590.6376714821	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_145
Epoch: 145	max: 0.99773395/1.0	min: 0.0022660843	loss: 34596.328125	train_loss: 34590.15101505404	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_146
Epoch: 146	max: 0.99774855/1.0	min: 0.0022513778	loss: 34595.80078125	train_loss: 34589.56275693283	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_147
Epoch: 147	max: 0.9977319/1.0	min: 0.002268004	loss: 34594.9921875	train_loss: 34589.041341024866	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_148
Epoch: 148	max: 0.9979583/1.0	min: 0.0020416665	loss: 34595.89453125	train_loss: 34588.61622218738	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_149
Epoch: 149	max: 0.99792635/1.0	min: 0.0020735709	loss: 34594.88671875	train_loss: 34588.22592137758	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_150
Epoch: 150	max: 0.9976708/1.0	min: 0.0023291048	loss: 34592.87890625	train_loss: 34587.55041738279	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_151
Epoch: 151	max: 0.9974854/1.0	min: 0.0025145435	loss: 34591.546875	train_loss: 34587.04279794531	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_152
Epoch: 152	max: 0.99762744/1.0	min: 0.0023725722	loss: 34591.453125	train_loss: 34586.60694405735	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_153
Epoch: 153	max: 0.9977325/1.0	min: 0.002267394	loss: 34591.421875	train_loss: 34586.05942164468	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_154
Epoch: 154	max: 0.9977465/1.0	min: 0.0022534486	loss: 34590.83984375	train_loss: 34585.62400226836	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_155
Epoch: 155	max: 0.99755716/1.0	min: 0.0024427718	loss: 34589.60546875	train_loss: 34585.151691014806	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_156
Epoch: 156	max: 0.99760497/1.0	min: 0.0023950008	loss: 34589.18359375	train_loss: 34584.76070601852	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_157
Epoch: 157	max: 0.99748385/1.0	min: 0.002516123	loss: 34588.390625	train_loss: 34584.28950426963	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_158
Epoch: 158	max: 0.9976179/1.0	min: 0.0023820887	loss: 34588.25390625	train_loss: 34583.924901097795	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_159
Epoch: 159	max: 0.99789584/1.0	min: 0.0021041315	loss: 34588.8515625	train_loss: 34583.45900251997	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_160
Epoch: 160	max: 0.9979405/1.0	min: 0.0020595423	loss: 34588.4765625	train_loss: 34582.993841837764	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_161
Epoch: 161	max: 0.9980392/1.0	min: 0.0019608298	loss: 34588.51171875	train_loss: 34582.630113011735	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_162
Epoch: 162	max: 0.99779725/1.0	min: 0.0022027725	loss: 34586.8046875	train_loss: 34582.20114356884	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_163
Epoch: 163	max: 0.997736/1.0	min: 0.0022639816	loss: 34585.99609375	train_loss: 34581.785998660656	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_164
Epoch: 164	max: 0.99774146/1.0	min: 0.0022585036	loss: 34585.53125	train_loss: 34581.43854031184	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_165
Epoch: 165	max: 0.99785197/1.0	min: 0.0021480045	loss: 34585.4609375	train_loss: 34581.03610172411	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_166
Epoch: 166	max: 0.99773043/1.0	min: 0.002269559	loss: 34584.5703125	train_loss: 34580.64027274557	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_167
Epoch: 167	max: 0.99800295/1.0	min: 0.0019970816	loss: 34585.19921875	train_loss: 34580.292382788306	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_168
Epoch: 168	max: 0.9980641/1.0	min: 0.0019359224	loss: 34584.98828125	train_loss: 34579.888945985076	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_169
Epoch: 169	max: 0.9980775/1.0	min: 0.0019224351	loss: 34584.65625	train_loss: 34579.51934254227	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_170
Epoch: 170	max: 0.9980585/1.0	min: 0.0019415194	loss: 34583.953125	train_loss: 34579.19925600768	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_171
Epoch: 171	max: 0.9979724/1.0	min: 0.0020276064	loss: 34583.109375	train_loss: 34578.88824244395	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_172
Epoch: 172	max: 0.9979692/1.0	min: 0.002030819	loss: 34582.69921875	train_loss: 34578.508018626904	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_173
Epoch: 173	max: 0.9980685/1.0	min: 0.001931517	loss: 34582.67578125	train_loss: 34578.14038161541	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_174
Epoch: 174	max: 0.9981269/1.0	min: 0.001873128	loss: 34582.6484375	train_loss: 34577.81265193391	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_175
Epoch: 175	max: 0.99818146/1.0	min: 0.0018186106	loss: 34582.5	train_loss: 34577.446180555555	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_176
Epoch: 176	max: 0.99779415/1.0	min: 0.002205898	loss: 34580.53125	train_loss: 34577.11333979778	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_177
Epoch: 177	max: 0.9980069/1.0	min: 0.001993088	loss: 34580.62890625	train_loss: 34576.847207222374	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_178
Epoch: 178	max: 0.9980027/1.0	min: 0.0019972885	loss: 34580.25390625	train_loss: 34576.4647527832	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_179
Epoch: 179	max: 0.99821496/1.0	min: 0.0017850676	loss: 34580.83984375	train_loss: 34576.17013211476	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_180
Epoch: 180	max: 0.99798113/1.0	min: 0.0020188533	loss: 34579.44140625	train_loss: 34575.877763842436	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_181
Epoch: 181	max: 0.9980367/1.0	min: 0.001963339	loss: 34579.171875	train_loss: 34575.55815730289	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_182
Epoch: 182	max: 0.99789524/1.0	min: 0.0021047327	loss: 34578.359375	train_loss: 34575.32461648783	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_183
Epoch: 183	max: 0.9980227/1.0	min: 0.0019773676	loss: 34578.38671875	train_loss: 34575.016102091846	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_184
Epoch: 184	max: 0.9979861/1.0	min: 0.0020139029	loss: 34577.82421875	train_loss: 34574.6736638525	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_185
Epoch: 185	max: 0.9979832/1.0	min: 0.0020167266	loss: 34577.58203125	train_loss: 34574.45843929998	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_186
Epoch: 186	max: 0.9982418/1.0	min: 0.0017581993	loss: 34578.234375	train_loss: 34574.110483053075	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_187
Epoch: 187	max: 0.9980837/1.0	min: 0.0019163532	loss: 34577.24609375	train_loss: 34573.799389167594	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_188
Epoch: 188	max: 0.99814165/1.0	min: 0.001858295	loss: 34576.9609375	train_loss: 34573.51594144835	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_189
Epoch: 189	max: 0.9983505/1.0	min: 0.0016495468	loss: 34577.66015625	train_loss: 34573.25017080469	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_190
Epoch: 190	max: 0.9982843/1.0	min: 0.0017156432	loss: 34576.75	train_loss: 34572.99873614208	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_191
Epoch: 191	max: 0.9982327/1.0	min: 0.0017672998	loss: 34576.37890625	train_loss: 34572.740942996716	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_192
Epoch: 192	max: 0.99836224/1.0	min: 0.0016377042	loss: 34576.6015625	train_loss: 34572.47109820157	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_193
Epoch: 193	max: 0.9982318/1.0	min: 0.0017682388	loss: 34575.609375	train_loss: 34572.24261620525	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_194
Epoch: 194	max: 0.9981919/1.0	min: 0.0018081014	loss: 34574.99609375	train_loss: 34571.9303871702	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_195
Epoch: 195	max: 0.99824786/1.0	min: 0.0017522166	loss: 34575.109375	train_loss: 34571.696763614054	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_196
Epoch: 196	max: 0.9981781/1.0	min: 0.0018218523	loss: 34574.41015625	train_loss: 34571.41788117026	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_197
Epoch: 197	max: 0.99843746/1.0	min: 0.0015625906	loss: 34575.296875	train_loss: 34571.16627812229	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_198
Epoch: 198	max: 0.99832934/1.0	min: 0.0016706102	loss: 34574.32421875	train_loss: 34570.92565883191	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_199
Epoch: 199	max: 0.99818784/1.0	min: 0.00181209	loss: 34573.55078125	train_loss: 34570.6981010196	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_200
Epoch: 200	max: 0.99842936/1.0	min: 0.0015705947	loss: 34574.31640625	train_loss: 34570.51533758361	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_201
Epoch: 201	max: 0.9982666/1.0	min: 0.0017333827	loss: 34573.13671875	train_loss: 34570.2237739804	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_202
Epoch: 202	max: 0.9984137/1.0	min: 0.0015863504	loss: 34573.43359375	train_loss: 34569.98611353044	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_203
Epoch: 203	max: 0.9983944/1.0	min: 0.0016055133	loss: 34573.08984375	train_loss: 34569.76677563328	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_204
Epoch: 204	max: 0.99849164/1.0	min: 0.0015083165	loss: 34573.2578125	train_loss: 34569.52973308018	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_205
Epoch: 205	max: 0.99852127/1.0	min: 0.0014787883	loss: 34573.03515625	train_loss: 34569.462901511986	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_206
Epoch: 206	max: 0.9983846/1.0	min: 0.0016153859	loss: 34572.1015625	train_loss: 34569.12640756612	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_207
Epoch: 207	max: 0.9985115/1.0	min: 0.0014885304	loss: 34572.4921875	train_loss: 34568.86424124009	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_208
Epoch: 208	max: 0.99846125/1.0	min: 0.00153878	loss: 34571.7890625	train_loss: 34568.636034079645	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_209
Epoch: 209	max: 0.9983772/1.0	min: 0.0016228211	loss: 34571.2890625	train_loss: 34568.442243822	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_210
Epoch: 210	max: 0.99833065/1.0	min: 0.0016693597	loss: 34570.90625	train_loss: 34568.25527268751	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_211
Epoch: 211	max: 0.99856347/1.0	min: 0.0014366016	loss: 34571.51953125	train_loss: 34568.011106175676	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_212
Epoch: 212	max: 0.99844766/1.0	min: 0.0015523089	loss: 34570.66015625	train_loss: 34567.82778822928	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_213
Epoch: 213	max: 0.99848855/1.0	min: 0.0015114392	loss: 34570.671875	train_loss: 34567.60997547767	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_214
Epoch: 214	max: 0.9985831/1.0	min: 0.0014168951	loss: 34570.734375	train_loss: 34567.40091344219	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_215
Epoch: 215	max: 0.9985032/1.0	min: 0.0014968243	loss: 34570.35546875	train_loss: 34567.196488294314	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_216
Epoch: 216	max: 0.9982974/1.0	min: 0.0017026064	loss: 34569.26171875	train_loss: 34566.9943503809	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_217
Epoch: 217	max: 0.9984357/1.0	min: 0.0015643591	loss: 34569.3984375	train_loss: 34566.878827863715	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_218
Epoch: 218	max: 0.998623/1.0	min: 0.0013769402	loss: 34570.01953125	train_loss: 34566.64133579911	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_219
Epoch: 219	max: 0.9986022/1.0	min: 0.001397834	loss: 34569.57421875	train_loss: 34566.464559720676	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_220
Epoch: 220	max: 0.9986511/1.0	min: 0.0013489929	loss: 34569.609375	train_loss: 34566.26758659266	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_221
Epoch: 221	max: 0.9985056/1.0	min: 0.0014944666	loss: 34568.60546875	train_loss: 34566.13493376842	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_222
Epoch: 222	max: 0.9985556/1.0	min: 0.0014444174	loss: 34568.66015625	train_loss: 34565.894187221296	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_223
Epoch: 223	max: 0.9985891/1.0	min: 0.0014109013	loss: 34568.609375	train_loss: 34565.691496732936	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_224
Epoch: 224	max: 0.99857795/1.0	min: 0.0014220217	loss: 34568.2265625	train_loss: 34565.50137417937	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_225
Epoch: 225	max: 0.9986589/1.0	min: 0.0013411044	loss: 34568.37890625	train_loss: 34565.33327091462	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_226
Epoch: 226	max: 0.9984926/1.0	min: 0.0015074018	loss: 34567.44921875	train_loss: 34565.20039696364	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_227
Epoch: 227	max: 0.99859697/1.0	min: 0.0014029805	loss: 34567.68359375	train_loss: 34564.96232038895	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_228
Epoch: 228	max: 0.99861014/1.0	min: 0.0013897925	loss: 34567.48046875	train_loss: 34564.79991416218	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_229
Epoch: 229	max: 0.998574/1.0	min: 0.0014259244	loss: 34567.09375	train_loss: 34564.62054456212	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_230
Epoch: 230	max: 0.9985329/1.0	min: 0.001467124	loss: 34566.75	train_loss: 34564.45568755419	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_231
Epoch: 231	max: 0.9987531/1.0	min: 0.0012469747	loss: 34567.515625	train_loss: 34564.309803898796	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_232
Epoch: 232	max: 0.9986889/1.0	min: 0.0013111377	loss: 34567.125	train_loss: 34564.11843393875	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_233
Epoch: 233	max: 0.9988219/1.0	min: 0.0011780838	loss: 34567.390625	train_loss: 34564.00493252973	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_234
Epoch: 234	max: 0.9986916/1.0	min: 0.0013084051	loss: 34566.53125	train_loss: 34563.81523771367	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_235
Epoch: 235	max: 0.998701/1.0	min: 0.0012989708	loss: 34566.265625	train_loss: 34563.62218535163	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_236
Epoch: 236	max: 0.99859935/1.0	min: 0.001400649	loss: 34565.6640625	train_loss: 34563.476089762946	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_237
Epoch: 237	max: 0.99872977/1.0	min: 0.0012702146	loss: 34566.23046875	train_loss: 34563.32053943314	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_238
Epoch: 238	max: 0.9987381/1.0	min: 0.001261911	loss: 34565.82421875	train_loss: 34563.18700597284	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_239
Epoch: 239	max: 0.99859864/1.0	min: 0.0014013575	loss: 34565.109375	train_loss: 34563.00741185898	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_240
Epoch: 240	max: 0.99863607/1.0	min: 0.0013639474	loss: 34564.9453125	train_loss: 34562.86303060743	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_241
Epoch: 241	max: 0.9987128/1.0	min: 0.0012872829	loss: 34565.12890625	train_loss: 34562.720722237704	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_242
Epoch: 242	max: 0.99897695/1.0	min: 0.0010230648	loss: 34566.46484375	train_loss: 34562.599688487084	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_243
Epoch: 243	max: 0.9987018/1.0	min: 0.0012982262	loss: 34564.671875	train_loss: 34562.45329822402	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_244
Epoch: 244	max: 0.9987752/1.0	min: 0.0012247715	loss: 34564.6484375	train_loss: 34562.27963775858	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_245
Epoch: 245	max: 0.9986922/1.0	min: 0.001307802	loss: 34564.23046875	train_loss: 34562.09371129072	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_246
Epoch: 246	max: 0.9988411/1.0	min: 0.0011589361	loss: 34564.67578125	train_loss: 34561.964321174746	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_247
Epoch: 247	max: 0.9987539/1.0	min: 0.0012460544	loss: 34564.125	train_loss: 34561.821683776165	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_248
Epoch: 248	max: 0.9989145/1.0	min: 0.001085538	loss: 34564.94921875	train_loss: 34561.73649626842	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_249
Epoch: 249	max: 0.9987406/1.0	min: 0.001259378	loss: 34563.6640625	train_loss: 34561.586267012724	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_250
Epoch: 250	max: 0.99892527/1.0	min: 0.0010747188	loss: 34564.56640625	train_loss: 34561.38455828843	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_251
Epoch: 251	max: 0.9988556/1.0	min: 0.0011444461	loss: 34563.859375	train_loss: 34561.301783820294	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_252
Epoch: 252	max: 0.9988362/1.0	min: 0.0011638136	loss: 34563.60546875	train_loss: 34561.111003692866	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_253
Epoch: 253	max: 0.9989656/1.0	min: 0.0010344131	loss: 34564.26953125	train_loss: 34560.96438746439	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_254
Epoch: 254	max: 0.99885714/1.0	min: 0.0011429199	loss: 34563.2734375	train_loss: 34560.86184949059	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_255
Epoch: 255	max: 0.99868864/1.0	min: 0.0013113911	loss: 34562.5546875	train_loss: 34560.730249558714	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_256
Epoch: 256	max: 0.9988171/1.0	min: 0.0011829608	loss: 34562.6953125	train_loss: 34560.63690116747	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_257
Epoch: 257	max: 0.9987729/1.0	min: 0.0012270636	loss: 34562.44140625	train_loss: 34560.42357675663	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_258
Epoch: 258	max: 0.99890935/1.0	min: 0.0010906064	loss: 34562.74609375	train_loss: 34560.30328574028	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_259
Epoch: 259	max: 0.99879754/1.0	min: 0.0012024041	loss: 34562.1953125	train_loss: 34560.1633429913	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_260
Epoch: 260	max: 0.9988649/1.0	min: 0.0011350919	loss: 34562.3359375	train_loss: 34560.05046044686	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_261
Epoch: 261	max: 0.99892503/1.0	min: 0.0010749518	loss: 34562.49609375	train_loss: 34559.917208596555	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_262
Epoch: 262	max: 0.9989467/1.0	min: 0.0010533466	loss: 34562.25390625	train_loss: 34559.797022095256	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_263
Epoch: 263	max: 0.9988784/1.0	min: 0.001121552	loss: 34561.828125	train_loss: 34559.66078963056	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_264
Epoch: 264	max: 0.9988674/1.0	min: 0.0011326629	loss: 34561.59765625	train_loss: 34559.52842035179	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_265
Epoch: 265	max: 0.9989458/1.0	min: 0.0010541962	loss: 34561.98828125	train_loss: 34559.4659842221	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_266
Epoch: 266	max: 0.99881953/1.0	min: 0.0011804247	loss: 34560.94921875	train_loss: 34559.301320276696	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_267
Epoch: 267	max: 0.99880433/1.0	min: 0.0011956521	loss: 34560.95703125	train_loss: 34559.20060018735	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_268
Epoch: 268	max: 0.99889874/1.0	min: 0.0011012245	loss: 34561.03515625	train_loss: 34559.08501234826	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_269
Epoch: 269	max: 0.9988593/1.0	min: 0.0011406824	loss: 34560.71875	train_loss: 34558.91086995231	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_270
Epoch: 270	max: 0.99884546/1.0	min: 0.0011545379	loss: 34560.73828125	train_loss: 34558.785943016075	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_271
Epoch: 271	max: 0.99900717/1.0	min: 0.0009928159	loss: 34561.15625	train_loss: 34558.66851164762	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_272
Epoch: 272	max: 0.99895406/1.0	min: 0.0010458875	loss: 34560.69921875	train_loss: 34558.559725028645	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_273
Epoch: 273	max: 0.99878937/1.0	min: 0.0012106068	loss: 34559.94921875	train_loss: 34558.46898999752	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_274
Epoch: 274	max: 0.9989525/1.0	min: 0.0010474195	loss: 34560.359375	train_loss: 34558.37917382788	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_275
Epoch: 275	max: 0.998776/1.0	min: 0.0012239936	loss: 34559.73828125	train_loss: 34558.22682765855	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_276
Epoch: 276	max: 0.998955/1.0	min: 0.00104501	loss: 34560.1640625	train_loss: 34558.17885234733	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_277
Epoch: 277	max: 0.99903405/1.0	min: 0.00096600986	loss: 34560.359375	train_loss: 34558.01333002369	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_278
Epoch: 278	max: 0.9987882/1.0	min: 0.0012118812	loss: 34559.28125	train_loss: 34557.902588586185	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_279
Epoch: 279	max: 0.9987913/1.0	min: 0.0012087442	loss: 34559.15625	train_loss: 34557.83800699477	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_280
Epoch: 280	max: 0.9990589/1.0	min: 0.0009410469	loss: 34560.1640625	train_loss: 34557.71198894076	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_281
Epoch: 281	max: 0.9989525/1.0	min: 0.0010474968	loss: 34559.4765625	train_loss: 34557.51452759197	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_282
Epoch: 282	max: 0.9990809/1.0	min: 0.0009190636	loss: 34559.98046875	train_loss: 34557.40393470132	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_283
Epoch: 283	max: 0.99899036/1.0	min: 0.0010096245	loss: 34559.19921875	train_loss: 34557.33338655859	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_284
Epoch: 284	max: 0.998874/1.0	min: 0.0011260214	loss: 34558.78515625	train_loss: 34557.19590039716	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_285
Epoch: 285	max: 0.9989145/1.0	min: 0.0010855384	loss: 34558.58984375	train_loss: 34557.08853440868	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_286
Epoch: 286	max: 0.99899656/1.0	min: 0.0010034206	loss: 34558.97265625	train_loss: 34556.961174594326	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_287
Epoch: 287	max: 0.9988607/1.0	min: 0.0011392555	loss: 34558.21484375	train_loss: 34556.886439559334	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_288
Epoch: 288	max: 0.9991652/1.0	min: 0.0008348376	loss: 34559.6015625	train_loss: 34556.76851464759	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_289
Epoch: 289	max: 0.99916995/1.0	min: 0.0008300822	loss: 34559.453125	train_loss: 34556.79850224127	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_290
Epoch: 290	max: 0.99904615/1.0	min: 0.0009538953	loss: 34558.70703125	train_loss: 34556.610198539885	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_291
Epoch: 291	max: 0.99893314/1.0	min: 0.0010668433	loss: 34557.83984375	train_loss: 34556.47092836461	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_292
Epoch: 292	max: 0.9990902/1.0	min: 0.00090984977	loss: 34558.3359375	train_loss: 34556.374551940105	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_293
Epoch: 293	max: 0.9990313/1.0	min: 0.0009686992	loss: 34557.9765625	train_loss: 34556.26941657376	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_294
Epoch: 294	max: 0.99897027/1.0	min: 0.0010296872	loss: 34557.609375	train_loss: 34556.14769621733	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_295
Epoch: 295	max: 0.99905103/1.0	min: 0.0009489739	loss: 34557.92578125	train_loss: 34556.012473580915	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_296
Epoch: 296	max: 0.99905974/1.0	min: 0.0009402914	loss: 34558.02734375	train_loss: 34555.9079478857	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_297
Epoch: 297	max: 0.9990362/1.0	min: 0.0009638568	loss: 34557.546875	train_loss: 34555.813416926016	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_298
Epoch: 298	max: 0.99907136/1.0	min: 0.0009285829	loss: 34557.66796875	train_loss: 34555.69488863341	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_299
Epoch: 299	max: 0.9991033/1.0	min: 0.0008967188	loss: 34557.68359375	train_loss: 34555.58431025873	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_300
Epoch: 300	max: 0.9990632/1.0	min: 0.00093681464	loss: 34557.28515625	train_loss: 34555.48868624582	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_301
Epoch: 301	max: 0.99910283/1.0	min: 0.0008972146	loss: 34557.375	train_loss: 34555.40949238589	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_302
Epoch: 302	max: 0.9989588/1.0	min: 0.001041198	loss: 34556.69921875	train_loss: 34555.29723354468	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_303
Epoch: 303	max: 0.99911016/1.0	min: 0.00088986254	loss: 34557.1796875	train_loss: 34555.19696296683	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_304
Epoch: 304	max: 0.9990901/1.0	min: 0.00090992777	loss: 34557.0703125	train_loss: 34555.09151066828	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_305
Epoch: 305	max: 0.99911267/1.0	min: 0.0008873364	loss: 34556.92578125	train_loss: 34555.03484076939	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_306
Epoch: 306	max: 0.998914/1.0	min: 0.0010859587	loss: 34555.9765625	train_loss: 34554.93590808095	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_307
Epoch: 307	max: 0.9990392/1.0	min: 0.00096081547	loss: 34556.46484375	train_loss: 34554.91890357906	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_308
Epoch: 308	max: 0.9990446/1.0	min: 0.00095532945	loss: 34556.24609375	train_loss: 34554.695083147526	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_309
Epoch: 309	max: 0.99902093/1.0	min: 0.0009790307	loss: 34556.05078125	train_loss: 34554.61708879134	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_310
Epoch: 310	max: 0.99913317/1.0	min: 0.00086690404	loss: 34556.43359375	train_loss: 34554.50751153537	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_311
Epoch: 311	max: 0.99903643/1.0	min: 0.0009636029	loss: 34555.83984375	train_loss: 34554.394437380004	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_312
Epoch: 312	max: 0.99902403/1.0	min: 0.0009759984	loss: 34555.53125	train_loss: 34554.29626581274	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_313
Epoch: 313	max: 0.99913883/1.0	min: 0.00086108263	loss: 34556.18359375	train_loss: 34554.21910322216	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_314
Epoch: 314	max: 0.99920064/1.0	min: 0.00079934706	loss: 34556.140625	train_loss: 34554.16333428171	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_315
Epoch: 315	max: 0.99896693/1.0	min: 0.0010330476	loss: 34555.12890625	train_loss: 34554.06683398752	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_316
Epoch: 316	max: 0.99915683/1.0	min: 0.00084316276	loss: 34555.84375	train_loss: 34553.94978100226	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_317
Epoch: 317	max: 0.9991903/1.0	min: 0.0008097455	loss: 34555.7734375	train_loss: 34553.8282217732	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_318
Epoch: 318	max: 0.99910456/1.0	min: 0.00089536305	loss: 34555.390625	train_loss: 34553.71350102193	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_319
Epoch: 319	max: 0.99924254/1.0	min: 0.00075750914	loss: 34555.7734375	train_loss: 34553.633997971636	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_320
Epoch: 320	max: 0.99899834/1.0	min: 0.0010017043	loss: 34554.80078125	train_loss: 34553.56776059086	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_321
Epoch: 321	max: 0.99911076/1.0	min: 0.00088918355	loss: 34554.94921875	train_loss: 34553.47225706057	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_322
Epoch: 322	max: 0.99910706/1.0	min: 0.00089291023	loss: 34554.80859375	train_loss: 34553.35240539452	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_323
Epoch: 323	max: 0.99917334/1.0	min: 0.00082657335	loss: 34554.796875	train_loss: 34553.25003774155	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_324
Epoch: 324	max: 0.99911934/1.0	min: 0.00088060746	loss: 34554.63671875	train_loss: 34553.203169999535	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_325
Epoch: 325	max: 0.99907255/1.0	min: 0.0009274654	loss: 34554.328125	train_loss: 34553.079654016474	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_326
Epoch: 326	max: 0.99914885/1.0	min: 0.0008511494	loss: 34554.49609375	train_loss: 34552.99314265143	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_327
Epoch: 327	max: 0.99919754/1.0	min: 0.00080247235	loss: 34554.65625	train_loss: 34552.90488985275	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_328
Epoch: 328	max: 0.99925476/1.0	min: 0.00074526155	loss: 34554.6796875	train_loss: 34552.78833524944	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_329
Epoch: 329	max: 0.9992613/1.0	min: 0.00073867553	loss: 34554.66015625	train_loss: 34552.732228570545	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_330
Epoch: 330	max: 0.99928457/1.0	min: 0.00071549794	loss: 34554.84375	train_loss: 34552.67432723275	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_331
Epoch: 331	max: 0.999215/1.0	min: 0.00078491645	loss: 34554.1015625	train_loss: 34552.53263627601	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_332
Epoch: 332	max: 0.99926084/1.0	min: 0.0007391667	loss: 34554.171875	train_loss: 34552.433848747365	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_333
Epoch: 333	max: 0.9991493/1.0	min: 0.00085068156	loss: 34553.87109375	train_loss: 34552.341178252354	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_334
Epoch: 334	max: 0.9992981/1.0	min: 0.0007018877	loss: 34554.30859375	train_loss: 34552.2700673735	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_335
Epoch: 335	max: 0.9992205/1.0	min: 0.0007795146	loss: 34553.74609375	train_loss: 34552.25709637836	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_336
Epoch: 336	max: 0.99921536/1.0	min: 0.00078461214	loss: 34553.421875	train_loss: 34552.14699993419	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_337
Epoch: 337	max: 0.99925035/1.0	min: 0.0007496804	loss: 34553.6484375	train_loss: 34551.99368845225	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_338
Epoch: 338	max: 0.9992071/1.0	min: 0.0007929633	loss: 34553.2734375	train_loss: 34551.97312947092	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_339
Epoch: 339	max: 0.9993088/1.0	min: 0.00069119723	loss: 34553.8125	train_loss: 34551.84150341029	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_340
Epoch: 340	max: 0.9993123/1.0	min: 0.0006877588	loss: 34553.43359375	train_loss: 34551.73019972052	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_341
Epoch: 341	max: 0.9992161/1.0	min: 0.0007839448	loss: 34553.13671875	train_loss: 34551.6373729368	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_342
Epoch: 342	max: 0.9991978/1.0	min: 0.00080228737	loss: 34552.86328125	train_loss: 34551.589083596555	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_343
Epoch: 343	max: 0.999323/1.0	min: 0.00067700096	loss: 34553.296875	train_loss: 34551.48654852595	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_344
Epoch: 344	max: 0.9993197/1.0	min: 0.0006803795	loss: 34553.2109375	train_loss: 34551.40010441828	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_345
Epoch: 345	max: 0.99920976/1.0	min: 0.0007902044	loss: 34552.55859375	train_loss: 34551.3088071349	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_346
Epoch: 346	max: 0.99922705/1.0	min: 0.0007729001	loss: 34552.59765625	train_loss: 34551.24212266196	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_347
Epoch: 347	max: 0.99933416/1.0	min: 0.00066583493	loss: 34552.82421875	train_loss: 34551.13959291388	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_348
Epoch: 348	max: 0.9994179/1.0	min: 0.00058214745	loss: 34553.13671875	train_loss: 34551.07645324306	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_349
Epoch: 349	max: 0.99920195/1.0	min: 0.0007980753	loss: 34552.078125	train_loss: 34550.984554514274	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_350
Epoch: 350	max: 0.9993017/1.0	min: 0.0006983222	loss: 34552.3984375	train_loss: 34550.89243320714	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_351
Epoch: 351	max: 0.99936193/1.0	min: 0.00063811225	loss: 34552.39453125	train_loss: 34550.76394888827	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_352
Epoch: 352	max: 0.9994/1.0	min: 0.0005999277	loss: 34552.87109375	train_loss: 34550.67863993017	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_353
Epoch: 353	max: 0.99940836/1.0	min: 0.0005916711	loss: 34552.52734375	train_loss: 34550.63330555943	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_354
Epoch: 354	max: 0.99934536/1.0	min: 0.0006545855	loss: 34552.02734375	train_loss: 34550.49271878484	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_355
Epoch: 355	max: 0.99934405/1.0	min: 0.00065595884	loss: 34552.01171875	train_loss: 34550.43522728152	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_356
Epoch: 356	max: 0.99943846/1.0	min: 0.00056151353	loss: 34552.3203125	train_loss: 34550.39415335067	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_357
Epoch: 357	max: 0.99940753/1.0	min: 0.00059247046	loss: 34552.0390625	train_loss: 34550.265834513964	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_358
Epoch: 358	max: 0.99928445/1.0	min: 0.00071553024	loss: 34551.46484375	train_loss: 34550.14327029527	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_359
Epoch: 359	max: 0.99935764/1.0	min: 0.0006424072	loss: 34551.53125	train_loss: 34550.08338413926	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_360
Epoch: 360	max: 0.999376/1.0	min: 0.00062405295	loss: 34551.74609375	train_loss: 34549.97836828781	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_361
Epoch: 361	max: 0.9994306/1.0	min: 0.00056942605	loss: 34551.50390625	train_loss: 34549.889268239815	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_362
Epoch: 362	max: 0.99940836/1.0	min: 0.00059159944	loss: 34551.57421875	train_loss: 34549.80701150827	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_363
Epoch: 363	max: 0.9993672/1.0	min: 0.0006328983	loss: 34551.25390625	train_loss: 34549.747037288646	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_364
Epoch: 364	max: 0.99942833/1.0	min: 0.0005716907	loss: 34551.40625	train_loss: 34549.633728458284	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_365
Epoch: 365	max: 0.9993705/1.0	min: 0.0006295009	loss: 34551.0	train_loss: 34549.533575459864	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_366
Epoch: 366	max: 0.9994393/1.0	min: 0.0005606421	loss: 34551.18359375	train_loss: 34549.479346180946	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_367
Epoch: 367	max: 0.9994593/1.0	min: 0.0005406293	loss: 34551.078125	train_loss: 34549.3642567238	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_368
Epoch: 368	max: 0.9994294/1.0	min: 0.00057056634	loss: 34550.96484375	train_loss: 34549.2822496671	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_369
Epoch: 369	max: 0.99939656/1.0	min: 0.00060343446	loss: 34550.68359375	train_loss: 34549.18452325653	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_370
Epoch: 370	max: 0.9994848/1.0	min: 0.00051518175	loss: 34550.921875	train_loss: 34549.09624432909	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_371
Epoch: 371	max: 0.9994411/1.0	min: 0.000558902	loss: 34550.59375	train_loss: 34549.05439524495	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_372
Epoch: 372	max: 0.99947494/1.0	min: 0.000525046	loss: 34550.70703125	train_loss: 34548.93693339294	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_373
Epoch: 373	max: 0.99943453/1.0	min: 0.00056543085	loss: 34550.30859375	train_loss: 34548.82601824756	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_374
Epoch: 374	max: 0.99943596/1.0	min: 0.00056405127	loss: 34550.26171875	train_loss: 34548.75367544593	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_375
Epoch: 375	max: 0.99943227/1.0	min: 0.000567713	loss: 34550.11328125	train_loss: 34548.62743094265	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_376
Epoch: 376	max: 0.99948835/1.0	min: 0.0005115681	loss: 34550.0703125	train_loss: 34548.558071174746	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_377
Epoch: 377	max: 0.9994754/1.0	min: 0.00052462233	loss: 34550.0234375	train_loss: 34548.45894784312	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_378
Epoch: 378	max: 0.99959034/1.0	min: 0.00040972955	loss: 34550.80859375	train_loss: 34548.39698348275	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_379
Epoch: 379	max: 0.9995402/1.0	min: 0.0004597753	loss: 34550.00390625	train_loss: 34548.31680640716	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_380
Epoch: 380	max: 0.9995357/1.0	min: 0.0004643491	loss: 34550.0078125	train_loss: 34548.176823497306	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_381
Epoch: 381	max: 0.9995067/1.0	min: 0.0004932532	loss: 34549.75	train_loss: 34548.08702910163	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_382
Epoch: 382	max: 0.99954766/1.0	min: 0.0004523275	loss: 34549.8984375	train_loss: 34548.01726578952	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_383
Epoch: 383	max: 0.99956816/1.0	min: 0.0004318247	loss: 34549.73828125	train_loss: 34547.917492625886	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_384
Epoch: 384	max: 0.99953413/1.0	min: 0.00046584205	loss: 34549.62109375	train_loss: 34547.80410250604	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_385
Epoch: 385	max: 0.9996001/1.0	min: 0.0003998968	loss: 34550.0234375	train_loss: 34547.70241323316	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_386
Epoch: 386	max: 0.99953055/1.0	min: 0.0004694497	loss: 34549.265625	train_loss: 34547.65396663648	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_387
Epoch: 387	max: 0.9994555/1.0	min: 0.0005444898	loss: 34548.875	train_loss: 34547.611429011056	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_388
Epoch: 388	max: 0.99959856/1.0	min: 0.0004014135	loss: 34549.33203125	train_loss: 34547.44782037734	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_389
Epoch: 389	max: 0.99962425/1.0	min: 0.00037569564	loss: 34549.625	train_loss: 34547.346284006104	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_390
Epoch: 390	max: 0.99956256/1.0	min: 0.0004374036	loss: 34548.96875	train_loss: 34547.25300190449	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_391
Epoch: 391	max: 0.9995652/1.0	min: 0.00043483276	loss: 34548.73046875	train_loss: 34547.14631623158	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_392
Epoch: 392	max: 0.9995927/1.0	min: 0.0004072455	loss: 34549.0234375	train_loss: 34547.05871713582	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_393
Epoch: 393	max: 0.999569/1.0	min: 0.00043097528	loss: 34548.6640625	train_loss: 34546.99488553667	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_394
Epoch: 394	max: 0.99956757/1.0	min: 0.00043240323	loss: 34548.578125	train_loss: 34546.87264599204	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_395
Epoch: 395	max: 0.9995505/1.0	min: 0.00044949644	loss: 34548.2890625	train_loss: 34546.78393690775	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_396
Epoch: 396	max: 0.99958557/1.0	min: 0.00041445458	loss: 34548.4296875	train_loss: 34546.71224055107	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_397
Epoch: 397	max: 0.9996252/1.0	min: 0.00037483138	loss: 34548.5390625	train_loss: 34546.600235739505	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_398
Epoch: 398	max: 0.99968386/1.0	min: 0.0003161863	loss: 34549.0703125	train_loss: 34546.54122586476	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_399
Epoch: 399	max: 0.9996766/1.0	min: 0.00032341984	loss: 34548.6640625	train_loss: 34546.43941175446	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_400
Epoch: 400	max: 0.99962986/1.0	min: 0.00037013987	loss: 34548.19140625	train_loss: 34546.32788838954	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_401
Epoch: 401	max: 0.9995521/1.0	min: 0.000447932	loss: 34547.90625	train_loss: 34546.21858451784	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_402
Epoch: 402	max: 0.9996213/1.0	min: 0.00037874278	loss: 34547.9609375	train_loss: 34546.142963524246	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_403
Epoch: 403	max: 0.9995745/1.0	min: 0.00042549073	loss: 34547.69140625	train_loss: 34546.04200392125	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_404
Epoch: 404	max: 0.9996722/1.0	min: 0.00032778332	loss: 34548.1015625	train_loss: 34545.96661711879	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_405
Epoch: 405	max: 0.9996879/1.0	min: 0.00031214466	loss: 34548.05859375	train_loss: 34545.87904028087	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_406
Epoch: 406	max: 0.99968934/1.0	min: 0.00031068097	loss: 34548.234375	train_loss: 34545.7896924935	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_407
Epoch: 407	max: 0.9997178/1.0	min: 0.00028223742	loss: 34548.53515625	train_loss: 34545.73036907361	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_408
Epoch: 408	max: 0.9996939/1.0	min: 0.00030614645	loss: 34547.77734375	train_loss: 34545.637090359065	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_409
Epoch: 409	max: 0.99969375/1.0	min: 0.00030627346	loss: 34547.9140625	train_loss: 34545.50178352997	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_410
Epoch: 410	max: 0.999678/1.0	min: 0.0003220061	loss: 34547.5234375	train_loss: 34545.45758963133	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_411
Epoch: 411	max: 0.99963295/1.0	min: 0.00036705675	loss: 34547.1640625	train_loss: 34545.31860542085	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_412
Epoch: 412	max: 0.9996313/1.0	min: 0.0003687239	loss: 34547.015625	train_loss: 34545.26638805664	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_413
Epoch: 413	max: 0.9996997/1.0	min: 0.00030037115	loss: 34547.578125	train_loss: 34545.15782159668	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_414
Epoch: 414	max: 0.99967885/1.0	min: 0.00032110847	loss: 34547.3984375	train_loss: 34545.08634104422	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_415
Epoch: 415	max: 0.999699/1.0	min: 0.00030107872	loss: 34547.1328125	train_loss: 34544.99175492382	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_416
Epoch: 416	max: 0.9996797/1.0	min: 0.00032029796	loss: 34546.84765625	train_loss: 34544.93189538043	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_417
Epoch: 417	max: 0.9996686/1.0	min: 0.00033146533	loss: 34546.87890625	train_loss: 34544.809860511115	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_418
Epoch: 418	max: 0.99965525/1.0	min: 0.00034476508	loss: 34546.4765625	train_loss: 34544.751015634676	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_419
Epoch: 419	max: 0.9996772/1.0	min: 0.00032281727	loss: 34546.60546875	train_loss: 34544.65626209665	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_420
Epoch: 420	max: 0.99964166/1.0	min: 0.00035831638	loss: 34546.36328125	train_loss: 34544.58392171436	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_421
Epoch: 421	max: 0.99968433/1.0	min: 0.00031562938	loss: 34546.6953125	train_loss: 34544.50256061873	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_422
Epoch: 422	max: 0.99970645/1.0	min: 0.00029349787	loss: 34546.71875	train_loss: 34544.390237907224	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_423
Epoch: 423	max: 0.999706/1.0	min: 0.00029397113	loss: 34546.3671875	train_loss: 34544.319142512075	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_424
Epoch: 424	max: 0.99971837/1.0	min: 0.000281558	loss: 34546.53515625	train_loss: 34544.22501412889	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_425
Epoch: 425	max: 0.9996649/1.0	min: 0.00033506856	loss: 34545.90625	train_loss: 34544.16623747755	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_426
Epoch: 426	max: 0.9996972/1.0	min: 0.0003028481	loss: 34545.9921875	train_loss: 34544.07182216184	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_427
Epoch: 427	max: 0.9997421/1.0	min: 0.0002579223	loss: 34546.5234375	train_loss: 34543.994821666354	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_428
Epoch: 428	max: 0.99971396/1.0	min: 0.00028606644	loss: 34546.13671875	train_loss: 34543.899904097765	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_429
Epoch: 429	max: 0.99972075/1.0	min: 0.00027918964	loss: 34545.984375	train_loss: 34543.8089435851	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_430
Epoch: 430	max: 0.9996487/1.0	min: 0.00035128853	loss: 34545.4296875	train_loss: 34543.73809351	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_431
Epoch: 431	max: 0.9997397/1.0	min: 0.0002602919	loss: 34545.98828125	train_loss: 34543.6827818229	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_432
Epoch: 432	max: 0.99974984/1.0	min: 0.0002501782	loss: 34546.15625	train_loss: 34543.56992589109	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_433
Epoch: 433	max: 0.9996773/1.0	min: 0.0003227379	loss: 34545.57421875	train_loss: 34543.51814110306	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_434
Epoch: 434	max: 0.9997768/1.0	min: 0.00022322578	loss: 34546.15625	train_loss: 34543.421333553975	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_435
Epoch: 435	max: 0.99972683/1.0	min: 0.00027317338	loss: 34545.46875	train_loss: 34543.37071633454	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_436
Epoch: 436	max: 0.9996679/1.0	min: 0.00033208018	loss: 34545.1484375	train_loss: 34543.257566696084	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_437
Epoch: 437	max: 0.9996848/1.0	min: 0.00031516305	loss: 34545.109375	train_loss: 34543.172700959214	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_438
Epoch: 438	max: 0.99972445/1.0	min: 0.00027559345	loss: 34545.19140625	train_loss: 34543.088146348164	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_439
Epoch: 439	max: 0.999691/1.0	min: 0.00030904144	loss: 34544.98046875	train_loss: 34542.999660809954	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_440
Epoch: 440	max: 0.99974376/1.0	min: 0.0002561915	loss: 34545.12109375	train_loss: 34542.93523066858	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_441
Epoch: 441	max: 0.9997712/1.0	min: 0.00022881516	loss: 34545.7109375	train_loss: 34542.87968962901	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_442
Epoch: 442	max: 0.99976605/1.0	min: 0.00023392918	loss: 34545.140625	train_loss: 34542.85913597021	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_443
Epoch: 443	max: 0.9997348/1.0	min: 0.00026513348	loss: 34545.05078125	train_loss: 34542.68183876811	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_444
Epoch: 444	max: 0.9997154/1.0	min: 0.00028457303	loss: 34544.5703125	train_loss: 34542.60684631643	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_445
Epoch: 445	max: 0.999716/1.0	min: 0.00028396942	loss: 34544.6484375	train_loss: 34542.53508173464	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_446
Epoch: 446	max: 0.9997856/1.0	min: 0.0002143571	loss: 34545.13671875	train_loss: 34542.45936783878	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_447
Epoch: 447	max: 0.9997421/1.0	min: 0.00025785418	loss: 34544.578125	train_loss: 34542.39426657531	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_448
Epoch: 448	max: 0.99973494/1.0	min: 0.00026507027	loss: 34544.5	train_loss: 34542.31386305045	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_449
Epoch: 449	max: 0.9997217/1.0	min: 0.00027828076	loss: 34544.2578125	train_loss: 34542.24470650626	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_450
Epoch: 450	max: 0.9997682/1.0	min: 0.00023183713	loss: 34544.296875	train_loss: 34542.16374992258	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_451
Epoch: 451	max: 0.999703/1.0	min: 0.00029701882	loss: 34544.21484375	train_loss: 34542.105902293915	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_452
Epoch: 452	max: 0.99979895/1.0	min: 0.00020109043	loss: 34544.8515625	train_loss: 34541.99595923526	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_453
Epoch: 453	max: 0.9997876/1.0	min: 0.00021238698	loss: 34544.2109375	train_loss: 34541.93293424068	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_454
Epoch: 454	max: 0.9997738/1.0	min: 0.00022621836	loss: 34544.34375	train_loss: 34541.90617790397	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_455
Epoch: 455	max: 0.9997321/1.0	min: 0.00026789447	loss: 34543.76171875	train_loss: 34541.80207994627	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_456
Epoch: 456	max: 0.99970776/1.0	min: 0.00029221966	loss: 34543.60546875	train_loss: 34541.74664922814	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_457
Epoch: 457	max: 0.99972767/1.0	min: 0.00027234099	loss: 34543.7421875	train_loss: 34541.64749686455	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_458
Epoch: 458	max: 0.99978155/1.0	min: 0.00021845233	loss: 34543.9375	train_loss: 34541.56983056949	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_459
Epoch: 459	max: 0.9997689/1.0	min: 0.000231059	loss: 34543.8203125	train_loss: 34541.48612998189	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_460
Epoch: 460	max: 0.9997688/1.0	min: 0.00023120403	loss: 34543.7421875	train_loss: 34541.40038022188	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_461
Epoch: 461	max: 0.9997125/1.0	min: 0.0002874087	loss: 34543.25390625	train_loss: 34541.334432192954	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_462
Epoch: 462	max: 0.9997658/1.0	min: 0.00023422315	loss: 34543.57421875	train_loss: 34541.28638381798	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_463
Epoch: 463	max: 0.9998053/1.0	min: 0.00019469057	loss: 34543.8359375	train_loss: 34541.18577695327	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_464
Epoch: 464	max: 0.9997812/1.0	min: 0.0002188695	loss: 34543.28125	train_loss: 34541.15493194909	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_465
Epoch: 465	max: 0.99979705/1.0	min: 0.00020298811	loss: 34543.37109375	train_loss: 34541.06793816967	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_466
Epoch: 466	max: 0.9998048/1.0	min: 0.00019519635	loss: 34543.39453125	train_loss: 34540.97250479995	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_467
Epoch: 467	max: 0.9998042/1.0	min: 0.00019581467	loss: 34543.796875	train_loss: 34540.935802598164	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_468
Epoch: 468	max: 0.99976367/1.0	min: 0.00023636872	loss: 34543.14453125	train_loss: 34540.84457837854	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_469
Epoch: 469	max: 0.99977905/1.0	min: 0.0002209872	loss: 34543.140625	train_loss: 34540.76122230351	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_470
Epoch: 470	max: 0.99979633/1.0	min: 0.00020373466	loss: 34542.96875	train_loss: 34540.724748486464	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_471
Epoch: 471	max: 0.99978644/1.0	min: 0.00021360854	loss: 34543.09375	train_loss: 34540.62308824554	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_472
Epoch: 472	max: 0.99973553/1.0	min: 0.0002644937	loss: 34542.421875	train_loss: 34540.56477465394	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_473
Epoch: 473	max: 0.9997756/1.0	min: 0.00022442536	loss: 34542.796875	train_loss: 34540.50474140267	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_474
Epoch: 474	max: 0.9998031/1.0	min: 0.00019692855	loss: 34543.32421875	train_loss: 34540.429296052425	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_475
Epoch: 475	max: 0.99979407/1.0	min: 0.00020593432	loss: 34542.74609375	train_loss: 34540.37966011318	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_476
Epoch: 476	max: 0.9997969/1.0	min: 0.00020304792	loss: 34542.53515625	train_loss: 34540.27295895655	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_477
Epoch: 477	max: 0.9997446/1.0	min: 0.0002554469	loss: 34542.078125	train_loss: 34540.21880225753	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_478
Epoch: 478	max: 0.99974805/1.0	min: 0.0002519308	loss: 34542.26953125	train_loss: 34540.15526242955	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_479
Epoch: 479	max: 0.99973696/1.0	min: 0.0002630399	loss: 34542.23046875	train_loss: 34540.08220011922	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_480
Epoch: 480	max: 0.99976283/1.0	min: 0.00023718073	loss: 34542.35546875	train_loss: 34540.01641999179	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_481
Epoch: 481	max: 0.9997826/1.0	min: 0.00021740902	loss: 34542.04296875	train_loss: 34539.965675031744	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_482
Epoch: 482	max: 0.9998374/1.0	min: 0.0001625878	loss: 34542.87890625	train_loss: 34539.8904629049	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_483
Epoch: 483	max: 0.99985385/1.0	min: 0.00014614756	loss: 34543.0390625	train_loss: 34539.91334831382	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_484
Epoch: 484	max: 0.99986255/1.0	min: 0.0001374389	loss: 34543.30859375	train_loss: 34539.9241302993	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_485
Epoch: 485	max: 0.9998129/1.0	min: 0.00018708876	loss: 34542.0390625	train_loss: 34539.76714675849	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_486
Epoch: 486	max: 0.99973935/1.0	min: 0.0002606209	loss: 34541.69921875	train_loss: 34539.61312931609	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_487
Epoch: 487	max: 0.9997514/1.0	min: 0.0002486643	loss: 34541.71875	train_loss: 34539.56232145346	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_488
Epoch: 488	max: 0.9998348/1.0	min: 0.00016514966	loss: 34542.44921875	train_loss: 34539.514467108726	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_489
Epoch: 489	max: 0.9998135/1.0	min: 0.0001865768	loss: 34541.9609375	train_loss: 34539.519303832996	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_490
Epoch: 490	max: 0.9998227/1.0	min: 0.00017731162	loss: 34541.94140625	train_loss: 34539.38045655658	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_491
Epoch: 491	max: 0.9998204/1.0	min: 0.00017964818	loss: 34541.68359375	train_loss: 34539.30465217779	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_492
Epoch: 492	max: 0.9997564/1.0	min: 0.00024363972	loss: 34541.4296875	train_loss: 34539.23998494209	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_493
Epoch: 493	max: 0.9997868/1.0	min: 0.00021318105	loss: 34541.1640625	train_loss: 34539.23388435991	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_494
Epoch: 494	max: 0.9998047/1.0	min: 0.00019536243	loss: 34541.5	train_loss: 34539.11983231141	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_495
Epoch: 495	max: 0.9998055/1.0	min: 0.00019454121	loss: 34541.453125	train_loss: 34539.04986625945	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_496
Epoch: 496	max: 0.9997944/1.0	min: 0.00020564532	loss: 34541.2734375	train_loss: 34538.98780899681	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_497
Epoch: 497	max: 0.99975806/1.0	min: 0.00024194294	loss: 34541.02734375	train_loss: 34538.94293042782	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_498
Epoch: 498	max: 0.999765/1.0	min: 0.0002350269	loss: 34540.8984375	train_loss: 34538.93356181485	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_499
Epoch: 499	max: 0.9997967/1.0	min: 0.00020331373	loss: 34541.03125	train_loss: 34538.826553887186	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_500
Epoch: 500	max: 0.9997838/1.0	min: 0.00021623747	loss: 34541.03125	train_loss: 34538.76634547643	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_501
Epoch: 501	max: 0.9998248/1.0	min: 0.00017516439	loss: 34541.0859375	train_loss: 34538.709745254244	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_502
Epoch: 502	max: 0.99981207/1.0	min: 0.00018793157	loss: 34541.12109375	train_loss: 34538.626371276165	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_503
Epoch: 503	max: 0.99981004/1.0	min: 0.00018994132	loss: 34540.7890625	train_loss: 34538.580112721414	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_504
Epoch: 504	max: 0.999778/1.0	min: 0.0002220123	loss: 34540.74609375	train_loss: 34538.51554564598	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_505
Epoch: 505	max: 0.9997875/1.0	min: 0.00021248458	loss: 34540.6015625	train_loss: 34538.46390553388	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_506
Epoch: 506	max: 0.9997845/1.0	min: 0.00021547513	loss: 34540.390625	train_loss: 34538.41026753918	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_507
Epoch: 507	max: 0.99975246/1.0	min: 0.00024757162	loss: 34540.37109375	train_loss: 34538.3714179402	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_508
Epoch: 508	max: 0.99979013/1.0	min: 0.0002099015	loss: 34540.5546875	train_loss: 34538.29694516057	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_509
Epoch: 509	max: 0.99980885/1.0	min: 0.00019112507	loss: 34540.453125	train_loss: 34538.233052594296	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_510
Epoch: 510	max: 0.9997862/1.0	min: 0.00021386023	loss: 34540.44140625	train_loss: 34538.16282283538	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_511
Epoch: 511	max: 0.9997979/1.0	min: 0.0002021948	loss: 34540.3046875	train_loss: 34538.112115616874	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_512
Epoch: 512	max: 0.99978274/1.0	min: 0.00021729628	loss: 34540.12890625	train_loss: 34538.043836805555	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_513
Epoch: 513	max: 0.9997869/1.0	min: 0.00021315343	loss: 34540.171875	train_loss: 34538.021126556116	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_514
Epoch: 514	max: 0.9997924/1.0	min: 0.00020766913	loss: 34540.3984375	train_loss: 34537.93591243574	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_515
Epoch: 515	max: 0.9998272/1.0	min: 0.00017280388	loss: 34540.3515625	train_loss: 34537.89919039545	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_516
Epoch: 516	max: 0.9998202/1.0	min: 0.00017988576	loss: 34540.38671875	train_loss: 34537.82476164762	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_517
Epoch: 517	max: 0.99980277/1.0	min: 0.00019722694	loss: 34539.93359375	train_loss: 34537.76724885421	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_518
Epoch: 518	max: 0.9997874/1.0	min: 0.00021261878	loss: 34539.8984375	train_loss: 34537.70898703626	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_519
Epoch: 519	max: 0.9998272/1.0	min: 0.00017281526	loss: 34540.55859375	train_loss: 34537.64209546869	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_520
Epoch: 520	max: 0.9998505/1.0	min: 0.00014948948	loss: 34540.671875	train_loss: 34537.692970588694	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_521
Epoch: 521	max: 0.9998092/1.0	min: 0.00019087485	loss: 34540.07421875	train_loss: 34537.55251590951	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_522
Epoch: 522	max: 0.9998652/1.0	min: 0.00013475753	loss: 34540.26953125	train_loss: 34537.51932996175	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_523
Epoch: 523	max: 0.9998056/1.0	min: 0.0001944012	loss: 34539.79296875	train_loss: 34537.46214861653	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_524
Epoch: 524	max: 0.99981326/1.0	min: 0.00018672092	loss: 34539.84375	train_loss: 34537.372638250185	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_525
Epoch: 525	max: 0.9997842/1.0	min: 0.00021590044	loss: 34539.64453125	train_loss: 34537.35530326784	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_526
Epoch: 526	max: 0.9998023/1.0	min: 0.00019769085	loss: 34539.65234375	train_loss: 34537.25881700576	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_527
Epoch: 527	max: 0.99981517/1.0	min: 0.00018490777	loss: 34539.36328125	train_loss: 34537.20852107333	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_528
Epoch: 528	max: 0.99980503/1.0	min: 0.00019494393	loss: 34539.55078125	train_loss: 34537.1865714612	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_529
Epoch: 529	max: 0.9998323/1.0	min: 0.00016765833	loss: 34539.984375	train_loss: 34537.13273943624	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_530
Epoch: 530	max: 0.9998344/1.0	min: 0.00016558866	loss: 34539.37109375	train_loss: 34537.07765613387	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_531
Epoch: 531	max: 0.9998578/1.0	min: 0.00014221676	loss: 34539.65625	train_loss: 34537.005064141274	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_532
Epoch: 532	max: 0.9998342/1.0	min: 0.00016574423	loss: 34539.5	train_loss: 34536.97471219652	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_533
Epoch: 533	max: 0.99982685/1.0	min: 0.0001731405	loss: 34539.265625	train_loss: 34536.891148542985	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_534
Epoch: 534	max: 0.99981755/1.0	min: 0.00018250907	loss: 34539.1484375	train_loss: 34536.83793441487	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_535
Epoch: 535	max: 0.9998258/1.0	min: 0.000174312	loss: 34539.19921875	train_loss: 34536.795269532704	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_536
Epoch: 536	max: 0.99983/1.0	min: 0.00016999684	loss: 34539.09375	train_loss: 34536.72482735662	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_537
Epoch: 537	max: 0.9998579/1.0	min: 0.00014206523	loss: 34539.1640625	train_loss: 34536.70925171095	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_538
Epoch: 538	max: 0.99986696/1.0	min: 0.00013304384	loss: 34539.50390625	train_loss: 34536.631175097544	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_539
Epoch: 539	max: 0.9998772/1.0	min: 0.00012279033	loss: 34539.421875	train_loss: 34536.63542247306	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_540
Epoch: 540	max: 0.99981683/1.0	min: 0.00018318152	loss: 34538.76953125	train_loss: 34536.530735166605	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_541
Epoch: 541	max: 0.99983764/1.0	min: 0.00016230729	loss: 34538.83984375	train_loss: 34536.470593045495	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_542
Epoch: 542	max: 0.99981433/1.0	min: 0.0001857002	loss: 34538.75	train_loss: 34536.39769041094	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_543
Epoch: 543	max: 0.99981934/1.0	min: 0.00018067424	loss: 34538.59375	train_loss: 34536.37178664607	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_544
Epoch: 544	max: 0.9998247/1.0	min: 0.00017532731	loss: 34538.49609375	train_loss: 34536.30937422581	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_545
Epoch: 545	max: 0.9998592/1.0	min: 0.00014072628	loss: 34538.87890625	train_loss: 34536.26259261195	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_546
Epoch: 546	max: 0.9998754/1.0	min: 0.00012452339	loss: 34539.30078125	train_loss: 34536.18113135606	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_547
Epoch: 547	max: 0.99982244/1.0	min: 0.00017759282	loss: 34538.4609375	train_loss: 34536.18589937136	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_548
Epoch: 548	max: 0.99986815/1.0	min: 0.00013183466	loss: 34538.703125	train_loss: 34536.12554967174	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_549
Epoch: 549	max: 0.9998429/1.0	min: 0.00015710575	loss: 34538.5390625	train_loss: 34536.055905390655	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_550
Epoch: 550	max: 0.99985003/1.0	min: 0.00014989926	loss: 34538.34375	train_loss: 34535.983112593676	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_551
Epoch: 551	max: 0.99988043/1.0	min: 0.0001195296	loss: 34538.8046875	train_loss: 34535.92445110244	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_552
Epoch: 552	max: 0.9998851/1.0	min: 0.00011485712	loss: 34538.94140625	train_loss: 34535.879489792365	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_553
Epoch: 553	max: 0.9999051/1.0	min: 9.4932824e-05	loss: 34539.21875	train_loss: 34535.87410920274	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_554
Epoch: 554	max: 0.9999014/1.0	min: 9.8595505e-05	loss: 34539.05859375	train_loss: 34535.83841682925	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_555
Epoch: 555	max: 0.9998981/1.0	min: 0.00010195132	loss: 34538.94140625	train_loss: 34535.799277878425	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_556
Epoch: 556	max: 0.9998441/1.0	min: 0.00015584705	loss: 34537.921875	train_loss: 34535.7103331514	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_557
Epoch: 557	max: 0.9998809/1.0	min: 0.0001190246	loss: 34538.30078125	train_loss: 34535.64262965673	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_558
Epoch: 558	max: 0.9998857/1.0	min: 0.00011436554	loss: 34538.36328125	train_loss: 34535.57812935479	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_559
Epoch: 559	max: 0.99990654/1.0	min: 9.343247e-05	loss: 34538.6484375	train_loss: 34535.54312116778	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_560
Epoch: 560	max: 0.9998915/1.0	min: 0.000108499305	loss: 34538.328125	train_loss: 34535.552409942866	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_561
Epoch: 561	max: 0.9998853/1.0	min: 0.00011463358	loss: 34538.1171875	train_loss: 34535.486422720795	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_562
Epoch: 562	max: 0.99988866/1.0	min: 0.00011131482	loss: 34538.00390625	train_loss: 34535.40764692106	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_563
Epoch: 563	max: 0.99987745/1.0	min: 0.00012254645	loss: 34538.03125	train_loss: 34535.352705875295	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_564
Epoch: 564	max: 0.9998901/1.0	min: 0.00010993022	loss: 34538.23828125	train_loss: 34535.29447841184	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_565
Epoch: 565	max: 0.9998946/1.0	min: 0.00010532365	loss: 34538.234375	train_loss: 34535.258420719525	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_566
Epoch: 566	max: 0.99988973/1.0	min: 0.000110284906	loss: 34537.86328125	train_loss: 34535.21646663648	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_567
Epoch: 567	max: 0.9998852/1.0	min: 0.00011480675	loss: 34537.8515625	train_loss: 34535.16929696209	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_568
Epoch: 568	max: 0.999882/1.0	min: 0.0001180272	loss: 34537.84375	train_loss: 34535.11450978571	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_569
Epoch: 569	max: 0.99989843/1.0	min: 0.000101520185	loss: 34537.87890625	train_loss: 34535.08198479887	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_570
Epoch: 570	max: 0.9999008/1.0	min: 9.91951e-05	loss: 34538.03125	train_loss: 34535.0394123351	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_571
Epoch: 571	max: 0.9998878/1.0	min: 0.000112114394	loss: 34538.03515625	train_loss: 34534.99450908894	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_572
Epoch: 572	max: 0.99989045/1.0	min: 0.000109504814	loss: 34537.8046875	train_loss: 34534.96499132912	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_573
Epoch: 573	max: 0.999871/1.0	min: 0.0001290102	loss: 34537.4609375	train_loss: 34534.90381518642	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_574
Epoch: 574	max: 0.9998914/1.0	min: 0.00010859587	loss: 34537.625	train_loss: 34534.860177249786	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_575
Epoch: 575	max: 0.99990845/1.0	min: 9.149007e-05	loss: 34537.9140625	train_loss: 34534.82521503004	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_576
Epoch: 576	max: 0.9999131/1.0	min: 8.687908e-05	loss: 34537.84375	train_loss: 34534.81074211492	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_577
Epoch: 577	max: 0.99990547/1.0	min: 9.451578e-05	loss: 34537.7265625	train_loss: 34534.730432460055	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_578
Epoch: 578	max: 0.9999026/1.0	min: 9.7388045e-05	loss: 34537.5859375	train_loss: 34534.686104530534	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_579
Epoch: 579	max: 0.9998779/1.0	min: 0.00012203266	loss: 34537.12109375	train_loss: 34534.62762981156	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_580
Epoch: 580	max: 0.9998981/1.0	min: 0.00010191029	loss: 34537.42578125	train_loss: 34534.58323317308	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_581
Epoch: 581	max: 0.99989855/1.0	min: 0.00010144181	loss: 34537.2421875	train_loss: 34534.538852018304	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_582
Epoch: 582	max: 0.99989927/1.0	min: 0.00010074406	loss: 34537.38671875	train_loss: 34534.50582235925	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_583
Epoch: 583	max: 0.9998764/1.0	min: 0.00012357507	loss: 34536.90625	train_loss: 34534.44443960579	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_584
Epoch: 584	max: 0.9998733/1.0	min: 0.00012665777	loss: 34537.11328125	train_loss: 34534.40051473662	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_585
Epoch: 585	max: 0.99986684/1.0	min: 0.00013318346	loss: 34536.82421875	train_loss: 34534.381120420694	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_586
Epoch: 586	max: 0.99988353/1.0	min: 0.00011647446	loss: 34536.75390625	train_loss: 34534.319181221355	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_587
Epoch: 587	max: 0.99988174/1.0	min: 0.00011820898	loss: 34536.9140625	train_loss: 34534.34687770965	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_588
Epoch: 588	max: 0.999895/1.0	min: 0.00010499225	loss: 34537.0546875	train_loss: 34534.26847690604	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_589
Epoch: 589	max: 0.9999151/1.0	min: 8.488305e-05	loss: 34537.2109375	train_loss: 34534.189967232596	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_590
Epoch: 590	max: 0.99990237/1.0	min: 9.764098e-05	loss: 34537.0859375	train_loss: 34534.153572769574	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_591
Epoch: 591	max: 0.9999033/1.0	min: 9.671257e-05	loss: 34537.08984375	train_loss: 34534.09411531881	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_592
Epoch: 592	max: 0.99985766/1.0	min: 0.00014226421	loss: 34536.62109375	train_loss: 34534.06796236297	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_593
Epoch: 593	max: 0.999902/1.0	min: 9.797338e-05	loss: 34536.80078125	train_loss: 34534.01039102177	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_594
Epoch: 594	max: 0.99989545/1.0	min: 0.000104514664	loss: 34536.9140625	train_loss: 34533.95865268487	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_595
Epoch: 595	max: 0.9998858/1.0	min: 0.00011419532	loss: 34536.80859375	train_loss: 34533.91139881782	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_596
Epoch: 596	max: 0.9998977/1.0	min: 0.00010222223	loss: 34536.5078125	train_loss: 34533.87682901338	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_597
Epoch: 597	max: 0.9999025/1.0	min: 9.746219e-05	loss: 34536.796875	train_loss: 34533.84936042596	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_598
Epoch: 598	max: 0.99989367/1.0	min: 0.00010629753	loss: 34536.8046875	train_loss: 34533.81056114905	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_599
Epoch: 599	max: 0.99991035/1.0	min: 8.960932e-05	loss: 34537.04296875	train_loss: 34533.73805141366	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_600
Epoch: 600	max: 0.99991024/1.0	min: 8.971518e-05	loss: 34536.640625	train_loss: 34533.764673719495	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_601
Epoch: 601	max: 0.9999032/1.0	min: 9.67455e-05	loss: 34536.7109375	train_loss: 34533.73825657283	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_602
Epoch: 602	max: 0.99989545/1.0	min: 0.000104484374	loss: 34536.48828125	train_loss: 34533.63030897746	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_603
Epoch: 603	max: 0.99990404/1.0	min: 9.592964e-05	loss: 34536.35546875	train_loss: 34533.57729323439	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_604
Epoch: 604	max: 0.9998983/1.0	min: 0.00010167645	loss: 34536.80859375	train_loss: 34533.549695454756	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_605
Epoch: 605	max: 0.9998888/1.0	min: 0.0001111645	loss: 34536.52734375	train_loss: 34533.499822905054	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_606
Epoch: 606	max: 0.99990106/1.0	min: 9.890862e-05	loss: 34536.69921875	train_loss: 34533.44384977316	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_607
Epoch: 607	max: 0.99991107/1.0	min: 8.888279e-05	loss: 34536.47265625	train_loss: 34533.44001658692	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_608
Epoch: 608	max: 0.99991596/1.0	min: 8.4014304e-05	loss: 34536.484375	train_loss: 34533.384913446054	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_609
Epoch: 609	max: 0.9999125/1.0	min: 8.7485474e-05	loss: 34536.64453125	train_loss: 34533.37488532376	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_610
Epoch: 610	max: 0.99991536/1.0	min: 8.4660016e-05	loss: 34536.71875	train_loss: 34533.29988754955	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_611
Epoch: 611	max: 0.99991393/1.0	min: 8.6096086e-05	loss: 34536.796875	train_loss: 34533.26763788245	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_612
Epoch: 612	max: 0.9999163/1.0	min: 8.36595e-05	loss: 34536.33984375	train_loss: 34533.213068445744	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_613
Epoch: 613	max: 0.99988973/1.0	min: 0.000110227484	loss: 34536.11328125	train_loss: 34533.17198048278	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_614
Epoch: 614	max: 0.9999062/1.0	min: 9.381735e-05	loss: 34536.49609375	train_loss: 34533.11504203828	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_615
Epoch: 615	max: 0.9999293/1.0	min: 7.0660826e-05	loss: 34536.75	train_loss: 34533.12053294934	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_616
Epoch: 616	max: 0.9999137/1.0	min: 8.634372e-05	loss: 34536.19921875	train_loss: 34533.061059531	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_617
Epoch: 617	max: 0.9998895/1.0	min: 0.00011047782	loss: 34535.859375	train_loss: 34533.00133740555	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_618
Epoch: 618	max: 0.99990225/1.0	min: 9.774662e-05	loss: 34535.98828125	train_loss: 34532.962862802706	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_619
Epoch: 619	max: 0.9998864/1.0	min: 0.00011360361	loss: 34535.83984375	train_loss: 34532.927405588074	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_620
Epoch: 620	max: 0.999913/1.0	min: 8.696495e-05	loss: 34536.0234375	train_loss: 34532.88616036867	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_621
Epoch: 621	max: 0.9999014/1.0	min: 9.859664e-05	loss: 34535.66796875	train_loss: 34532.854922949184	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_622
Epoch: 622	max: 0.9998919/1.0	min: 0.000108088825	loss: 34535.6796875	train_loss: 34532.81793671807	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_623
Epoch: 623	max: 0.99990034/1.0	min: 9.9602854e-05	loss: 34535.87890625	train_loss: 34532.76881996702	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_624
Epoch: 624	max: 0.99989355/1.0	min: 0.000106469975	loss: 34535.5859375	train_loss: 34532.739123660656	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_625
Epoch: 625	max: 0.9999107/1.0	min: 8.9275236e-05	loss: 34536.0234375	train_loss: 34532.71311538074	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_626
Epoch: 626	max: 0.9998839/1.0	min: 0.000116089024	loss: 34535.5859375	train_loss: 34532.65554355568	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_627
Epoch: 627	max: 0.99989915/1.0	min: 0.000100812584	loss: 34535.62109375	train_loss: 34532.62550515607	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_628
Epoch: 628	max: 0.9998995/1.0	min: 0.00010046767	loss: 34535.55859375	train_loss: 34532.57233360817	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_629
Epoch: 629	max: 0.9998969/1.0	min: 0.000103083636	loss: 34535.53515625	train_loss: 34532.55871374876	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_630
Epoch: 630	max: 0.99990857/1.0	min: 9.145047e-05	loss: 34535.53515625	train_loss: 34532.506026066825	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_631
Epoch: 631	max: 0.9999161/1.0	min: 8.392862e-05	loss: 34535.88671875	train_loss: 34532.456862864645	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_632
Epoch: 632	max: 0.99989855/1.0	min: 0.000101463185	loss: 34535.4609375	train_loss: 34532.447332156575	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_633
Epoch: 633	max: 0.9998809/1.0	min: 0.00011906796	loss: 34535.4140625	train_loss: 34532.43247553574	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_634
Epoch: 634	max: 0.99988353/1.0	min: 0.00011644314	loss: 34535.203125	train_loss: 34532.389879362534	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_635
Epoch: 635	max: 0.9998989/1.0	min: 0.000101090205	loss: 34535.5	train_loss: 34532.30535426731	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_636
Epoch: 636	max: 0.9998932/1.0	min: 0.000106798005	loss: 34535.35546875	train_loss: 34532.26951673402	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_637
Epoch: 637	max: 0.99992526/1.0	min: 7.468495e-05	loss: 34535.875	train_loss: 34532.23356500836	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_638
Epoch: 638	max: 0.99992836/1.0	min: 7.165375e-05	loss: 34535.7421875	train_loss: 34532.237966253255	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_639
Epoch: 639	max: 0.999923/1.0	min: 7.701498e-05	loss: 34535.46484375	train_loss: 34532.18615678806	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_640
Epoch: 640	max: 0.99991214/1.0	min: 8.788667e-05	loss: 34535.63671875	train_loss: 34532.12961801684	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_641
Epoch: 641	max: 0.9999261/1.0	min: 7.3959e-05	loss: 34535.67578125	train_loss: 34532.10170233727	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_642
Epoch: 642	max: 0.9999025/1.0	min: 9.746367e-05	loss: 34534.98828125	train_loss: 34532.06023308792	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_643
Epoch: 643	max: 0.99991715/1.0	min: 8.2807055e-05	loss: 34535.546875	train_loss: 34532.02867147823	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_644
Epoch: 644	max: 0.9999229/1.0	min: 7.717422e-05	loss: 34535.484375	train_loss: 34532.01096343522	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_645
Epoch: 645	max: 0.99991155/1.0	min: 8.843589e-05	loss: 34535.23828125	train_loss: 34531.98724480908	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_646
Epoch: 646	max: 0.99991024/1.0	min: 8.978698e-05	loss: 34535.03515625	train_loss: 34531.90535388022	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_647
Epoch: 647	max: 0.99991095/1.0	min: 8.90051e-05	loss: 34535.4609375	train_loss: 34531.9206677544	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_648
Epoch: 648	max: 0.9998934/1.0	min: 0.000106569416	loss: 34534.75390625	train_loss: 34531.84733641459	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_649
Epoch: 649	max: 0.9999049/1.0	min: 9.510452e-05	loss: 34534.8203125	train_loss: 34531.79455824972	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_650
Epoch: 650	max: 0.999905/1.0	min: 9.495554e-05	loss: 34534.859375	train_loss: 34531.761003112224	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_651
Epoch: 651	max: 0.99989486/1.0	min: 0.00010512438	loss: 34534.7734375	train_loss: 34531.72415139586	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_652
Epoch: 652	max: 0.9998863/1.0	min: 0.0001136903	loss: 34534.66015625	train_loss: 34531.71737823997	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_653
Epoch: 653	max: 0.99988735/1.0	min: 0.00011263927	loss: 34534.4921875	train_loss: 34531.731927605906	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_654
Epoch: 654	max: 0.99988115/1.0	min: 0.000118885655	loss: 34534.546875	train_loss: 34531.66288864115	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_655
Epoch: 655	max: 0.99987435/1.0	min: 0.00012566207	loss: 34534.7734375	train_loss: 34531.621623099374	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_656
Epoch: 656	max: 0.9999088/1.0	min: 9.1161484e-05	loss: 34534.984375	train_loss: 34531.55317009631	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_657
Epoch: 657	max: 0.9998926/1.0	min: 0.000107379456	loss: 34534.6640625	train_loss: 34531.52615102038	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_658
Epoch: 658	max: 0.99989545/1.0	min: 0.00010455255	loss: 34534.640625	train_loss: 34531.538600408	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_659
Epoch: 659	max: 0.99990606/1.0	min: 9.389432e-05	loss: 34535.046875	train_loss: 34531.46436907748	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_660
Epoch: 660	max: 0.99989045/1.0	min: 0.00010950545	loss: 34534.3984375	train_loss: 34531.44733989843	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_661
Epoch: 661	max: 0.9998938/1.0	min: 0.000106227	loss: 34534.421875	train_loss: 34531.42441094157	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_662
Epoch: 662	max: 0.99991477/1.0	min: 8.5257016e-05	loss: 34534.69140625	train_loss: 34531.382278795834	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_663
Epoch: 663	max: 0.999915/1.0	min: 8.503715e-05	loss: 34534.640625	train_loss: 34531.35320135405	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_664
Epoch: 664	max: 0.99993086/1.0	min: 6.909732e-05	loss: 34534.7109375	train_loss: 34531.30828407578	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_665
Epoch: 665	max: 0.9999316/1.0	min: 6.839533e-05	loss: 34535.2109375	train_loss: 34531.27961162981	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_666
Epoch: 666	max: 0.9999237/1.0	min: 7.632822e-05	loss: 34534.8515625	train_loss: 34531.25546671776	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_667
Epoch: 667	max: 0.9999119/1.0	min: 8.812047e-05	loss: 34534.30859375	train_loss: 34531.204774015234	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_668
Epoch: 668	max: 0.9999013/1.0	min: 9.865598e-05	loss: 34534.359375	train_loss: 34531.165193778645	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_669
Epoch: 669	max: 0.9999099/1.0	min: 9.005957e-05	loss: 34534.55859375	train_loss: 34531.120447788926	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_670
Epoch: 670	max: 0.9999238/1.0	min: 7.614509e-05	loss: 34534.68359375	train_loss: 34531.09530804843	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_671
Epoch: 671	max: 0.9998888/1.0	min: 0.000111251145	loss: 34534.06640625	train_loss: 34531.06429272343	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_672
Epoch: 672	max: 0.99992466/1.0	min: 7.533946e-05	loss: 34534.3203125	train_loss: 34531.039514914686	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_673
Epoch: 673	max: 0.999931/1.0	min: 6.90441e-05	loss: 34535.0546875	train_loss: 34531.000721444165	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_674
Epoch: 674	max: 0.99992454/1.0	min: 7.545076e-05	loss: 34534.41015625	train_loss: 34531.02543586647	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_675
Epoch: 675	max: 0.9998977/1.0	min: 0.00010232289	loss: 34533.94140625	train_loss: 34530.97193964449	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_676
Epoch: 676	max: 0.99992096/1.0	min: 7.897384e-05	loss: 34534.234375	train_loss: 34530.93659517063	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_677
Epoch: 677	max: 0.9999242/1.0	min: 7.585968e-05	loss: 34534.2890625	train_loss: 34530.8875819669	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_678
Epoch: 678	max: 0.9999291/1.0	min: 7.0981354e-05	loss: 34534.125	train_loss: 34530.87708255915	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_679
Epoch: 679	max: 0.99992704/1.0	min: 7.292162e-05	loss: 34534.39453125	train_loss: 34530.825964054566	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_680
Epoch: 680	max: 0.99991834/1.0	min: 8.1635e-05	loss: 34534.40625	train_loss: 34530.79039603462	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_681
Epoch: 681	max: 0.99990034/1.0	min: 9.961948e-05	loss: 34534.00390625	train_loss: 34530.77552199461	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_682
Epoch: 682	max: 0.9999316/1.0	min: 6.843801e-05	loss: 34534.3359375	train_loss: 34530.71558696814	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_683
Epoch: 683	max: 0.9999105/1.0	min: 8.946955e-05	loss: 34533.8671875	train_loss: 34530.69938519989	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_684
Epoch: 684	max: 0.9999354/1.0	min: 6.4554275e-05	loss: 34534.37890625	train_loss: 34530.666103446674	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_685
Epoch: 685	max: 0.99990964/1.0	min: 9.031362e-05	loss: 34533.96484375	train_loss: 34530.627407233216	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_686
Epoch: 686	max: 0.9999113/1.0	min: 8.8662775e-05	loss: 34533.81640625	train_loss: 34530.598603175706	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_687
Epoch: 687	max: 0.999918/1.0	min: 8.199146e-05	loss: 34533.89453125	train_loss: 34530.602915873125	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_688
Epoch: 688	max: 0.9999089/1.0	min: 9.10726e-05	loss: 34533.953125	train_loss: 34530.5405997422	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_689
Epoch: 689	max: 0.99992037/1.0	min: 7.966815e-05	loss: 34534.33984375	train_loss: 34530.49868291682	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_690
Epoch: 690	max: 0.99992645/1.0	min: 7.353249e-05	loss: 34534.05078125	train_loss: 34530.49594859021	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_691
Epoch: 691	max: 0.99991786/1.0	min: 8.215269e-05	loss: 34533.8203125	train_loss: 34530.438984500805	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_692
Epoch: 692	max: 0.99992144/1.0	min: 7.852874e-05	loss: 34533.84375	train_loss: 34530.41248848399	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_693
Epoch: 693	max: 0.9999306/1.0	min: 6.940665e-05	loss: 34534.234375	train_loss: 34530.39021274619	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_694
Epoch: 694	max: 0.9999249/1.0	min: 7.503674e-05	loss: 34533.93359375	train_loss: 34530.35295555014	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_695
Epoch: 695	max: 0.99992836/1.0	min: 7.167042e-05	loss: 34534.32421875	train_loss: 34530.32302940744	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_696
Epoch: 696	max: 0.9999324/1.0	min: 6.753993e-05	loss: 34534.171875	train_loss: 34530.351519919794	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_697
Epoch: 697	max: 0.9999498/1.0	min: 5.0222305e-05	loss: 34534.5234375	train_loss: 34530.31081856575	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_698
Epoch: 698	max: 0.9999386/1.0	min: 6.143382e-05	loss: 34533.71875	train_loss: 34530.26336631364	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_699
Epoch: 699	max: 0.9999324/1.0	min: 6.75702e-05	loss: 34534.06640625	train_loss: 34530.24375812895	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_700
Epoch: 700	max: 0.99992025/1.0	min: 7.973061e-05	loss: 34533.81640625	train_loss: 34530.1966378089	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_701
Epoch: 701	max: 0.99991536/1.0	min: 8.461111e-05	loss: 34533.421875	train_loss: 34530.16490345906	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_702
Epoch: 702	max: 0.9999068/1.0	min: 9.3245464e-05	loss: 34533.49609375	train_loss: 34530.118950707605	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_703
Epoch: 703	max: 0.9999274/1.0	min: 7.2608054e-05	loss: 34533.5546875	train_loss: 34530.12772852022	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_704
Epoch: 704	max: 0.9999343/1.0	min: 6.566778e-05	loss: 34534.03125	train_loss: 34530.08527702295	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_705
Epoch: 705	max: 0.999915/1.0	min: 8.4983476e-05	loss: 34533.5390625	train_loss: 34530.0473869302	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_706
Epoch: 706	max: 0.9999194/1.0	min: 8.0596255e-05	loss: 34533.30078125	train_loss: 34530.00584752028	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_707
Epoch: 707	max: 0.9999267/1.0	min: 7.333361e-05	loss: 34533.44140625	train_loss: 34529.98505483169	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_708
Epoch: 708	max: 0.9999263/1.0	min: 7.3629875e-05	loss: 34533.5546875	train_loss: 34529.94519782376	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_709
Epoch: 709	max: 0.99992406/1.0	min: 7.5980155e-05	loss: 34533.40234375	train_loss: 34529.92234047907	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_710
Epoch: 710	max: 0.9999317/1.0	min: 6.829015e-05	loss: 34533.44140625	train_loss: 34529.87119923278	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_711
Epoch: 711	max: 0.9998902/1.0	min: 0.00010977289	loss: 34533.1015625	train_loss: 34529.85443908321	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_712
Epoch: 712	max: 0.999905/1.0	min: 9.505304e-05	loss: 34533.1796875	train_loss: 34529.90032119023	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_713
Epoch: 713	max: 0.9999125/1.0	min: 8.748414e-05	loss: 34533.34375	train_loss: 34529.80853616995	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_714
Epoch: 714	max: 0.9999491/1.0	min: 5.0863964e-05	loss: 34534.1796875	train_loss: 34529.78198063762	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_715
Epoch: 715	max: 0.9999285/1.0	min: 7.147876e-05	loss: 34533.19921875	train_loss: 34529.77923179503	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_716
Epoch: 716	max: 0.999926/1.0	min: 7.398291e-05	loss: 34533.24609375	train_loss: 34529.7280300655	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_717
Epoch: 717	max: 0.9999074/1.0	min: 9.264737e-05	loss: 34532.953125	train_loss: 34529.67842606141	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_718
Epoch: 718	max: 0.99993587/1.0	min: 6.418897e-05	loss: 34533.30859375	train_loss: 34529.66337831351	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_719
Epoch: 719	max: 0.9999329/1.0	min: 6.712277e-05	loss: 34533.2109375	train_loss: 34529.62592950653	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_720
Epoch: 720	max: 0.9999367/1.0	min: 6.327287e-05	loss: 34533.48046875	train_loss: 34529.59363774309	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_721
Epoch: 721	max: 0.99993074/1.0	min: 6.9237416e-05	loss: 34533.38671875	train_loss: 34529.632518793354	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_722
Epoch: 722	max: 0.99991906/1.0	min: 8.088845e-05	loss: 34532.9921875	train_loss: 34529.53279740338	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_723
Epoch: 723	max: 0.99992347/1.0	min: 7.65277e-05	loss: 34533.0234375	train_loss: 34529.531240806544	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_724
Epoch: 724	max: 0.9999089/1.0	min: 9.106183e-05	loss: 34532.80859375	train_loss: 34529.506291709244	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_725
Epoch: 725	max: 0.9999168/1.0	min: 8.321505e-05	loss: 34533.1015625	train_loss: 34529.46212393937	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_726
Epoch: 726	max: 0.9999058/1.0	min: 9.419017e-05	loss: 34532.71484375	train_loss: 34529.43415890545	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_727
Epoch: 727	max: 0.99992883/1.0	min: 7.110858e-05	loss: 34533.125	train_loss: 34529.573762948254	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_728
Epoch: 728	max: 0.9999441/1.0	min: 5.590699e-05	loss: 34533.48046875	train_loss: 34529.41887503097	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_729
Epoch: 729	max: 0.999925/1.0	min: 7.4921205e-05	loss: 34532.83984375	train_loss: 34529.356582125605	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_730
Epoch: 730	max: 0.9999192/1.0	min: 8.084466e-05	loss: 34532.5859375	train_loss: 34529.31150952636	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_731
Epoch: 731	max: 0.9999337/1.0	min: 6.629984e-05	loss: 34532.90625	train_loss: 34529.31719737087	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_732
Epoch: 732	max: 0.9999193/1.0	min: 8.075136e-05	loss: 34532.73828125	train_loss: 34529.25462237164	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_733
Epoch: 733	max: 0.99994004/1.0	min: 5.9935803e-05	loss: 34532.88671875	train_loss: 34529.22127142559	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_734
Epoch: 734	max: 0.99992275/1.0	min: 7.723179e-05	loss: 34532.94140625	train_loss: 34529.21536390592	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_735
Epoch: 735	max: 0.99994135/1.0	min: 5.8596514e-05	loss: 34532.921875	train_loss: 34529.170795011145	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_736
Epoch: 736	max: 0.99993/1.0	min: 6.99874e-05	loss: 34532.7734375	train_loss: 34529.148129277375	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_737
Epoch: 737	max: 0.9999151/1.0	min: 8.4887826e-05	loss: 34532.515625	train_loss: 34529.10966919051	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_738
Epoch: 738	max: 0.99992275/1.0	min: 7.722449e-05	loss: 34532.703125	train_loss: 34529.11622992924	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_739
Epoch: 739	max: 0.9999279/1.0	min: 7.2150106e-05	loss: 34532.859375	train_loss: 34529.07861902716	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_740
Epoch: 740	max: 0.9999379/1.0	min: 6.208316e-05	loss: 34533.125	train_loss: 34529.0244613604	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_741
Epoch: 741	max: 0.9999362/1.0	min: 6.379531e-05	loss: 34532.859375	train_loss: 34529.062976124114	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_742
Epoch: 742	max: 0.99993837/1.0	min: 6.164273e-05	loss: 34532.80078125	train_loss: 34528.980615845256	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_743
Epoch: 743	max: 0.99991906/1.0	min: 8.094386e-05	loss: 34532.484375	train_loss: 34528.93834386225	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_744
Epoch: 744	max: 0.9999279/1.0	min: 7.207927e-05	loss: 34532.6328125	train_loss: 34528.91545845333	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_745
Epoch: 745	max: 0.99992263/1.0	min: 7.730834e-05	loss: 34532.5546875	train_loss: 34528.88294556314	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_746
Epoch: 746	max: 0.99992955/1.0	min: 7.046865e-05	loss: 34532.44140625	train_loss: 34528.90558807135	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_747
Epoch: 747	max: 0.9999443/1.0	min: 5.561087e-05	loss: 34532.56640625	train_loss: 34528.88407297086	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_748
Epoch: 748	max: 0.9999366/1.0	min: 6.347358e-05	loss: 34532.359375	train_loss: 34528.804397180415	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_749
Epoch: 749	max: 0.99994576/1.0	min: 5.4223914e-05	loss: 34533.0390625	train_loss: 34528.764624849035	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_750
Epoch: 750	max: 0.9999367/1.0	min: 6.334828e-05	loss: 34532.4609375	train_loss: 34528.78685800663	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_751
Epoch: 751	max: 0.99994004/1.0	min: 5.9989266e-05	loss: 34532.41015625	train_loss: 34528.71561890329	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_752
Epoch: 752	max: 0.99995065/1.0	min: 4.9316855e-05	loss: 34532.87890625	train_loss: 34528.69537056392	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_753
Epoch: 753	max: 0.9999261/1.0	min: 7.3909294e-05	loss: 34532.37890625	train_loss: 34528.68030830004	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_754
Epoch: 754	max: 0.99993384/1.0	min: 6.618797e-05	loss: 34532.57421875	train_loss: 34528.64558269076	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_755
Epoch: 755	max: 0.99992585/1.0	min: 7.413037e-05	loss: 34532.453125	train_loss: 34528.598982042764	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_756
Epoch: 756	max: 0.9999471/1.0	min: 5.28726e-05	loss: 34532.75	train_loss: 34528.58613830438	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_757
Epoch: 757	max: 0.9999293/1.0	min: 7.069264e-05	loss: 34532.12109375	train_loss: 34528.56669415026	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_758
Epoch: 758	max: 0.9999323/1.0	min: 6.765937e-05	loss: 34532.046875	train_loss: 34528.537694610895	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_759
Epoch: 759	max: 0.9999176/1.0	min: 8.236142e-05	loss: 34531.9296875	train_loss: 34528.530145333985	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_760
Epoch: 760	max: 0.9999372/1.0	min: 6.2797335e-05	loss: 34532.19921875	train_loss: 34528.54759257324	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_761
Epoch: 761	max: 0.9999428/1.0	min: 5.725182e-05	loss: 34532.421875	train_loss: 34528.44325897281	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_762
Epoch: 762	max: 0.99993575/1.0	min: 6.425947e-05	loss: 34532.07421875	train_loss: 34528.41951712111	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_763
Epoch: 763	max: 0.9999306/1.0	min: 6.9317284e-05	loss: 34532.2109375	train_loss: 34528.39587446194	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_764
Epoch: 764	max: 0.9999454/1.0	min: 5.4608852e-05	loss: 34532.5	train_loss: 34528.36461720395	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_765
Epoch: 765	max: 0.9999379/1.0	min: 6.208269e-05	loss: 34532.0390625	train_loss: 34528.36886457946	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_766
Epoch: 766	max: 0.99993086/1.0	min: 6.915711e-05	loss: 34532.33203125	train_loss: 34528.31639221789	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_767
Epoch: 767	max: 0.9999238/1.0	min: 7.613405e-05	loss: 34532.078125	train_loss: 34528.2744613604	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_768
Epoch: 768	max: 0.99993384/1.0	min: 6.617597e-05	loss: 34532.359375	train_loss: 34528.257842983556	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_769
Epoch: 769	max: 0.9999398/1.0	min: 6.022278e-05	loss: 34532.03125	train_loss: 34528.23689158692	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_770
Epoch: 770	max: 0.99993265/1.0	min: 6.736419e-05	loss: 34532.03125	train_loss: 34528.22011692137	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_771
Epoch: 771	max: 0.9999387/1.0	min: 6.132577e-05	loss: 34531.84375	train_loss: 34528.16820971525	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_772
Epoch: 772	max: 0.9999168/1.0	min: 8.316158e-05	loss: 34531.83203125	train_loss: 34528.16113559473	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_773
Epoch: 773	max: 0.9999312/1.0	min: 6.873783e-05	loss: 34532.34375	train_loss: 34528.161314141274	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_774
Epoch: 774	max: 0.9999019/1.0	min: 9.813318e-05	loss: 34531.9296875	train_loss: 34528.131926541406	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_775
Epoch: 775	max: 0.9999231/1.0	min: 7.683986e-05	loss: 34531.6640625	train_loss: 34528.10585632664	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_776
Epoch: 776	max: 0.9999465/1.0	min: 5.3500004e-05	loss: 34531.9765625	train_loss: 34528.08379639307	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_777
Epoch: 777	max: 0.9999391/1.0	min: 6.0920716e-05	loss: 34532.015625	train_loss: 34528.029238085284	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_778
Epoch: 778	max: 0.9999392/1.0	min: 6.084791e-05	loss: 34532.37109375	train_loss: 34528.01845416435	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_779
Epoch: 779	max: 0.9999131/1.0	min: 8.6860025e-05	loss: 34531.89453125	train_loss: 34527.98207566889	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_780
Epoch: 780	max: 0.99993/1.0	min: 7.002159e-05	loss: 34531.84375	train_loss: 34527.988657213864	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_781
Epoch: 781	max: 0.9999331/1.0	min: 6.685759e-05	loss: 34531.45703125	train_loss: 34527.94944761861	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_782
Epoch: 782	max: 0.9999385/1.0	min: 6.153331e-05	loss: 34531.8515625	train_loss: 34527.91703053388	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_783
Epoch: 783	max: 0.99993634/1.0	min: 6.367739e-05	loss: 34531.734375	train_loss: 34527.91023270082	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_784
Epoch: 784	max: 0.9999411/1.0	min: 5.8923702e-05	loss: 34532.03125	train_loss: 34527.85319167673	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_785
Epoch: 785	max: 0.99993/1.0	min: 6.999221e-05	loss: 34531.71875	train_loss: 34527.84534820931	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_786
Epoch: 786	max: 0.9999367/1.0	min: 6.334151e-05	loss: 34532.3359375	train_loss: 34527.829489502044	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_787
Epoch: 787	max: 0.9999409/1.0	min: 5.911376e-05	loss: 34532.140625	train_loss: 34527.80467395175	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_788
Epoch: 788	max: 0.9999274/1.0	min: 7.253919e-05	loss: 34531.68359375	train_loss: 34527.75644267543	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_789
Epoch: 789	max: 0.9999373/1.0	min: 6.271654e-05	loss: 34531.84765625	train_loss: 34527.75380173495	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_790
Epoch: 790	max: 0.9999372/1.0	min: 6.2797335e-05	loss: 34531.66015625	train_loss: 34527.694683474234	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_791
Epoch: 791	max: 0.9999571/1.0	min: 4.289955e-05	loss: 34531.98828125	train_loss: 34527.70192065759	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_792
Epoch: 792	max: 0.99995077/1.0	min: 4.9227157e-05	loss: 34531.55078125	train_loss: 34527.65636080531	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_793
Epoch: 793	max: 0.9999422/1.0	min: 5.7783305e-05	loss: 34531.68359375	train_loss: 34527.657303376225	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_794
Epoch: 794	max: 0.9999429/1.0	min: 5.705892e-05	loss: 34531.83984375	train_loss: 34527.605397137835	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_795
Epoch: 795	max: 0.9999354/1.0	min: 6.45608e-05	loss: 34531.390625	train_loss: 34527.58629846402	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_796
Epoch: 796	max: 0.999928/1.0	min: 7.197177e-05	loss: 34531.34375	train_loss: 34527.58439687074	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_797
Epoch: 797	max: 0.99993706/1.0	min: 6.2926934e-05	loss: 34531.51171875	train_loss: 34527.542017469495	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_798
Epoch: 798	max: 0.9999347/1.0	min: 6.532065e-05	loss: 34531.44140625	train_loss: 34527.51471388037	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_799
Epoch: 799	max: 0.99992263/1.0	min: 7.735709e-05	loss: 34531.30859375	train_loss: 34527.4963710052	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_800
Epoch: 800	max: 0.999926/1.0	min: 7.403331e-05	loss: 34531.3515625	train_loss: 34527.492153629384	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_801
Epoch: 801	max: 0.9999169/1.0	min: 8.309642e-05	loss: 34531.24609375	train_loss: 34527.45219888053	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_802
Epoch: 802	max: 0.9999274/1.0	min: 7.263548e-05	loss: 34531.46484375	train_loss: 34527.439819653475	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_803
Epoch: 803	max: 0.9999218/1.0	min: 7.813643e-05	loss: 34531.2734375	train_loss: 34527.40766434024	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_804
Epoch: 804	max: 0.99994504/1.0	min: 5.4945885e-05	loss: 34531.75	train_loss: 34527.42003679317	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_805
Epoch: 805	max: 0.9999212/1.0	min: 7.873525e-05	loss: 34531.15625	train_loss: 34527.34362758191	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_806
Epoch: 806	max: 0.9999329/1.0	min: 6.706569e-05	loss: 34531.38671875	train_loss: 34527.35371376811	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_807
Epoch: 807	max: 0.9999392/1.0	min: 6.082998e-05	loss: 34531.2265625	train_loss: 34527.32212167487	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_808
Epoch: 808	max: 0.9999449/1.0	min: 5.5093427e-05	loss: 34531.390625	train_loss: 34527.292807138765	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_809
Epoch: 809	max: 0.999938/1.0	min: 6.197823e-05	loss: 34531.13671875	train_loss: 34527.26632563793	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_810
Epoch: 810	max: 0.99994373/1.0	min: 5.6302157e-05	loss: 34531.10546875	train_loss: 34527.220970944814	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_811
Epoch: 811	max: 0.99994564/1.0	min: 5.432567e-05	loss: 34531.3984375	train_loss: 34527.200406640965	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_812
Epoch: 812	max: 0.9999323/1.0	min: 6.766731e-05	loss: 34531.1015625	train_loss: 34527.19075399867	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_813
Epoch: 813	max: 0.9999471/1.0	min: 5.2963747e-05	loss: 34531.19140625	train_loss: 34527.16603957637	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_814
Epoch: 814	max: 0.9999304/1.0	min: 6.9610665e-05	loss: 34531.03515625	train_loss: 34527.133674749166	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_815
Epoch: 815	max: 0.9999492/1.0	min: 5.082809e-05	loss: 34531.421875	train_loss: 34527.113496086495	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_816
Epoch: 816	max: 0.99994147/1.0	min: 5.853223e-05	loss: 34531.16015625	train_loss: 34527.09677561393	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_817
Epoch: 817	max: 0.99994326/1.0	min: 5.6731376e-05	loss: 34531.015625	train_loss: 34527.060965661	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_818
Epoch: 818	max: 0.99992895/1.0	min: 7.108039e-05	loss: 34530.83984375	train_loss: 34527.05051318825	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_819
Epoch: 819	max: 0.9999448/1.0	min: 5.516808e-05	loss: 34531.07421875	train_loss: 34527.01960431376	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_820
Epoch: 820	max: 0.9999192/1.0	min: 8.077191e-05	loss: 34530.7890625	train_loss: 34526.99527940357	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_821
Epoch: 821	max: 0.9999347/1.0	min: 6.532899e-05	loss: 34530.57421875	train_loss: 34526.9995122631	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_822
Epoch: 822	max: 0.9999269/1.0	min: 7.302879e-05	loss: 34530.6015625	train_loss: 34526.97632734114	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_823
Epoch: 823	max: 0.9999348/1.0	min: 6.519233e-05	loss: 34530.74609375	train_loss: 34526.97526864239	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_824
Epoch: 824	max: 0.99993753/1.0	min: 6.244786e-05	loss: 34531.109375	train_loss: 34526.89481915026	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_825
Epoch: 825	max: 0.9999385/1.0	min: 6.156354e-05	loss: 34530.828125	train_loss: 34526.87686917425	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_826
Epoch: 826	max: 0.99994206/1.0	min: 5.7923713e-05	loss: 34530.66796875	train_loss: 34526.85544939536	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_827
Epoch: 827	max: 0.99994254/1.0	min: 5.7399466e-05	loss: 34531.0234375	train_loss: 34526.82726662177	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_828
Epoch: 828	max: 0.99994576/1.0	min: 5.4180855e-05	loss: 34531.06640625	train_loss: 34526.83476944754	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_829
Epoch: 829	max: 0.9999423/1.0	min: 5.7718164e-05	loss: 34530.69921875	train_loss: 34526.81106727285	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_830
Epoch: 830	max: 0.9999356/1.0	min: 6.4344946e-05	loss: 34530.6640625	train_loss: 34526.76555145237	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_831
Epoch: 831	max: 0.9999441/1.0	min: 5.5955632e-05	loss: 34530.8203125	train_loss: 34526.74456666899	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_832
Epoch: 832	max: 0.99993575/1.0	min: 6.4259955e-05	loss: 34530.79296875	train_loss: 34526.73600756379	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_833
Epoch: 833	max: 0.9999362/1.0	min: 6.379227e-05	loss: 34530.5234375	train_loss: 34526.727058462624	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_834
Epoch: 834	max: 0.9999293/1.0	min: 7.065092e-05	loss: 34530.3203125	train_loss: 34526.696424907874	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_835
Epoch: 835	max: 0.9999372/1.0	min: 6.2772306e-05	loss: 34530.60546875	train_loss: 34526.70201210826	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_836
Epoch: 836	max: 0.9999244/1.0	min: 7.553758e-05	loss: 34530.40625	train_loss: 34526.63963307475	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_837
Epoch: 837	max: 0.99992836/1.0	min: 7.16962e-05	loss: 34530.3984375	train_loss: 34526.63580327558	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_838
Epoch: 838	max: 0.99992514/1.0	min: 7.4851225e-05	loss: 34530.2890625	train_loss: 34526.59896559132	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_839
Epoch: 839	max: 0.99994564/1.0	min: 5.435365e-05	loss: 34530.484375	train_loss: 34526.59712786836	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_840
Epoch: 840	max: 0.9999341/1.0	min: 6.5924214e-05	loss: 34530.625	train_loss: 34526.54722580283	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_841
Epoch: 841	max: 0.99994254/1.0	min: 5.7488272e-05	loss: 34530.42578125	train_loss: 34526.52696488294	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_842
Epoch: 842	max: 0.9999193/1.0	min: 8.0704165e-05	loss: 34530.17578125	train_loss: 34526.52714197789	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_843
Epoch: 843	max: 0.99994886/1.0	min: 5.1188774e-05	loss: 34530.8046875	train_loss: 34526.48736142078	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_844
Epoch: 844	max: 0.99993646/1.0	min: 6.348404e-05	loss: 34530.51171875	train_loss: 34526.54965384228	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_845
Epoch: 845	max: 0.999944/1.0	min: 5.6016816e-05	loss: 34530.59375	train_loss: 34526.44598700917	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_846
Epoch: 846	max: 0.9999442/1.0	min: 5.5834214e-05	loss: 34530.453125	train_loss: 34526.43680274914	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_847
Epoch: 847	max: 0.9999261/1.0	min: 7.385237e-05	loss: 34530.3203125	train_loss: 34526.401505694135	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_848
Epoch: 848	max: 0.99993753/1.0	min: 6.2459e-05	loss: 34530.109375	train_loss: 34526.381582512695	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_849
Epoch: 849	max: 0.99994516/1.0	min: 5.4815308e-05	loss: 34530.45703125	train_loss: 34526.36219351929	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_850
Epoch: 850	max: 0.9999387/1.0	min: 6.1296174e-05	loss: 34530.1015625	train_loss: 34526.347851247985	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_851
Epoch: 851	max: 0.9999275/1.0	min: 7.244186e-05	loss: 34530.26953125	train_loss: 34526.339382141865	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_852
Epoch: 852	max: 0.9999393/1.0	min: 6.070018e-05	loss: 34530.4140625	train_loss: 34526.28804831692	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_853
Epoch: 853	max: 0.9999367/1.0	min: 6.3276064e-05	loss: 34530.21484375	train_loss: 34526.26882335408	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_854
Epoch: 854	max: 0.9999348/1.0	min: 6.525329e-05	loss: 34530.09765625	train_loss: 34526.250885958594	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_855
Epoch: 855	max: 0.99993944/1.0	min: 6.0543338e-05	loss: 34529.96875	train_loss: 34526.227562650965	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_856
Epoch: 856	max: 0.9999237/1.0	min: 7.633026e-05	loss: 34529.8984375	train_loss: 34526.21874758067	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_857
Epoch: 857	max: 0.9999386/1.0	min: 6.141378e-05	loss: 34529.78125	train_loss: 34526.24445779915	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_858
Epoch: 858	max: 0.99994206/1.0	min: 5.791046e-05	loss: 34529.984375	train_loss: 34526.18383181206	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_859
Epoch: 859	max: 0.99991965/1.0	min: 8.029554e-05	loss: 34529.62109375	train_loss: 34526.16106930509	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_860
Epoch: 860	max: 0.99995136/1.0	min: 4.8669957e-05	loss: 34530.171875	train_loss: 34526.175260610216	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_861
Epoch: 861	max: 0.99994075/1.0	min: 5.9196736e-05	loss: 34529.765625	train_loss: 34526.09631013486	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_862
Epoch: 862	max: 0.99994946/1.0	min: 5.0498584e-05	loss: 34530.125	train_loss: 34526.1040524743	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_863
Epoch: 863	max: 0.99994195/1.0	min: 5.8077036e-05	loss: 34529.9296875	train_loss: 34526.05514523721	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_864
Epoch: 864	max: 0.9999504/1.0	min: 4.9580784e-05	loss: 34530.5390625	train_loss: 34526.054573791494	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_865
Epoch: 865	max: 0.99994016/1.0	min: 5.987177e-05	loss: 34529.96484375	train_loss: 34526.05224542844	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_866
Epoch: 866	max: 0.99993396/1.0	min: 6.6076405e-05	loss: 34529.9296875	train_loss: 34526.000943538646	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_867
Epoch: 867	max: 0.99993277/1.0	min: 6.7187386e-05	loss: 34529.8515625	train_loss: 34525.98373339372	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_868
Epoch: 868	max: 0.9999492/1.0	min: 5.075732e-05	loss: 34530.07421875	train_loss: 34525.95762011489	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_869
Epoch: 869	max: 0.99993443/1.0	min: 6.556491e-05	loss: 34529.82421875	train_loss: 34525.93167425368	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_870
Epoch: 870	max: 0.99994326/1.0	min: 5.6706336e-05	loss: 34530.06640625	train_loss: 34525.911392043694	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_871
Epoch: 871	max: 0.99993587/1.0	min: 6.4090855e-05	loss: 34529.71484375	train_loss: 34525.90954174021	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_872
Epoch: 872	max: 0.9999442/1.0	min: 5.5843855e-05	loss: 34529.8359375	train_loss: 34525.8738367862	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_873
Epoch: 873	max: 0.99994016/1.0	min: 5.9863312e-05	loss: 34529.52734375	train_loss: 34525.85077137913	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_874
Epoch: 874	max: 0.999926/1.0	min: 7.407164e-05	loss: 34529.6015625	train_loss: 34525.84863075607	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_875
Epoch: 875	max: 0.9999361/1.0	min: 6.3919055e-05	loss: 34529.64453125	train_loss: 34525.82604244085	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_876
Epoch: 876	max: 0.99992216/1.0	min: 7.782619e-05	loss: 34529.49609375	train_loss: 34525.80386444398	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_877
Epoch: 877	max: 0.9999434/1.0	min: 5.6668552e-05	loss: 34529.87109375	train_loss: 34525.7796730808	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_878
Epoch: 878	max: 0.99995863/1.0	min: 4.1393538e-05	loss: 34529.890625	train_loss: 34525.77604021507	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_879
Epoch: 879	max: 0.9999418/1.0	min: 5.8158006e-05	loss: 34529.75390625	train_loss: 34525.75153966153	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_880
Epoch: 880	max: 0.99994004/1.0	min: 5.9911745e-05	loss: 34529.30859375	train_loss: 34525.70175517543	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_881
Epoch: 881	max: 0.999938/1.0	min: 6.199644e-05	loss: 34529.65625	train_loss: 34525.70456063034	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_882
Epoch: 882	max: 0.99993217/1.0	min: 6.782573e-05	loss: 34529.796875	train_loss: 34525.685760017965	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_883
Epoch: 883	max: 0.9999169/1.0	min: 8.305997e-05	loss: 34529.50390625	train_loss: 34525.668541163446	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_884
Epoch: 884	max: 0.9999343/1.0	min: 6.565106e-05	loss: 34529.94140625	train_loss: 34525.63874808389	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_885
Epoch: 885	max: 0.9999366/1.0	min: 6.3381995e-05	loss: 34529.9140625	train_loss: 34525.67012582451	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_886
Epoch: 886	max: 0.9999341/1.0	min: 6.5945285e-05	loss: 34529.578125	train_loss: 34525.61850942184	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_887
Epoch: 887	max: 0.9999305/1.0	min: 6.953849e-05	loss: 34529.609375	train_loss: 34525.56702801777	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_888
Epoch: 888	max: 0.9999199/1.0	min: 8.010969e-05	loss: 34529.328125	train_loss: 34525.56081372708	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_889
Epoch: 889	max: 0.9999217/1.0	min: 7.828082e-05	loss: 34529.03125	train_loss: 34525.538716535826	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_890
Epoch: 890	max: 0.99992967/1.0	min: 7.034256e-05	loss: 34529.5	train_loss: 34525.59031455159	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_891
Epoch: 891	max: 0.9999218/1.0	min: 7.817176e-05	loss: 34529.37890625	train_loss: 34525.563012414066	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_892
Epoch: 892	max: 0.9999349/1.0	min: 6.511653e-05	loss: 34529.26171875	train_loss: 34525.49275217159	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_893
Epoch: 893	max: 0.99992764/1.0	min: 7.240346e-05	loss: 34529.38671875	train_loss: 34525.46562906447	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_894
Epoch: 894	max: 0.9999291/1.0	min: 7.08976e-05	loss: 34529.44140625	train_loss: 34525.49131412192	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_895
Epoch: 895	max: 0.99995065/1.0	min: 4.933572e-05	loss: 34529.30859375	train_loss: 34525.442385110866	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_896
Epoch: 896	max: 0.999941/1.0	min: 5.895855e-05	loss: 34529.234375	train_loss: 34525.40667628592	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_897
Epoch: 897	max: 0.9999373/1.0	min: 6.269992e-05	loss: 34529.22265625	train_loss: 34525.38222024805	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_898
Epoch: 898	max: 0.99994695/1.0	min: 5.3019634e-05	loss: 34529.17578125	train_loss: 34525.385759727644	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_899
Epoch: 899	max: 0.9999516/1.0	min: 4.8378475e-05	loss: 34529.44921875	train_loss: 34525.35471537068	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_900
Epoch: 900	max: 0.99995375/1.0	min: 4.623661e-05	loss: 34529.3359375	train_loss: 34525.328161289945	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_901
Epoch: 901	max: 0.9999385/1.0	min: 6.1529965e-05	loss: 34528.91015625	train_loss: 34525.30110108541	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_902
Epoch: 902	max: 0.99994826/1.0	min: 5.176306e-05	loss: 34529.07421875	train_loss: 34525.29871756162	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_903
Epoch: 903	max: 0.99994063/1.0	min: 5.9347716e-05	loss: 34529.0859375	train_loss: 34525.318098329306	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_904
Epoch: 904	max: 0.9999447/1.0	min: 5.5254317e-05	loss: 34529.09765625	train_loss: 34525.248281308064	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_905
Epoch: 905	max: 0.9999515/1.0	min: 4.8564438e-05	loss: 34529.6640625	train_loss: 34525.25725411867	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_906
Epoch: 906	max: 0.99993646/1.0	min: 6.356528e-05	loss: 34528.6484375	train_loss: 34525.27207493342	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_907
Epoch: 907	max: 0.9999331/1.0	min: 6.6894965e-05	loss: 34528.94921875	train_loss: 34525.2146105266	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_908
Epoch: 908	max: 0.999946/1.0	min: 5.402293e-05	loss: 34528.9453125	train_loss: 34525.21199813421	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_909
Epoch: 909	max: 0.9999337/1.0	min: 6.6309265e-05	loss: 34528.6796875	train_loss: 34525.164561849684	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_910
Epoch: 910	max: 0.99992895/1.0	min: 7.101344e-05	loss: 34528.81640625	train_loss: 34525.151599080265	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_911
Epoch: 911	max: 0.99994993/1.0	min: 5.001635e-05	loss: 34529.1953125	train_loss: 34525.127827228884	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_912
Epoch: 912	max: 0.9999403/1.0	min: 5.9719405e-05	loss: 34528.8046875	train_loss: 34525.11388463087	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_913
Epoch: 913	max: 0.9999361/1.0	min: 6.3900276e-05	loss: 34528.53125	train_loss: 34525.07292924718	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_914
Epoch: 914	max: 0.99992764/1.0	min: 7.2395735e-05	loss: 34528.83984375	train_loss: 34525.10183927134	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_915
Epoch: 915	max: 0.99993944/1.0	min: 6.0508995e-05	loss: 34528.99609375	train_loss: 34525.05691231575	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_916
Epoch: 916	max: 0.9999434/1.0	min: 5.6575835e-05	loss: 34529.14453125	train_loss: 34525.021974289295	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_917
Epoch: 917	max: 0.99993706/1.0	min: 6.2943196e-05	loss: 34528.71875	train_loss: 34524.99519182383	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_918
Epoch: 918	max: 0.9999436/1.0	min: 5.6432888e-05	loss: 34528.8359375	train_loss: 34524.989687848385	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_919
Epoch: 919	max: 0.9999372/1.0	min: 6.276859e-05	loss: 34529.00390625	train_loss: 34524.98541579571	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_920
Epoch: 920	max: 0.9999505/1.0	min: 4.94664e-05	loss: 34528.8515625	train_loss: 34524.94041964728	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_921
Epoch: 921	max: 0.9999498/1.0	min: 5.0235238e-05	loss: 34528.6796875	train_loss: 34524.932947788926	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_922
Epoch: 922	max: 0.99994147/1.0	min: 5.8568527e-05	loss: 34528.51171875	train_loss: 34524.91260993435	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_923
Epoch: 923	max: 0.99992514/1.0	min: 7.4872856e-05	loss: 34528.3515625	train_loss: 34524.91608264044	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_924
Epoch: 924	max: 0.9999393/1.0	min: 6.0617404e-05	loss: 34528.3203125	train_loss: 34524.924069332184	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_925
Epoch: 925	max: 0.999951/1.0	min: 4.894018e-05	loss: 34528.34375	train_loss: 34524.89787137681	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_926
Epoch: 926	max: 0.999938/1.0	min: 6.195565e-05	loss: 34528.546875	train_loss: 34524.881530255174	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_927
Epoch: 927	max: 0.9999269/1.0	min: 7.3126495e-05	loss: 34528.2890625	train_loss: 34524.8453796606	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_928
Epoch: 928	max: 0.99994004/1.0	min: 5.9918486e-05	loss: 34528.3515625	train_loss: 34524.80774650068	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_929
Epoch: 929	max: 0.9999405/1.0	min: 5.9467646e-05	loss: 34528.390625	train_loss: 34524.785015445	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_930
Epoch: 930	max: 0.9999486/1.0	min: 5.139112e-05	loss: 34528.4140625	train_loss: 34524.76755852843	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_931
Epoch: 931	max: 0.99995315/1.0	min: 4.6839017e-05	loss: 34528.94921875	train_loss: 34524.76421065976	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_932
Epoch: 932	max: 0.99994826/1.0	min: 5.1770072e-05	loss: 34528.67578125	train_loss: 34524.73467693237	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_933
Epoch: 933	max: 0.99995244/1.0	min: 4.7545884e-05	loss: 34528.5	train_loss: 34524.718986126594	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_934
Epoch: 934	max: 0.99994516/1.0	min: 5.4792676e-05	loss: 34528.28125	train_loss: 34524.69757602502	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_935
Epoch: 935	max: 0.99993753/1.0	min: 6.2470324e-05	loss: 34528.515625	train_loss: 34524.68958159142	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_936
Epoch: 936	max: 0.99995613/1.0	min: 4.3894484e-05	loss: 34529.09375	train_loss: 34524.66408185464	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_937
Epoch: 937	max: 0.9999517/1.0	min: 4.8323152e-05	loss: 34528.71484375	train_loss: 34524.66180478137	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_938
Epoch: 938	max: 0.9999491/1.0	min: 5.09344e-05	loss: 34528.40625	train_loss: 34524.63209589449	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_939
Epoch: 939	max: 0.999938/1.0	min: 6.193262e-05	loss: 34528.3359375	train_loss: 34524.65726757014	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_940
Epoch: 940	max: 0.9999231/1.0	min: 7.684844e-05	loss: 34528.109375	train_loss: 34524.60518907547	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_941
Epoch: 941	max: 0.9999405/1.0	min: 5.9473263e-05	loss: 34528.52734375	train_loss: 34524.56584399774	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_942
Epoch: 942	max: 0.999959/1.0	min: 4.1048563e-05	loss: 34529.0859375	train_loss: 34524.5774708132	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_943
Epoch: 943	max: 0.9999478/1.0	min: 5.224031e-05	loss: 34528.484375	train_loss: 34524.591445830236	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_944
Epoch: 944	max: 0.9999397/1.0	min: 6.0287766e-05	loss: 34528.296875	train_loss: 34524.528715026165	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_945
Epoch: 945	max: 0.9999541/1.0	min: 4.5851924e-05	loss: 34528.2265625	train_loss: 34524.4921434682	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_946
Epoch: 946	max: 0.9999448/1.0	min: 5.521745e-05	loss: 34528.140625	train_loss: 34524.48166244735	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_947
Epoch: 947	max: 0.9999459/1.0	min: 5.4096854e-05	loss: 34528.015625	train_loss: 34524.4649603617	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_948
Epoch: 948	max: 0.9999478/1.0	min: 5.2171155e-05	loss: 34528.359375	train_loss: 34524.46174604004	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_949
Epoch: 949	max: 0.9999306/1.0	min: 6.942015e-05	loss: 34528.33203125	train_loss: 34524.43606969219	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_950
Epoch: 950	max: 0.9999249/1.0	min: 7.509101e-05	loss: 34528.16015625	train_loss: 34524.413175573674	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_951
Epoch: 951	max: 0.99994516/1.0	min: 5.4810756e-05	loss: 34527.85546875	train_loss: 34524.427093494516	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_952
Epoch: 952	max: 0.9999571/1.0	min: 4.2966534e-05	loss: 34528.359375	train_loss: 34524.410353667314	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_953
Epoch: 953	max: 0.9999485/1.0	min: 5.1484807e-05	loss: 34528.66015625	train_loss: 34524.378121419395	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_954
Epoch: 954	max: 0.99995077/1.0	min: 4.919735e-05	loss: 34528.30859375	train_loss: 34524.37581531417	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_955
Epoch: 955	max: 0.9999442/1.0	min: 5.5783228e-05	loss: 34528.17578125	train_loss: 34524.33364639462	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_956
Epoch: 956	max: 0.9999486/1.0	min: 5.139671e-05	loss: 34528.140625	train_loss: 34524.31548303372	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_957
Epoch: 957	max: 0.99993455/1.0	min: 6.538322e-05	loss: 34527.8359375	train_loss: 34524.28169951149	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_958
Epoch: 958	max: 0.9999249/1.0	min: 7.506172e-05	loss: 34527.765625	train_loss: 34524.29452679843	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_959
Epoch: 959	max: 0.9999286/1.0	min: 7.14024e-05	loss: 34528.0	train_loss: 34524.28641672086	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_960
Epoch: 960	max: 0.9999292/1.0	min: 7.0863265e-05	loss: 34528.03125	train_loss: 34524.24606616964	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_961
Epoch: 961	max: 0.99994874/1.0	min: 5.122696e-05	loss: 34527.94140625	train_loss: 34524.2393733355	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_962
Epoch: 962	max: 0.9999368/1.0	min: 6.314454e-05	loss: 34527.734375	train_loss: 34524.210152669395	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_963
Epoch: 963	max: 0.9999503/1.0	min: 4.969183e-05	loss: 34528.1640625	train_loss: 34524.19533040304	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_964
Epoch: 964	max: 0.9999448/1.0	min: 5.513983e-05	loss: 34528.0390625	train_loss: 34524.18113571086	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_965
Epoch: 965	max: 0.99994826/1.0	min: 5.171362e-05	loss: 34527.984375	train_loss: 34524.16465136489	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_966
Epoch: 966	max: 0.9999442/1.0	min: 5.5733184e-05	loss: 34527.9375	train_loss: 34524.13149154589	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_967
Epoch: 967	max: 0.9999286/1.0	min: 7.140253e-05	loss: 34527.703125	train_loss: 34524.11288254444	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_968
Epoch: 968	max: 0.999933/1.0	min: 6.6932866e-05	loss: 34527.73828125	train_loss: 34524.104026345536	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_969
Epoch: 969	max: 0.9999424/1.0	min: 5.759857e-05	loss: 34527.515625	train_loss: 34524.10246007138	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_970
Epoch: 970	max: 0.9999511/1.0	min: 4.8884347e-05	loss: 34527.77734375	train_loss: 34524.147295092436	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_971
Epoch: 971	max: 0.99993/1.0	min: 6.996965e-05	loss: 34527.9140625	train_loss: 34524.04554678791	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_972
Epoch: 972	max: 0.9999391/1.0	min: 6.085957e-05	loss: 34527.78515625	train_loss: 34524.046761291494	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_973
Epoch: 973	max: 0.9999566/1.0	min: 4.335371e-05	loss: 34527.78515625	train_loss: 34524.01848513177	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_974
Epoch: 974	max: 0.99994874/1.0	min: 5.1227595e-05	loss: 34527.71875	train_loss: 34524.04203779187	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_975
Epoch: 975	max: 0.99995637/1.0	min: 4.363206e-05	loss: 34527.94140625	train_loss: 34523.999081138514	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_976
Epoch: 976	max: 0.9999471/1.0	min: 5.2966217e-05	loss: 34527.62890625	train_loss: 34524.020563819984	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_977
Epoch: 977	max: 0.9999509/1.0	min: 4.9149105e-05	loss: 34527.921875	train_loss: 34524.007914111855	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_978
Epoch: 978	max: 0.9999423/1.0	min: 5.76781e-05	loss: 34527.46875	train_loss: 34523.94505556717	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_979
Epoch: 979	max: 0.99993503/1.0	min: 6.491899e-05	loss: 34527.4453125	train_loss: 34523.92953653382	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_980
Epoch: 980	max: 0.9999466/1.0	min: 5.3353066e-05	loss: 34527.62109375	train_loss: 34523.90793095039	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_981
Epoch: 981	max: 0.99994636/1.0	min: 5.3672826e-05	loss: 34527.7890625	train_loss: 34523.89919716958	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_982
Epoch: 982	max: 0.9999386/1.0	min: 6.138579e-05	loss: 34527.81640625	train_loss: 34523.88330217236	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_983
Epoch: 983	max: 0.99993753/1.0	min: 6.25137e-05	loss: 34527.515625	train_loss: 34523.863197541184	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_984
Epoch: 984	max: 0.999928/1.0	min: 7.201633e-05	loss: 34527.6328125	train_loss: 34523.85738485925	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_985
Epoch: 985	max: 0.9999497/1.0	min: 5.0299896e-05	loss: 34527.41015625	train_loss: 34523.8513534699	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_986
Epoch: 986	max: 0.99995923/1.0	min: 4.0737013e-05	loss: 34527.94140625	train_loss: 34523.8302409459	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_987
Epoch: 987	max: 0.9999577/1.0	min: 4.237415e-05	loss: 34527.5859375	train_loss: 34523.80705989487	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_988
Epoch: 988	max: 0.99993384/1.0	min: 6.612815e-05	loss: 34527.3046875	train_loss: 34523.79790466679	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_989
Epoch: 989	max: 0.9999554/1.0	min: 4.453669e-05	loss: 34527.65625	train_loss: 34523.760554084605	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_990
Epoch: 990	max: 0.99992645/1.0	min: 7.3543284e-05	loss: 34527.30859375	train_loss: 34523.77683423913	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_991
Epoch: 991	max: 0.9999337/1.0	min: 6.6229826e-05	loss: 34527.30078125	train_loss: 34523.76375776121	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_992
Epoch: 992	max: 0.999948/1.0	min: 5.1987998e-05	loss: 34527.26953125	train_loss: 34523.73347404156	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_993
Epoch: 993	max: 0.9999467/1.0	min: 5.331909e-05	loss: 34527.40234375	train_loss: 34523.7252115462	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_994
Epoch: 994	max: 0.9999305/1.0	min: 6.9436304e-05	loss: 34527.13671875	train_loss: 34523.689825459864	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_995
Epoch: 995	max: 0.9999386/1.0	min: 6.137643e-05	loss: 34527.47265625	train_loss: 34523.69406170646	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_996
Epoch: 996	max: 0.9999325/1.0	min: 6.7449495e-05	loss: 34527.51171875	train_loss: 34523.669998567755	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_997
Epoch: 997	max: 0.99993265/1.0	min: 6.7384564e-05	loss: 34527.64453125	train_loss: 34523.66487345937	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_998
Epoch: 998	max: 0.99994504/1.0	min: 5.5010845e-05	loss: 34527.44921875	train_loss: 34523.629702209524	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_999
Epoch: 999	max: 0.9999336/1.0	min: 6.641982e-05	loss: 34527.328125	train_loss: 34523.61053918153	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1000
Epoch: 1000	max: 0.99994135/1.0	min: 5.866674e-05	loss: 34527.80859375	train_loss: 34523.60410618342	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1001
Epoch: 1001	max: 0.9999293/1.0	min: 7.0644724e-05	loss: 34527.04296875	train_loss: 34523.60193556066	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1002
Epoch: 1002	max: 0.9999566/1.0	min: 4.335276e-05	loss: 34527.84375	train_loss: 34523.57306569738	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1003
Epoch: 1003	max: 0.99995613/1.0	min: 4.391089e-05	loss: 34527.48828125	train_loss: 34523.628885443766	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1004
Epoch: 1004	max: 0.9999393/1.0	min: 6.06904e-05	loss: 34527.47265625	train_loss: 34523.56252854809	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1005
Epoch: 1005	max: 0.9999567/1.0	min: 4.3323544e-05	loss: 34528.171875	train_loss: 34523.557049249815	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1006
Epoch: 1006	max: 0.99994326/1.0	min: 5.6701847e-05	loss: 34527.484375	train_loss: 34523.59270388177	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1007
Epoch: 1007	max: 0.9999343/1.0	min: 6.573539e-05	loss: 34527.28515625	train_loss: 34523.54129167054	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1008
Epoch: 1008	max: 0.9999348/1.0	min: 6.5219385e-05	loss: 34527.16015625	train_loss: 34523.507223151246	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1009
Epoch: 1009	max: 0.9999529/1.0	min: 4.7038564e-05	loss: 34527.34375	train_loss: 34523.46802226557	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1010
Epoch: 1010	max: 0.99993944/1.0	min: 6.0587292e-05	loss: 34527.1796875	train_loss: 34523.471366263315	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1011
Epoch: 1011	max: 0.99995446/1.0	min: 4.548618e-05	loss: 34527.06640625	train_loss: 34523.45590964868	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1012
Epoch: 1012	max: 0.99993694/1.0	min: 6.3006795e-05	loss: 34527.30078125	train_loss: 34523.42825815992	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1013
Epoch: 1013	max: 0.99991274/1.0	min: 8.719788e-05	loss: 34526.953125	train_loss: 34523.41362266583	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1014
Epoch: 1014	max: 0.9999422/1.0	min: 5.785543e-05	loss: 34526.99609375	train_loss: 34523.428923959495	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1015
Epoch: 1015	max: 0.9999454/1.0	min: 5.464063e-05	loss: 34527.34375	train_loss: 34523.37999156138	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1016
Epoch: 1016	max: 0.99993455/1.0	min: 6.538278e-05	loss: 34527.203125	train_loss: 34523.389184531	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1017
Epoch: 1017	max: 0.999931/1.0	min: 6.905378e-05	loss: 34527.01171875	train_loss: 34523.37600402189	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1018
Epoch: 1018	max: 0.99993646/1.0	min: 6.358517e-05	loss: 34527.01171875	train_loss: 34523.345677722034	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1019
Epoch: 1019	max: 0.99992824/1.0	min: 7.175605e-05	loss: 34527.21875	train_loss: 34523.327954679175	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1020
Epoch: 1020	max: 0.99993813/1.0	min: 6.184267e-05	loss: 34526.7734375	train_loss: 34523.35054154279	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1021
Epoch: 1021	max: 0.9999355/1.0	min: 6.443447e-05	loss: 34526.94140625	train_loss: 34523.34090148102	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1022
Epoch: 1022	max: 0.9999474/1.0	min: 5.260194e-05	loss: 34527.078125	train_loss: 34523.2856909219	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1023
Epoch: 1023	max: 0.9999467/1.0	min: 5.331309e-05	loss: 34526.890625	train_loss: 34523.2715547775	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1024
Epoch: 1024	max: 0.999944/1.0	min: 5.6069246e-05	loss: 34527.078125	train_loss: 34523.27048059504	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1025
Epoch: 1025	max: 0.99994755/1.0	min: 5.239422e-05	loss: 34526.875	train_loss: 34523.26001021925	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1026
Epoch: 1026	max: 0.9999511/1.0	min: 4.885042e-05	loss: 34527.0234375	train_loss: 34523.24442779946	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1027
Epoch: 1027	max: 0.99994564/1.0	min: 5.4409717e-05	loss: 34526.69140625	train_loss: 34523.23292098275	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1028
Epoch: 1028	max: 0.9999528/1.0	min: 4.7168876e-05	loss: 34526.80078125	train_loss: 34523.22379768983	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1029
Epoch: 1029	max: 0.9999207/1.0	min: 7.9243684e-05	loss: 34526.546875	train_loss: 34523.2114494302	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1030
Epoch: 1030	max: 0.9999335/1.0	min: 6.651864e-05	loss: 34526.53125	train_loss: 34523.23345226759	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1031
Epoch: 1031	max: 0.9999523/1.0	min: 4.7731963e-05	loss: 34526.94921875	train_loss: 34523.22132465084	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1032
Epoch: 1032	max: 0.9999238/1.0	min: 7.614058e-05	loss: 34526.671875	train_loss: 34523.19823843754	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1033
Epoch: 1033	max: 0.999941/1.0	min: 5.8990718e-05	loss: 34526.88671875	train_loss: 34523.26596564164	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1034
Epoch: 1034	max: 0.99994314/1.0	min: 5.683545e-05	loss: 34527.02734375	train_loss: 34523.19308042627	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1035
Epoch: 1035	max: 0.99994814/1.0	min: 5.1848034e-05	loss: 34526.85546875	train_loss: 34523.123521305584	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1036
Epoch: 1036	max: 0.99994063/1.0	min: 5.932966e-05	loss: 34526.76171875	train_loss: 34523.107306472964	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1037
Epoch: 1037	max: 0.9999554/1.0	min: 4.453053e-05	loss: 34527.1796875	train_loss: 34523.10768098523	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1038
Epoch: 1038	max: 0.9999349/1.0	min: 6.5143366e-05	loss: 34526.46484375	train_loss: 34523.076087440386	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1039
Epoch: 1039	max: 0.9999473/1.0	min: 5.2746203e-05	loss: 34526.8515625	train_loss: 34523.10299619488	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1040
Epoch: 1040	max: 0.99992764/1.0	min: 7.237143e-05	loss: 34526.69921875	train_loss: 34523.04076715982	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1041
Epoch: 1041	max: 0.9999279/1.0	min: 7.213882e-05	loss: 34526.515625	train_loss: 34523.04633452171	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1042
Epoch: 1042	max: 0.9999348/1.0	min: 6.521945e-05	loss: 34526.8046875	train_loss: 34523.030995970366	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1043
Epoch: 1043	max: 0.999925/1.0	min: 7.5033466e-05	loss: 34526.59375	train_loss: 34523.01623031633	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1044
Epoch: 1044	max: 0.9999429/1.0	min: 5.7075576e-05	loss: 34526.75390625	train_loss: 34523.00351625402	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1045
Epoch: 1045	max: 0.99994886/1.0	min: 5.110771e-05	loss: 34526.73046875	train_loss: 34523.000685638086	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1046
Epoch: 1046	max: 0.9999229/1.0	min: 7.710889e-05	loss: 34526.80078125	train_loss: 34523.00911990586	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1047
Epoch: 1047	max: 0.9999442/1.0	min: 5.5784927e-05	loss: 34526.94921875	train_loss: 34522.981314547724	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1048
Epoch: 1048	max: 0.9999559/1.0	min: 4.4099354e-05	loss: 34527.14453125	train_loss: 34522.96440585129	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1049
Epoch: 1049	max: 0.99993765/1.0	min: 6.2317464e-05	loss: 34526.578125	train_loss: 34522.97481671157	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1050
Epoch: 1050	max: 0.99991727/1.0	min: 8.278378e-05	loss: 34526.36328125	train_loss: 34522.939203208225	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1051
Epoch: 1051	max: 0.9999317/1.0	min: 6.829171e-05	loss: 34526.5546875	train_loss: 34522.96382859919	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1052
Epoch: 1052	max: 0.9999552/1.0	min: 4.4801138e-05	loss: 34527.1953125	train_loss: 34522.915035070604	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1053
Epoch: 1053	max: 0.9999441/1.0	min: 5.5934506e-05	loss: 34527.0703125	train_loss: 34522.91852955066	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1054
Epoch: 1054	max: 0.9999305/1.0	min: 6.950176e-05	loss: 34526.671875	train_loss: 34522.898177180105	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1055
Epoch: 1055	max: 0.9999305/1.0	min: 6.946597e-05	loss: 34526.50390625	train_loss: 34522.90455985616	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1056
Epoch: 1056	max: 0.9999397/1.0	min: 6.0271268e-05	loss: 34526.578125	train_loss: 34522.862805125886	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1057
Epoch: 1057	max: 0.9999403/1.0	min: 5.97716e-05	loss: 34526.5	train_loss: 34522.83885279249	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1058
Epoch: 1058	max: 0.99993336/1.0	min: 6.657499e-05	loss: 34526.4140625	train_loss: 34522.82197845054	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1059
Epoch: 1059	max: 0.9999473/1.0	min: 5.273363e-05	loss: 34526.5234375	train_loss: 34522.82056798123	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1060
Epoch: 1060	max: 0.9999478/1.0	min: 5.2153893e-05	loss: 34526.6640625	train_loss: 34522.80964857782	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1061
Epoch: 1061	max: 0.99995434/1.0	min: 4.5706813e-05	loss: 34526.69140625	train_loss: 34522.810114540756	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1062
Epoch: 1062	max: 0.9999237/1.0	min: 7.6335644e-05	loss: 34526.34765625	train_loss: 34522.79194247027	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1063
Epoch: 1063	max: 0.9999293/1.0	min: 7.071233e-05	loss: 34526.30859375	train_loss: 34522.80067721882	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1064
Epoch: 1064	max: 0.9999366/1.0	min: 6.343157e-05	loss: 34526.390625	train_loss: 34522.776081343676	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1065
Epoch: 1065	max: 0.99993443/1.0	min: 6.559074e-05	loss: 34526.32421875	train_loss: 34522.76891383702	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1066
Epoch: 1066	max: 0.9999461/1.0	min: 5.3820637e-05	loss: 34526.55078125	train_loss: 34522.73559772931	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1067
Epoch: 1067	max: 0.9999356/1.0	min: 6.440867e-05	loss: 34526.39453125	train_loss: 34522.72072417317	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1068
Epoch: 1068	max: 0.99993825/1.0	min: 6.1781844e-05	loss: 34526.40625	train_loss: 34522.71875338706	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1069
Epoch: 1069	max: 0.9999542/1.0	min: 4.5772544e-05	loss: 34527.1015625	train_loss: 34522.71174362071	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1070
Epoch: 1070	max: 0.99993885/1.0	min: 6.1194325e-05	loss: 34526.40625	train_loss: 34522.73545789205	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1071
Epoch: 1071	max: 0.99993885/1.0	min: 6.113879e-05	loss: 34526.25390625	train_loss: 34522.6906654512	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1072
Epoch: 1072	max: 0.9999268/1.0	min: 7.319682e-05	loss: 34526.31640625	train_loss: 34522.65474517683	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1073
Epoch: 1073	max: 0.9999285/1.0	min: 7.1489056e-05	loss: 34525.99609375	train_loss: 34522.6666903761	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1074
Epoch: 1074	max: 0.99991786/1.0	min: 8.2108505e-05	loss: 34526.23828125	train_loss: 34522.68917078921	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1075
Epoch: 1075	max: 0.9999434/1.0	min: 5.6620367e-05	loss: 34526.24609375	train_loss: 34522.66225622832	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1076
Epoch: 1076	max: 0.99994755/1.0	min: 5.2454165e-05	loss: 34526.20703125	train_loss: 34522.621662776386	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1077
Epoch: 1077	max: 0.9999411/1.0	min: 5.8895053e-05	loss: 34526.2109375	train_loss: 34522.596754807695	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1078
Epoch: 1078	max: 0.99993086/1.0	min: 6.911774e-05	loss: 34526.06640625	train_loss: 34522.62652417782	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1079
Epoch: 1079	max: 0.99993753/1.0	min: 6.246728e-05	loss: 34526.26171875	train_loss: 34522.586656524836	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1080
Epoch: 1080	max: 0.9999293/1.0	min: 7.073203e-05	loss: 34526.0859375	train_loss: 34522.55043673743	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1081
Epoch: 1081	max: 0.99993396/1.0	min: 6.60512e-05	loss: 34526.05859375	train_loss: 34522.58648668788	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1082
Epoch: 1082	max: 0.99993896/1.0	min: 6.1006172e-05	loss: 34526.171875	train_loss: 34522.5401061989	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1083
Epoch: 1083	max: 0.9999565/1.0	min: 4.3554905e-05	loss: 34526.484375	train_loss: 34522.55553232999	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1084
Epoch: 1084	max: 0.99994934/1.0	min: 5.067022e-05	loss: 34526.46875	train_loss: 34522.55490136876	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1085
Epoch: 1085	max: 0.9999341/1.0	min: 6.591523e-05	loss: 34526.15625	train_loss: 34522.50111966586	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1086
Epoch: 1086	max: 0.9999337/1.0	min: 6.632381e-05	loss: 34526.23046875	train_loss: 34522.4861851426	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1087
Epoch: 1087	max: 0.9999397/1.0	min: 6.035329e-05	loss: 34526.19921875	train_loss: 34522.50007016057	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1088
Epoch: 1088	max: 0.99993384/1.0	min: 6.616259e-05	loss: 34526.34375	train_loss: 34522.456174323364	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1089
Epoch: 1089	max: 0.99993193/1.0	min: 6.8085195e-05	loss: 34526.23046875	train_loss: 34522.48924075622	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1090
Epoch: 1090	max: 0.9999343/1.0	min: 6.5639106e-05	loss: 34526.01953125	train_loss: 34522.434248420665	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1091
Epoch: 1091	max: 0.9999528/1.0	min: 4.7227662e-05	loss: 34526.45703125	train_loss: 34522.4363382378	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1092
Epoch: 1092	max: 0.99993813/1.0	min: 6.185624e-05	loss: 34526.43359375	train_loss: 34522.44007465084	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1093
Epoch: 1093	max: 0.99992955/1.0	min: 7.039093e-05	loss: 34526.38671875	train_loss: 34522.41059801963	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1094
Epoch: 1094	max: 0.99994826/1.0	min: 5.1765233e-05	loss: 34526.25390625	train_loss: 34522.397451865014	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1095
Epoch: 1095	max: 0.99994457/1.0	min: 5.5452798e-05	loss: 34526.14453125	train_loss: 34522.40048038214	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1096
Epoch: 1096	max: 0.9999356/1.0	min: 6.4399945e-05	loss: 34526.12109375	train_loss: 34522.370801011086	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1097
Epoch: 1097	max: 0.999943/1.0	min: 5.7007146e-05	loss: 34526.37109375	train_loss: 34522.36198739239	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1098
Epoch: 1098	max: 0.9999466/1.0	min: 5.3428932e-05	loss: 34526.28125	train_loss: 34522.347170448564	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1099
Epoch: 1099	max: 0.9999403/1.0	min: 5.9685808e-05	loss: 34526.046875	train_loss: 34522.33311752911	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1100
Epoch: 1100	max: 0.9999454/1.0	min: 5.4601565e-05	loss: 34526.265625	train_loss: 34522.33608991778	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1101
Epoch: 1101	max: 0.99994683/1.0	min: 5.3171734e-05	loss: 34525.99609375	train_loss: 34522.310575665026	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1102
Epoch: 1102	max: 0.99995005/1.0	min: 4.990915e-05	loss: 34525.796875	train_loss: 34522.3012235035	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1103
Epoch: 1103	max: 0.999943/1.0	min: 5.702776e-05	loss: 34526.125	train_loss: 34522.290181681994	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1104
Epoch: 1104	max: 0.9999392/1.0	min: 6.0840077e-05	loss: 34525.83984375	train_loss: 34522.28006694769	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1105
Epoch: 1105	max: 0.9999399/1.0	min: 6.0072736e-05	loss: 34526.07421875	train_loss: 34522.25863991081	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1106
Epoch: 1106	max: 0.9999517/1.0	min: 4.8310343e-05	loss: 34526.4765625	train_loss: 34522.27488716246	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1107
Epoch: 1107	max: 0.9999478/1.0	min: 5.2172945e-05	loss: 34526.19921875	train_loss: 34522.29461921683	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1108
Epoch: 1108	max: 0.9999306/1.0	min: 6.9334674e-05	loss: 34526.015625	train_loss: 34522.23370436176	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1109
Epoch: 1109	max: 0.9999447/1.0	min: 5.5268232e-05	loss: 34526.0234375	train_loss: 34522.21124475489	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1110
Epoch: 1110	max: 0.99995184/1.0	min: 4.8144408e-05	loss: 34525.921875	train_loss: 34522.20675447866	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1111
Epoch: 1111	max: 0.99994993/1.0	min: 5.012274e-05	loss: 34525.76953125	train_loss: 34522.19716280348	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1112
Epoch: 1112	max: 0.99994504/1.0	min: 5.4992644e-05	loss: 34526.03125	train_loss: 34522.18479760854	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1113
Epoch: 1113	max: 0.9999529/1.0	min: 4.7108282e-05	loss: 34526.0234375	train_loss: 34522.172326446955	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1114
Epoch: 1114	max: 0.99995744/1.0	min: 4.256596e-05	loss: 34525.984375	train_loss: 34522.158578363065	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1115
Epoch: 1115	max: 0.9999523/1.0	min: 4.769702e-05	loss: 34525.76171875	train_loss: 34522.15296019525	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1116
Epoch: 1116	max: 0.9999467/1.0	min: 5.3324176e-05	loss: 34525.890625	train_loss: 34522.1331608835	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1117
Epoch: 1117	max: 0.99993145/1.0	min: 6.8557674e-05	loss: 34525.9140625	train_loss: 34522.13079235956	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1118
Epoch: 1118	max: 0.99992216/1.0	min: 7.786665e-05	loss: 34525.984375	train_loss: 34522.12157035798	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1119
Epoch: 1119	max: 0.99993336/1.0	min: 6.6589404e-05	loss: 34525.87890625	train_loss: 34522.140733385975	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1120
Epoch: 1120	max: 0.99994564/1.0	min: 5.4343596e-05	loss: 34526.21875	train_loss: 34522.12050827217	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1121
Epoch: 1121	max: 0.9999498/1.0	min: 5.0225797e-05	loss: 34526.0703125	train_loss: 34522.105960357825	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1122
Epoch: 1122	max: 0.99995923/1.0	min: 4.0708546e-05	loss: 34526.4921875	train_loss: 34522.09077470813	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1123
Epoch: 1123	max: 0.9999558/1.0	min: 4.425933e-05	loss: 34525.9921875	train_loss: 34522.07884499257	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1124
Epoch: 1124	max: 0.99995816/1.0	min: 4.188433e-05	loss: 34525.8984375	train_loss: 34522.061990972994	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1125
Epoch: 1125	max: 0.9999523/1.0	min: 4.7687827e-05	loss: 34525.8984375	train_loss: 34522.02316121253	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1126
Epoch: 1126	max: 0.9999416/1.0	min: 5.84469e-05	loss: 34525.6015625	train_loss: 34522.01905657748	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1127
Epoch: 1127	max: 0.9999496/1.0	min: 5.0473747e-05	loss: 34525.60546875	train_loss: 34522.01224084139	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1128
Epoch: 1128	max: 0.99992025/1.0	min: 7.968972e-05	loss: 34525.7890625	train_loss: 34521.98573563112	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1129
Epoch: 1129	max: 0.99994755/1.0	min: 5.250331e-05	loss: 34525.7265625	train_loss: 34521.99122750991	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1130
Epoch: 1130	max: 0.9999474/1.0	min: 5.258343e-05	loss: 34525.5546875	train_loss: 34521.96534455128	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1131
Epoch: 1131	max: 0.9999341/1.0	min: 6.595585e-05	loss: 34525.36328125	train_loss: 34521.97044304704	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1132
Epoch: 1132	max: 0.99995077/1.0	min: 4.9207956e-05	loss: 34525.91796875	train_loss: 34521.95900590703	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1133
Epoch: 1133	max: 0.999949/1.0	min: 5.103879e-05	loss: 34526.04296875	train_loss: 34521.9380830585	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1134
Epoch: 1134	max: 0.99993813/1.0	min: 6.181095e-05	loss: 34525.62109375	train_loss: 34521.921898709435	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1135
Epoch: 1135	max: 0.9999416/1.0	min: 5.8392186e-05	loss: 34525.38671875	train_loss: 34521.92269660442	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1136
Epoch: 1136	max: 0.9999349/1.0	min: 6.512672e-05	loss: 34525.2734375	train_loss: 34521.90744418122	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1137
Epoch: 1137	max: 0.9999386/1.0	min: 6.138919e-05	loss: 34525.296875	train_loss: 34521.90711515236	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1138
Epoch: 1138	max: 0.9999151/1.0	min: 8.48302e-05	loss: 34525.47265625	train_loss: 34521.92417626657	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1139
Epoch: 1139	max: 0.9999473/1.0	min: 5.2742987e-05	loss: 34525.62109375	train_loss: 34521.87799319491	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1140
Epoch: 1140	max: 0.9999337/1.0	min: 6.62786e-05	loss: 34525.53125	train_loss: 34521.85149524263	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1141
Epoch: 1141	max: 0.9999356/1.0	min: 6.437606e-05	loss: 34525.5234375	train_loss: 34521.82649485554	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1142
Epoch: 1142	max: 0.99994826/1.0	min: 5.177975e-05	loss: 34525.421875	train_loss: 34521.80323735368	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1143
Epoch: 1143	max: 0.99994004/1.0	min: 5.991751e-05	loss: 34525.26953125	train_loss: 34521.79341293896	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1144
Epoch: 1144	max: 0.999944/1.0	min: 5.6072833e-05	loss: 34525.48828125	train_loss: 34521.77724649294	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1145
Epoch: 1145	max: 0.9999424/1.0	min: 5.7538175e-05	loss: 34525.36328125	train_loss: 34521.785103508606	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1146
Epoch: 1146	max: 0.9999417/1.0	min: 5.8243146e-05	loss: 34525.31640625	train_loss: 34521.7616021383	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1147
Epoch: 1147	max: 0.9999517/1.0	min: 4.829597e-05	loss: 34525.36328125	train_loss: 34521.726981527936	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1148
Epoch: 1148	max: 0.99994826/1.0	min: 5.1715102e-05	loss: 34525.6015625	train_loss: 34521.73344404187	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1149
Epoch: 1149	max: 0.99994886/1.0	min: 5.1188337e-05	loss: 34525.68359375	train_loss: 34521.72251496113	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1150
Epoch: 1150	max: 0.9999473/1.0	min: 5.272151e-05	loss: 34525.48828125	train_loss: 34521.68667936331	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1151
Epoch: 1151	max: 0.999961/1.0	min: 3.893868e-05	loss: 34526.11328125	train_loss: 34521.70280371299	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1152
Epoch: 1152	max: 0.99994004/1.0	min: 5.9908543e-05	loss: 34525.2265625	train_loss: 34521.667890363715	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1153
Epoch: 1153	max: 0.99994326/1.0	min: 5.6697412e-05	loss: 34525.1953125	train_loss: 34521.67916879568	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1154
Epoch: 1154	max: 0.99994826/1.0	min: 5.1732557e-05	loss: 34525.34375	train_loss: 34521.64714606172	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1155
Epoch: 1155	max: 0.99993443/1.0	min: 6.551754e-05	loss: 34525.36328125	train_loss: 34521.624491940725	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1156
Epoch: 1156	max: 0.9999205/1.0	min: 7.949807e-05	loss: 34525.24609375	train_loss: 34521.666469733216	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1157
Epoch: 1157	max: 0.9999367/1.0	min: 6.3246865e-05	loss: 34525.4140625	train_loss: 34521.62425823346	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1158
Epoch: 1158	max: 0.99992645/1.0	min: 7.355857e-05	loss: 34525.30078125	train_loss: 34521.59386419237	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1159
Epoch: 1159	max: 0.9999192/1.0	min: 8.07632e-05	loss: 34525.1484375	train_loss: 34521.603768928835	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1160
Epoch: 1160	max: 0.9999385/1.0	min: 6.1499464e-05	loss: 34525.23828125	train_loss: 34521.59950655348	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1161
Epoch: 1161	max: 0.9999409/1.0	min: 5.9072678e-05	loss: 34525.265625	train_loss: 34521.53948781819	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1162
Epoch: 1162	max: 0.99994576/1.0	min: 5.4223605e-05	loss: 34525.078125	train_loss: 34521.527667456336	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1163
Epoch: 1163	max: 0.9999362/1.0	min: 6.372987e-05	loss: 34525.26953125	train_loss: 34521.520297209834	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1164
Epoch: 1164	max: 0.99995494/1.0	min: 4.5015135e-05	loss: 34525.44140625	train_loss: 34521.51147246222	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1165
Epoch: 1165	max: 0.99995744/1.0	min: 4.2553052e-05	loss: 34525.23046875	train_loss: 34521.51670547272	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1166
Epoch: 1166	max: 0.9999552/1.0	min: 4.4767607e-05	loss: 34525.484375	train_loss: 34521.48669320188	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1167
Epoch: 1167	max: 0.9999441/1.0	min: 5.5872875e-05	loss: 34525.48046875	train_loss: 34521.46477891196	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1168
Epoch: 1168	max: 0.99994874/1.0	min: 5.123302e-05	loss: 34525.2578125	train_loss: 34521.474927033014	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1169
Epoch: 1169	max: 0.99993193/1.0	min: 6.806383e-05	loss: 34525.046875	train_loss: 34521.44661555107	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1170
Epoch: 1170	max: 0.9999237/1.0	min: 7.63069e-05	loss: 34524.78125	train_loss: 34521.466772439766	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1171
Epoch: 1171	max: 0.99993324/1.0	min: 6.67129e-05	loss: 34524.67578125	train_loss: 34521.497740345905	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1172
Epoch: 1172	max: 0.9999422/1.0	min: 5.7756588e-05	loss: 34524.68359375	train_loss: 34521.50848555757	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1173
Epoch: 1173	max: 0.9999578/1.0	min: 4.215256e-05	loss: 34524.95703125	train_loss: 34521.41929744596	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1174
Epoch: 1174	max: 0.99996257/1.0	min: 3.7440026e-05	loss: 34525.2265625	train_loss: 34521.42493061362	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1175
Epoch: 1175	max: 0.9999522/1.0	min: 4.7794274e-05	loss: 34525.34375	train_loss: 34521.443150586834	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1176
Epoch: 1176	max: 0.9999447/1.0	min: 5.536804e-05	loss: 34524.98046875	train_loss: 34521.37020295274	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1177
Epoch: 1177	max: 0.99994457/1.0	min: 5.547406e-05	loss: 34524.92578125	train_loss: 34521.36292899557	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1178
Epoch: 1178	max: 0.9999473/1.0	min: 5.2712163e-05	loss: 34525.14453125	train_loss: 34521.33637394711	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1179
Epoch: 1179	max: 0.9999474/1.0	min: 5.2593008e-05	loss: 34524.96875	train_loss: 34521.32124200653	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1180
Epoch: 1180	max: 0.99993765/1.0	min: 6.2324e-05	loss: 34524.90625	train_loss: 34521.318361552396	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1181
Epoch: 1181	max: 0.99995065/1.0	min: 4.932593e-05	loss: 34525.015625	train_loss: 34521.34020229468	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1182
Epoch: 1182	max: 0.99994934/1.0	min: 5.060286e-05	loss: 34525.31640625	train_loss: 34521.303834928156	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1183
Epoch: 1183	max: 0.99994373/1.0	min: 5.62779e-05	loss: 34525.27734375	train_loss: 34521.30206155936	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1184
Epoch: 1184	max: 0.99992204/1.0	min: 7.796644e-05	loss: 34524.96875	train_loss: 34521.26417485368	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1185
Epoch: 1185	max: 0.99992454/1.0	min: 7.548243e-05	loss: 34525.1796875	train_loss: 34521.28640994673	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1186
Epoch: 1186	max: 0.9999299/1.0	min: 7.00519e-05	loss: 34525.07421875	train_loss: 34521.251957721724	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1187
Epoch: 1187	max: 0.99993885/1.0	min: 6.114491e-05	loss: 34524.69921875	train_loss: 34521.231353257	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1188
Epoch: 1188	max: 0.99994767/1.0	min: 5.2385483e-05	loss: 34524.71875	train_loss: 34521.22773103633	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1189
Epoch: 1189	max: 0.9999449/1.0	min: 5.5127588e-05	loss: 34524.99609375	train_loss: 34521.213831502384	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1190
Epoch: 1190	max: 0.9999492/1.0	min: 5.082174e-05	loss: 34524.98046875	train_loss: 34521.19565217391	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1191
Epoch: 1191	max: 0.9999411/1.0	min: 5.894276e-05	loss: 34524.69140625	train_loss: 34521.18376358696	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1192
Epoch: 1192	max: 0.9999337/1.0	min: 6.6231085e-05	loss: 34524.734375	train_loss: 34521.18830079819	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1193
Epoch: 1193	max: 0.99994016/1.0	min: 5.9872225e-05	loss: 34524.8046875	train_loss: 34521.18728806671	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1194
Epoch: 1194	max: 0.999951/1.0	min: 4.897926e-05	loss: 34525.02734375	train_loss: 34521.142537238324	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1195
Epoch: 1195	max: 0.99993277/1.0	min: 6.719904e-05	loss: 34524.80859375	train_loss: 34521.13782728694	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1196
Epoch: 1196	max: 0.999941/1.0	min: 5.900197e-05	loss: 34525.078125	train_loss: 34521.133468138396	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1197
Epoch: 1197	max: 0.99994683/1.0	min: 5.3181575e-05	loss: 34524.73828125	train_loss: 34521.11451946302	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1198
Epoch: 1198	max: 0.99994314/1.0	min: 5.6916924e-05	loss: 34524.83984375	train_loss: 34521.123698884396	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1199
Epoch: 1199	max: 0.99994516/1.0	min: 5.4884615e-05	loss: 34524.87890625	train_loss: 34521.0882397343	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1200
Epoch: 1200	max: 0.9999497/1.0	min: 5.03176e-05	loss: 34524.83984375	train_loss: 34521.112227873775	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1201
Epoch: 1201	max: 0.999954/1.0	min: 4.601966e-05	loss: 34525.18359375	train_loss: 34521.081993024585	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1202
Epoch: 1202	max: 0.9999393/1.0	min: 6.070383e-05	loss: 34524.875	train_loss: 34521.08042191177	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1203
Epoch: 1203	max: 0.9999422/1.0	min: 5.7805955e-05	loss: 34525.1484375	train_loss: 34521.04681161356	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1204
Epoch: 1204	max: 0.99992657/1.0	min: 7.345743e-05	loss: 34524.93359375	train_loss: 34521.029119054256	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1205
Epoch: 1205	max: 0.9999188/1.0	min: 8.119441e-05	loss: 34524.9375	train_loss: 34521.045060986464	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1206
Epoch: 1206	max: 0.9999149/1.0	min: 8.50734e-05	loss: 34524.8359375	train_loss: 34521.02864147854	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1207
Epoch: 1207	max: 0.9999403/1.0	min: 5.9679776e-05	loss: 34524.9609375	train_loss: 34521.014104209244	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1208
Epoch: 1208	max: 0.99993813/1.0	min: 6.181849e-05	loss: 34524.80078125	train_loss: 34520.98270227533	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1209
Epoch: 1209	max: 0.9999428/1.0	min: 5.7213558e-05	loss: 34524.546875	train_loss: 34520.9837237164	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1210
Epoch: 1210	max: 0.99992895/1.0	min: 7.099949e-05	loss: 34524.65625	train_loss: 34520.959902026814	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1211
Epoch: 1211	max: 0.99992764/1.0	min: 7.237385e-05	loss: 34524.4921875	train_loss: 34520.95384015391	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1212
Epoch: 1212	max: 0.9999304/1.0	min: 6.958956e-05	loss: 34524.9296875	train_loss: 34520.948301823984	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1213
Epoch: 1213	max: 0.999928/1.0	min: 7.196731e-05	loss: 34524.53515625	train_loss: 34520.94913939598	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1214
Epoch: 1214	max: 0.99992514/1.0	min: 7.483552e-05	loss: 34524.49609375	train_loss: 34520.92337982317	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1215
Epoch: 1215	max: 0.99993634/1.0	min: 6.369538e-05	loss: 34524.57421875	train_loss: 34520.93041039576	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1216
Epoch: 1216	max: 0.9999347/1.0	min: 6.527382e-05	loss: 34524.8125	train_loss: 34520.89549220782	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1217
Epoch: 1217	max: 0.9999324/1.0	min: 6.7536e-05	loss: 34524.83984375	train_loss: 34520.90274922969	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1218
Epoch: 1218	max: 0.9999441/1.0	min: 5.5946886e-05	loss: 34524.92578125	train_loss: 34520.8900419415	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1219
Epoch: 1219	max: 0.99994004/1.0	min: 5.9976395e-05	loss: 34524.953125	train_loss: 34520.88039558946	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1220
Epoch: 1220	max: 0.9999441/1.0	min: 5.5867444e-05	loss: 34524.76171875	train_loss: 34520.85057251022	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1221
Epoch: 1221	max: 0.9999436/1.0	min: 5.6350287e-05	loss: 34524.390625	train_loss: 34520.83598878979	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1222
Epoch: 1222	max: 0.99995875/1.0	min: 4.123044e-05	loss: 34524.5859375	train_loss: 34520.831567706395	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1223
Epoch: 1223	max: 0.9999585/1.0	min: 4.146734e-05	loss: 34524.80859375	train_loss: 34520.83115738805	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1224
Epoch: 1224	max: 0.9999602/1.0	min: 3.9761326e-05	loss: 34524.953125	train_loss: 34520.853148128794	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1225
Epoch: 1225	max: 0.9999558/1.0	min: 4.427554e-05	loss: 34524.8984375	train_loss: 34520.831863832376	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1226
Epoch: 1226	max: 0.99994445/1.0	min: 5.5522854e-05	loss: 34524.65625	train_loss: 34520.80159075777	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1227
Epoch: 1227	max: 0.9999485/1.0	min: 5.144265e-05	loss: 34524.57421875	train_loss: 34520.76324099235	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1228
Epoch: 1228	max: 0.99994457/1.0	min: 5.547099e-05	loss: 34524.65625	train_loss: 34520.751646595905	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1229
Epoch: 1229	max: 0.99993396/1.0	min: 6.608365e-05	loss: 34524.43359375	train_loss: 34520.74287797674	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1230
Epoch: 1230	max: 0.9999498/1.0	min: 5.01332e-05	loss: 34524.8984375	train_loss: 34520.75124837421	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1231
Epoch: 1231	max: 0.99992883/1.0	min: 7.1164075e-05	loss: 34524.68359375	train_loss: 34520.74514827589	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1232
Epoch: 1232	max: 0.999956/1.0	min: 4.3969303e-05	loss: 34524.79296875	train_loss: 34520.73584788802	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1233
Epoch: 1233	max: 0.99996006/1.0	min: 3.995838e-05	loss: 34524.73828125	train_loss: 34520.743295553075	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1234
Epoch: 1234	max: 0.9999639/1.0	min: 3.610886e-05	loss: 34525.30859375	train_loss: 34520.739217046794	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1235
Epoch: 1235	max: 0.99994993/1.0	min: 5.0081646e-05	loss: 34524.98828125	train_loss: 34520.75352544748	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1236
Epoch: 1236	max: 0.9999485/1.0	min: 5.1486182e-05	loss: 34524.49609375	train_loss: 34520.68745935526	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1237
Epoch: 1237	max: 0.9999392/1.0	min: 6.076105e-05	loss: 34524.328125	train_loss: 34520.67181161356	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1238
Epoch: 1238	max: 0.99993384/1.0	min: 6.609751e-05	loss: 34524.359375	train_loss: 34520.63654213892	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1239
Epoch: 1239	max: 0.9999286/1.0	min: 7.141479e-05	loss: 34524.4765625	train_loss: 34520.633578459834	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1240
Epoch: 1240	max: 0.99993026/1.0	min: 6.97864e-05	loss: 34524.36328125	train_loss: 34520.641307734884	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1241
Epoch: 1241	max: 0.9999263/1.0	min: 7.361879e-05	loss: 34524.1640625	train_loss: 34520.68367310402	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1242
Epoch: 1242	max: 0.99993885/1.0	min: 6.119386e-05	loss: 34524.453125	train_loss: 34520.719802408494	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1243
Epoch: 1243	max: 0.99993944/1.0	min: 6.0595154e-05	loss: 34524.3125	train_loss: 34520.586350237674	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1244
Epoch: 1244	max: 0.9999428/1.0	min: 5.726831e-05	loss: 34524.5234375	train_loss: 34520.58525137805	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1245
Epoch: 1245	max: 0.99994016/1.0	min: 5.983107e-05	loss: 34524.390625	train_loss: 34520.55976470566	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1246
Epoch: 1246	max: 0.99995935/1.0	min: 4.0634353e-05	loss: 34524.484375	train_loss: 34520.559425999476	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1247
Epoch: 1247	max: 0.9999436/1.0	min: 5.643025e-05	loss: 34524.109375	train_loss: 34520.54632097346	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1248
Epoch: 1248	max: 0.99993503/1.0	min: 6.498044e-05	loss: 34524.4609375	train_loss: 34520.543306972315	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1249
Epoch: 1249	max: 0.9999572/1.0	min: 4.2747062e-05	loss: 34524.453125	train_loss: 34520.54361664654	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1250
Epoch: 1250	max: 0.999938/1.0	min: 6.2023406e-05	loss: 34524.3046875	train_loss: 34520.51163358959	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1251
Epoch: 1251	max: 0.9999373/1.0	min: 6.264761e-05	loss: 34524.5234375	train_loss: 34520.4933478106	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1252
Epoch: 1252	max: 0.9999291/1.0	min: 7.0947375e-05	loss: 34524.32421875	train_loss: 34520.46324070203	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1253
Epoch: 1253	max: 0.99993503/1.0	min: 6.4911255e-05	loss: 34524.484375	train_loss: 34520.45795446628	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1254
Epoch: 1254	max: 0.9999114/1.0	min: 8.854449e-05	loss: 34524.44921875	train_loss: 34520.5062994511	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1255
Epoch: 1255	max: 0.9999472/1.0	min: 5.2849016e-05	loss: 34524.28125	train_loss: 34520.371509874734	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1256
Epoch: 1256	max: 0.9999416/1.0	min: 5.839352e-05	loss: 34524.39453125	train_loss: 34520.35927387201	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1257
Epoch: 1257	max: 0.99994457/1.0	min: 5.5413944e-05	loss: 34524.28515625	train_loss: 34520.351062182584	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1258
Epoch: 1258	max: 0.9999441/1.0	min: 5.587714e-05	loss: 34524.4296875	train_loss: 34520.31754285117	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1259
Epoch: 1259	max: 0.9999341/1.0	min: 6.593831e-05	loss: 34524.08203125	train_loss: 34520.30718811935	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1260
Epoch: 1260	max: 0.99994504/1.0	min: 5.4933098e-05	loss: 34524.05078125	train_loss: 34520.3601201536	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1261
Epoch: 1261	max: 0.99994695/1.0	min: 5.3000116e-05	loss: 34524.0	train_loss: 34520.30271187523	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1262
Epoch: 1262	max: 0.9999269/1.0	min: 7.312698e-05	loss: 34524.0390625	train_loss: 34520.29183214883	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1263
Epoch: 1263	max: 0.99994695/1.0	min: 5.3022213e-05	loss: 34524.40625	train_loss: 34520.31110065961	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1264
Epoch: 1264	max: 0.9999527/1.0	min: 4.7365997e-05	loss: 34524.28125	train_loss: 34520.24991871051	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1265
Epoch: 1265	max: 0.99995327/1.0	min: 4.677068e-05	loss: 34524.53515625	train_loss: 34520.25355544717	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1266
Epoch: 1266	max: 0.99993896/1.0	min: 6.104482e-05	loss: 34524.30859375	train_loss: 34520.30867939428	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1267
Epoch: 1267	max: 0.9999416/1.0	min: 5.8443387e-05	loss: 34524.48828125	train_loss: 34520.25887410194	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1268
Epoch: 1268	max: 0.99995613/1.0	min: 4.3823253e-05	loss: 34524.6640625	train_loss: 34520.23706481094	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1269
Epoch: 1269	max: 0.99995816/1.0	min: 4.1895917e-05	loss: 34524.265625	train_loss: 34520.212802803326	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1270
Epoch: 1270	max: 0.9999609/1.0	min: 3.910044e-05	loss: 34524.4921875	train_loss: 34520.18843095813	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1271
Epoch: 1271	max: 0.9999416/1.0	min: 5.8354002e-05	loss: 34524.3828125	train_loss: 34520.16098124148	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1272
Epoch: 1272	max: 0.9999409/1.0	min: 5.9072678e-05	loss: 34524.3984375	train_loss: 34520.13921211136	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1273
Epoch: 1273	max: 0.99995065/1.0	min: 4.931869e-05	loss: 34524.6484375	train_loss: 34520.11524477812	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1274
Epoch: 1274	max: 0.99994886/1.0	min: 5.1185994e-05	loss: 34524.2109375	train_loss: 34520.11689766428	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1275
Epoch: 1275	max: 0.9999546/1.0	min: 4.537752e-05	loss: 34524.46484375	train_loss: 34520.10950225675	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1276
Epoch: 1276	max: 0.9999422/1.0	min: 5.7857527e-05	loss: 34524.0234375	train_loss: 34520.12109133067	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1277
Epoch: 1277	max: 0.9999374/1.0	min: 6.256147e-05	loss: 34523.94140625	train_loss: 34520.09637981156	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1278
Epoch: 1278	max: 0.99993837/1.0	min: 6.160253e-05	loss: 34523.921875	train_loss: 34520.07795613078	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1279
Epoch: 1279	max: 0.9999379/1.0	min: 6.213328e-05	loss: 34524.12890625	train_loss: 34520.06791204091	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1280
Epoch: 1280	max: 0.99995446/1.0	min: 4.5562247e-05	loss: 34524.41796875	train_loss: 34520.01931496191	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1281
Epoch: 1281	max: 0.9999591/1.0	min: 4.0910454e-05	loss: 34524.375	train_loss: 34520.00877103849	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1282
Epoch: 1282	max: 0.9999478/1.0	min: 5.2257554e-05	loss: 34524.1796875	train_loss: 34520.01103359578	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1283
Epoch: 1283	max: 0.99995387/1.0	min: 4.6114947e-05	loss: 34524.48828125	train_loss: 34519.98083552041	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1284
Epoch: 1284	max: 0.9999583/1.0	min: 4.1731393e-05	loss: 34524.921875	train_loss: 34519.97593153877	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1285
Epoch: 1285	max: 0.9999502/1.0	min: 4.9833627e-05	loss: 34524.28515625	train_loss: 34519.98103196999	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1286
Epoch: 1286	max: 0.99995553/1.0	min: 4.4411107e-05	loss: 34524.484375	train_loss: 34519.95443434132	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1287
Epoch: 1287	max: 0.9999436/1.0	min: 5.6393346e-05	loss: 34524.375	train_loss: 34520.00001403211	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1288
Epoch: 1288	max: 0.9999567/1.0	min: 4.321786e-05	loss: 34524.18359375	train_loss: 34519.92406788059	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1289
Epoch: 1289	max: 0.99994516/1.0	min: 5.481201e-05	loss: 34524.30078125	train_loss: 34519.87903689381	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1290
Epoch: 1290	max: 0.9999596/1.0	min: 4.0397736e-05	loss: 34524.46484375	train_loss: 34519.85218378391	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1291
Epoch: 1291	max: 0.9999534/1.0	min: 4.6655216e-05	loss: 34524.0859375	train_loss: 34519.84013213412	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1292
Epoch: 1292	max: 0.9999423/1.0	min: 5.7728234e-05	loss: 34524.3984375	train_loss: 34519.82652146817	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1293
Epoch: 1293	max: 0.9999417/1.0	min: 5.829032e-05	loss: 34524.1484375	train_loss: 34519.807939079335	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1294
Epoch: 1294	max: 0.999949/1.0	min: 5.1061237e-05	loss: 34524.2109375	train_loss: 34519.786993972964	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1295
Epoch: 1295	max: 0.9999573/1.0	min: 4.2654217e-05	loss: 34524.171875	train_loss: 34519.81944734764	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1296
Epoch: 1296	max: 0.9999509/1.0	min: 4.9150323e-05	loss: 34524.00390625	train_loss: 34519.83561427753	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1297
Epoch: 1297	max: 0.99994063/1.0	min: 5.937121e-05	loss: 34524.25390625	train_loss: 34519.762533580295	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1298
Epoch: 1298	max: 0.9999374/1.0	min: 6.256374e-05	loss: 34523.890625	train_loss: 34519.735359667255	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1299
Epoch: 1299	max: 0.99994826/1.0	min: 5.174016e-05	loss: 34524.328125	train_loss: 34519.71030460331	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1300
Epoch: 1300	max: 0.9999373/1.0	min: 6.268138e-05	loss: 34523.94140625	train_loss: 34519.71698824399	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1301
Epoch: 1301	max: 0.9999243/1.0	min: 7.564802e-05	loss: 34523.81640625	train_loss: 34519.69208414623	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1302
Epoch: 1302	max: 0.9999422/1.0	min: 5.780524e-05	loss: 34523.875	train_loss: 34519.684069874114	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1303
Epoch: 1303	max: 0.99994683/1.0	min: 5.3173768e-05	loss: 34523.7734375	train_loss: 34519.65781966122	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1304
Epoch: 1304	max: 0.9999509/1.0	min: 4.9091017e-05	loss: 34523.890625	train_loss: 34519.647366220735	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1305
Epoch: 1305	max: 0.99994636/1.0	min: 5.3591604e-05	loss: 34523.859375	train_loss: 34519.62549402716	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1306
Epoch: 1306	max: 0.9999391/1.0	min: 6.09109e-05	loss: 34523.6328125	train_loss: 34519.590054231696	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1307
Epoch: 1307	max: 0.99994826/1.0	min: 5.172314e-05	loss: 34523.94921875	train_loss: 34519.58684958736	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1308
Epoch: 1308	max: 0.9999546/1.0	min: 4.5373978e-05	loss: 34524.6015625	train_loss: 34519.5855208914	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1309
Epoch: 1309	max: 0.99992764/1.0	min: 7.236605e-05	loss: 34523.90234375	train_loss: 34519.57865918803	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1310
Epoch: 1310	max: 0.9999329/1.0	min: 6.711503e-05	loss: 34523.87890625	train_loss: 34519.543136167624	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1311
Epoch: 1311	max: 0.9999447/1.0	min: 5.530118e-05	loss: 34524.0390625	train_loss: 34519.51798433049	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1312
Epoch: 1312	max: 0.99994993/1.0	min: 5.004364e-05	loss: 34524.17578125	train_loss: 34519.51132923789	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1313
Epoch: 1313	max: 0.9999521/1.0	min: 4.7951227e-05	loss: 34524.1796875	train_loss: 34519.51597677056	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1314
Epoch: 1314	max: 0.9999565/1.0	min: 4.345176e-05	loss: 34524.171875	train_loss: 34519.54888207606	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1315
Epoch: 1315	max: 0.9999362/1.0	min: 6.374884e-05	loss: 34523.625	train_loss: 34519.468186296144	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1316
Epoch: 1316	max: 0.99993646/1.0	min: 6.3549516e-05	loss: 34523.75390625	train_loss: 34519.43869418122	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1317
Epoch: 1317	max: 0.9999379/1.0	min: 6.21539e-05	loss: 34523.69140625	train_loss: 34519.44221479004	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1318
Epoch: 1318	max: 0.99991715/1.0	min: 8.2822386e-05	loss: 34523.515625	train_loss: 34519.40923206599	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1319
Epoch: 1319	max: 0.9999447/1.0	min: 5.5361703e-05	loss: 34523.73046875	train_loss: 34519.428641865634	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1320
Epoch: 1320	max: 0.9999393/1.0	min: 6.0693354e-05	loss: 34523.8359375	train_loss: 34519.39583091401	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1321
Epoch: 1321	max: 0.9999423/1.0	min: 5.7673977e-05	loss: 34523.734375	train_loss: 34519.40456759801	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1322
Epoch: 1322	max: 0.9999504/1.0	min: 4.9556907e-05	loss: 34523.78125	train_loss: 34519.37167003437	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1323
Epoch: 1323	max: 0.99993706/1.0	min: 6.2891115e-05	loss: 34523.890625	train_loss: 34519.36236190465	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1324
Epoch: 1324	max: 0.9999106/1.0	min: 8.934234e-05	loss: 34523.34375	train_loss: 34519.35593326134	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1325
Epoch: 1325	max: 0.9999243/1.0	min: 7.566577e-05	loss: 34523.48046875	train_loss: 34519.35774243621	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1326
Epoch: 1326	max: 0.99991894/1.0	min: 8.10013e-05	loss: 34523.6015625	train_loss: 34519.32916918277	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1327
Epoch: 1327	max: 0.99993193/1.0	min: 6.803677e-05	loss: 34523.66015625	train_loss: 34519.29048990462	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1328
Epoch: 1328	max: 0.9999471/1.0	min: 5.2894287e-05	loss: 34523.921875	train_loss: 34519.276802303975	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1329
Epoch: 1329	max: 0.99992836/1.0	min: 7.164672e-05	loss: 34523.61328125	train_loss: 34519.338844566766	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1330
Epoch: 1330	max: 0.9999393/1.0	min: 6.0712453e-05	loss: 34523.6796875	train_loss: 34519.24733728555	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1331
Epoch: 1331	max: 0.99993145/1.0	min: 6.8541325e-05	loss: 34523.22265625	train_loss: 34519.29351213149	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1332
Epoch: 1332	max: 0.99994016/1.0	min: 5.9879992e-05	loss: 34523.69140625	train_loss: 34519.21976611854	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1333
Epoch: 1333	max: 0.9999418/1.0	min: 5.8216494e-05	loss: 34523.67578125	train_loss: 34519.22438558699	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1334
Epoch: 1334	max: 0.99993443/1.0	min: 6.550123e-05	loss: 34523.2890625	train_loss: 34519.197704249505	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1335
Epoch: 1335	max: 0.9999366/1.0	min: 6.342915e-05	loss: 34523.4296875	train_loss: 34519.17894476573	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1336
Epoch: 1336	max: 0.9999324/1.0	min: 6.7558154e-05	loss: 34523.2890625	train_loss: 34519.17723865431	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1337
Epoch: 1337	max: 0.99993324/1.0	min: 6.67861e-05	loss: 34523.34375	train_loss: 34519.144956084325	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1338
Epoch: 1338	max: 0.99991703/1.0	min: 8.293453e-05	loss: 34523.2109375	train_loss: 34519.154576791465	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1339
Epoch: 1339	max: 0.9999298/1.0	min: 7.0254944e-05	loss: 34523.15625	train_loss: 34519.16273235244	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1340
Epoch: 1340	max: 0.99993336/1.0	min: 6.665185e-05	loss: 34523.2734375	train_loss: 34519.11420059535	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1341
Epoch: 1341	max: 0.99994147/1.0	min: 5.8560825e-05	loss: 34523.26171875	train_loss: 34519.09404419051	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1342
Epoch: 1342	max: 0.9999405/1.0	min: 5.9541362e-05	loss: 34523.62109375	train_loss: 34519.08602266041	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1343
Epoch: 1343	max: 0.9999299/1.0	min: 7.0104965e-05	loss: 34523.67578125	train_loss: 34519.06783317075	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1344
Epoch: 1344	max: 0.99995184/1.0	min: 4.812338e-05	loss: 34523.57421875	train_loss: 34519.09405677103	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1345
Epoch: 1345	max: 0.9999417/1.0	min: 5.8236143e-05	loss: 34523.296875	train_loss: 34519.060032767404	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1346
Epoch: 1346	max: 0.999933/1.0	min: 6.7000816e-05	loss: 34523.21875	train_loss: 34519.02204735306	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1347
Epoch: 1347	max: 0.99994636/1.0	min: 5.3664076e-05	loss: 34523.69921875	train_loss: 34519.01473178341	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1348
Epoch: 1348	max: 0.9999368/1.0	min: 6.316188e-05	loss: 34523.546875	train_loss: 34519.06488207218	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1349
Epoch: 1349	max: 0.99993896/1.0	min: 6.103539e-05	loss: 34523.4765625	train_loss: 34518.996707292055	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1350
Epoch: 1350	max: 0.99994755/1.0	min: 5.2498704e-05	loss: 34523.19921875	train_loss: 34518.993496357456	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1351
Epoch: 1351	max: 0.9999465/1.0	min: 5.3571377e-05	loss: 34523.08984375	train_loss: 34518.97282415149	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1352
Epoch: 1352	max: 0.99994516/1.0	min: 5.4779295e-05	loss: 34523.15625	train_loss: 34518.96962531355	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1353
Epoch: 1353	max: 0.9999281/1.0	min: 7.185773e-05	loss: 34523.26171875	train_loss: 34518.940041747956	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1354
Epoch: 1354	max: 0.9999294/1.0	min: 7.058661e-05	loss: 34523.328125	train_loss: 34518.92360433699	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1355
Epoch: 1355	max: 0.99994063/1.0	min: 5.941516e-05	loss: 34523.57421875	train_loss: 34518.92486722718	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1356
Epoch: 1356	max: 0.99995816/1.0	min: 4.1836945e-05	loss: 34523.40234375	train_loss: 34518.91507861854	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1357
Epoch: 1357	max: 0.99993765/1.0	min: 6.230564e-05	loss: 34523.05859375	train_loss: 34518.89536108015	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1358
Epoch: 1358	max: 0.9999318/1.0	min: 6.815203e-05	loss: 34523.46484375	train_loss: 34518.868232166635	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1359
Epoch: 1359	max: 0.9999422/1.0	min: 5.7823603e-05	loss: 34523.828125	train_loss: 34518.88103671188	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1360
Epoch: 1360	max: 0.9999373/1.0	min: 6.266124e-05	loss: 34523.3515625	train_loss: 34518.87259857317	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1361
Epoch: 1361	max: 0.9999448/1.0	min: 5.522651e-05	loss: 34523.2734375	train_loss: 34518.83974068655	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1362
Epoch: 1362	max: 0.9999238/1.0	min: 7.618351e-05	loss: 34523.4140625	train_loss: 34518.84199695358	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1363
Epoch: 1363	max: 0.9999478/1.0	min: 5.2211675e-05	loss: 34523.56640625	train_loss: 34518.810049218846	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1364
Epoch: 1364	max: 0.99993527/1.0	min: 6.473033e-05	loss: 34522.94140625	train_loss: 34518.815304003314	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1365
Epoch: 1365	max: 0.9999304/1.0	min: 6.9607944e-05	loss: 34522.7890625	train_loss: 34518.78353578286	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1366
Epoch: 1366	max: 0.9999206/1.0	min: 7.9351055e-05	loss: 34522.96484375	train_loss: 34518.812392581756	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1367
Epoch: 1367	max: 0.99993765/1.0	min: 6.234225e-05	loss: 34522.859375	train_loss: 34518.773327178555	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1368
Epoch: 1368	max: 0.99995685/1.0	min: 4.3209457e-05	loss: 34523.5	train_loss: 34518.74413747987	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1369
Epoch: 1369	max: 0.99994814/1.0	min: 5.189364e-05	loss: 34523.15625	train_loss: 34518.790954415956	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1370
Epoch: 1370	max: 0.99995005/1.0	min: 4.9924194e-05	loss: 34522.8515625	train_loss: 34518.7278195838	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1371
Epoch: 1371	max: 0.9999186/1.0	min: 8.14452e-05	loss: 34522.98046875	train_loss: 34518.731600996376	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1372
Epoch: 1372	max: 0.99993265/1.0	min: 6.733832e-05	loss: 34522.93359375	train_loss: 34518.716630183175	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1373
Epoch: 1373	max: 0.99993443/1.0	min: 6.5534965e-05	loss: 34522.91796875	train_loss: 34518.67261047628	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1374
Epoch: 1374	max: 0.99992955/1.0	min: 7.044365e-05	loss: 34522.96875	train_loss: 34518.66759859253	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1375
Epoch: 1375	max: 0.99994373/1.0	min: 5.6205645e-05	loss: 34523.23828125	train_loss: 34518.66102962808	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1376
Epoch: 1376	max: 0.9999682/1.0	min: 3.1791937e-05	loss: 34522.984375	train_loss: 34518.673507079926	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1377
Epoch: 1377	max: 0.99995327/1.0	min: 4.6732875e-05	loss: 34523.32421875	train_loss: 34518.65540952481	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1378
Epoch: 1378	max: 0.9999497/1.0	min: 5.0278606e-05	loss: 34523.43359375	train_loss: 34518.6401358115	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1379
Epoch: 1379	max: 0.99994695/1.0	min: 5.2991323e-05	loss: 34522.89453125	train_loss: 34518.62500193546	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1380
Epoch: 1380	max: 0.9999219/1.0	min: 7.803234e-05	loss: 34522.71875	train_loss: 34518.59011374721	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1381
Epoch: 1381	max: 0.9999422/1.0	min: 5.7840094e-05	loss: 34522.7890625	train_loss: 34518.594310316796	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1382
Epoch: 1382	max: 0.9999615/1.0	min: 3.8519345e-05	loss: 34522.82421875	train_loss: 34518.57775774573	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1383
Epoch: 1383	max: 0.9999591/1.0	min: 4.0882573e-05	loss: 34523.10546875	train_loss: 34518.57291279574	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1384
Epoch: 1384	max: 0.99994576/1.0	min: 5.4270164e-05	loss: 34523.0	train_loss: 34518.55396024944	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1385
Epoch: 1385	max: 0.99995816/1.0	min: 4.1860574e-05	loss: 34523.0546875	train_loss: 34518.55005835424	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1386
Epoch: 1386	max: 0.9999372/1.0	min: 6.279877e-05	loss: 34523.37109375	train_loss: 34518.54528308095	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1387
Epoch: 1387	max: 0.99995303/1.0	min: 4.695006e-05	loss: 34523.31640625	train_loss: 34518.55690409002	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1388
Epoch: 1388	max: 0.9999608/1.0	min: 3.920472e-05	loss: 34523.109375	train_loss: 34518.539458302366	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1389
Epoch: 1389	max: 0.9999393/1.0	min: 6.0724324e-05	loss: 34522.828125	train_loss: 34518.485547407254	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1390
Epoch: 1390	max: 0.999928/1.0	min: 7.2003146e-05	loss: 34522.9921875	train_loss: 34518.47949714713	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1391
Epoch: 1391	max: 0.9999429/1.0	min: 5.7100184e-05	loss: 34522.78125	train_loss: 34518.466394540446	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1392
Epoch: 1392	max: 0.9999541/1.0	min: 4.5949277e-05	loss: 34522.6484375	train_loss: 34518.452574360526	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1393
Epoch: 1393	max: 0.99996066/1.0	min: 3.9291364e-05	loss: 34522.8203125	train_loss: 34518.47530735167	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1394
Epoch: 1394	max: 0.99994683/1.0	min: 5.315693e-05	loss: 34523.0390625	train_loss: 34518.44743328456	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1395
Epoch: 1395	max: 0.9999398/1.0	min: 6.0212562e-05	loss: 34522.765625	train_loss: 34518.41709585579	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1396
Epoch: 1396	max: 0.9999515/1.0	min: 4.856481e-05	loss: 34522.82421875	train_loss: 34518.404696790225	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1397
Epoch: 1397	max: 0.9999194/1.0	min: 8.054217e-05	loss: 34522.796875	train_loss: 34518.39165563452	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1398
Epoch: 1398	max: 0.99994457/1.0	min: 5.541664e-05	loss: 34522.8515625	train_loss: 34518.38148090084	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1399
Epoch: 1399	max: 0.9999374/1.0	min: 6.25493e-05	loss: 34522.66015625	train_loss: 34518.3761632138	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1400
Epoch: 1400	max: 0.9999368/1.0	min: 6.314393e-05	loss: 34522.63671875	train_loss: 34518.39903071968	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1401
Epoch: 1401	max: 0.99993825/1.0	min: 6.1706945e-05	loss: 34522.94921875	train_loss: 34518.34580933358	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1402
Epoch: 1402	max: 0.9999583/1.0	min: 4.17783e-05	loss: 34522.86328125	train_loss: 34518.38789647978	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1403
Epoch: 1403	max: 0.9999455/1.0	min: 5.4441218e-05	loss: 34522.46875	train_loss: 34518.362495451656	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1404
Epoch: 1404	max: 0.9999305/1.0	min: 6.9543064e-05	loss: 34522.453125	train_loss: 34518.32837515871	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1405
Epoch: 1405	max: 0.99994457/1.0	min: 5.544423e-05	loss: 34522.46484375	train_loss: 34518.31050985925	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1406
Epoch: 1406	max: 0.9999585/1.0	min: 4.1538904e-05	loss: 34522.5234375	train_loss: 34518.28782089991	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1407
Epoch: 1407	max: 0.99996567/1.0	min: 3.4352648e-05	loss: 34522.51953125	train_loss: 34518.27890131457	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1408
Epoch: 1408	max: 0.9999565/1.0	min: 4.349766e-05	loss: 34522.75390625	train_loss: 34518.27533328688	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1409
Epoch: 1409	max: 0.99994636/1.0	min: 5.3661668e-05	loss: 34522.45703125	train_loss: 34518.243762967606	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1410
Epoch: 1410	max: 0.9999137/1.0	min: 8.630092e-05	loss: 34522.703125	train_loss: 34518.26182278118	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1411
Epoch: 1411	max: 0.999915/1.0	min: 8.5033906e-05	loss: 34522.7109375	train_loss: 34518.30734344033	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1412
Epoch: 1412	max: 0.9999324/1.0	min: 6.759012e-05	loss: 34522.484375	train_loss: 34518.23267469497	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1413
Epoch: 1413	max: 0.9999496/1.0	min: 5.0400344e-05	loss: 34522.82421875	train_loss: 34518.19901310696	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1414
Epoch: 1414	max: 0.99995995/1.0	min: 4.009297e-05	loss: 34522.58984375	train_loss: 34518.20410579633	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1415
Epoch: 1415	max: 0.99995553/1.0	min: 4.4506163e-05	loss: 34522.6640625	train_loss: 34518.18062619999	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1416
Epoch: 1416	max: 0.99993634/1.0	min: 6.364498e-05	loss: 34522.4296875	train_loss: 34518.1568785419	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1417
Epoch: 1417	max: 0.9999474/1.0	min: 5.2542273e-05	loss: 34522.328125	train_loss: 34518.167586012016	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1418
Epoch: 1418	max: 0.99994195/1.0	min: 5.807222e-05	loss: 34522.2109375	train_loss: 34518.16393621098	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1419
Epoch: 1419	max: 0.9999423/1.0	min: 5.7702473e-05	loss: 34522.38671875	train_loss: 34518.15587113294	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1420
Epoch: 1420	max: 0.99993646/1.0	min: 6.3481195e-05	loss: 34522.50390625	train_loss: 34518.10262845674	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1421
Epoch: 1421	max: 0.9999589/1.0	min: 4.118156e-05	loss: 34522.78125	train_loss: 34518.12973898334	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1422
Epoch: 1422	max: 0.999961/1.0	min: 3.9011946e-05	loss: 34523.078125	train_loss: 34518.14663945405	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1423
Epoch: 1423	max: 0.9999583/1.0	min: 4.169519e-05	loss: 34523.0	train_loss: 34518.10438005156	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1424
Epoch: 1424	max: 0.9999598/1.0	min: 4.011599e-05	loss: 34522.76171875	train_loss: 34518.10834339775	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1425
Epoch: 1425	max: 0.99994946/1.0	min: 5.0543684e-05	loss: 34522.6640625	train_loss: 34518.069217995166	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1426
Epoch: 1426	max: 0.99995005/1.0	min: 4.9944763e-05	loss: 34522.68359375	train_loss: 34518.04998045181	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1427
Epoch: 1427	max: 0.9999522/1.0	min: 4.7757774e-05	loss: 34522.44140625	train_loss: 34518.02611279496	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1428
Epoch: 1428	max: 0.99995565/1.0	min: 4.4320146e-05	loss: 34522.4921875	train_loss: 34518.01298067246	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1429
Epoch: 1429	max: 0.9999678/1.0	min: 3.2153526e-05	loss: 34522.59375	train_loss: 34518.005427040756	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1430
Epoch: 1430	max: 0.9999547/1.0	min: 4.5271496e-05	loss: 34522.4296875	train_loss: 34517.98864173015	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1431
Epoch: 1431	max: 0.99994934/1.0	min: 5.0695595e-05	loss: 34522.3125	train_loss: 34517.967801138824	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1432
Epoch: 1432	max: 0.99994266/1.0	min: 5.7325895e-05	loss: 34522.44140625	train_loss: 34517.976607499535	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1433
Epoch: 1433	max: 0.9999472/1.0	min: 5.280614e-05	loss: 34522.40625	train_loss: 34517.951302760746	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1434
Epoch: 1434	max: 0.9999596/1.0	min: 4.0421975e-05	loss: 34522.421875	train_loss: 34517.929588307474	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1435
Epoch: 1435	max: 0.9999517/1.0	min: 4.8249658e-05	loss: 34522.20703125	train_loss: 34517.924122557444	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1436
Epoch: 1436	max: 0.9999478/1.0	min: 5.217349e-05	loss: 34522.24609375	train_loss: 34517.91247493574	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1437
Epoch: 1437	max: 0.99994576/1.0	min: 5.4227738e-05	loss: 34522.14453125	train_loss: 34517.906952573394	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1438
Epoch: 1438	max: 0.9999583/1.0	min: 4.1764717e-05	loss: 34522.39453125	train_loss: 34517.889935974854	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1439
Epoch: 1439	max: 0.9999398/1.0	min: 6.0141745e-05	loss: 34522.4296875	train_loss: 34517.87984107906	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1440
Epoch: 1440	max: 0.9999534/1.0	min: 4.6554684e-05	loss: 34522.44921875	train_loss: 34517.854427470425	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1441
Epoch: 1441	max: 0.99995387/1.0	min: 4.6115558e-05	loss: 34522.26953125	train_loss: 34517.832004153504	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1442
Epoch: 1442	max: 0.9999589/1.0	min: 4.1137126e-05	loss: 34522.5546875	train_loss: 34517.87260631503	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1443
Epoch: 1443	max: 0.9999614/1.0	min: 3.8646398e-05	loss: 34522.09375	train_loss: 34517.840558420045	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1444
Epoch: 1444	max: 0.9999645/1.0	min: 3.552253e-05	loss: 34522.234375	train_loss: 34517.82515744999	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1445
Epoch: 1445	max: 0.9999604/1.0	min: 3.9516377e-05	loss: 34522.28125	train_loss: 34517.79478953766	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1446
Epoch: 1446	max: 0.999951/1.0	min: 4.9014212e-05	loss: 34522.19140625	train_loss: 34517.777193267684	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1447
Epoch: 1447	max: 0.99994385/1.0	min: 5.6170982e-05	loss: 34522.32421875	train_loss: 34517.77342298402	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1448
Epoch: 1448	max: 0.9999559/1.0	min: 4.4114036e-05	loss: 34522.1015625	train_loss: 34517.76504000604	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1449
Epoch: 1449	max: 0.9999509/1.0	min: 4.9109374e-05	loss: 34522.0859375	train_loss: 34517.75578074678	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1450
Epoch: 1450	max: 0.999944/1.0	min: 5.607379e-05	loss: 34522.23828125	train_loss: 34517.71975498962	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1451
Epoch: 1451	max: 0.99995756/1.0	min: 4.2488988e-05	loss: 34522.27734375	train_loss: 34517.712997317445	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1452
Epoch: 1452	max: 0.9999559/1.0	min: 4.4161432e-05	loss: 34522.0234375	train_loss: 34517.6861519494	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1453
Epoch: 1453	max: 0.9999496/1.0	min: 5.0426454e-05	loss: 34522.37109375	train_loss: 34517.68692952202	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1454
Epoch: 1454	max: 0.99995303/1.0	min: 4.7020585e-05	loss: 34522.04296875	train_loss: 34517.671204845625	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1455
Epoch: 1455	max: 0.999956/1.0	min: 4.3958822e-05	loss: 34522.19921875	train_loss: 34517.66591619054	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1456
Epoch: 1456	max: 0.99994075/1.0	min: 5.9207017e-05	loss: 34521.96875	train_loss: 34517.66173026601	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1457
Epoch: 1457	max: 0.999949/1.0	min: 5.1010473e-05	loss: 34522.03125	train_loss: 34517.6363248831	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1458
Epoch: 1458	max: 0.9999614/1.0	min: 3.8572754e-05	loss: 34521.98828125	train_loss: 34517.622081804315	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1459
Epoch: 1459	max: 0.9999515/1.0	min: 4.8495614e-05	loss: 34521.83984375	train_loss: 34517.60647325576	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1460
Epoch: 1460	max: 0.999956/1.0	min: 4.4027965e-05	loss: 34521.80078125	train_loss: 34517.647456219805	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1461
Epoch: 1461	max: 0.9999664/1.0	min: 3.3564127e-05	loss: 34522.53515625	train_loss: 34517.61214803589	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1462
Epoch: 1462	max: 0.999943/1.0	min: 5.6958674e-05	loss: 34522.40625	train_loss: 34517.60732292441	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1463
Epoch: 1463	max: 0.999951/1.0	min: 4.8990285e-05	loss: 34522.3984375	train_loss: 34517.56599060913	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1464
Epoch: 1464	max: 0.9999634/1.0	min: 3.6550267e-05	loss: 34522.08984375	train_loss: 34517.55683489719	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1465
Epoch: 1465	max: 0.9999658/1.0	min: 3.422251e-05	loss: 34522.21484375	train_loss: 34517.521336553946	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1466
Epoch: 1466	max: 0.9999589/1.0	min: 4.1182106e-05	loss: 34521.88671875	train_loss: 34517.536326237925	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1467
Epoch: 1467	max: 0.9999639/1.0	min: 3.6119774e-05	loss: 34521.9140625	train_loss: 34517.49289878298	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1468
Epoch: 1468	max: 0.9999405/1.0	min: 5.94837e-05	loss: 34521.77734375	train_loss: 34517.48848447371	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1469
Epoch: 1469	max: 0.99996316/1.0	min: 3.68815e-05	loss: 34522.08984375	train_loss: 34517.494078448224	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1470
Epoch: 1470	max: 0.9999565/1.0	min: 4.3547843e-05	loss: 34521.828125	train_loss: 34517.46804694274	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1471
Epoch: 1471	max: 0.9999521/1.0	min: 4.7891317e-05	loss: 34522.43359375	train_loss: 34517.444493314906	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1472
Epoch: 1472	max: 0.99994874/1.0	min: 5.1239127e-05	loss: 34522.05078125	train_loss: 34517.4276881658	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1473
Epoch: 1473	max: 0.9999608/1.0	min: 3.9234234e-05	loss: 34522.31640625	train_loss: 34517.40492372337	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1474
Epoch: 1474	max: 0.9999459/1.0	min: 5.4082928e-05	loss: 34522.00390625	train_loss: 34517.418333584945	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1475
Epoch: 1475	max: 0.99994445/1.0	min: 5.5556433e-05	loss: 34521.98046875	train_loss: 34517.398721529324	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1476
Epoch: 1476	max: 0.99995315/1.0	min: 4.6874182e-05	loss: 34522.1640625	train_loss: 34517.36539042178	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1477
Epoch: 1477	max: 0.99995446/1.0	min: 4.5562596e-05	loss: 34521.94921875	train_loss: 34517.36479478276	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1478
Epoch: 1478	max: 0.9999653/1.0	min: 3.4739613e-05	loss: 34522.0234375	train_loss: 34517.34732431794	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1479
Epoch: 1479	max: 0.9999621/1.0	min: 3.796173e-05	loss: 34521.953125	train_loss: 34517.32499148396	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1480
Epoch: 1480	max: 0.9999585/1.0	min: 4.1533713e-05	loss: 34522.15625	train_loss: 34517.30284784157	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1481
Epoch: 1481	max: 0.9999659/1.0	min: 3.4121877e-05	loss: 34522.25390625	train_loss: 34517.298656110645	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1482
Epoch: 1482	max: 0.9999658/1.0	min: 3.423191e-05	loss: 34522.40625	train_loss: 34517.35624825808	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1483
Epoch: 1483	max: 0.9999585/1.0	min: 4.1425013e-05	loss: 34522.12890625	train_loss: 34517.312913705406	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1484
Epoch: 1484	max: 0.99995494/1.0	min: 4.5100733e-05	loss: 34521.96484375	train_loss: 34517.261331657224	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1485
Epoch: 1485	max: 0.9999554/1.0	min: 4.4613247e-05	loss: 34521.91015625	train_loss: 34517.258725071224	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1486
Epoch: 1486	max: 0.9999542/1.0	min: 4.571867e-05	loss: 34521.6796875	train_loss: 34517.227458135916	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1487
Epoch: 1487	max: 0.99995613/1.0	min: 4.3826305e-05	loss: 34521.7265625	train_loss: 34517.23398984269	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1488
Epoch: 1488	max: 0.9999523/1.0	min: 4.773301e-05	loss: 34521.9453125	train_loss: 34517.2251660628	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1489
Epoch: 1489	max: 0.9999604/1.0	min: 3.9589966e-05	loss: 34521.7265625	train_loss: 34517.19522927505	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1490
Epoch: 1490	max: 0.9999597/1.0	min: 4.02422e-05	loss: 34521.82421875	train_loss: 34517.20771011396	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1491
Epoch: 1491	max: 0.9999591/1.0	min: 4.0868377e-05	loss: 34521.9375	train_loss: 34517.16085785566	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1492
Epoch: 1492	max: 0.99996126/1.0	min: 3.874396e-05	loss: 34521.875	train_loss: 34517.15633516041	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1493
Epoch: 1493	max: 0.9999479/1.0	min: 5.2102398e-05	loss: 34521.8046875	train_loss: 34517.187409517064	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1494
Epoch: 1494	max: 0.99995804/1.0	min: 4.200545e-05	loss: 34522.10546875	train_loss: 34517.14328094033	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1495
Epoch: 1495	max: 0.9999491/1.0	min: 5.095058e-05	loss: 34521.90625	train_loss: 34517.10643406262	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1496
Epoch: 1496	max: 0.99993646/1.0	min: 6.3552485e-05	loss: 34521.8046875	train_loss: 34517.08931875542	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1497
Epoch: 1497	max: 0.9999423/1.0	min: 5.7742436e-05	loss: 34521.640625	train_loss: 34517.15008603137	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1498
Epoch: 1498	max: 0.999961/1.0	min: 3.895313e-05	loss: 34521.44921875	train_loss: 34517.09027148752	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1499
Epoch: 1499	max: 0.99995077/1.0	min: 4.917695e-05	loss: 34521.88671875	train_loss: 34517.065184004554	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1500
Epoch: 1500	max: 0.9999604/1.0	min: 3.9626004e-05	loss: 34521.953125	train_loss: 34517.03860621439	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1501
Epoch: 1501	max: 0.9999516/1.0	min: 4.838577e-05	loss: 34521.73046875	train_loss: 34517.035617858135	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1502
Epoch: 1502	max: 0.9999515/1.0	min: 4.8478138e-05	loss: 34521.69140625	train_loss: 34517.01893609485	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1503
Epoch: 1503	max: 0.9999529/1.0	min: 4.7035603e-05	loss: 34521.74609375	train_loss: 34517.03133661201	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1504
Epoch: 1504	max: 0.9999573/1.0	min: 4.2639494e-05	loss: 34522.13671875	train_loss: 34517.019075448254	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1505
Epoch: 1505	max: 0.99995697/1.0	min: 4.3014414e-05	loss: 34521.82421875	train_loss: 34516.996476487984	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1506
Epoch: 1506	max: 0.99995303/1.0	min: 4.700422e-05	loss: 34522.3515625	train_loss: 34516.965442776076	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1507
Epoch: 1507	max: 0.9999379/1.0	min: 6.212581e-05	loss: 34521.71875	train_loss: 34516.98114761396	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1508
Epoch: 1508	max: 0.9999515/1.0	min: 4.8482805e-05	loss: 34521.46484375	train_loss: 34516.95358515654	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1509
Epoch: 1509	max: 0.9999534/1.0	min: 4.6557787e-05	loss: 34521.48828125	train_loss: 34516.931082969466	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1510
Epoch: 1510	max: 0.9999585/1.0	min: 4.154009e-05	loss: 34521.5234375	train_loss: 34516.91800745928	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1511
Epoch: 1511	max: 0.99995923/1.0	min: 4.081382e-05	loss: 34521.69921875	train_loss: 34516.928641865634	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1512
Epoch: 1512	max: 0.9999503/1.0	min: 4.9699935e-05	loss: 34521.51953125	train_loss: 34516.869744731666	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1513
Epoch: 1513	max: 0.9999472/1.0	min: 5.283672e-05	loss: 34521.3984375	train_loss: 34516.909156099035	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1514
Epoch: 1514	max: 0.99995923/1.0	min: 4.0736893e-05	loss: 34522.10546875	train_loss: 34516.88632149604	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1515
Epoch: 1515	max: 0.99995685/1.0	min: 4.3116677e-05	loss: 34521.875	train_loss: 34516.84260710857	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1516
Epoch: 1516	max: 0.99995863/1.0	min: 4.1312065e-05	loss: 34521.46484375	train_loss: 34516.82418439552	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1517
Epoch: 1517	max: 0.99995613/1.0	min: 4.387766e-05	loss: 34521.55859375	train_loss: 34516.81482400827	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1518
Epoch: 1518	max: 0.9999591/1.0	min: 4.0945077e-05	loss: 34521.734375	train_loss: 34516.80728344095	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1519
Epoch: 1519	max: 0.99994314/1.0	min: 5.6802182e-05	loss: 34521.53125	train_loss: 34516.78429545243	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1520
Epoch: 1520	max: 0.9999689/1.0	min: 3.1160107e-05	loss: 34521.53515625	train_loss: 34516.83827457265	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1521
Epoch: 1521	max: 0.99997675/1.0	min: 2.329915e-05	loss: 34521.98046875	train_loss: 34516.764843556455	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1522
Epoch: 1522	max: 0.9999654/1.0	min: 3.4563083e-05	loss: 34522.10546875	train_loss: 34516.81042373111	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1523
Epoch: 1523	max: 0.9999646/1.0	min: 3.5357632e-05	loss: 34521.953125	train_loss: 34516.74966129382	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1524
Epoch: 1524	max: 0.99995327/1.0	min: 4.6733498e-05	loss: 34521.60546875	train_loss: 34516.72871570358	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1525
Epoch: 1525	max: 0.9999665/1.0	min: 3.347587e-05	loss: 34522.0859375	train_loss: 34516.70778946798	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1526
Epoch: 1526	max: 0.99995744/1.0	min: 4.252409e-05	loss: 34521.546875	train_loss: 34516.71801936238	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1527
Epoch: 1527	max: 0.9999572/1.0	min: 4.2757496e-05	loss: 34521.7421875	train_loss: 34516.672977246686	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1528
Epoch: 1528	max: 0.99995136/1.0	min: 4.860298e-05	loss: 34521.94921875	train_loss: 34516.667492625886	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1529
Epoch: 1529	max: 0.9999614/1.0	min: 3.856334e-05	loss: 34521.65234375	train_loss: 34516.695467337115	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1530
Epoch: 1530	max: 0.999951/1.0	min: 4.901795e-05	loss: 34521.671875	train_loss: 34516.71758339914	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1531
Epoch: 1531	max: 0.99996364/1.0	min: 3.6309928e-05	loss: 34521.6328125	train_loss: 34516.62779916466	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1532
Epoch: 1532	max: 0.99995744/1.0	min: 4.260052e-05	loss: 34521.63671875	train_loss: 34516.624879517374	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1533
Epoch: 1533	max: 0.9999602/1.0	min: 3.979615e-05	loss: 34521.8984375	train_loss: 34516.60950177289	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1534
Epoch: 1534	max: 0.99996483/1.0	min: 3.5141453e-05	loss: 34521.81640625	train_loss: 34516.60001654822	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1535
Epoch: 1535	max: 0.99995244/1.0	min: 4.752512e-05	loss: 34521.62109375	train_loss: 34516.6021470101	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1536
