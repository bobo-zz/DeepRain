Epoch: 0	max: 0.54334867/1.0	min: 0.4566513	loss: 36656.19921875	train_loss: 36949.809652932614	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1
Epoch: 1	max: 0.6234425/1.0	min: 0.37655756	loss: 36235.44921875	train_loss: 36469.03542769881	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_2
Epoch: 2	max: 0.6902026/1.0	min: 0.30979735	loss: 35942.6328125	train_loss: 36125.714271336554	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_3
Epoch: 3	max: 0.7436007/1.0	min: 0.25639927	loss: 35746.3515625	train_loss: 35894.71403279063	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_4
Epoch: 4	max: 0.7847707/1.0	min: 0.21522926	loss: 35618.38671875	train_loss: 35744.189102080236	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_5
Epoch: 5	max: 0.81619936/1.0	min: 0.1838007	loss: 35536.31640625	train_loss: 35649.696131685094	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_6
Epoch: 6	max: 0.8395273/1.0	min: 0.16047268	loss: 35485.69921875	train_loss: 35592.327185816146	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_7
Epoch: 7	max: 0.8565102/1.0	min: 0.14348976	loss: 35455.21875	train_loss: 35559.11916312477	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_8
Epoch: 8	max: 0.86817443/1.0	min: 0.13182555	loss: 35437.796875	train_loss: 35540.49818453487	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_9
Epoch: 9	max: 0.8765142/1.0	min: 0.123485774	loss: 35427.2421875	train_loss: 35530.5981483417	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_10
Epoch: 10	max: 0.8821837/1.0	min: 0.11781629	loss: 35420.87890625	train_loss: 35524.867295885975	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_11
Epoch: 11	max: 0.8858486/1.0	min: 0.11415136	loss: 35416.8515625	train_loss: 35521.32436197433	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_12
Epoch: 12	max: 0.8883163/1.0	min: 0.11168366	loss: 35413.90625	train_loss: 35518.50001064505	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_13
Epoch: 13	max: 0.88970757/1.0	min: 0.110292375	loss: 35411.65625	train_loss: 35515.86466171962	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_14
Epoch: 14	max: 0.89056677/1.0	min: 0.10943329	loss: 35409.56640625	train_loss: 35513.02832551406	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_15
Epoch: 15	max: 0.89078623/1.0	min: 0.10921377	loss: 35407.59765625	train_loss: 35509.816516571445	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_16
Epoch: 16	max: 0.8914323/1.0	min: 0.10856769	loss: 35405.11328125	train_loss: 35506.06941541249	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_17
Epoch: 17	max: 0.8916996/1.0	min: 0.10830036	loss: 35402.4296875	train_loss: 35501.65049102719	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_18
Epoch: 18	max: 0.8923975/1.0	min: 0.10760252	loss: 35399.03515625	train_loss: 35496.44698135374	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_19
Epoch: 19	max: 0.8929248/1.0	min: 0.10707523	loss: 35395.0546875	train_loss: 35490.22577476619	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_20
Epoch: 20	max: 0.89393157/1.0	min: 0.10606842	loss: 35390.015625	train_loss: 35482.73178389772	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_21
Epoch: 21	max: 0.89511025/1.0	min: 0.10488973	loss: 35383.7890625	train_loss: 35473.66213187477	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_22
Epoch: 22	max: 0.8966382/1.0	min: 0.10336184	loss: 35376.01171875	train_loss: 35462.55520039793	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_23
Epoch: 23	max: 0.89880556/1.0	min: 0.10119448	loss: 35365.9453125	train_loss: 35448.826990334295	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_24
Epoch: 24	max: 0.9020415/1.0	min: 0.09795845	loss: 35352.6640625	train_loss: 35431.38715858417	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_25
Epoch: 25	max: 0.9058774/1.0	min: 0.09412257	loss: 35334.8203125	train_loss: 35408.76872270996	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_26
Epoch: 26	max: 0.9104224/1.0	min: 0.0895776	loss: 35309.96484375	train_loss: 35378.542998265824	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_27
Epoch: 27	max: 0.9162744/1.0	min: 0.08372555	loss: 35274.98046875	train_loss: 35337.821683776165	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_28
Epoch: 28	max: 0.9250559/1.0	min: 0.07494411	loss: 35226.84765625	train_loss: 35283.814873846466	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_29
Epoch: 29	max: 0.93556565/1.0	min: 0.064434394	loss: 35166.13671875	train_loss: 35215.29129167054	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_30
Epoch: 30	max: 0.94708455/1.0	min: 0.05291549	loss: 35102.625	train_loss: 35138.921623389695	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_31
Epoch: 31	max: 0.9597044/1.0	min: 0.04029563	loss: 35049.9609375	train_loss: 35069.41014318562	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_32
Epoch: 32	max: 0.96921843/1.0	min: 0.030781565	loss: 35015.078125	train_loss: 35017.969865794934	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_33
Epoch: 33	max: 0.9748582/1.0	min: 0.025141777	loss: 34994.328125	train_loss: 34986.71767678527	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_34
Epoch: 34	max: 0.97819126/1.0	min: 0.021808773	loss: 34979.13671875	train_loss: 34967.78893185619	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_35
Epoch: 35	max: 0.9806938/1.0	min: 0.019306168	loss: 34968.7109375	train_loss: 34954.72692104468	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_36
Epoch: 36	max: 0.98248553/1.0	min: 0.01751443	loss: 34959.953125	train_loss: 34944.63679568469	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_37
Epoch: 37	max: 0.9840136/1.0	min: 0.015986381	loss: 34953.734375	train_loss: 34936.30161495107	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_38
Epoch: 38	max: 0.9848706/1.0	min: 0.015129407	loss: 34945.42578125	train_loss: 34929.02803664607	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_39
Epoch: 39	max: 0.98563427/1.0	min: 0.01436575	loss: 34938.59765625	train_loss: 34922.62769658507	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_40
Epoch: 40	max: 0.98630255/1.0	min: 0.013697451	loss: 34932.49609375	train_loss: 34916.803077677905	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_41
Epoch: 41	max: 0.9867884/1.0	min: 0.013211577	loss: 34926.2109375	train_loss: 34911.43992271693	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_42
Epoch: 42	max: 0.9874598/1.0	min: 0.012540285	loss: 34921.80859375	train_loss: 34906.40314212885	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_43
Epoch: 43	max: 0.9879325/1.0	min: 0.012067534	loss: 34916.8125	train_loss: 34901.514912749284	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_44
Epoch: 44	max: 0.98826796/1.0	min: 0.011732076	loss: 34911.5	train_loss: 34896.81711946845	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_45
Epoch: 45	max: 0.988504/1.0	min: 0.011495971	loss: 34905.79296875	train_loss: 34892.194992180725	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_46
Epoch: 46	max: 0.9890878/1.0	min: 0.010912142	loss: 34902.59375	train_loss: 34887.63295669206	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_47
Epoch: 47	max: 0.9893036/1.0	min: 0.010696386	loss: 34897.0234375	train_loss: 34883.06133388301	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_48
Epoch: 48	max: 0.9895309/1.0	min: 0.010469027	loss: 34891.859375	train_loss: 34878.51246148427	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_49
Epoch: 49	max: 0.9897512/1.0	min: 0.010248697	loss: 34886.64453125	train_loss: 34873.95414547333	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_50
Epoch: 50	max: 0.9900727/1.0	min: 0.009927294	loss: 34882.21875	train_loss: 34869.3659758996	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_51
Epoch: 51	max: 0.9900587/1.0	min: 0.009941261	loss: 34875.87109375	train_loss: 34864.7687633547	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_52
Epoch: 52	max: 0.9905794/1.0	min: 0.009420529	loss: 34872.80859375	train_loss: 34860.26913786696	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_53
Epoch: 53	max: 0.9905896/1.0	min: 0.009410375	loss: 34866.7109375	train_loss: 34855.74628923185	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_54
Epoch: 54	max: 0.9908522/1.0	min: 0.009147861	loss: 34862.46484375	train_loss: 34851.15476162827	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_55
Epoch: 55	max: 0.9912532/1.0	min: 0.008746752	loss: 34859.1015625	train_loss: 34846.55187285163	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_56
Epoch: 56	max: 0.99117273/1.0	min: 0.008827232	loss: 34853.17578125	train_loss: 34841.980804552986	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_57
Epoch: 57	max: 0.99155045/1.0	min: 0.008449537	loss: 34850.0859375	train_loss: 34837.38669842763	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_58
Epoch: 58	max: 0.99164104/1.0	min: 0.008358897	loss: 34845.2734375	train_loss: 34832.86362334324	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_59
Epoch: 59	max: 0.99190044/1.0	min: 0.008099523	loss: 34841.703125	train_loss: 34828.35467327434	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_60
Epoch: 60	max: 0.9916437/1.0	min: 0.008356281	loss: 34835.515625	train_loss: 34823.81994814892	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_61
Epoch: 61	max: 0.9921117/1.0	min: 0.007888335	loss: 34832.99609375	train_loss: 34819.27429394277	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_62
Epoch: 62	max: 0.99229395/1.0	min: 0.007706024	loss: 34829.1640625	train_loss: 34814.68124264524	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_63
Epoch: 63	max: 0.99261546/1.0	min: 0.007384501	loss: 34824.78125	train_loss: 34810.20069841215	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_64
Epoch: 64	max: 0.99293995/1.0	min: 0.0070600403	loss: 34820.78515625	train_loss: 34805.997701636625	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_65
Epoch: 65	max: 0.9931855/1.0	min: 0.0068144733	loss: 34816.42578125	train_loss: 34801.89248885173	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_66
Epoch: 66	max: 0.9933977/1.0	min: 0.006602326	loss: 34812.20703125	train_loss: 34797.99775389415	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_67
Epoch: 67	max: 0.99400735/1.0	min: 0.005992676	loss: 34810.203125	train_loss: 34794.26531629351	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_68
Epoch: 68	max: 0.99423534/1.0	min: 0.0057646283	loss: 34806.37109375	train_loss: 34790.60993725226	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_69
Epoch: 69	max: 0.99450845/1.0	min: 0.005491534	loss: 34803.12890625	train_loss: 34787.109659029324	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_70
Epoch: 70	max: 0.99480313/1.0	min: 0.0051968377	loss: 34800.26171875	train_loss: 34783.85990725257	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_71
Epoch: 71	max: 0.9952081/1.0	min: 0.0047919666	loss: 34798.59375	train_loss: 34780.636577945	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_72
Epoch: 72	max: 0.99528235/1.0	min: 0.0047176396	loss: 34794.78125	train_loss: 34777.5591255187	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_73
Epoch: 73	max: 0.9955379/1.0	min: 0.0044620973	loss: 34792.7109375	train_loss: 34774.73812447742	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_74
Epoch: 74	max: 0.99564457/1.0	min: 0.0043554557	loss: 34789.76171875	train_loss: 34772.24852033785	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_75
Epoch: 75	max: 0.99600405/1.0	min: 0.0039959354	loss: 34789.078125	train_loss: 34769.92966427443	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_76
Epoch: 76	max: 0.9959915/1.0	min: 0.004008484	loss: 34785.734375	train_loss: 34767.81151001022	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_77
Epoch: 77	max: 0.99610496/1.0	min: 0.0038950592	loss: 34783.54296875	train_loss: 34765.61117836848	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_78
Epoch: 78	max: 0.99641573/1.0	min: 0.0035841914	loss: 34783.2265625	train_loss: 34763.59494756829	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_79
Epoch: 79	max: 0.99643326/1.0	min: 0.0035667806	loss: 34780.546875	train_loss: 34761.689229820855	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_80
Epoch: 80	max: 0.9964148/1.0	min: 0.0035852394	loss: 34777.74609375	train_loss: 34759.70571610228	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_81
Epoch: 81	max: 0.99655825/1.0	min: 0.003441726	loss: 34776.34765625	train_loss: 34757.90836933296	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_82
Epoch: 82	max: 0.996549/1.0	min: 0.0034509148	loss: 34773.99609375	train_loss: 34756.09730447944	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_83
Epoch: 83	max: 0.99668854/1.0	min: 0.003311521	loss: 34772.76171875	train_loss: 34754.29407535148	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_84
Epoch: 84	max: 0.9968286/1.0	min: 0.003171353	loss: 34771.81640625	train_loss: 34752.57107216958	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_85
Epoch: 85	max: 0.9967308/1.0	min: 0.003269147	loss: 34768.94921875	train_loss: 34750.86485381441	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_86
Epoch: 86	max: 0.99675626/1.0	min: 0.0032437365	loss: 34767.06640625	train_loss: 34749.16442878654	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_87
Epoch: 87	max: 0.9970325/1.0	min: 0.0029674892	loss: 34767.6796875	train_loss: 34747.50378721897	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_88
Epoch: 88	max: 0.996874/1.0	min: 0.0031260299	loss: 34764.1953125	train_loss: 34745.85518278521	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_89
Epoch: 89	max: 0.9970022/1.0	min: 0.0029978328	loss: 34763.55078125	train_loss: 34744.19563717407	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_90
Epoch: 90	max: 0.9969091/1.0	min: 0.0030909346	loss: 34761.015625	train_loss: 34742.663208960425	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_91
Epoch: 91	max: 0.99691427/1.0	min: 0.0030857306	loss: 34759.38671875	train_loss: 34740.99350071225	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_92
Epoch: 92	max: 0.99694544/1.0	min: 0.0030545027	loss: 34757.9765625	train_loss: 34739.41180042658	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_93
Epoch: 93	max: 0.99691135/1.0	min: 0.0030887083	loss: 34756.16015625	train_loss: 34737.83966713892	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_94
Epoch: 94	max: 0.997086/1.0	min: 0.0029140757	loss: 34756.17578125	train_loss: 34736.26111343367	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_95
Epoch: 95	max: 0.9970583/1.0	min: 0.0029417987	loss: 34754.34375	train_loss: 34734.77207106249	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_96
Epoch: 96	max: 0.9970548/1.0	min: 0.0029451696	loss: 34752.73828125	train_loss: 34733.16930034916	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_97
Epoch: 97	max: 0.9969132/1.0	min: 0.0030868351	loss: 34750.2890625	train_loss: 34731.60721889322	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_98
Epoch: 98	max: 0.99679154/1.0	min: 0.0032084342	loss: 34748.16015625	train_loss: 34730.08550105289	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_99
Epoch: 99	max: 0.99697316/1.0	min: 0.0030268244	loss: 34748.00390625	train_loss: 34728.56122356156	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_100
Epoch: 100	max: 0.9970342/1.0	min: 0.0029658293	loss: 34747.234375	train_loss: 34727.14253094807	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_101
Epoch: 101	max: 0.99675816/1.0	min: 0.0032418824	loss: 34743.9765625	train_loss: 34725.551032860305	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_102
Epoch: 102	max: 0.9968291/1.0	min: 0.003170872	loss: 34743.09375	train_loss: 34724.032213377155	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_103
Epoch: 103	max: 0.99686676/1.0	min: 0.0031332164	loss: 34742.22265625	train_loss: 34722.57439971587	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_104
Epoch: 104	max: 0.9966684/1.0	min: 0.0033315937	loss: 34739.875	train_loss: 34721.12230341493	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_105
Epoch: 105	max: 0.99672323/1.0	min: 0.0032768254	loss: 34739.04296875	train_loss: 34719.65309422612	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_106
Epoch: 106	max: 0.9963689/1.0	min: 0.0036311653	loss: 34736.21875	train_loss: 34718.185142604976	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_107
Epoch: 107	max: 0.9964998/1.0	min: 0.0035001484	loss: 34735.703125	train_loss: 34716.78494770377	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_108
Epoch: 108	max: 0.99640465/1.0	min: 0.0035954232	loss: 34734.140625	train_loss: 34715.36332431407	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_109
Epoch: 109	max: 0.9962915/1.0	min: 0.0037084965	loss: 34732.73046875	train_loss: 34713.97306366515	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_110
Epoch: 110	max: 0.9963198/1.0	min: 0.0036801691	loss: 34731.8515625	train_loss: 34712.5511978586	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_111
Epoch: 111	max: 0.9962291/1.0	min: 0.0037708285	loss: 34730.58984375	train_loss: 34711.120962138455	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_112
Epoch: 112	max: 0.99621177/1.0	min: 0.003788271	loss: 34729.69921875	train_loss: 34709.75291916342	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_113
Epoch: 113	max: 0.9963451/1.0	min: 0.0036548856	loss: 34729.76171875	train_loss: 34708.4395932042	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_114
Epoch: 114	max: 0.9961054/1.0	min: 0.0038945489	loss: 34726.88671875	train_loss: 34707.179678306544	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_115
Epoch: 115	max: 0.99610174/1.0	min: 0.003898319	loss: 34725.5546875	train_loss: 34705.75829007572	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_116
Epoch: 116	max: 0.9959279/1.0	min: 0.004072122	loss: 34723.44140625	train_loss: 34704.41383701846	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_117
Epoch: 117	max: 0.99599445/1.0	min: 0.0040055118	loss: 34722.51171875	train_loss: 34703.10320377338	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_118
Epoch: 118	max: 0.9957944/1.0	min: 0.0042055417	loss: 34720.46484375	train_loss: 34701.7895516885	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_119
Epoch: 119	max: 0.99594384/1.0	min: 0.004056141	loss: 34719.82421875	train_loss: 34700.5563597408	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_120
Epoch: 120	max: 0.99612194/1.0	min: 0.0038780258	loss: 34719.4609375	train_loss: 34699.21947047643	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_121
Epoch: 121	max: 0.9961358/1.0	min: 0.0038641784	loss: 34718.35546875	train_loss: 34697.96927499458	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_122
Epoch: 122	max: 0.99600476/1.0	min: 0.003995235	loss: 34716.515625	train_loss: 34696.693459293325	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_123
Epoch: 123	max: 0.9960228/1.0	min: 0.003977108	loss: 34715.3828125	train_loss: 34695.44132399278	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_124
Epoch: 124	max: 0.9959817/1.0	min: 0.004018337	loss: 34714.015625	train_loss: 34694.1568272521	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_125
Epoch: 125	max: 0.9958703/1.0	min: 0.004129632	loss: 34712.578125	train_loss: 34692.869961503624	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_126
Epoch: 126	max: 0.9959935/1.0	min: 0.004006423	loss: 34712.0390625	train_loss: 34691.666686505174	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_127
Epoch: 127	max: 0.9959681/1.0	min: 0.00403189	loss: 34710.6484375	train_loss: 34690.36099111235	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_128
Epoch: 128	max: 0.9961052/1.0	min: 0.003894856	loss: 34710.12109375	train_loss: 34689.187544999535	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_129
Epoch: 129	max: 0.9960055/1.0	min: 0.0039945203	loss: 34708.49609375	train_loss: 34687.971135459244	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_130
Epoch: 130	max: 0.995974/1.0	min: 0.0040259603	loss: 34707.359375	train_loss: 34686.89158547395	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_131
Epoch: 131	max: 0.9961302/1.0	min: 0.003869788	loss: 34706.8515625	train_loss: 34685.643159006104	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_132
Epoch: 132	max: 0.99593395/1.0	min: 0.0040660985	loss: 34705.12890625	train_loss: 34684.51424646584	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_133
Epoch: 133	max: 0.99601954/1.0	min: 0.00398043	loss: 34704.3671875	train_loss: 34683.415672322095	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_134
Epoch: 134	max: 0.9959758/1.0	min: 0.0040242434	loss: 34703.171875	train_loss: 34682.30668635033	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_135
Epoch: 135	max: 0.9959644/1.0	min: 0.004035545	loss: 34702.12890625	train_loss: 34681.24687374195	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_136
Epoch: 136	max: 0.9957488/1.0	min: 0.0042512673	loss: 34700.60546875	train_loss: 34680.21166862149	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_137
Epoch: 137	max: 0.99596256/1.0	min: 0.004037502	loss: 34700.109375	train_loss: 34679.17804719435	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_138
Epoch: 138	max: 0.99595416/1.0	min: 0.0040458054	loss: 34699.16015625	train_loss: 34678.084560901305	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_139
Epoch: 139	max: 0.9961533/1.0	min: 0.0038466929	loss: 34698.9921875	train_loss: 34677.07329456599	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_140
Epoch: 140	max: 0.9960961/1.0	min: 0.003903922	loss: 34697.80078125	train_loss: 34676.13980533104	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_141
Epoch: 141	max: 0.9959812/1.0	min: 0.004018751	loss: 34696.42578125	train_loss: 34675.183619878764	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_142
Epoch: 142	max: 0.996061/1.0	min: 0.003938917	loss: 34695.796875	train_loss: 34674.164901523596	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_143
Epoch: 143	max: 0.9959857/1.0	min: 0.00401423	loss: 34694.69921875	train_loss: 34673.26317373498	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_144
Epoch: 144	max: 0.99612135/1.0	min: 0.003878634	loss: 34694.203125	train_loss: 34672.45297500155	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_145
Epoch: 145	max: 0.9960531/1.0	min: 0.00394685	loss: 34693.15625	train_loss: 34671.511469559024	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_146
Epoch: 146	max: 0.99612206/1.0	min: 0.0038779709	loss: 34692.48046875	train_loss: 34670.68315875449	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_147
Epoch: 147	max: 0.9957599/1.0	min: 0.0042401436	loss: 34690.9140625	train_loss: 34669.92057533599	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_148
Epoch: 148	max: 0.9961243/1.0	min: 0.0038756302	loss: 34690.8828125	train_loss: 34669.18173909173	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_149
Epoch: 149	max: 0.9957474/1.0	min: 0.0042526117	loss: 34689.38671875	train_loss: 34668.37419145996	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_150
Epoch: 150	max: 0.99595696/1.0	min: 0.0040430785	loss: 34688.89453125	train_loss: 34667.695955074014	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_151
Epoch: 151	max: 0.9960413/1.0	min: 0.0039587035	loss: 34688.4140625	train_loss: 34666.92337788771	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_152
Epoch: 152	max: 0.9960129/1.0	min: 0.0039871396	loss: 34687.66015625	train_loss: 34666.13586569429	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_153
Epoch: 153	max: 0.99596125/1.0	min: 0.004038764	loss: 34686.8515625	train_loss: 34665.464804556854	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_154
Epoch: 154	max: 0.9961747/1.0	min: 0.0038252957	loss: 34686.6640625	train_loss: 34664.80478088613	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_155
Epoch: 155	max: 0.9962141/1.0	min: 0.0037858747	loss: 34686.13671875	train_loss: 34664.10603003453	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_156
Epoch: 156	max: 0.99644715/1.0	min: 0.0035528904	loss: 34686.3359375	train_loss: 34663.42162145423	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_157
Epoch: 157	max: 0.9962651/1.0	min: 0.003734893	loss: 34684.98046875	train_loss: 34662.82788355088	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_158
Epoch: 158	max: 0.99625814/1.0	min: 0.0037419065	loss: 34684.27734375	train_loss: 34662.16046592422	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_159
Epoch: 159	max: 0.9961028/1.0	min: 0.0038972583	loss: 34683.234375	train_loss: 34661.53824186331	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_160
Epoch: 160	max: 0.99638927/1.0	min: 0.0036107393	loss: 34683.44921875	train_loss: 34661.03938378701	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_161
Epoch: 161	max: 0.99641526/1.0	min: 0.0035846632	loss: 34682.93359375	train_loss: 34660.33628201257	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_162
Epoch: 162	max: 0.9962863/1.0	min: 0.003713676	loss: 34681.8828125	train_loss: 34659.74652051979	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_163
Epoch: 163	max: 0.99639374/1.0	min: 0.0036062077	loss: 34681.5546875	train_loss: 34659.193840095846	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_164
Epoch: 164	max: 0.995795/1.0	min: 0.0042049927	loss: 34679.92578125	train_loss: 34658.65597661572	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_165
Epoch: 165	max: 0.99651957/1.0	min: 0.0034804263	loss: 34680.71875	train_loss: 34658.27882341215	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_166
Epoch: 166	max: 0.996536/1.0	min: 0.0034639498	loss: 34680.1328125	train_loss: 34657.60346070621	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_167
Epoch: 167	max: 0.99608445/1.0	min: 0.0039155525	loss: 34678.41796875	train_loss: 34657.03195837978	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_168
Epoch: 168	max: 0.9963856/1.0	min: 0.0036144832	loss: 34678.359375	train_loss: 34656.50310448408	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_169
Epoch: 169	max: 0.9963456/1.0	min: 0.0036543908	loss: 34677.62109375	train_loss: 34655.94219495154	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_170
Epoch: 170	max: 0.9963372/1.0	min: 0.003662807	loss: 34677.04296875	train_loss: 34655.45742850396	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_171
Epoch: 171	max: 0.9966288/1.0	min: 0.003371158	loss: 34677.1640625	train_loss: 34654.97896247522	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_172
Epoch: 172	max: 0.9965018/1.0	min: 0.0034982236	loss: 34676.2734375	train_loss: 34654.49489956878	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_173
Epoch: 173	max: 0.9965468/1.0	min: 0.0034531753	loss: 34675.828125	train_loss: 34654.02191767698	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_174
Epoch: 174	max: 0.9967906/1.0	min: 0.0032093616	loss: 34676.078125	train_loss: 34653.51080908197	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_175
Epoch: 175	max: 0.9966534/1.0	min: 0.0033466965	loss: 34674.984375	train_loss: 34653.052070268954	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_176
Epoch: 176	max: 0.99679595/1.0	min: 0.0032040528	loss: 34674.80859375	train_loss: 34652.5655231946	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_177
Epoch: 177	max: 0.9967956/1.0	min: 0.0032043743	loss: 34674.33203125	train_loss: 34652.17457739146	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_178
Epoch: 178	max: 0.99667716/1.0	min: 0.0033228777	loss: 34673.50390625	train_loss: 34651.68558727781	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_179
Epoch: 179	max: 0.9968894/1.0	min: 0.0031106493	loss: 34673.5	train_loss: 34651.24018042394	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_180
Epoch: 180	max: 0.99655426/1.0	min: 0.003445704	loss: 34672.17578125	train_loss: 34650.813085961694	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_181
Epoch: 181	max: 0.99669075/1.0	min: 0.0033092094	loss: 34671.87890625	train_loss: 34650.362994317475	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_182
Epoch: 182	max: 0.99664295/1.0	min: 0.0033570698	loss: 34671.3203125	train_loss: 34649.93358068562	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_183
Epoch: 183	max: 0.99715024/1.0	min: 0.002849759	loss: 34672.48046875	train_loss: 34649.53445319274	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_184
Epoch: 184	max: 0.9968303/1.0	min: 0.0031697315	loss: 34670.6875	train_loss: 34649.15988286572	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_185
Epoch: 185	max: 0.9965926/1.0	min: 0.0034074069	loss: 34669.86328125	train_loss: 34648.70349515747	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_186
Epoch: 186	max: 0.9971064/1.0	min: 0.0028936546	loss: 34670.7109375	train_loss: 34648.38681213613	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_187
Epoch: 187	max: 0.9968528/1.0	min: 0.0031472447	loss: 34669.33203125	train_loss: 34647.92551609145	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_188
Epoch: 188	max: 0.99678195/1.0	min: 0.003218055	loss: 34668.71875	train_loss: 34647.540854739564	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_189
Epoch: 189	max: 0.99698144/1.0	min: 0.003018552	loss: 34668.78125	train_loss: 34647.10302183977	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_190
Epoch: 190	max: 0.997088/1.0	min: 0.0029120413	loss: 34668.62890625	train_loss: 34646.754499953546	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_191
Epoch: 191	max: 0.9970246/1.0	min: 0.0029753663	loss: 34667.94921875	train_loss: 34646.40004683823	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_192
Epoch: 192	max: 0.9968953/1.0	min: 0.003104727	loss: 34667.1796875	train_loss: 34645.97345366112	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_193
Epoch: 193	max: 0.9972801/1.0	min: 0.002719892	loss: 34667.9453125	train_loss: 34645.68772886861	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_194
Epoch: 194	max: 0.99702555/1.0	min: 0.0029744725	loss: 34666.5859375	train_loss: 34645.297043385355	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_195
Epoch: 195	max: 0.99697185/1.0	min: 0.0030281865	loss: 34666.08984375	train_loss: 34644.8909491902	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_196
Epoch: 196	max: 0.99727553/1.0	min: 0.0027244291	loss: 34666.5703125	train_loss: 34644.57114329788	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_197
Epoch: 197	max: 0.9969649/1.0	min: 0.003035159	loss: 34665.171875	train_loss: 34644.35897290738	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_198
Epoch: 198	max: 0.99711585/1.0	min: 0.0028841824	loss: 34665.11328125	train_loss: 34643.86814845782	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_199
Epoch: 199	max: 0.99725926/1.0	min: 0.002740737	loss: 34665.00390625	train_loss: 34643.4936037757	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_200
Epoch: 200	max: 0.9971615/1.0	min: 0.0028385401	loss: 34664.48828125	train_loss: 34643.18228440868	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_201
Epoch: 201	max: 0.99708146/1.0	min: 0.0029184818	loss: 34663.87890625	train_loss: 34642.84810624536	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_202
Epoch: 202	max: 0.99722505/1.0	min: 0.002774991	loss: 34663.73046875	train_loss: 34642.49211104918	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_203
Epoch: 203	max: 0.99692446/1.0	min: 0.0030755703	loss: 34662.84375	train_loss: 34642.17708430107	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_204
Epoch: 204	max: 0.99730057/1.0	min: 0.0026994296	loss: 34663.203125	train_loss: 34641.883756038646	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_205
Epoch: 205	max: 0.9974011/1.0	min: 0.0025989136	loss: 34663.1015625	train_loss: 34641.53838460377	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_206
Epoch: 206	max: 0.99697554/1.0	min: 0.003024486	loss: 34661.71875	train_loss: 34641.25553978152	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_207
Epoch: 207	max: 0.9973597/1.0	min: 0.0026402597	loss: 34662.328125	train_loss: 34640.9658448687	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_208
Epoch: 208	max: 0.99701715/1.0	min: 0.0029828202	loss: 34661.12109375	train_loss: 34640.645042696335	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_209
Epoch: 209	max: 0.99722505/1.0	min: 0.002774965	loss: 34661.19140625	train_loss: 34640.34119809086	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_210
Epoch: 210	max: 0.99704033/1.0	min: 0.0029596104	loss: 34660.50390625	train_loss: 34640.00126192246	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_211
Epoch: 211	max: 0.9974375/1.0	min: 0.0025624374	loss: 34661.19921875	train_loss: 34639.71987111746	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_212
Epoch: 212	max: 0.9969002/1.0	min: 0.003099856	loss: 34659.78125	train_loss: 34639.5080215301	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_213
Epoch: 213	max: 0.99736834/1.0	min: 0.0026316089	loss: 34660.234375	train_loss: 34639.17650753282	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_214
Epoch: 214	max: 0.9971904/1.0	min: 0.002809584	loss: 34659.5	train_loss: 34638.87872721959	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_215
Epoch: 215	max: 0.9971636/1.0	min: 0.0028364381	loss: 34659.02734375	train_loss: 34638.553315256104	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_216
Epoch: 216	max: 0.9974892/1.0	min: 0.0025107313	loss: 34659.390625	train_loss: 34638.31417417627	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_217
Epoch: 217	max: 0.9971154/1.0	min: 0.0028846804	loss: 34658.28125	train_loss: 34638.05657651276	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_218
Epoch: 218	max: 0.9972205/1.0	min: 0.0027794943	loss: 34658.18359375	train_loss: 34637.72679330407	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_219
Epoch: 219	max: 0.99740136/1.0	min: 0.0025987136	loss: 34658.05859375	train_loss: 34637.468687097426	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_220
Epoch: 220	max: 0.9977673/1.0	min: 0.0022327048	loss: 34659.00390625	train_loss: 34637.2577413717	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_221
Epoch: 221	max: 0.99732333/1.0	min: 0.002676718	loss: 34657.32421875	train_loss: 34637.01302470426	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_222
Epoch: 222	max: 0.9974751/1.0	min: 0.0025249356	loss: 34657.30859375	train_loss: 34636.66946921838	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_223
Epoch: 223	max: 0.9975533/1.0	min: 0.0024467574	loss: 34657.24609375	train_loss: 34636.40265487582	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_224
Epoch: 224	max: 0.9973328/1.0	min: 0.0026672434	loss: 34656.3984375	train_loss: 34636.14950152127	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_225
Epoch: 225	max: 0.9973833/1.0	min: 0.0026167324	loss: 34656.234375	train_loss: 34635.92286886071	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_226
Epoch: 226	max: 0.9973218/1.0	min: 0.0026782318	loss: 34655.828125	train_loss: 34635.67379885111	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_227
Epoch: 227	max: 0.9974286/1.0	min: 0.0025713325	loss: 34655.625	train_loss: 34635.454098538336	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_228
Epoch: 228	max: 0.99738044/1.0	min: 0.002619564	loss: 34655.2734375	train_loss: 34635.22183125852	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_229
Epoch: 229	max: 0.9976108/1.0	min: 0.0023891928	loss: 34655.33984375	train_loss: 34634.97383010885	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_230
Epoch: 230	max: 0.99752396/1.0	min: 0.002476008	loss: 34654.8984375	train_loss: 34634.68973352533	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_231
Epoch: 231	max: 0.9978058/1.0	min: 0.0021942034	loss: 34655.42578125	train_loss: 34634.47811425818	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_232
Epoch: 232	max: 0.9975133/1.0	min: 0.0024867153	loss: 34654.28125	train_loss: 34634.2880613813	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_233
Epoch: 233	max: 0.9974099/1.0	min: 0.0025901045	loss: 34653.98828125	train_loss: 34634.02110284668	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_234
Epoch: 234	max: 0.9976069/1.0	min: 0.002393085	loss: 34654.0	train_loss: 34633.75785604794	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_235
Epoch: 235	max: 0.9975635/1.0	min: 0.0024365112	loss: 34653.63671875	train_loss: 34633.52882099282	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_236
Epoch: 236	max: 0.9975944/1.0	min: 0.0024055783	loss: 34653.421875	train_loss: 34633.2992454594	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_237
Epoch: 237	max: 0.9975356/1.0	min: 0.0024644274	loss: 34652.96484375	train_loss: 34633.08077319847	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_238
Epoch: 238	max: 0.99753976/1.0	min: 0.0024602178	loss: 34652.78515625	train_loss: 34632.87459742351	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_239
Epoch: 239	max: 0.9976597/1.0	min: 0.0023403643	loss: 34652.67578125	train_loss: 34632.66202252106	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_240
Epoch: 240	max: 0.9978017/1.0	min: 0.0021982787	loss: 34652.859375	train_loss: 34632.4228504738	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_241
Epoch: 241	max: 0.99772483/1.0	min: 0.002275142	loss: 34652.28125	train_loss: 34632.21187523226	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_242
Epoch: 242	max: 0.99766135/1.0	min: 0.0023386555	loss: 34651.92578125	train_loss: 34632.059942768334	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_243
Epoch: 243	max: 0.9979359/1.0	min: 0.0020641114	loss: 34652.3046875	train_loss: 34631.80877036108	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_244
Epoch: 244	max: 0.9978898/1.0	min: 0.0021101618	loss: 34651.8359375	train_loss: 34631.6244425864	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_245
Epoch: 245	max: 0.99782336/1.0	min: 0.0021767055	loss: 34651.51171875	train_loss: 34631.39352722811	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_246
Epoch: 246	max: 0.9977235/1.0	min: 0.0022764152	loss: 34651.0546875	train_loss: 34631.16598296405	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_247
Epoch: 247	max: 0.99783784/1.0	min: 0.0021622193	loss: 34650.9765625	train_loss: 34630.969635958594	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_248
Epoch: 248	max: 0.9979303/1.0	min: 0.0020697431	loss: 34650.93359375	train_loss: 34630.767640301776	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_249
Epoch: 249	max: 0.9980186/1.0	min: 0.0019813236	loss: 34650.9765625	train_loss: 34630.55295671141	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_250
Epoch: 250	max: 0.9977648/1.0	min: 0.0022351725	loss: 34650.0625	train_loss: 34630.354307471665	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_251
Epoch: 251	max: 0.9978236/1.0	min: 0.0021763884	loss: 34650.046875	train_loss: 34630.187168551805	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_252
Epoch: 252	max: 0.99815685/1.0	min: 0.0018430898	loss: 34650.640625	train_loss: 34629.96744065868	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_253
Epoch: 253	max: 0.99792516/1.0	min: 0.00207479	loss: 34649.68359375	train_loss: 34629.856821155394	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_254
Epoch: 254	max: 0.99783427/1.0	min: 0.0021657902	loss: 34649.43359375	train_loss: 34629.58217786139	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_255
Epoch: 255	max: 0.99801934/1.0	min: 0.001980642	loss: 34649.50390625	train_loss: 34629.43117587173	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_256
Epoch: 256	max: 0.9977471/1.0	min: 0.0022528225	loss: 34648.8359375	train_loss: 34629.20718899031	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_257
Epoch: 257	max: 0.9980141/1.0	min: 0.0019858414	loss: 34648.9609375	train_loss: 34629.036626234825	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_258
Epoch: 258	max: 0.99807775/1.0	min: 0.0019222723	loss: 34648.8515625	train_loss: 34628.84508063143	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_259
Epoch: 259	max: 0.9981816/1.0	min: 0.0018184955	loss: 34648.97265625	train_loss: 34628.67238063994	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_260
Epoch: 260	max: 0.9979108/1.0	min: 0.0020892306	loss: 34648.1015625	train_loss: 34628.51031360321	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_261
Epoch: 261	max: 0.9981838/1.0	min: 0.0018162454	loss: 34648.66015625	train_loss: 34628.31999024526	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_262
Epoch: 262	max: 0.99813205/1.0	min: 0.0018679606	loss: 34648.1328125	train_loss: 34628.174402231976	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_263
Epoch: 263	max: 0.9981318/1.0	min: 0.0018681883	loss: 34648.03125	train_loss: 34627.96321215394	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_264
Epoch: 264	max: 0.9978927/1.0	min: 0.002107332	loss: 34647.21484375	train_loss: 34627.788885405054	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_265
Epoch: 265	max: 0.9979479/1.0	min: 0.0020521511	loss: 34647.15625	train_loss: 34627.59650900378	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_266
Epoch: 266	max: 0.99808913/1.0	min: 0.0019108872	loss: 34647.1171875	train_loss: 34627.43628501254	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_267
Epoch: 267	max: 0.99818856/1.0	min: 0.0018113831	loss: 34647.109375	train_loss: 34627.25121256813	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_268
Epoch: 268	max: 0.9982193/1.0	min: 0.0017807226	loss: 34647.1484375	train_loss: 34627.13371781324	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_269
Epoch: 269	max: 0.99817026/1.0	min: 0.0018297449	loss: 34646.82421875	train_loss: 34626.95062050972	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_270
Epoch: 270	max: 0.99818355/1.0	min: 0.0018164712	loss: 34646.578125	train_loss: 34626.77132252183	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_271
Epoch: 271	max: 0.9981578/1.0	min: 0.0018422076	loss: 34646.19140625	train_loss: 34626.59866075576	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_272
Epoch: 272	max: 0.9980856/1.0	min: 0.001914366	loss: 34645.84375	train_loss: 34626.42309530998	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_273
Epoch: 273	max: 0.9981211/1.0	min: 0.0018788402	loss: 34645.796875	train_loss: 34626.26278180354	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_274
Epoch: 274	max: 0.99820817/1.0	min: 0.0017918318	loss: 34645.8046875	train_loss: 34626.205995776814	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_275
Epoch: 275	max: 0.99844223/1.0	min: 0.001557775	loss: 34646.390625	train_loss: 34625.979639403726	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_276
Epoch: 276	max: 0.99820673/1.0	min: 0.0017932206	loss: 34645.40625	train_loss: 34625.80598280921	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_277
Epoch: 277	max: 0.9980896/1.0	min: 0.001910365	loss: 34645.0546875	train_loss: 34625.63528263579	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_278
Epoch: 278	max: 0.9983474/1.0	min: 0.0016525632	loss: 34645.48828125	train_loss: 34625.479472953826	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_279
Epoch: 279	max: 0.9982193/1.0	min: 0.00178071	loss: 34644.93359375	train_loss: 34625.35430940713	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_280
Epoch: 280	max: 0.9979286/1.0	min: 0.0020713154	loss: 34644.19921875	train_loss: 34625.17355449879	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_281
Epoch: 281	max: 0.9983071/1.0	min: 0.001692856	loss: 34644.6640625	train_loss: 34625.03408255141	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_282
Epoch: 282	max: 0.9980872/1.0	min: 0.0019127978	loss: 34644.08203125	train_loss: 34624.863589472625	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_283
Epoch: 283	max: 0.9981238/1.0	min: 0.0018761257	loss: 34643.92578125	train_loss: 34624.71351118311	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_284
Epoch: 284	max: 0.9983071/1.0	min: 0.0016928996	loss: 34643.984375	train_loss: 34624.592151306824	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_285
Epoch: 285	max: 0.9983656/1.0	min: 0.00163443	loss: 34644.03515625	train_loss: 34624.41626118698	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_286
Epoch: 286	max: 0.9982717/1.0	min: 0.0017283075	loss: 34643.6796875	train_loss: 34624.31224935743	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_287
Epoch: 287	max: 0.99792445/1.0	min: 0.002075497	loss: 34643.11328125	train_loss: 34624.138898566205	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_288
Epoch: 288	max: 0.99815863/1.0	min: 0.0018414056	loss: 34643.0703125	train_loss: 34624.01164471851	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_289
Epoch: 289	max: 0.998058/1.0	min: 0.0019419648	loss: 34642.80859375	train_loss: 34623.83474767357	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_290
Epoch: 290	max: 0.99824476/1.0	min: 0.0017552081	loss: 34642.9765625	train_loss: 34623.693753483836	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_291
Epoch: 291	max: 0.99837106/1.0	min: 0.0016289428	loss: 34643.08984375	train_loss: 34623.553062194194	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_292
Epoch: 292	max: 0.99832696/1.0	min: 0.0016730033	loss: 34642.60546875	train_loss: 34623.425409640935	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_293
Epoch: 293	max: 0.9982381/1.0	min: 0.0017619041	loss: 34642.4140625	train_loss: 34623.26825626316	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_294
Epoch: 294	max: 0.998524/1.0	min: 0.0014759598	loss: 34643.0234375	train_loss: 34623.13608004692	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_295
Epoch: 295	max: 0.9982974/1.0	min: 0.0017026584	loss: 34642.25	train_loss: 34623.060712599094	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_296
Epoch: 296	max: 0.99833727/1.0	min: 0.0016626525	loss: 34642.0546875	train_loss: 34622.892188370955	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_297
Epoch: 297	max: 0.9981292/1.0	min: 0.001870789	loss: 34641.625	train_loss: 34622.76011134724	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_298
Epoch: 298	max: 0.99819547/1.0	min: 0.001804516	loss: 34641.48828125	train_loss: 34622.66610054348	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_299
Epoch: 299	max: 0.998302/1.0	min: 0.0016979339	loss: 34641.578125	train_loss: 34622.46642308854	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_300
Epoch: 300	max: 0.9987047/1.0	min: 0.0012953731	loss: 34642.61328125	train_loss: 34622.3339125209	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_301
Epoch: 301	max: 0.99835795/1.0	min: 0.0016420011	loss: 34641.20703125	train_loss: 34622.27807922628	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_302
Epoch: 302	max: 0.9982626/1.0	min: 0.0017374677	loss: 34641.015625	train_loss: 34622.14181531029	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_303
Epoch: 303	max: 0.9982168/1.0	min: 0.0017832095	loss: 34640.67578125	train_loss: 34621.936192110275	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_304
Epoch: 304	max: 0.9986029/1.0	min: 0.0013971414	loss: 34641.6953125	train_loss: 34621.789203305	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_305
Epoch: 305	max: 0.9983059/1.0	min: 0.0016940298	loss: 34640.60546875	train_loss: 34621.74472634476	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_306
Epoch: 306	max: 0.9983766/1.0	min: 0.0016234106	loss: 34640.53125	train_loss: 34621.54332052056	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_307
Epoch: 307	max: 0.9986008/1.0	min: 0.0013992632	loss: 34641.11328125	train_loss: 34621.40092553883	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_308
Epoch: 308	max: 0.99854726/1.0	min: 0.0014527064	loss: 34640.56640625	train_loss: 34621.3090814869	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_309
Epoch: 309	max: 0.99841607/1.0	min: 0.0015839362	loss: 34640.3046875	train_loss: 34621.178125096776	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_310
Epoch: 310	max: 0.9982122/1.0	min: 0.0017877475	loss: 34639.765625	train_loss: 34621.10827517264	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_311
Epoch: 311	max: 0.99833125/1.0	min: 0.0016687686	loss: 34639.765625	train_loss: 34620.973694142514	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_312
Epoch: 312	max: 0.9983802/1.0	min: 0.0016198038	loss: 34639.7109375	train_loss: 34620.81183710362	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_313
Epoch: 313	max: 0.9984761/1.0	min: 0.0015239067	loss: 34639.7734375	train_loss: 34620.67909040939	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_314
Epoch: 314	max: 0.9986444/1.0	min: 0.0013555402	loss: 34640.03515625	train_loss: 34620.546159362224	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_315
Epoch: 315	max: 0.9984547/1.0	min: 0.0015453597	loss: 34639.33984375	train_loss: 34620.452448071504	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_316
Epoch: 316	max: 0.99828786/1.0	min: 0.0017120928	loss: 34639.06640625	train_loss: 34620.31969847408	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_317
Epoch: 317	max: 0.998437/1.0	min: 0.0015630384	loss: 34639.19140625	train_loss: 34620.22087223616	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_318
Epoch: 318	max: 0.9987104/1.0	min: 0.0012896451	loss: 34639.71484375	train_loss: 34620.155186462594	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_319
Epoch: 319	max: 0.9984743/1.0	min: 0.0015257319	loss: 34638.87890625	train_loss: 34620.00986505946	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_320
Epoch: 320	max: 0.998467/1.0	min: 0.001532977	loss: 34638.6953125	train_loss: 34619.82200167611	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_321
Epoch: 321	max: 0.9986737/1.0	min: 0.0013262917	loss: 34638.953125	train_loss: 34619.69823843754	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_322
Epoch: 322	max: 0.99859804/1.0	min: 0.0014019955	loss: 34638.71484375	train_loss: 34619.603754412856	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_323
Epoch: 323	max: 0.9986407/1.0	min: 0.0013592376	loss: 34638.765625	train_loss: 34619.51155471944	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_324
Epoch: 324	max: 0.9985172/1.0	min: 0.0014828368	loss: 34638.1640625	train_loss: 34619.41154107441	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_325
Epoch: 325	max: 0.9986951/1.0	min: 0.0013049827	loss: 34638.37890625	train_loss: 34619.298787238324	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_326
Epoch: 326	max: 0.9982723/1.0	min: 0.0017276773	loss: 34637.78515625	train_loss: 34619.22835328797	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_327
Epoch: 327	max: 0.9984415/1.0	min: 0.0015585346	loss: 34637.7734375	train_loss: 34619.17844589991	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_328
Epoch: 328	max: 0.9985026/1.0	min: 0.0014974083	loss: 34637.75	train_loss: 34618.979424083365	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_329
Epoch: 329	max: 0.9986979/1.0	min: 0.0013021345	loss: 34638.0390625	train_loss: 34618.80239010436	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_330
Epoch: 330	max: 0.9985291/1.0	min: 0.0014709578	loss: 34637.46875	train_loss: 34618.72801893658	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_331
Epoch: 331	max: 0.9986426/1.0	min: 0.0013573683	loss: 34637.72265625	train_loss: 34618.57073781819	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_332
Epoch: 332	max: 0.9986994/1.0	min: 0.001300523	loss: 34637.5234375	train_loss: 34618.55157624179	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_333
Epoch: 333	max: 0.99857545/1.0	min: 0.001424513	loss: 34637.21875	train_loss: 34618.38687600644	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_334
Epoch: 334	max: 0.9987214/1.0	min: 0.0012785869	loss: 34637.2734375	train_loss: 34618.26697256674	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_335
Epoch: 335	max: 0.99864167/1.0	min: 0.0013583667	loss: 34637.17578125	train_loss: 34618.14266304348	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_336
Epoch: 336	max: 0.9987206/1.0	min: 0.001279433	loss: 34637.171875	train_loss: 34618.022689443205	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_337
Epoch: 337	max: 0.9988079/1.0	min: 0.0011921041	loss: 34637.37890625	train_loss: 34617.93739742041	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_338
Epoch: 338	max: 0.9983041/1.0	min: 0.001695893	loss: 34636.37890625	train_loss: 34617.870259081195	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_339
Epoch: 339	max: 0.9989135/1.0	min: 0.0010865063	loss: 34637.21484375	train_loss: 34617.844959181064	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_340
Epoch: 340	max: 0.99874485/1.0	min: 0.0012551305	loss: 34636.6015625	train_loss: 34617.63474457683	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_341
Epoch: 341	max: 0.9985654/1.0	min: 0.0014346637	loss: 34636.27734375	train_loss: 34617.47913521538	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_342
Epoch: 342	max: 0.9988049/1.0	min: 0.0011950469	loss: 34636.6015625	train_loss: 34617.3893011427	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_343
Epoch: 343	max: 0.99882835/1.0	min: 0.0011716048	loss: 34636.44140625	train_loss: 34617.27919985987	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_344
Epoch: 344	max: 0.9987357/1.0	min: 0.0012642521	loss: 34636.11328125	train_loss: 34617.17963959727	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_345
Epoch: 345	max: 0.9988557/1.0	min: 0.0011442344	loss: 34636.51171875	train_loss: 34617.03703364998	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_346
Epoch: 346	max: 0.9987789/1.0	min: 0.0012211488	loss: 34635.94921875	train_loss: 34616.99127299331	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_347
Epoch: 347	max: 0.99864584/1.0	min: 0.0013542048	loss: 34635.625	train_loss: 34616.85281280967	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_348
Epoch: 348	max: 0.9988819/1.0	min: 0.0011181511	loss: 34636.04296875	train_loss: 34616.79114796234	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_349
Epoch: 349	max: 0.9986615/1.0	min: 0.0013384299	loss: 34635.4765625	train_loss: 34616.66151010699	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_350
Epoch: 350	max: 0.99864584/1.0	min: 0.0013542268	loss: 34635.15625	train_loss: 34616.52685069057	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_351
Epoch: 351	max: 0.99875593/1.0	min: 0.0012441084	loss: 34635.390625	train_loss: 34616.437876931595	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_352
Epoch: 352	max: 0.9988279/1.0	min: 0.0011721234	loss: 34635.4296875	train_loss: 34616.29837256519	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_353
Epoch: 353	max: 0.99863213/1.0	min: 0.0013678682	loss: 34634.91015625	train_loss: 34616.184525191995	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_354
Epoch: 354	max: 0.99881697/1.0	min: 0.001183114	loss: 34635.234375	train_loss: 34616.085509278615	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_355
Epoch: 355	max: 0.9986486/1.0	min: 0.00135138	loss: 34634.80859375	train_loss: 34616.012184712934	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_356
Epoch: 356	max: 0.99865925/1.0	min: 0.0013407762	loss: 34634.67578125	train_loss: 34615.86082659792	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_357
Epoch: 357	max: 0.99890447/1.0	min: 0.0010954682	loss: 34634.921875	train_loss: 34615.75603767961	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_358
Epoch: 358	max: 0.9987852/1.0	min: 0.0012148243	loss: 34634.68359375	train_loss: 34615.67713171993	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_359
Epoch: 359	max: 0.99887735/1.0	min: 0.0011226112	loss: 34634.765625	train_loss: 34615.52662714449	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_360
Epoch: 360	max: 0.99872893/1.0	min: 0.0012710242	loss: 34634.24609375	train_loss: 34615.47292624721	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_361
Epoch: 361	max: 0.9987508/1.0	min: 0.0012491774	loss: 34634.3671875	train_loss: 34615.322819893474	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_362
Epoch: 362	max: 0.99874914/1.0	min: 0.0012508389	loss: 34634.07421875	train_loss: 34615.22002934163	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_363
Epoch: 363	max: 0.99865675/1.0	min: 0.0013432557	loss: 34633.88671875	train_loss: 34615.12545628561	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_364
Epoch: 364	max: 0.99862015/1.0	min: 0.0013798572	loss: 34633.74609375	train_loss: 34614.99650358448	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_365
Epoch: 365	max: 0.9989666/1.0	min: 0.0010334355	loss: 34634.50390625	train_loss: 34614.995764237276	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_366
Epoch: 366	max: 0.99880636/1.0	min: 0.0011936584	loss: 34633.6796875	train_loss: 34614.80860584665	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_367
Epoch: 367	max: 0.99881315/1.0	min: 0.0011868207	loss: 34633.78125	train_loss: 34614.66218800322	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_368
Epoch: 368	max: 0.9988801/1.0	min: 0.0011199666	loss: 34633.67578125	train_loss: 34614.56896686873	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_369
Epoch: 369	max: 0.9988041/1.0	min: 0.0011959199	loss: 34633.39453125	train_loss: 34614.49117718785	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_370
Epoch: 370	max: 0.9987368/1.0	min: 0.0012632092	loss: 34633.15234375	train_loss: 34614.393681097485	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_371
Epoch: 371	max: 0.9989543/1.0	min: 0.001045726	loss: 34633.53125	train_loss: 34614.2606223097	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_372
Epoch: 372	max: 0.99868864/1.0	min: 0.0013113499	loss: 34632.98046875	train_loss: 34614.192241886536	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_373
Epoch: 373	max: 0.9988311/1.0	min: 0.0011689098	loss: 34633.13671875	train_loss: 34614.03380190914	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_374
Epoch: 374	max: 0.9988586/1.0	min: 0.0011414858	loss: 34633.015625	train_loss: 34613.922530638396	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_375
Epoch: 375	max: 0.9987332/1.0	min: 0.0012667405	loss: 34632.69921875	train_loss: 34613.847858989844	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_376
Epoch: 376	max: 0.99914455/1.0	min: 0.0008554546	loss: 34634.0	train_loss: 34613.869230866	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_377
Epoch: 377	max: 0.99879456/1.0	min: 0.0012054392	loss: 34632.453125	train_loss: 34613.7330254978	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_378
Epoch: 378	max: 0.9989458/1.0	min: 0.0010542163	loss: 34632.88671875	train_loss: 34613.51950608897	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_379
Epoch: 379	max: 0.99908316/1.0	min: 0.00091683335	loss: 34633.13671875	train_loss: 34613.429417986656	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_380
Epoch: 380	max: 0.9988708/1.0	min: 0.0011291665	loss: 34632.36328125	train_loss: 34613.360848371885	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_381
Epoch: 381	max: 0.9988458/1.0	min: 0.0011541746	loss: 34632.2265625	train_loss: 34613.242813138706	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_382
Epoch: 382	max: 0.9988626/1.0	min: 0.0011373633	loss: 34632.1015625	train_loss: 34613.14674590456	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_383
Epoch: 383	max: 0.99898225/1.0	min: 0.001017707	loss: 34632.265625	train_loss: 34613.040660225444	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_384
Epoch: 384	max: 0.9989229/1.0	min: 0.0010770643	loss: 34632.0859375	train_loss: 34612.92416755698	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_385
Epoch: 385	max: 0.9989159/1.0	min: 0.0010840787	loss: 34631.9296875	train_loss: 34612.802826551466	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_386
Epoch: 386	max: 0.99880695/1.0	min: 0.0011930321	loss: 34631.66015625	train_loss: 34612.7148892334	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_387
Epoch: 387	max: 0.9990081/1.0	min: 0.0009918549	loss: 34632.1484375	train_loss: 34612.69751070312	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_388
Epoch: 388	max: 0.9988937/1.0	min: 0.0011063346	loss: 34631.5859375	train_loss: 34612.50643203038	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_389
Epoch: 389	max: 0.99893826/1.0	min: 0.0010617095	loss: 34631.53515625	train_loss: 34612.4058091981	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_390
Epoch: 390	max: 0.9989784/1.0	min: 0.0010216023	loss: 34631.59765625	train_loss: 34612.3201944367	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_391
Epoch: 391	max: 0.9988796/1.0	min: 0.0011203666	loss: 34631.34375	train_loss: 34612.20887816642	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_392
Epoch: 392	max: 0.9988739/1.0	min: 0.0011260352	loss: 34631.16015625	train_loss: 34612.11261303109	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_393
Epoch: 393	max: 0.9987936/1.0	min: 0.0012064185	loss: 34631.015625	train_loss: 34612.00249190976	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_394
Epoch: 394	max: 0.9990233/1.0	min: 0.0009766541	loss: 34631.32421875	train_loss: 34611.96163039607	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_395
Epoch: 395	max: 0.9989222/1.0	min: 0.0010778471	loss: 34630.9765625	train_loss: 34611.818731709864	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_396
Epoch: 396	max: 0.9989925/1.0	min: 0.001007514	loss: 34631.03125	train_loss: 34611.70473675756	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_397
Epoch: 397	max: 0.998958/1.0	min: 0.0010420295	loss: 34630.96484375	train_loss: 34611.587182971016	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_398
Epoch: 398	max: 0.99895823/1.0	min: 0.0010417054	loss: 34630.63671875	train_loss: 34611.52452135978	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_399
Epoch: 399	max: 0.99906725/1.0	min: 0.0009328351	loss: 34630.7734375	train_loss: 34611.407100152515	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_400
Epoch: 400	max: 0.9989611/1.0	min: 0.0010389037	loss: 34630.5234375	train_loss: 34611.3066142543	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_401
Epoch: 401	max: 0.9990396/1.0	min: 0.0009603245	loss: 34630.73828125	train_loss: 34611.20356289871	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_402
Epoch: 402	max: 0.99909496/1.0	min: 0.0009050994	loss: 34630.53515625	train_loss: 34611.08469251285	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_403
Epoch: 403	max: 0.99889344/1.0	min: 0.0011066315	loss: 34630.19140625	train_loss: 34610.990296551776	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_404
Epoch: 404	max: 0.99907887/1.0	min: 0.00092117116	loss: 34630.4296875	train_loss: 34610.89909846092	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_405
Epoch: 405	max: 0.99914587/1.0	min: 0.00085410423	loss: 34630.46875	train_loss: 34610.776265696615	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_406
Epoch: 406	max: 0.9990208/1.0	min: 0.0009791893	loss: 34630.1015625	train_loss: 34610.748724529294	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_407
Epoch: 407	max: 0.99898165/1.0	min: 0.0010182783	loss: 34629.875	train_loss: 34610.56873074213	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_408
Epoch: 408	max: 0.99904543/1.0	min: 0.00095455797	loss: 34629.9140625	train_loss: 34610.46169475025	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_409
Epoch: 409	max: 0.9990601/1.0	min: 0.00093988836	loss: 34629.87109375	train_loss: 34610.356157775146	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_410
Epoch: 410	max: 0.99915874/1.0	min: 0.0008412929	loss: 34630.078125	train_loss: 34610.24211346851	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_411
Epoch: 411	max: 0.9990656/1.0	min: 0.0009344603	loss: 34629.5234375	train_loss: 34610.16521071395	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_412
Epoch: 412	max: 0.9989249/1.0	min: 0.0010750572	loss: 34629.36328125	train_loss: 34610.07302892357	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_413
Epoch: 413	max: 0.99888295/1.0	min: 0.0011170172	loss: 34629.17578125	train_loss: 34609.99945032826	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_414
Epoch: 414	max: 0.9992944/1.0	min: 0.0007055279	loss: 34630.03515625	train_loss: 34609.95277032624	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_415
Epoch: 415	max: 0.99900156/1.0	min: 0.0009984705	loss: 34629.2109375	train_loss: 34609.778298417565	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_416
Epoch: 416	max: 0.9991066/1.0	min: 0.0008934469	loss: 34629.17578125	train_loss: 34609.663919759536	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_417
Epoch: 417	max: 0.9992508/1.0	min: 0.00074915297	loss: 34629.44140625	train_loss: 34609.49663761535	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_418
Epoch: 418	max: 0.9988733/1.0	min: 0.0011266806	loss: 34628.73828125	train_loss: 34609.47760861823	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_419
Epoch: 419	max: 0.9991447/1.0	min: 0.000855339	loss: 34629.1484375	train_loss: 34609.35691163833	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_420
Epoch: 420	max: 0.99904877/1.0	min: 0.00095119525	loss: 34628.671875	train_loss: 34609.174879807695	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_421
Epoch: 421	max: 0.99921846/1.0	min: 0.0007814893	loss: 34628.94921875	train_loss: 34609.07485938855	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_422
Epoch: 422	max: 0.99905676/1.0	min: 0.00094320666	loss: 34628.49609375	train_loss: 34609.010038767345	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_423
Epoch: 423	max: 0.9988477/1.0	min: 0.0011522091	loss: 34628.34765625	train_loss: 34608.90653790026	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_424
Epoch: 424	max: 0.9991418/1.0	min: 0.0008581557	loss: 34628.67578125	train_loss: 34608.80035206088	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_425
Epoch: 425	max: 0.99907947/1.0	min: 0.0009205237	loss: 34628.203125	train_loss: 34608.66670392435	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_426
Epoch: 426	max: 0.9990398/1.0	min: 0.0009600916	loss: 34628.2109375	train_loss: 34608.621465359065	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_427
Epoch: 427	max: 0.99911624/1.0	min: 0.0008837845	loss: 34628.13671875	train_loss: 34608.44763166961	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_428
Epoch: 428	max: 0.9990594/1.0	min: 0.0009406638	loss: 34627.953125	train_loss: 34608.366081866254	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_429
Epoch: 429	max: 0.99902713/1.0	min: 0.0009728818	loss: 34627.9765625	train_loss: 34608.26566467701	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_430
Epoch: 430	max: 0.9991584/1.0	min: 0.0008416754	loss: 34627.953125	train_loss: 34608.130492846525	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_431
Epoch: 431	max: 0.9990853/1.0	min: 0.0009146568	loss: 34627.62890625	train_loss: 34608.026365856866	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_432
Epoch: 432	max: 0.9989955/1.0	min: 0.0010045527	loss: 34627.546875	train_loss: 34607.949214879074	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_433
Epoch: 433	max: 0.9992036/1.0	min: 0.0007963796	loss: 34627.99609375	train_loss: 34607.96230151818	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_434
Epoch: 434	max: 0.99900013/1.0	min: 0.0009999375	loss: 34627.49609375	train_loss: 34607.73805818779	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_435
Epoch: 435	max: 0.99911577/1.0	min: 0.00088425574	loss: 34627.3515625	train_loss: 34607.65713982953	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_436
Epoch: 436	max: 0.9991059/1.0	min: 0.000894149	loss: 34627.14453125	train_loss: 34607.53119677474	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_437
Epoch: 437	max: 0.999121/1.0	min: 0.0008789757	loss: 34627.125	train_loss: 34607.41806842639	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_438
Epoch: 438	max: 0.99926263/1.0	min: 0.0007374205	loss: 34627.5546875	train_loss: 34607.34227372491	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_439
Epoch: 439	max: 0.99915457/1.0	min: 0.0008454605	loss: 34627.0859375	train_loss: 34607.293349068656	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_440
Epoch: 440	max: 0.9992236/1.0	min: 0.0007764358	loss: 34627.07421875	train_loss: 34607.106016970145	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_441
Epoch: 441	max: 0.99909556/1.0	min: 0.00090450887	loss: 34626.80078125	train_loss: 34607.033093045495	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_442
Epoch: 442	max: 0.99931943/1.0	min: 0.00068058126	loss: 34627.046875	train_loss: 34606.90523968785	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_443
Epoch: 443	max: 0.999265/1.0	min: 0.0007349996	loss: 34626.93359375	train_loss: 34606.88359249195	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_444
Epoch: 444	max: 0.9991997/1.0	min: 0.00080032035	loss: 34626.67578125	train_loss: 34606.73143986901	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_445
Epoch: 445	max: 0.999172/1.0	min: 0.00082800013	loss: 34626.578125	train_loss: 34606.62970414499	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_446
Epoch: 446	max: 0.9990675/1.0	min: 0.0009325747	loss: 34626.26171875	train_loss: 34606.567055598134	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_447
Epoch: 447	max: 0.9992655/1.0	min: 0.0007344531	loss: 34626.5625	train_loss: 34606.44351445405	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_448
Epoch: 448	max: 0.99927145/1.0	min: 0.0007285518	loss: 34626.40625	train_loss: 34606.345331274	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_449
Epoch: 449	max: 0.9992273/1.0	min: 0.0007727374	loss: 34626.03125	train_loss: 34606.242157016444	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_450
Epoch: 450	max: 0.9991716/1.0	min: 0.0008283853	loss: 34626.03125	train_loss: 34606.12996252942	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_451
Epoch: 451	max: 0.9992224/1.0	min: 0.0007775871	loss: 34626.0	train_loss: 34606.033678523316	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_452
Epoch: 452	max: 0.9991128/1.0	min: 0.0008872426	loss: 34625.7890625	train_loss: 34605.95301322696	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_453
Epoch: 453	max: 0.9993006/1.0	min: 0.0006994305	loss: 34626.01171875	train_loss: 34605.85481262774	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_454
Epoch: 454	max: 0.99902356/1.0	min: 0.00097643177	loss: 34625.6171875	train_loss: 34605.76805642652	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_455
Epoch: 455	max: 0.9991636/1.0	min: 0.0008364273	loss: 34625.65625	train_loss: 34605.67931831026	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_456
Epoch: 456	max: 0.9991866/1.0	min: 0.00081341236	loss: 34625.578125	train_loss: 34605.5696839581	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_457
Epoch: 457	max: 0.99911815/1.0	min: 0.0008818919	loss: 34625.34375	train_loss: 34605.491538151866	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_458
Epoch: 458	max: 0.999193/1.0	min: 0.00080702355	loss: 34625.296875	train_loss: 34605.38505521879	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_459
Epoch: 459	max: 0.9993405/1.0	min: 0.0006595188	loss: 34625.5234375	train_loss: 34605.29402164236	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_460
Epoch: 460	max: 0.9991196/1.0	min: 0.00088037964	loss: 34625.0390625	train_loss: 34605.204259665705	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_461
Epoch: 461	max: 0.9993443/1.0	min: 0.0006557332	loss: 34625.46484375	train_loss: 34605.11763265669	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_462
Epoch: 462	max: 0.99935764/1.0	min: 0.0006424176	loss: 34625.38671875	train_loss: 34605.08875843862	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_463
Epoch: 463	max: 0.99935764/1.0	min: 0.0006423695	loss: 34625.12109375	train_loss: 34604.93832644308	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_464
Epoch: 464	max: 0.99903023/1.0	min: 0.0009697801	loss: 34624.7265625	train_loss: 34604.8649762325	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_465
Epoch: 465	max: 0.9991887/1.0	min: 0.00081122713	loss: 34624.76171875	train_loss: 34604.74354377632	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_466
Epoch: 466	max: 0.9993674/1.0	min: 0.0006325738	loss: 34624.92578125	train_loss: 34604.63276362954	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_467
Epoch: 467	max: 0.9993413/1.0	min: 0.00065866037	loss: 34624.78515625	train_loss: 34604.61088127478	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_468
Epoch: 468	max: 0.9992342/1.0	min: 0.0007658493	loss: 34624.453125	train_loss: 34604.480255848976	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_469
Epoch: 469	max: 0.9992281/1.0	min: 0.00077190023	loss: 34624.37109375	train_loss: 34604.4215962932	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_470
Epoch: 470	max: 0.99941015/1.0	min: 0.00058982684	loss: 34624.5703125	train_loss: 34604.288371055525	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_471
Epoch: 471	max: 0.9992086/1.0	min: 0.0007913777	loss: 34624.1015625	train_loss: 34604.22654362923	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_472
Epoch: 472	max: 0.99927837/1.0	min: 0.0007216655	loss: 34624.0390625	train_loss: 34604.11612589806	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_473
Epoch: 473	max: 0.99937904/1.0	min: 0.0006209462	loss: 34624.4140625	train_loss: 34604.035930919425	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_474
Epoch: 474	max: 0.9993349/1.0	min: 0.0006651157	loss: 34624.03515625	train_loss: 34603.94157802242	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_475
Epoch: 475	max: 0.9994011/1.0	min: 0.0005989253	loss: 34624.12890625	train_loss: 34603.827505651556	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_476
Epoch: 476	max: 0.99925464/1.0	min: 0.0007452942	loss: 34623.73046875	train_loss: 34603.78524141041	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_477
Epoch: 477	max: 0.99926025/1.0	min: 0.0007396976	loss: 34623.66015625	train_loss: 34603.65370438112	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_478
Epoch: 478	max: 0.9992194/1.0	min: 0.0007805281	loss: 34623.6015625	train_loss: 34603.56965734547	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_479
Epoch: 479	max: 0.9992157/1.0	min: 0.0007842635	loss: 34623.484375	train_loss: 34603.514666945375	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_480
Epoch: 480	max: 0.9992467/1.0	min: 0.00075334025	loss: 34623.47265625	train_loss: 34603.3941799633	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_481
Epoch: 481	max: 0.9991423/1.0	min: 0.00085765176	loss: 34623.37890625	train_loss: 34603.35397650734	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_482
Epoch: 482	max: 0.99946445/1.0	min: 0.0005356039	loss: 34623.734375	train_loss: 34603.309485998856	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_483
Epoch: 483	max: 0.99924904/1.0	min: 0.0007508933	loss: 34623.24609375	train_loss: 34603.169726151216	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_484
Epoch: 484	max: 0.9991234/1.0	min: 0.00087661424	loss: 34623.02734375	train_loss: 34603.125356125354	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_485
Epoch: 485	max: 0.9993467/1.0	min: 0.0006533615	loss: 34623.05859375	train_loss: 34603.00357576954	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_486
Epoch: 486	max: 0.9992969/1.0	min: 0.0007031089	loss: 34623.00390625	train_loss: 34602.919836472654	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_487
Epoch: 487	max: 0.9994673/1.0	min: 0.00053266226	loss: 34623.21875	train_loss: 34602.86689234176	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_488
Epoch: 488	max: 0.9993523/1.0	min: 0.00064772565	loss: 34622.8125	train_loss: 34602.746902773906	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_489
Epoch: 489	max: 0.9993143/1.0	min: 0.0006857027	loss: 34622.69140625	train_loss: 34602.677280266784	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_490
Epoch: 490	max: 0.9993055/1.0	min: 0.00069452915	loss: 34622.6640625	train_loss: 34602.5651491662	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_491
Epoch: 491	max: 0.9993113/1.0	min: 0.00068872067	loss: 34622.66796875	train_loss: 34602.484675480766	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_492
Epoch: 492	max: 0.9994824/1.0	min: 0.0005176133	loss: 34622.890625	train_loss: 34602.42623995494	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_493
Epoch: 493	max: 0.999368/1.0	min: 0.0006319887	loss: 34622.4921875	train_loss: 34602.35106702124	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_494
Epoch: 494	max: 0.9993954/1.0	min: 0.0006046705	loss: 34622.48828125	train_loss: 34602.25586590719	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_495
Epoch: 495	max: 0.9992092/1.0	min: 0.0007908281	loss: 34622.171875	train_loss: 34602.23208728168	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_496
Epoch: 496	max: 0.99928147/1.0	min: 0.00071856537	loss: 34622.1484375	train_loss: 34602.097111416915	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_497
Epoch: 497	max: 0.9993412/1.0	min: 0.00065881235	loss: 34621.984375	train_loss: 34602.019067706395	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_498
Epoch: 498	max: 0.9993587/1.0	min: 0.0006413183	loss: 34621.91015625	train_loss: 34601.92618576196	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_499
Epoch: 499	max: 0.9993674/1.0	min: 0.00063262356	loss: 34621.9296875	train_loss: 34601.8616332025	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_500
Epoch: 500	max: 0.9993918/1.0	min: 0.0006081713	loss: 34621.75390625	train_loss: 34601.78173434984	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_501
Epoch: 501	max: 0.9992424/1.0	min: 0.0007575535	loss: 34621.7109375	train_loss: 34601.705772230736	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_502
Epoch: 502	max: 0.9993894/1.0	min: 0.0006105181	loss: 34621.73828125	train_loss: 34601.619654732596	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_503
Epoch: 503	max: 0.9993241/1.0	min: 0.00067590404	loss: 34621.703125	train_loss: 34601.574361490464	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_504
Epoch: 504	max: 0.9991757/1.0	min: 0.00082424487	loss: 34621.4609375	train_loss: 34601.49717422272	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_505
Epoch: 505	max: 0.9994543/1.0	min: 0.0005457196	loss: 34621.61328125	train_loss: 34601.43558582621	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_506
Epoch: 506	max: 0.9993851/1.0	min: 0.000614819	loss: 34621.359375	train_loss: 34601.30522265576	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_507
Epoch: 507	max: 0.99939334/1.0	min: 0.0006066174	loss: 34621.140625	train_loss: 34601.27793503422	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_508
Epoch: 508	max: 0.9992737/1.0	min: 0.00072624657	loss: 34621.07421875	train_loss: 34601.218957094636	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_509
Epoch: 509	max: 0.99948597/1.0	min: 0.0005140422	loss: 34621.328125	train_loss: 34601.079317245756	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_510
Epoch: 510	max: 0.99935347/1.0	min: 0.00064651866	loss: 34620.96484375	train_loss: 34600.98931623931	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_511
Epoch: 511	max: 0.99939346/1.0	min: 0.0006065591	loss: 34620.99609375	train_loss: 34600.90036086724	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_512
Epoch: 512	max: 0.9993753/1.0	min: 0.00062470656	loss: 34620.94921875	train_loss: 34600.834892833365	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_513
Epoch: 513	max: 0.99942553/1.0	min: 0.0005745153	loss: 34620.83984375	train_loss: 34600.743237489165	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_514
Epoch: 514	max: 0.99936694/1.0	min: 0.00063305505	loss: 34620.66015625	train_loss: 34600.698380694135	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_515
Epoch: 515	max: 0.9994804/1.0	min: 0.0005196208	loss: 34620.84375	train_loss: 34600.62675933668	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_516
Epoch: 516	max: 0.99936026/1.0	min: 0.0006397435	loss: 34620.5859375	train_loss: 34600.52392717236	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_517
Epoch: 517	max: 0.9992855/1.0	min: 0.000714514	loss: 34620.44140625	train_loss: 34600.43822870216	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_518
Epoch: 518	max: 0.99946004/1.0	min: 0.00053999154	loss: 34620.63671875	train_loss: 34600.37203099839	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_519
Epoch: 519	max: 0.99945/1.0	min: 0.000549945	loss: 34620.40625	train_loss: 34600.28827912099	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_520
Epoch: 520	max: 0.99953866/1.0	min: 0.0004613206	loss: 34620.5859375	train_loss: 34600.23463483603	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_521
Epoch: 521	max: 0.9994343/1.0	min: 0.00056572986	loss: 34620.234375	train_loss: 34600.17905121625	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_522
Epoch: 522	max: 0.99944144/1.0	min: 0.0005585366	loss: 34620.1328125	train_loss: 34600.05962486839	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_523
Epoch: 523	max: 0.9993648/1.0	min: 0.00063521904	loss: 34619.98046875	train_loss: 34599.986943360585	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_524
Epoch: 524	max: 0.9993741/1.0	min: 0.00062597933	loss: 34619.953125	train_loss: 34599.91563748374	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_525
Epoch: 525	max: 0.9994248/1.0	min: 0.00057526195	loss: 34619.87890625	train_loss: 34599.83890505001	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_526
Epoch: 526	max: 0.99951863/1.0	min: 0.00048135276	loss: 34619.984375	train_loss: 34599.76897722346	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_527
Epoch: 527	max: 0.9993476/1.0	min: 0.0006524234	loss: 34619.7421875	train_loss: 34599.69489056887	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_528
Epoch: 528	max: 0.9992077/1.0	min: 0.0007924002	loss: 34619.75390625	train_loss: 34599.684394064316	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_529
Epoch: 529	max: 0.9995192/1.0	min: 0.00048079746	loss: 34619.73828125	train_loss: 34599.57542406014	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_530
Epoch: 530	max: 0.99942976/1.0	min: 0.00057025434	loss: 34619.53515625	train_loss: 34599.50139595333	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_531
Epoch: 531	max: 0.99949384/1.0	min: 0.0005061819	loss: 34619.46875	train_loss: 34599.4198500209	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_532
Epoch: 532	max: 0.9994863/1.0	min: 0.00051368447	loss: 34619.546875	train_loss: 34599.32587453936	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_533
Epoch: 533	max: 0.9994598/1.0	min: 0.0005401833	loss: 34619.515625	train_loss: 34599.29195795398	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_534
Epoch: 534	max: 0.9994618/1.0	min: 0.00053819333	loss: 34619.203125	train_loss: 34599.22472332544	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_535
Epoch: 535	max: 0.9994005/1.0	min: 0.0005994921	loss: 34619.02734375	train_loss: 34599.13639746299	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_536
Epoch: 536	max: 0.99941766/1.0	min: 0.0005823633	loss: 34619.01953125	train_loss: 34599.08723619627	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_537
Epoch: 537	max: 0.999446/1.0	min: 0.00055404095	loss: 34619.08984375	train_loss: 34599.03297691766	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_538
Epoch: 538	max: 0.99952614/1.0	min: 0.00047389092	loss: 34619.125	train_loss: 34598.91614602688	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_539
Epoch: 539	max: 0.999476/1.0	min: 0.00052398065	loss: 34618.9453125	train_loss: 34598.84369532314	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_540
Epoch: 540	max: 0.9994167/1.0	min: 0.0005833174	loss: 34618.81640625	train_loss: 34598.76804723306	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_541
Epoch: 541	max: 0.9993451/1.0	min: 0.0006548164	loss: 34618.7265625	train_loss: 34598.710581374646	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_542
Epoch: 542	max: 0.99941957/1.0	min: 0.0005804064	loss: 34618.7109375	train_loss: 34598.66540958287	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_543
Epoch: 543	max: 0.9994117/1.0	min: 0.0005882955	loss: 34618.65625	train_loss: 34598.55986147885	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_544
Epoch: 544	max: 0.9994098/1.0	min: 0.000590194	loss: 34618.51171875	train_loss: 34598.4937203874	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_545
Epoch: 545	max: 0.99932706/1.0	min: 0.00067293586	loss: 34618.44921875	train_loss: 34598.43921288555	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_546
Epoch: 546	max: 0.9995048/1.0	min: 0.00049514644	loss: 34618.328125	train_loss: 34598.37421904032	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_547
Epoch: 547	max: 0.9995852/1.0	min: 0.0004148497	loss: 34618.515625	train_loss: 34598.3019628507	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_548
Epoch: 548	max: 0.99955505/1.0	min: 0.00044498188	loss: 34618.3359375	train_loss: 34598.27379556082	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_549
Epoch: 549	max: 0.9995158/1.0	min: 0.00048420683	loss: 34618.19140625	train_loss: 34598.15531033228	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_550
Epoch: 550	max: 0.9993461/1.0	min: 0.0006538853	loss: 34618.140625	train_loss: 34598.08305607813	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_551
Epoch: 551	max: 0.9995208/1.0	min: 0.00047918552	loss: 34618.06640625	train_loss: 34598.0631541868	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_552
Epoch: 552	max: 0.99940455/1.0	min: 0.00059542176	loss: 34617.94140625	train_loss: 34597.94878472222	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_553
Epoch: 553	max: 0.9994289/1.0	min: 0.0005710813	loss: 34617.8359375	train_loss: 34597.87604176344	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_554
Epoch: 554	max: 0.9995283/1.0	min: 0.00047174285	loss: 34618.0	train_loss: 34597.84692851557	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_555
Epoch: 555	max: 0.9996214/1.0	min: 0.00037864243	loss: 34618.171875	train_loss: 34597.77369830376	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_556
Epoch: 556	max: 0.9995147/1.0	min: 0.00048526633	loss: 34617.78125	train_loss: 34597.67733300818	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_557
Epoch: 557	max: 0.99952984/1.0	min: 0.00047017794	loss: 34617.7109375	train_loss: 34597.595764334044	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_558
Epoch: 558	max: 0.99949574/1.0	min: 0.00050425064	loss: 34617.51171875	train_loss: 34597.551387050196	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_559
Epoch: 559	max: 0.9995254/1.0	min: 0.00047458522	loss: 34617.5390625	train_loss: 34597.51569709603	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_560
Epoch: 560	max: 0.9995328/1.0	min: 0.00046723473	loss: 34617.640625	train_loss: 34597.4265278552	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_561
Epoch: 561	max: 0.99946374/1.0	min: 0.0005363094	loss: 34617.4609375	train_loss: 34597.330575781154	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_562
Epoch: 562	max: 0.9992829/1.0	min: 0.00071713596	loss: 34617.39453125	train_loss: 34597.29319132835	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_563
Epoch: 563	max: 0.9994734/1.0	min: 0.0005265937	loss: 34617.3203125	train_loss: 34597.26679450406	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_564
Epoch: 564	max: 0.99951863/1.0	min: 0.0004813913	loss: 34617.12109375	train_loss: 34597.13355378267	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_565
Epoch: 565	max: 0.99947137/1.0	min: 0.00052863354	loss: 34617.05859375	train_loss: 34597.082752694165	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_566
Epoch: 566	max: 0.99963427/1.0	min: 0.00036570572	loss: 34617.33984375	train_loss: 34597.02261008919	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_567
Epoch: 567	max: 0.9995202/1.0	min: 0.00047979338	loss: 34616.9921875	train_loss: 34596.96294651152	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_568
Epoch: 568	max: 0.9996301/1.0	min: 0.00036986807	loss: 34617.01171875	train_loss: 34596.86998424532	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_569
Epoch: 569	max: 0.99952984/1.0	min: 0.00047018193	loss: 34616.9609375	train_loss: 34596.826385985696	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_570
Epoch: 570	max: 0.9996542/1.0	min: 0.0003457769	loss: 34617.1328125	train_loss: 34596.74201185665	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_571
Epoch: 571	max: 0.99943084/1.0	min: 0.00056913926	loss: 34616.828125	train_loss: 34596.82441665118	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_572
Epoch: 572	max: 0.99954647/1.0	min: 0.00045344798	loss: 34616.67578125	train_loss: 34596.64581301096	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_573
Epoch: 573	max: 0.9995597/1.0	min: 0.00044030437	loss: 34616.69921875	train_loss: 34596.56902202945	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_574
Epoch: 574	max: 0.99961156/1.0	min: 0.0003884488	loss: 34616.640625	train_loss: 34596.49536940264	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_575
Epoch: 575	max: 0.9996092/1.0	min: 0.00039083275	loss: 34616.7578125	train_loss: 34596.43192586399	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_576
Epoch: 576	max: 0.9995621/1.0	min: 0.0004379226	loss: 34616.5234375	train_loss: 34596.37751900626	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_577
Epoch: 577	max: 0.9995639/1.0	min: 0.0004361539	loss: 34616.33984375	train_loss: 34596.327388072124	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_578
Epoch: 578	max: 0.9995315/1.0	min: 0.00046846064	loss: 34616.24609375	train_loss: 34596.23121583906	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_579
Epoch: 579	max: 0.999463/1.0	min: 0.00053704035	loss: 34616.15234375	train_loss: 34596.19921778227	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_580
Epoch: 580	max: 0.9995277/1.0	min: 0.00047226518	loss: 34616.14453125	train_loss: 34596.11915586678	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_581
Epoch: 581	max: 0.99952817/1.0	min: 0.00047190482	loss: 34616.11328125	train_loss: 34596.054107344695	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_582
Epoch: 582	max: 0.99957675/1.0	min: 0.0004232609	loss: 34616.12890625	train_loss: 34595.968271940415	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_583
Epoch: 583	max: 0.9995278/1.0	min: 0.00047217877	loss: 34615.9609375	train_loss: 34595.90629064474	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_584
Epoch: 584	max: 0.99960953/1.0	min: 0.00039054247	loss: 34616.1640625	train_loss: 34595.845719818375	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_585
Epoch: 585	max: 0.99956435/1.0	min: 0.0004356883	loss: 34615.98828125	train_loss: 34595.83175689799	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_586
Epoch: 586	max: 0.9995259/1.0	min: 0.00047409622	loss: 34615.890625	train_loss: 34595.77007221216	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_587
Epoch: 587	max: 0.9995301/1.0	min: 0.00046998303	loss: 34615.7890625	train_loss: 34595.72317592205	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_588
Epoch: 588	max: 0.9996044/1.0	min: 0.000395625	loss: 34615.78125	train_loss: 34595.594701280505	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_589
Epoch: 589	max: 0.9995622/1.0	min: 0.0004377761	loss: 34615.6484375	train_loss: 34595.5412040908	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_590
Epoch: 590	max: 0.99952435/1.0	min: 0.0004756493	loss: 34615.5390625	train_loss: 34595.48118487164	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_591
Epoch: 591	max: 0.999495/1.0	min: 0.0005049974	loss: 34615.546875	train_loss: 34595.41106833736	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_592
Epoch: 592	max: 0.99981767/1.0	min: 0.00018234938	loss: 34616.24609375	train_loss: 34595.40176698176	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_593
Epoch: 593	max: 0.9995815/1.0	min: 0.00041851532	loss: 34615.37890625	train_loss: 34595.41891712731	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_594
Epoch: 594	max: 0.9995009/1.0	min: 0.00049906527	loss: 34615.296875	train_loss: 34595.22062546451	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_595
Epoch: 595	max: 0.99961543/1.0	min: 0.00038459522	loss: 34615.296875	train_loss: 34595.1742440078	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_596
Epoch: 596	max: 0.99957794/1.0	min: 0.00042204474	loss: 34615.16796875	train_loss: 34595.09864769138	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_597
Epoch: 597	max: 0.99956244/1.0	min: 0.0004375218	loss: 34615.1484375	train_loss: 34595.042837138455	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_598
Epoch: 598	max: 0.99943465/1.0	min: 0.00056529074	loss: 34615.16015625	train_loss: 34594.99635165057	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_599
Epoch: 599	max: 0.9995004/1.0	min: 0.0004995424	loss: 34615.09375	train_loss: 34594.93887466323	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_600
Epoch: 600	max: 0.99964654/1.0	min: 0.00035350936	loss: 34615.2265625	train_loss: 34594.88919662765	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_601
Epoch: 601	max: 0.99961686/1.0	min: 0.00038315004	loss: 34615.140625	train_loss: 34594.785796404685	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_602
Epoch: 602	max: 0.999663/1.0	min: 0.0003369581	loss: 34615.125	train_loss: 34594.73877527716	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_603
Epoch: 603	max: 0.99962234/1.0	min: 0.00037760698	loss: 34615.0859375	train_loss: 34594.67666769246	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_604
Epoch: 604	max: 0.9995301/1.0	min: 0.00046992477	loss: 34614.80078125	train_loss: 34594.61115949771	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_605
Epoch: 605	max: 0.99972075/1.0	min: 0.00027924395	loss: 34615.09375	train_loss: 34594.551693821224	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_606
Epoch: 606	max: 0.9995708/1.0	min: 0.0004292494	loss: 34614.69921875	train_loss: 34594.479178763315	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_607
Epoch: 607	max: 0.9995371/1.0	min: 0.00046296665	loss: 34614.65625	train_loss: 34594.42467610012	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_608
Epoch: 608	max: 0.99968064/1.0	min: 0.0003194304	loss: 34614.796875	train_loss: 34594.383492815556	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_609
Epoch: 609	max: 0.99958354/1.0	min: 0.00041650896	loss: 34614.6484375	train_loss: 34594.312227583454	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_610
Epoch: 610	max: 0.99954385/1.0	min: 0.00045613543	loss: 34614.484375	train_loss: 34594.265202585004	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_611
Epoch: 611	max: 0.9996345/1.0	min: 0.0003655182	loss: 34614.46484375	train_loss: 34594.20025809411	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_612
Epoch: 612	max: 0.99979454/1.0	min: 0.00020541895	loss: 34614.8203125	train_loss: 34594.125168385355	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_613
Epoch: 613	max: 0.999683/1.0	min: 0.00031704782	loss: 34614.421875	train_loss: 34594.1103761187	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_614
Epoch: 614	max: 0.999616/1.0	min: 0.00038396765	loss: 34614.2109375	train_loss: 34594.042734075	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_615
Epoch: 615	max: 0.9996164/1.0	min: 0.00038357527	loss: 34614.34375	train_loss: 34593.96819887665	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_616
Epoch: 616	max: 0.9995521/1.0	min: 0.0004479211	loss: 34614.21484375	train_loss: 34593.90570952171	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_617
Epoch: 617	max: 0.99961036/1.0	min: 0.00038962334	loss: 34614.1953125	train_loss: 34593.848868334266	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_618
Epoch: 618	max: 0.9995987/1.0	min: 0.00040130614	loss: 34614.0859375	train_loss: 34593.76443517357	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_619
Epoch: 619	max: 0.99959356/1.0	min: 0.00040640778	loss: 34614.09375	train_loss: 34593.72029740338	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_620
Epoch: 620	max: 0.9996743/1.0	min: 0.00032568412	loss: 34614.05078125	train_loss: 34593.65581984315	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_621
Epoch: 621	max: 0.9997497/1.0	min: 0.0002502755	loss: 34614.03515625	train_loss: 34593.59579868853	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_622
Epoch: 622	max: 0.9995567/1.0	min: 0.00044328946	loss: 34613.8515625	train_loss: 34593.556846026106	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_623
Epoch: 623	max: 0.99957544/1.0	min: 0.00042460847	loss: 34613.84375	train_loss: 34593.53756445095	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_624
Epoch: 624	max: 0.9996686/1.0	min: 0.00033137875	loss: 34613.93359375	train_loss: 34593.446489262045	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_625
Epoch: 625	max: 0.99976176/1.0	min: 0.00023826963	loss: 34613.8984375	train_loss: 34593.40117521367	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_626
Epoch: 626	max: 0.99954647/1.0	min: 0.0004535241	loss: 34613.69921875	train_loss: 34593.32821983773	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_627
Epoch: 627	max: 0.99969125/1.0	min: 0.0003087599	loss: 34613.62109375	train_loss: 34593.352334750096	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_628
Epoch: 628	max: 0.99977213/1.0	min: 0.0002278366	loss: 34613.80859375	train_loss: 34593.24914210563	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_629
Epoch: 629	max: 0.9996388/1.0	min: 0.0003612066	loss: 34613.5546875	train_loss: 34593.165769095285	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_630
Epoch: 630	max: 0.99973303/1.0	min: 0.00026698012	loss: 34613.7734375	train_loss: 34593.13150170708	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_631
Epoch: 631	max: 0.9996661/1.0	min: 0.0003339021	loss: 34613.44921875	train_loss: 34593.10790356358	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_632
Epoch: 632	max: 0.999653/1.0	min: 0.0003469624	loss: 34613.43359375	train_loss: 34593.0090710354	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_633
Epoch: 633	max: 0.9996983/1.0	min: 0.00030175285	loss: 34613.33984375	train_loss: 34592.95526271987	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_634
Epoch: 634	max: 0.9996916/1.0	min: 0.0003084557	loss: 34613.52734375	train_loss: 34592.90110069831	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_635
Epoch: 635	max: 0.9997311/1.0	min: 0.00026888374	loss: 34613.51171875	train_loss: 34592.852974904774	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_636
Epoch: 636	max: 0.99952745/1.0	min: 0.00047261786	loss: 34613.3671875	train_loss: 34592.79664951846	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_637
Epoch: 637	max: 0.99972636/1.0	min: 0.00027367496	loss: 34613.34375	train_loss: 34592.79609984671	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_638
Epoch: 638	max: 0.9996387/1.0	min: 0.00036127714	loss: 34613.203125	train_loss: 34592.686090982286	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_639
Epoch: 639	max: 0.99980253/1.0	min: 0.00019748701	loss: 34613.42578125	train_loss: 34592.65180665877	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_640
Epoch: 640	max: 0.9996331/1.0	min: 0.0003669448	loss: 34613.109375	train_loss: 34592.61287480258	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_641
Epoch: 641	max: 0.99969196/1.0	min: 0.00030809565	loss: 34612.95703125	train_loss: 34592.54191150285	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_642
Epoch: 642	max: 0.99981385/1.0	min: 0.00018620356	loss: 34613.24609375	train_loss: 34592.53865460098	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_643
Epoch: 643	max: 0.9996842/1.0	min: 0.00031580974	loss: 34612.87109375	train_loss: 34592.448796335004	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_644
Epoch: 644	max: 0.99977905/1.0	min: 0.00022095579	loss: 34612.96875	train_loss: 34592.399233459524	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_645
Epoch: 645	max: 0.9996902/1.0	min: 0.0003097892	loss: 34612.796875	train_loss: 34592.33369913601	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_646
Epoch: 646	max: 0.9998412/1.0	min: 0.00015874379	loss: 34612.98828125	train_loss: 34592.27369830376	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_647
Epoch: 647	max: 0.99979645/1.0	min: 0.00020361715	loss: 34612.7421875	train_loss: 34592.2518870773	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_648
Epoch: 648	max: 0.99985325/1.0	min: 0.00014676664	loss: 34613.0859375	train_loss: 34592.186969682894	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_649
Epoch: 649	max: 0.9997713/1.0	min: 0.00022870152	loss: 34612.75	train_loss: 34592.16180091044	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_650
Epoch: 650	max: 0.99980325/1.0	min: 0.00019682418	loss: 34612.921875	train_loss: 34592.10774921033	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_651
Epoch: 651	max: 0.9997168/1.0	min: 0.00028311575	loss: 34612.66015625	train_loss: 34592.04660403506	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_652
Epoch: 652	max: 0.99980336/1.0	min: 0.00019670863	loss: 34612.6015625	train_loss: 34591.99564810944	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_653
Epoch: 653	max: 0.9998147/1.0	min: 0.00018534693	loss: 34612.62109375	train_loss: 34591.994767957236	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_654
Epoch: 654	max: 0.9998149/1.0	min: 0.0001851417	loss: 34612.4609375	train_loss: 34591.90784578998	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_655
Epoch: 655	max: 0.9997979/1.0	min: 0.00020209263	loss: 34612.453125	train_loss: 34591.831339805525	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_656
Epoch: 656	max: 0.999793/1.0	min: 0.00020703686	loss: 34612.39453125	train_loss: 34591.77530473879	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_657
Epoch: 657	max: 0.99972814/1.0	min: 0.0002718823	loss: 34612.17578125	train_loss: 34591.79216020996	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_658
Epoch: 658	max: 0.99978226/1.0	min: 0.00021777189	loss: 34612.30078125	train_loss: 34591.676131568966	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_659
Epoch: 659	max: 0.9997305/1.0	min: 0.00026948197	loss: 34612.1640625	train_loss: 34591.62036069305	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_660
Epoch: 660	max: 0.9998318/1.0	min: 0.0001681848	loss: 34612.359375	train_loss: 34591.61106659544	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_661
Epoch: 661	max: 0.9997892/1.0	min: 0.00021088708	loss: 34612.140625	train_loss: 34591.536853651836	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_662
Epoch: 662	max: 0.9998197/1.0	min: 0.00018029442	loss: 34612.40625	train_loss: 34591.48575256643	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_663
Epoch: 663	max: 0.9997509/1.0	min: 0.00024912562	loss: 34612.1796875	train_loss: 34591.47888166961	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_664
Epoch: 664	max: 0.9996426/1.0	min: 0.0003574249	loss: 34612.09765625	train_loss: 34591.38204799176	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_665
Epoch: 665	max: 0.9997688/1.0	min: 0.00023123158	loss: 34612.0	train_loss: 34591.3753241902	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_666
Epoch: 666	max: 0.9998165/1.0	min: 0.000183559	loss: 34612.01171875	train_loss: 34591.32639905007	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_667
Epoch: 667	max: 0.99980396/1.0	min: 0.00019608148	loss: 34612.09375	train_loss: 34591.23121922612	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_668
Epoch: 668	max: 0.99974996/1.0	min: 0.00025008374	loss: 34611.890625	train_loss: 34591.231341160346	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_669
Epoch: 669	max: 0.9998098/1.0	min: 0.000190211	loss: 34611.8515625	train_loss: 34591.12809093583	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_670
Epoch: 670	max: 0.9997826/1.0	min: 0.00021734537	loss: 34611.80078125	train_loss: 34591.14192030921	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_671
Epoch: 671	max: 0.9998673/1.0	min: 0.00013266974	loss: 34611.81640625	train_loss: 34591.0401531339	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_672
Epoch: 672	max: 0.99984336/1.0	min: 0.00015663367	loss: 34611.83984375	train_loss: 34590.99459570095	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_673
Epoch: 673	max: 0.99978524/1.0	min: 0.00021478633	loss: 34611.703125	train_loss: 34590.94914423464	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_674
Epoch: 674	max: 0.99987185/1.0	min: 0.00012807532	loss: 34611.78515625	train_loss: 34590.90550145934	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_675
Epoch: 675	max: 0.9998222/1.0	min: 0.00017778545	loss: 34611.54296875	train_loss: 34590.846626099345	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_676
Epoch: 676	max: 0.99972874/1.0	min: 0.0002712521	loss: 34611.51171875	train_loss: 34590.811481945995	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_677
Epoch: 677	max: 0.99989855/1.0	min: 0.00010140988	loss: 34611.7734375	train_loss: 34590.755588168126	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_678
Epoch: 678	max: 0.99974424/1.0	min: 0.00025572247	loss: 34611.515625	train_loss: 34590.698246179396	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_679
Epoch: 679	max: 0.9998229/1.0	min: 0.00017714467	loss: 34611.5	train_loss: 34590.64526527468	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_680
Epoch: 680	max: 0.9998654/1.0	min: 0.00013452169	loss: 34611.609375	train_loss: 34590.584335419764	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_681
Epoch: 681	max: 0.9997402/1.0	min: 0.000259799	loss: 34611.3125	train_loss: 34590.54040571194	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_682
Epoch: 682	max: 0.9998129/1.0	min: 0.00018710108	loss: 34611.35546875	train_loss: 34590.47889134693	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_683
Epoch: 683	max: 0.9998416/1.0	min: 0.00015838425	loss: 34611.328125	train_loss: 34590.43465583581	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_684
Epoch: 684	max: 0.9998115/1.0	min: 0.00018855942	loss: 34611.1953125	train_loss: 34590.42777864874	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_685
Epoch: 685	max: 0.99981207/1.0	min: 0.00018796886	loss: 34611.1015625	train_loss: 34590.3574922775	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_686
Epoch: 686	max: 0.99988604/1.0	min: 0.000113898524	loss: 34611.234375	train_loss: 34590.33712442323	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_687
Epoch: 687	max: 0.9997136/1.0	min: 0.0002863909	loss: 34611.03125	train_loss: 34590.27828922411	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_688
Epoch: 688	max: 0.99979264/1.0	min: 0.00020736085	loss: 34611.171875	train_loss: 34590.2187756449	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_689
Epoch: 689	max: 0.99976104/1.0	min: 0.00023900272	loss: 34611.06640625	train_loss: 34590.146674292395	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_690
Epoch: 690	max: 0.99989223/1.0	min: 0.00010777049	loss: 34611.11328125	train_loss: 34590.119016029515	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_691
Epoch: 691	max: 0.9997918/1.0	min: 0.00020817426	loss: 34610.91015625	train_loss: 34590.055570071534	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_692
Epoch: 692	max: 0.9998084/1.0	min: 0.0001916689	loss: 34610.82421875	train_loss: 34590.0212320389	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_693
Epoch: 693	max: 0.9998325/1.0	min: 0.00016749727	loss: 34610.9296875	train_loss: 34589.99700196643	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_694
Epoch: 694	max: 0.9998117/1.0	min: 0.00018831508	loss: 34610.7890625	train_loss: 34589.92444965084	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_695
Epoch: 695	max: 0.9997886/1.0	min: 0.00021141052	loss: 34610.70703125	train_loss: 34589.88725390576	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_696
Epoch: 696	max: 0.9998264/1.0	min: 0.00017363913	loss: 34610.68359375	train_loss: 34589.85694357348	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_697
Epoch: 697	max: 0.9998754/1.0	min: 0.00012452886	loss: 34610.7265625	train_loss: 34589.83582959789	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_698
Epoch: 698	max: 0.9997894/1.0	min: 0.00021059712	loss: 34610.5859375	train_loss: 34589.75050709154	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_699
Epoch: 699	max: 0.999793/1.0	min: 0.00020700211	loss: 34610.546875	train_loss: 34589.70400563607	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_700
Epoch: 700	max: 0.999869/1.0	min: 0.00013100232	loss: 34610.703125	train_loss: 34589.696519261735	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_701
Epoch: 701	max: 0.9997993/1.0	min: 0.00020066733	loss: 34610.515625	train_loss: 34589.64765895965	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_702
Epoch: 702	max: 0.9998599/1.0	min: 0.00014007057	loss: 34610.6484375	train_loss: 34589.58053997507	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_703
Epoch: 703	max: 0.99987197/1.0	min: 0.00012802027	loss: 34610.55078125	train_loss: 34589.53635139895	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_704
Epoch: 704	max: 0.99980754/1.0	min: 0.00019244959	loss: 34610.3828125	train_loss: 34589.48994720054	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_705
Epoch: 705	max: 0.99989545/1.0	min: 0.00010454348	loss: 34610.578125	train_loss: 34589.46116733634	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_706
Epoch: 706	max: 0.9997762/1.0	min: 0.00022382019	loss: 34610.328125	train_loss: 34589.416016834664	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_707
Epoch: 707	max: 0.99994016/1.0	min: 5.9853668e-05	loss: 34610.73828125	train_loss: 34589.427214461015	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_708
Epoch: 708	max: 0.9998042/1.0	min: 0.00019583093	loss: 34610.25	train_loss: 34589.36032337731	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_709
Epoch: 709	max: 0.99991775/1.0	min: 8.2301354e-05	loss: 34610.375	train_loss: 34589.300940441906	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_710
Epoch: 710	max: 0.99978334/1.0	min: 0.00021669111	loss: 34610.296875	train_loss: 34589.24662261551	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_711
Epoch: 711	max: 0.9999306/1.0	min: 6.935828e-05	loss: 34610.44921875	train_loss: 34589.20305629103	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_712
Epoch: 712	max: 0.9998704/1.0	min: 0.00012956769	loss: 34610.20703125	train_loss: 34589.14831846897	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_713
Epoch: 713	max: 0.9998659/1.0	min: 0.00013412145	loss: 34610.19921875	train_loss: 34589.104028281	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_714
Epoch: 714	max: 0.9998784/1.0	min: 0.00012159464	loss: 34610.28515625	train_loss: 34589.061391946925	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_715
Epoch: 715	max: 0.9998735/1.0	min: 0.00012648966	loss: 34610.09375	train_loss: 34589.023373629694	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_716
Epoch: 716	max: 0.9998605/1.0	min: 0.00013947532	loss: 34610.05078125	train_loss: 34588.97678798154	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_717
Epoch: 717	max: 0.9998971/1.0	min: 0.00010291706	loss: 34610.0390625	train_loss: 34588.93810192927	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_718
Epoch: 718	max: 0.99991417/1.0	min: 8.57701e-05	loss: 34610.01953125	train_loss: 34588.93235214991	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_719
Epoch: 719	max: 0.9999132/1.0	min: 8.672007e-05	loss: 34610.015625	train_loss: 34588.87810448408	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_720
Epoch: 720	max: 0.9998939/1.0	min: 0.000106058564	loss: 34609.984375	train_loss: 34588.8195446047	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_721
Epoch: 721	max: 0.99991286/1.0	min: 8.709392e-05	loss: 34609.92578125	train_loss: 34588.8129877369	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_722
Epoch: 722	max: 0.99988484/1.0	min: 0.000115117204	loss: 34609.8828125	train_loss: 34588.750993376845	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_723
Epoch: 723	max: 0.9998653/1.0	min: 0.00013463873	loss: 34609.82421875	train_loss: 34588.75112692385	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_724
Epoch: 724	max: 0.99992454/1.0	min: 7.5485455e-05	loss: 34609.9765625	train_loss: 34588.71078895315	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_725
Epoch: 725	max: 0.9998271/1.0	min: 0.00017291876	loss: 34609.734375	train_loss: 34588.72177561393	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_726
Epoch: 726	max: 0.9998479/1.0	min: 0.00015207173	loss: 34609.703125	train_loss: 34588.58499202589	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_727
Epoch: 727	max: 0.9999496/1.0	min: 5.0417413e-05	loss: 34610.07421875	train_loss: 34588.543059232936	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_728
Epoch: 728	max: 0.99981576/1.0	min: 0.00018421352	loss: 34609.75	train_loss: 34588.539457334635	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_729
Epoch: 729	max: 0.9998271/1.0	min: 0.00017296264	loss: 34609.578125	train_loss: 34588.48652336492	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_730
Epoch: 730	max: 0.99993026/1.0	min: 6.977123e-05	loss: 34609.8515625	train_loss: 34588.443849289295	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_731
Epoch: 731	max: 0.9998349/1.0	min: 0.00016508526	loss: 34609.53125	train_loss: 34588.375352738294	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_732
Epoch: 732	max: 0.9999052/1.0	min: 9.4776435e-05	loss: 34609.62890625	train_loss: 34588.348581885606	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_733
Epoch: 733	max: 0.9999007/1.0	min: 9.926123e-05	loss: 34609.671875	train_loss: 34588.288253476094	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_734
Epoch: 734	max: 0.9998381/1.0	min: 0.00016181434	loss: 34609.515625	train_loss: 34588.28314820621	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_735
Epoch: 735	max: 0.999918/1.0	min: 8.1983795e-05	loss: 34609.56640625	train_loss: 34588.22042756333	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_736
Epoch: 736	max: 0.9998492/1.0	min: 0.00015080362	loss: 34609.37109375	train_loss: 34588.196278296484	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_737
Epoch: 737	max: 0.9999231/1.0	min: 7.686999e-05	loss: 34609.2890625	train_loss: 34588.14894701087	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_738
Epoch: 738	max: 0.9999399/1.0	min: 6.0102473e-05	loss: 34609.37890625	train_loss: 34588.12114262046	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_739
Epoch: 739	max: 0.9998362/1.0	min: 0.00016379236	loss: 34609.2578125	train_loss: 34588.086606686644	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_740
Epoch: 740	max: 0.9999554/1.0	min: 4.461444e-05	loss: 34609.61328125	train_loss: 34588.06653931314	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_741
Epoch: 741	max: 0.9998728/1.0	min: 0.00012716484	loss: 34609.19140625	train_loss: 34588.022215254554	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_742
Epoch: 742	max: 0.99991286/1.0	min: 8.714668e-05	loss: 34609.19921875	train_loss: 34587.96967321628	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_743
Epoch: 743	max: 0.99995756/1.0	min: 4.2379885e-05	loss: 34609.390625	train_loss: 34587.925250932894	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_744
Epoch: 744	max: 0.9998765/1.0	min: 0.0001234407	loss: 34609.1953125	train_loss: 34587.912287195744	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_745
Epoch: 745	max: 0.99991524/1.0	min: 8.469755e-05	loss: 34609.10546875	train_loss: 34587.85278861637	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_746
Epoch: 746	max: 0.9999378/1.0	min: 6.2210354e-05	loss: 34609.40625	train_loss: 34587.79770047535	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_747
Epoch: 747	max: 0.9999478/1.0	min: 5.2182353e-05	loss: 34609.19921875	train_loss: 34587.76978915057	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_748
Epoch: 748	max: 0.99985385/1.0	min: 0.00014618367	loss: 34609.109375	train_loss: 34587.72942166404	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_749
Epoch: 749	max: 0.9999126/1.0	min: 8.7389584e-05	loss: 34609.03515625	train_loss: 34587.67851702821	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_750
Epoch: 750	max: 0.9999229/1.0	min: 7.716347e-05	loss: 34609.015625	train_loss: 34587.65509162486	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_751
Epoch: 751	max: 0.9999238/1.0	min: 7.6153e-05	loss: 34609.328125	train_loss: 34587.60419134383	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_752
Epoch: 752	max: 0.99995744/1.0	min: 4.2556625e-05	loss: 34609.34765625	train_loss: 34587.59102583457	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_753
Epoch: 753	max: 0.9998186/1.0	min: 0.00018139872	loss: 34609.01171875	train_loss: 34587.59617658785	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_754
Epoch: 754	max: 0.9999354/1.0	min: 6.459103e-05	loss: 34609.13671875	train_loss: 34587.53027936486	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_755
Epoch: 755	max: 0.9999286/1.0	min: 7.145526e-05	loss: 34608.88671875	train_loss: 34587.48234760157	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_756
Epoch: 756	max: 0.99991274/1.0	min: 8.723057e-05	loss: 34608.93359375	train_loss: 34587.41823874721	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_757
Epoch: 757	max: 0.99991214/1.0	min: 8.7877874e-05	loss: 34608.80078125	train_loss: 34587.38574763099	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_758
Epoch: 758	max: 0.99987996/1.0	min: 0.000119974364	loss: 34608.93359375	train_loss: 34587.334080906265	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_759
Epoch: 759	max: 0.9999356/1.0	min: 6.433844e-05	loss: 34609.015625	train_loss: 34587.34139986297	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_760
Epoch: 760	max: 0.9999455/1.0	min: 5.452248e-05	loss: 34608.796875	train_loss: 34587.258910391894	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_761
Epoch: 761	max: 0.9999596/1.0	min: 4.0468567e-05	loss: 34608.8359375	train_loss: 34587.21687260002	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_762
Epoch: 762	max: 0.9999027/1.0	min: 9.728725e-05	loss: 34608.8828125	train_loss: 34587.17254370278	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_763
Epoch: 763	max: 0.9999291/1.0	min: 7.09486e-05	loss: 34608.83984375	train_loss: 34587.153899379104	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_764
Epoch: 764	max: 0.99995625/1.0	min: 4.379121e-05	loss: 34608.921875	train_loss: 34587.093500809024	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_765
Epoch: 765	max: 0.9999598/1.0	min: 4.0177976e-05	loss: 34608.8984375	train_loss: 34587.08658539654	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_766
Epoch: 766	max: 0.9999534/1.0	min: 4.656525e-05	loss: 34608.69921875	train_loss: 34587.03573592143	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_767
Epoch: 767	max: 0.999905/1.0	min: 9.502584e-05	loss: 34608.578125	train_loss: 34587.003609156294	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_768
Epoch: 768	max: 0.9998933/1.0	min: 0.000106735504	loss: 34608.53515625	train_loss: 34586.98728835702	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_769
Epoch: 769	max: 0.99998283/1.0	min: 1.7124892e-05	loss: 34608.81640625	train_loss: 34586.963463764245	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_770
Epoch: 770	max: 0.9999436/1.0	min: 5.6366298e-05	loss: 34608.390625	train_loss: 34586.90030231946	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_771
Epoch: 771	max: 0.99992824/1.0	min: 7.1783215e-05	loss: 34608.4140625	train_loss: 34586.84819334123	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_772
Epoch: 772	max: 0.9999416/1.0	min: 5.845916e-05	loss: 34608.45703125	train_loss: 34586.79528162935	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_773
Epoch: 773	max: 0.9999331/1.0	min: 6.687168e-05	loss: 34608.4765625	train_loss: 34586.76209713319	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_774
Epoch: 774	max: 0.9999484/1.0	min: 5.160563e-05	loss: 34608.3984375	train_loss: 34586.713182638116	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_775
Epoch: 775	max: 0.9999529/1.0	min: 4.7111025e-05	loss: 34608.265625	train_loss: 34586.67386707621	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_776
Epoch: 776	max: 0.99996126/1.0	min: 3.8701903e-05	loss: 34608.4609375	train_loss: 34586.65947399898	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_777
Epoch: 777	max: 0.99991655/1.0	min: 8.3420346e-05	loss: 34608.4296875	train_loss: 34586.60312345163	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_778
Epoch: 778	max: 0.9999372/1.0	min: 6.28283e-05	loss: 34608.37890625	train_loss: 34586.578896282364	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_779
Epoch: 779	max: 0.999943/1.0	min: 5.700193e-05	loss: 34608.171875	train_loss: 34586.54221295135	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_780
Epoch: 780	max: 0.9999573/1.0	min: 4.2671712e-05	loss: 34608.19140625	train_loss: 34586.51072730862	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_781
Epoch: 781	max: 0.99996984/1.0	min: 3.0171066e-05	loss: 34608.19140625	train_loss: 34586.461311528394	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_782
Epoch: 782	max: 0.99996626/1.0	min: 3.374366e-05	loss: 34608.13671875	train_loss: 34586.4438463861	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_783
Epoch: 783	max: 0.9999349/1.0	min: 6.507618e-05	loss: 34608.0859375	train_loss: 34586.425656412575	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_784
Epoch: 784	max: 0.999972/1.0	min: 2.8016286e-05	loss: 34608.359375	train_loss: 34586.33794796312	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_785
Epoch: 785	max: 0.9999465/1.0	min: 5.3481326e-05	loss: 34608.2109375	train_loss: 34586.28516834665	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_786
Epoch: 786	max: 0.9999603/1.0	min: 3.9704417e-05	loss: 34607.921875	train_loss: 34586.261080530785	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_787
Epoch: 787	max: 0.9999665/1.0	min: 3.3472326e-05	loss: 34607.99609375	train_loss: 34586.22926102053	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_788
Epoch: 788	max: 0.9999689/1.0	min: 3.1123247e-05	loss: 34608.01171875	train_loss: 34586.163655568715	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_789
Epoch: 789	max: 0.99998033/1.0	min: 1.9626024e-05	loss: 34608.16015625	train_loss: 34586.13228750542	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_790
Epoch: 790	max: 0.99993765/1.0	min: 6.238953e-05	loss: 34607.91015625	train_loss: 34586.104483115014	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_791
Epoch: 791	max: 0.9999726/1.0	min: 2.7428396e-05	loss: 34607.80078125	train_loss: 34586.04784031262	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_792
Epoch: 792	max: 0.9999689/1.0	min: 3.1099156e-05	loss: 34607.765625	train_loss: 34586.00557897467	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_793
Epoch: 793	max: 0.9999753/1.0	min: 2.466215e-05	loss: 34607.85546875	train_loss: 34585.95546933064	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_794
Epoch: 794	max: 0.99994576/1.0	min: 5.4263695e-05	loss: 34607.79296875	train_loss: 34585.922273221695	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_795
Epoch: 795	max: 0.99997497/1.0	min: 2.4991574e-05	loss: 34607.890625	train_loss: 34585.89663267992	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_796
Epoch: 796	max: 0.99996674/1.0	min: 3.327665e-05	loss: 34607.93359375	train_loss: 34585.89245207791	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_797
Epoch: 797	max: 0.9999678/1.0	min: 3.2148957e-05	loss: 34607.59375	train_loss: 34585.834895252694	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_798
Epoch: 798	max: 0.9999808/1.0	min: 1.9250469e-05	loss: 34607.58984375	train_loss: 34585.77027108107	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_799
Epoch: 799	max: 0.99997175/1.0	min: 2.8282315e-05	loss: 34607.49609375	train_loss: 34585.740214294565	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_800
Epoch: 800	max: 0.99997616/1.0	min: 2.3819972e-05	loss: 34607.4140625	train_loss: 34585.66066914793	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_801
Epoch: 801	max: 0.99996555/1.0	min: 3.4435627e-05	loss: 34607.5546875	train_loss: 34585.65569016707	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_802
Epoch: 802	max: 0.99995935/1.0	min: 4.0678864e-05	loss: 34607.38671875	train_loss: 34585.58685200669	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_803
Epoch: 803	max: 0.99997663/1.0	min: 2.3412433e-05	loss: 34607.5859375	train_loss: 34585.54149489425	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_804
Epoch: 804	max: 0.9999553/1.0	min: 4.470729e-05	loss: 34607.37890625	train_loss: 34585.50515268875	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_805
Epoch: 805	max: 0.9999713/1.0	min: 2.8710647e-05	loss: 34607.4375	train_loss: 34585.46024702326	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_806
Epoch: 806	max: 0.99998486/1.0	min: 1.5082314e-05	loss: 34607.640625	train_loss: 34585.42911121563	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_807
Epoch: 807	max: 0.9999709/1.0	min: 2.9049537e-05	loss: 34607.12109375	train_loss: 34585.423544821475	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_808
Epoch: 808	max: 0.9999783/1.0	min: 2.170042e-05	loss: 34607.32421875	train_loss: 34585.331986250465	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_809
Epoch: 809	max: 0.99996996/1.0	min: 3.0011826e-05	loss: 34607.18359375	train_loss: 34585.26513387604	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_810
Epoch: 810	max: 0.9999863/1.0	min: 1.3743695e-05	loss: 34607.53125	train_loss: 34585.22300269804	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_811
Epoch: 811	max: 0.9999813/1.0	min: 1.8666213e-05	loss: 34607.25390625	train_loss: 34585.196724904774	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_812
Epoch: 812	max: 0.99996793/1.0	min: 3.2120213e-05	loss: 34607.09375	train_loss: 34585.15439243853	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_813
Epoch: 813	max: 0.9999926/1.0	min: 7.3515157e-06	loss: 34607.3046875	train_loss: 34585.126385792144	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_814
Epoch: 814	max: 0.9999888/1.0	min: 1.1261465e-05	loss: 34607.1015625	train_loss: 34585.1012126649	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_815
Epoch: 815	max: 0.99998605/1.0	min: 1.3984467e-05	loss: 34606.9453125	train_loss: 34585.020081889474	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_816
Epoch: 816	max: 0.9999819/1.0	min: 1.8151237e-05	loss: 34606.95703125	train_loss: 34584.949425844636	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_817
Epoch: 817	max: 0.9999635/1.0	min: 3.643195e-05	loss: 34606.8203125	train_loss: 34584.911741878794	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_818
Epoch: 818	max: 0.9999764/1.0	min: 2.3558907e-05	loss: 34606.89453125	train_loss: 34584.89644832699	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_819
Epoch: 819	max: 0.99998736/1.0	min: 1.2594328e-05	loss: 34606.984375	train_loss: 34584.85798533692	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_820
Epoch: 820	max: 0.99998/1.0	min: 2.0075537e-05	loss: 34606.76171875	train_loss: 34584.79793611808	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_821
Epoch: 821	max: 0.99997556/1.0	min: 2.4446257e-05	loss: 34606.69140625	train_loss: 34584.75791604732	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_822
Epoch: 822	max: 0.9999751/1.0	min: 2.4922556e-05	loss: 34606.64453125	train_loss: 34584.72461977812	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_823
Epoch: 823	max: 0.9999826/1.0	min: 1.7367813e-05	loss: 34606.671875	train_loss: 34584.711953134676	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_824
Epoch: 824	max: 0.9999863/1.0	min: 1.3688768e-05	loss: 34606.76953125	train_loss: 34584.63374200653	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_825
Epoch: 825	max: 0.99997556/1.0	min: 2.438511e-05	loss: 34606.640625	train_loss: 34584.603145709465	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_826
Epoch: 826	max: 0.99997854/1.0	min: 2.1474625e-05	loss: 34606.69140625	train_loss: 34584.561695330885	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_827
Epoch: 827	max: 0.99998105/1.0	min: 1.8928396e-05	loss: 34606.5078125	train_loss: 34584.52396636551	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_828
Epoch: 828	max: 0.9999815/1.0	min: 1.8526607e-05	loss: 34606.68359375	train_loss: 34584.466621473584	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_829
Epoch: 829	max: 0.9999839/1.0	min: 1.6039077e-05	loss: 34606.484375	train_loss: 34584.43346310619	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_830
Epoch: 830	max: 0.99997985/1.0	min: 2.012977e-05	loss: 34606.48828125	train_loss: 34584.40178246547	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_831
Epoch: 831	max: 0.9999831/1.0	min: 1.6949582e-05	loss: 34606.56640625	train_loss: 34584.350103644094	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_832
Epoch: 832	max: 0.99998546/1.0	min: 1.4496895e-05	loss: 34606.49609375	train_loss: 34584.303285256414	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_833
Epoch: 833	max: 0.99998546/1.0	min: 1.4500573e-05	loss: 34606.5234375	train_loss: 34584.286734136935	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_834
Epoch: 834	max: 0.99998045/1.0	min: 1.9509245e-05	loss: 34606.4140625	train_loss: 34584.265349196394	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_835
Epoch: 835	max: 0.99997926/1.0	min: 2.0685033e-05	loss: 34606.38671875	train_loss: 34584.232716307444	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_836
Epoch: 836	max: 0.999985/1.0	min: 1.5052126e-05	loss: 34606.265625	train_loss: 34584.15265390809	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_837
Epoch: 837	max: 0.9999788/1.0	min: 2.1160111e-05	loss: 34606.328125	train_loss: 34584.125147095256	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_838
Epoch: 838	max: 0.99997807/1.0	min: 2.194474e-05	loss: 34606.60546875	train_loss: 34584.08621959386	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_839
Epoch: 839	max: 0.9999769/1.0	min: 2.3172954e-05	loss: 34606.234375	train_loss: 34584.04878772219	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_840
Epoch: 840	max: 0.99998057/1.0	min: 1.9400783e-05	loss: 34606.1484375	train_loss: 34584.004726402825	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_841
Epoch: 841	max: 0.99998665/1.0	min: 1.3408194e-05	loss: 34606.5234375	train_loss: 34583.96631518642	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_842
Epoch: 842	max: 0.9999734/1.0	min: 2.6558586e-05	loss: 34606.26953125	train_loss: 34583.93620807785	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_843
Epoch: 843	max: 0.99998164/1.0	min: 1.83878e-05	loss: 34606.2421875	train_loss: 34583.904286955745	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_844
Epoch: 844	max: 0.9999881/1.0	min: 1.1973899e-05	loss: 34606.82421875	train_loss: 34583.84142599173	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_845
Epoch: 845	max: 0.9999778/1.0	min: 2.2179329e-05	loss: 34606.1875	train_loss: 34583.86149626842	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_846
Epoch: 846	max: 0.9999721/1.0	min: 2.7922186e-05	loss: 34606.08984375	train_loss: 34583.77614618171	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_847
Epoch: 847	max: 0.99997413/1.0	min: 2.590975e-05	loss: 34606.0234375	train_loss: 34583.801867045244	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_848
Epoch: 848	max: 0.9999813/1.0	min: 1.8730587e-05	loss: 34605.96875	train_loss: 34583.70547029837	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_849
Epoch: 849	max: 0.9999912/1.0	min: 8.844179e-06	loss: 34606.4609375	train_loss: 34583.72961762975	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_850
Epoch: 850	max: 0.99997807/1.0	min: 2.1893235e-05	loss: 34606.16015625	train_loss: 34583.72187335486	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_851
Epoch: 851	max: 0.9999747/1.0	min: 2.5300875e-05	loss: 34606.4453125	train_loss: 34583.60412844126	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_852
Epoch: 852	max: 0.9999709/1.0	min: 2.9031398e-05	loss: 34606.0234375	train_loss: 34583.528900346835	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_853
Epoch: 853	max: 0.999985/1.0	min: 1.5010899e-05	loss: 34606.203125	train_loss: 34583.54703612737	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_854
Epoch: 854	max: 0.9999851/1.0	min: 1.4891144e-05	loss: 34606.12109375	train_loss: 34583.505421718226	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_855
Epoch: 855	max: 0.99998903/1.0	min: 1.095584e-05	loss: 34606.1171875	train_loss: 34583.44318107039	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_856
Epoch: 856	max: 0.99998593/1.0	min: 1.4123669e-05	loss: 34606.07421875	train_loss: 34583.4126433211	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_857
Epoch: 857	max: 0.9999783/1.0	min: 2.1676095e-05	loss: 34606.14453125	train_loss: 34583.36305286526	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_858
Epoch: 858	max: 0.9999857/1.0	min: 1.43283605e-05	loss: 34605.9921875	train_loss: 34583.35155911294	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_859
Epoch: 859	max: 0.999985/1.0	min: 1.5070641e-05	loss: 34605.953125	train_loss: 34583.28052807197	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_860
Epoch: 860	max: 0.9999856/1.0	min: 1.4398932e-05	loss: 34606.01953125	train_loss: 34583.26959850737	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_861
Epoch: 861	max: 0.99998546/1.0	min: 1.4559131e-05	loss: 34606.2109375	train_loss: 34583.28847363511	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_862
Epoch: 862	max: 0.99997675/1.0	min: 2.3252027e-05	loss: 34605.8671875	train_loss: 34583.22337333937	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_863
Epoch: 863	max: 0.99997306/1.0	min: 2.6892225e-05	loss: 34605.828125	train_loss: 34583.1796420166	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_864
Epoch: 864	max: 0.9999845/1.0	min: 1.5515374e-05	loss: 34606.18359375	train_loss: 34583.17616979437	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_865
Epoch: 865	max: 0.99995446/1.0	min: 4.5498935e-05	loss: 34605.859375	train_loss: 34583.11129739951	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_866
Epoch: 866	max: 0.9999765/1.0	min: 2.3440938e-05	loss: 34605.81640625	train_loss: 34583.11551138827	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_867
Epoch: 867	max: 0.999977/1.0	min: 2.3009186e-05	loss: 34605.80859375	train_loss: 34582.99977548619	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_868
Epoch: 868	max: 0.999982/1.0	min: 1.7993469e-05	loss: 34605.703125	train_loss: 34582.9701648241	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_869
Epoch: 869	max: 0.9999753/1.0	min: 2.4688696e-05	loss: 34605.7265625	train_loss: 34582.926940109006	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_870
Epoch: 870	max: 0.99997973/1.0	min: 2.0259824e-05	loss: 34605.63671875	train_loss: 34582.89672945312	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_871
Epoch: 871	max: 0.99998593/1.0	min: 1.4082592e-05	loss: 34605.75	train_loss: 34582.879778660346	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_872
Epoch: 872	max: 0.9999857/1.0	min: 1.4253048e-05	loss: 34605.9375	train_loss: 34582.82103249257	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_873
Epoch: 873	max: 0.9999722/1.0	min: 2.7716842e-05	loss: 34605.7421875	train_loss: 34582.82442439304	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_874
Epoch: 874	max: 0.99998486/1.0	min: 1.5165493e-05	loss: 34605.56640625	train_loss: 34582.77465442292	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_875
Epoch: 875	max: 0.9999801/1.0	min: 1.9939476e-05	loss: 34605.625	train_loss: 34582.7250494511	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_876
Epoch: 876	max: 0.99998236/1.0	min: 1.7591045e-05	loss: 34605.53125	train_loss: 34582.69509185712	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_877
Epoch: 877	max: 0.99998/1.0	min: 1.9976187e-05	loss: 34605.5546875	train_loss: 34582.6656921606	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_878
Epoch: 878	max: 0.9999751/1.0	min: 2.4874067e-05	loss: 34605.63671875	train_loss: 34582.64282900951	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_879
Epoch: 879	max: 0.9999747/1.0	min: 2.5264566e-05	loss: 34605.62109375	train_loss: 34582.59201146956	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_880
Epoch: 880	max: 0.9999857/1.0	min: 1.4352444e-05	loss: 34605.546875	train_loss: 34582.57865386551	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_881
Epoch: 881	max: 0.9999876/1.0	min: 1.2348097e-05	loss: 34605.51171875	train_loss: 34582.52518570776	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_882
Epoch: 882	max: 0.9999802/1.0	min: 1.9840403e-05	loss: 34605.62109375	train_loss: 34582.5042106017	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_883
Epoch: 883	max: 0.99996555/1.0	min: 3.448387e-05	loss: 34605.75	train_loss: 34582.45102211848	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_884
Epoch: 884	max: 0.99998045/1.0	min: 1.9569097e-05	loss: 34605.828125	train_loss: 34582.415521355906	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_885
Epoch: 885	max: 0.9999864/1.0	min: 1.3615158e-05	loss: 34605.76953125	train_loss: 34582.378622220676	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_886
Epoch: 886	max: 0.9999739/1.0	min: 2.6163332e-05	loss: 34605.3984375	train_loss: 34582.36062095488	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_887
Epoch: 887	max: 0.9999776/1.0	min: 2.2450313e-05	loss: 34605.6015625	train_loss: 34582.315100779604	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_888
Epoch: 888	max: 0.9999634/1.0	min: 3.658179e-05	loss: 34605.53515625	train_loss: 34582.30282364827	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_889
Epoch: 889	max: 0.9999771/1.0	min: 2.286281e-05	loss: 34605.51171875	train_loss: 34582.24829388858	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_890
Epoch: 890	max: 0.99997675/1.0	min: 2.3288087e-05	loss: 34605.44921875	train_loss: 34582.20518530131	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_891
Epoch: 891	max: 0.9999863/1.0	min: 1.3692894e-05	loss: 34605.6640625	train_loss: 34582.18741774278	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_892
Epoch: 892	max: 0.99998116/1.0	min: 1.884549e-05	loss: 34605.51953125	train_loss: 34582.23951994689	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_893
Epoch: 893	max: 0.9999654/1.0	min: 3.457762e-05	loss: 34605.37109375	train_loss: 34582.11897441704	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_894
Epoch: 894	max: 0.9999758/1.0	min: 2.4240597e-05	loss: 34605.3515625	train_loss: 34582.11037805416	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_895
Epoch: 895	max: 0.9999745/1.0	min: 2.5484771e-05	loss: 34605.27734375	train_loss: 34582.04109909188	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_896
Epoch: 896	max: 0.9999746/1.0	min: 2.5375954e-05	loss: 34605.546875	train_loss: 34582.03349997677	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_897
Epoch: 897	max: 0.9999585/1.0	min: 4.1482534e-05	loss: 34605.234375	train_loss: 34581.99974645423	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_898
Epoch: 898	max: 0.9999809/1.0	min: 1.9059502e-05	loss: 34605.26171875	train_loss: 34582.01844351929	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_899
Epoch: 899	max: 0.9999676/1.0	min: 3.244259e-05	loss: 34605.40625	train_loss: 34581.93152764229	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_900
Epoch: 900	max: 0.9999678/1.0	min: 3.220729e-05	loss: 34605.35546875	train_loss: 34581.89608300818	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_901
Epoch: 901	max: 0.999967/1.0	min: 3.3030297e-05	loss: 34605.19140625	train_loss: 34581.91320944429	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_902
Epoch: 902	max: 0.9999845/1.0	min: 1.5507148e-05	loss: 34605.26171875	train_loss: 34581.8230811811	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_903
Epoch: 903	max: 0.99996877/1.0	min: 3.1206317e-05	loss: 34605.41015625	train_loss: 34581.826505984456	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_904
Epoch: 904	max: 0.9999777/1.0	min: 2.2236489e-05	loss: 34605.1953125	train_loss: 34581.784198195375	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_905
Epoch: 905	max: 0.999974/1.0	min: 2.6015889e-05	loss: 34605.1640625	train_loss: 34581.750296125974	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_906
Epoch: 906	max: 0.99998486/1.0	min: 1.5132683e-05	loss: 34605.921875	train_loss: 34581.731837606836	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_907
Epoch: 907	max: 0.999979/1.0	min: 2.101075e-05	loss: 34605.13671875	train_loss: 34581.765345809334	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_908
Epoch: 908	max: 0.9999752/1.0	min: 2.4759382e-05	loss: 34605.0703125	train_loss: 34581.67779122925	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_909
Epoch: 909	max: 0.99996793/1.0	min: 3.2012354e-05	loss: 34604.94921875	train_loss: 34581.63720309984	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_910
Epoch: 910	max: 0.99998474/1.0	min: 1.528072e-05	loss: 34605.30078125	train_loss: 34581.684330677876	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_911
Epoch: 911	max: 0.99995375/1.0	min: 4.6235156e-05	loss: 34604.90234375	train_loss: 34581.63853131193	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_912
Epoch: 912	max: 0.9999685/1.0	min: 3.1510175e-05	loss: 34605.109375	train_loss: 34581.66179026539	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_913
Epoch: 913	max: 0.9999739/1.0	min: 2.6078586e-05	loss: 34604.96875	train_loss: 34581.51740175585	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_914
Epoch: 914	max: 0.99998426/1.0	min: 1.5690266e-05	loss: 34605.34375	train_loss: 34581.47878634801	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_915
Epoch: 915	max: 0.999962/1.0	min: 3.8049075e-05	loss: 34604.94140625	train_loss: 34581.48179792983	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_916
Epoch: 916	max: 0.9999852/1.0	min: 1.4767627e-05	loss: 34605.00390625	train_loss: 34581.42606673092	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_917
Epoch: 917	max: 0.9999629/1.0	min: 3.712973e-05	loss: 34604.83984375	train_loss: 34581.42242418788	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_918
Epoch: 918	max: 0.9999832/1.0	min: 1.6793385e-05	loss: 34605.078125	train_loss: 34581.39991425895	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_919
Epoch: 919	max: 0.99996126/1.0	min: 3.8717666e-05	loss: 34604.7578125	train_loss: 34581.51092762913	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_920
Epoch: 920	max: 0.99997604/1.0	min: 2.4010777e-05	loss: 34605.13671875	train_loss: 34581.339796815	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_921
Epoch: 921	max: 0.99997854/1.0	min: 2.1473927e-05	loss: 34604.98828125	train_loss: 34581.30563200638	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_922
Epoch: 922	max: 0.99997056/1.0	min: 2.9418175e-05	loss: 34604.640625	train_loss: 34581.28535608665	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_923
Epoch: 923	max: 0.9999728/1.0	min: 2.714745e-05	loss: 34604.8203125	train_loss: 34581.25140611452	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_924
Epoch: 924	max: 0.99997795/1.0	min: 2.2018086e-05	loss: 34604.62890625	train_loss: 34581.21098733819	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_925
Epoch: 925	max: 0.9999695/1.0	min: 3.0558076e-05	loss: 34604.69140625	train_loss: 34581.197713442954	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_926
Epoch: 926	max: 0.9999763/1.0	min: 2.3737746e-05	loss: 34604.765625	train_loss: 34581.18620227146	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_927
Epoch: 927	max: 0.9999665/1.0	min: 3.3480756e-05	loss: 34604.74609375	train_loss: 34581.13922807894	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_928
Epoch: 928	max: 0.99998784/1.0	min: 1.2105663e-05	loss: 34604.81640625	train_loss: 34581.14027322944	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_929
Epoch: 929	max: 0.99997544/1.0	min: 2.4580886e-05	loss: 34604.72265625	train_loss: 34581.1041647312	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_930
Epoch: 930	max: 0.9999629/1.0	min: 3.7107213e-05	loss: 34604.7890625	train_loss: 34581.07337875867	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_931
Epoch: 931	max: 0.99996805/1.0	min: 3.1967906e-05	loss: 34604.65625	train_loss: 34581.04760563762	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_932
Epoch: 932	max: 0.9999602/1.0	min: 3.983716e-05	loss: 34604.55859375	train_loss: 34581.01434904543	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_933
Epoch: 933	max: 0.9999807/1.0	min: 1.9347166e-05	loss: 34604.74609375	train_loss: 34580.992578947575	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_934
Epoch: 934	max: 0.9999702/1.0	min: 2.9854828e-05	loss: 34604.5625	train_loss: 34580.97613718181	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_935
Epoch: 935	max: 0.9999707/1.0	min: 2.9377441e-05	loss: 34604.6953125	train_loss: 34580.94830037238	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_936
Epoch: 936	max: 0.99997413/1.0	min: 2.5828213e-05	loss: 34604.94921875	train_loss: 34580.930540071844	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_937
Epoch: 937	max: 0.99998116/1.0	min: 1.8797185e-05	loss: 34604.5234375	train_loss: 34580.91645908816	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_938
Epoch: 938	max: 0.9999763/1.0	min: 2.3739785e-05	loss: 34604.84375	train_loss: 34580.86631702512	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_939
Epoch: 939	max: 0.9999634/1.0	min: 3.660371e-05	loss: 34604.59375	train_loss: 34580.86908231915	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_940
Epoch: 940	max: 0.9999746/1.0	min: 2.5403653e-05	loss: 34604.75	train_loss: 34580.8082424633	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_941
Epoch: 941	max: 0.9999738/1.0	min: 2.6279109e-05	loss: 34604.5078125	train_loss: 34580.79360842082	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_942
Epoch: 942	max: 0.99997246/1.0	min: 2.7490245e-05	loss: 34604.73828125	train_loss: 34580.798422887245	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_943
Epoch: 943	max: 0.9999311/1.0	min: 6.8935544e-05	loss: 34604.48828125	train_loss: 34580.79405841617	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_944
Epoch: 944	max: 0.9999794/1.0	min: 2.0596926e-05	loss: 34604.42578125	train_loss: 34580.757364440105	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_945
Epoch: 945	max: 0.9999664/1.0	min: 3.3658944e-05	loss: 34604.296875	train_loss: 34580.67422174997	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_946
Epoch: 946	max: 0.99997663/1.0	min: 2.3331699e-05	loss: 34604.38671875	train_loss: 34580.67849767357	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_947
Epoch: 947	max: 0.99996686/1.0	min: 3.310557e-05	loss: 34604.37890625	train_loss: 34580.64628381255	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_948
Epoch: 948	max: 0.99995184/1.0	min: 4.8211623e-05	loss: 34604.171875	train_loss: 34580.62375162579	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_949
Epoch: 949	max: 0.9999788/1.0	min: 2.1171636e-05	loss: 34604.4140625	train_loss: 34580.61450736637	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_950
Epoch: 950	max: 0.99995995/1.0	min: 4.0101688e-05	loss: 34604.2109375	train_loss: 34580.59070164437	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_951
Epoch: 951	max: 0.9999496/1.0	min: 5.0374303e-05	loss: 34604.21875	train_loss: 34580.55224204137	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_952
Epoch: 952	max: 0.99997544/1.0	min: 2.4614339e-05	loss: 34604.53515625	train_loss: 34580.61003354159	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_953
Epoch: 953	max: 0.9999534/1.0	min: 4.6608744e-05	loss: 34604.1875	train_loss: 34580.49025542317	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_954
Epoch: 954	max: 0.9999758/1.0	min: 2.419909e-05	loss: 34604.23828125	train_loss: 34580.46906354515	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_955
Epoch: 955	max: 0.9999827/1.0	min: 1.7293934e-05	loss: 34604.44140625	train_loss: 34580.436674040786	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_956
Epoch: 956	max: 0.99998/1.0	min: 2.0042631e-05	loss: 34604.046875	train_loss: 34580.44449525037	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_957
Epoch: 957	max: 0.99998486/1.0	min: 1.5111541e-05	loss: 34604.2734375	train_loss: 34580.39069225737	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_958
Epoch: 958	max: 0.99996936/1.0	min: 3.0595656e-05	loss: 34604.2265625	train_loss: 34580.37281195807	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_959
Epoch: 959	max: 0.99996555/1.0	min: 3.4406545e-05	loss: 34604.12890625	train_loss: 34580.336479913756	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_960
Epoch: 960	max: 0.9999815/1.0	min: 1.853e-05	loss: 34604.296875	train_loss: 34580.380160914465	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_961
Epoch: 961	max: 0.9999672/1.0	min: 3.274171e-05	loss: 34604.05078125	train_loss: 34580.3025246191	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_962
Epoch: 962	max: 0.99998343/1.0	min: 1.6566208e-05	loss: 34604.40234375	train_loss: 34580.28386577945	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_963
Epoch: 963	max: 0.9999788/1.0	min: 2.1267477e-05	loss: 34604.26171875	train_loss: 34580.27879002539	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_964
Epoch: 964	max: 0.99996054/1.0	min: 3.9407845e-05	loss: 34603.96484375	train_loss: 34580.237796416295	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_965
Epoch: 965	max: 0.99997926/1.0	min: 2.0735615e-05	loss: 34604.4765625	train_loss: 34580.19928020098	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_966
Epoch: 966	max: 0.99994934/1.0	min: 5.07176e-05	loss: 34603.94140625	train_loss: 34580.20917719559	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_967
Epoch: 967	max: 0.99995613/1.0	min: 4.383483e-05	loss: 34604.01171875	train_loss: 34580.164334916546	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_968
Epoch: 968	max: 0.9999776/1.0	min: 2.242408e-05	loss: 34604.1640625	train_loss: 34580.15093279682	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_969
Epoch: 969	max: 0.9999548/1.0	min: 4.513562e-05	loss: 34604.18359375	train_loss: 34580.11158529977	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_970
Epoch: 970	max: 0.999966/1.0	min: 3.4032833e-05	loss: 34603.9296875	train_loss: 34580.10804243311	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_971
Epoch: 971	max: 0.99998176/1.0	min: 1.8270774e-05	loss: 34604.23828125	train_loss: 34580.06662931221	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_972
Epoch: 972	max: 0.9999529/1.0	min: 4.710801e-05	loss: 34603.703125	train_loss: 34580.08484928543	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_973
Epoch: 973	max: 0.99995816/1.0	min: 4.18773e-05	loss: 34603.90625	train_loss: 34580.057551502694	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_974
Epoch: 974	max: 0.9999682/1.0	min: 3.181165e-05	loss: 34603.69921875	train_loss: 34579.9874451296	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_975
Epoch: 975	max: 0.9999788/1.0	min: 2.1190463e-05	loss: 34604.0390625	train_loss: 34579.98070100567	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_976
Epoch: 976	max: 0.9999348/1.0	min: 6.521242e-05	loss: 34603.81640625	train_loss: 34579.978281191936	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_977
Epoch: 977	max: 0.999977/1.0	min: 2.3014058e-05	loss: 34603.9609375	train_loss: 34579.986807878115	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_978
Epoch: 978	max: 0.9999732/1.0	min: 2.6768717e-05	loss: 34603.984375	train_loss: 34579.90606226	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_979
Epoch: 979	max: 0.99996126/1.0	min: 3.87447e-05	loss: 34603.76953125	train_loss: 34579.89263739858	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_980
Epoch: 980	max: 0.9999676/1.0	min: 3.2389416e-05	loss: 34603.66015625	train_loss: 34579.83417719559	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_981
Epoch: 981	max: 0.9999856/1.0	min: 1.44240275e-05	loss: 34604.078125	train_loss: 34579.870150211354	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_982
Epoch: 982	max: 0.99998474/1.0	min: 1.5232922e-05	loss: 34604.07421875	train_loss: 34579.8322901183	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_983
Epoch: 983	max: 0.9999504/1.0	min: 4.95814e-05	loss: 34603.76171875	train_loss: 34579.85551810433	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_984
Epoch: 984	max: 0.99997294/1.0	min: 2.7069067e-05	loss: 34603.796875	train_loss: 34579.767252725134	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_985
Epoch: 985	max: 0.99997926/1.0	min: 2.0773676e-05	loss: 34603.6796875	train_loss: 34579.75788266057	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_986
Epoch: 986	max: 0.9999746/1.0	min: 2.5337647e-05	loss: 34603.71875	train_loss: 34579.708111238855	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_987
Epoch: 987	max: 0.9999703/1.0	min: 2.9702584e-05	loss: 34603.80859375	train_loss: 34579.71031428063	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_988
Epoch: 988	max: 0.9999559/1.0	min: 4.4054166e-05	loss: 34603.8515625	train_loss: 34579.70474256395	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_989
Epoch: 989	max: 0.9999682/1.0	min: 3.1836902e-05	loss: 34603.76953125	train_loss: 34579.66095462885	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_990
Epoch: 990	max: 0.9999764/1.0	min: 2.3607441e-05	loss: 34603.765625	train_loss: 34579.65181536836	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_991
Epoch: 991	max: 0.9999769/1.0	min: 2.3068133e-05	loss: 34603.53515625	train_loss: 34579.60989031726	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_992
Epoch: 992	max: 0.9999635/1.0	min: 3.6422745e-05	loss: 34603.53515625	train_loss: 34579.59136066982	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_993
Epoch: 993	max: 0.99996686/1.0	min: 3.3171844e-05	loss: 34603.7265625	train_loss: 34579.55290203456	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_994
Epoch: 994	max: 0.99998415/1.0	min: 1.5822136e-05	loss: 34603.6484375	train_loss: 34579.53454899821	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_995
Epoch: 995	max: 0.9999639/1.0	min: 3.6132315e-05	loss: 34603.55078125	train_loss: 34579.52136800523	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_996
Epoch: 996	max: 0.999966/1.0	min: 3.3928e-05	loss: 34603.78125	train_loss: 34579.47211093305	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_997
Epoch: 997	max: 0.9999752/1.0	min: 2.4808876e-05	loss: 34603.578125	train_loss: 34579.46835903629	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_998
Epoch: 998	max: 0.99998355/1.0	min: 1.6395052e-05	loss: 34603.6640625	train_loss: 34579.454487082716	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_999
Epoch: 999	max: 0.9999609/1.0	min: 3.9144314e-05	loss: 34603.37890625	train_loss: 34579.42412642837	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1000
Epoch: 1000	max: 0.9999721/1.0	min: 2.7834687e-05	loss: 34603.625	train_loss: 34579.42674607875	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1001
Epoch: 1001	max: 0.99996555/1.0	min: 3.450446e-05	loss: 34603.5	train_loss: 34579.369345058374	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1002
Epoch: 1002	max: 0.9999862/1.0	min: 1.3790341e-05	loss: 34603.5	train_loss: 34579.348866398796	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1003
Epoch: 1003	max: 0.9999714/1.0	min: 2.855868e-05	loss: 34603.4765625	train_loss: 34579.3426990431	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1004
Epoch: 1004	max: 0.9999865/1.0	min: 1.34911415e-05	loss: 34603.703125	train_loss: 34579.30744214899	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1005
Epoch: 1005	max: 0.9999895/1.0	min: 1.0490902e-05	loss: 34603.4609375	train_loss: 34579.36228690542	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1006
Epoch: 1006	max: 0.9999757/1.0	min: 2.4271567e-05	loss: 34603.33984375	train_loss: 34579.26323712142	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1007
Epoch: 1007	max: 0.999962/1.0	min: 3.8084872e-05	loss: 34603.390625	train_loss: 34579.22473638982	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1008
Epoch: 1008	max: 0.9999871/1.0	min: 1.2856059e-05	loss: 34603.5390625	train_loss: 34579.21052427846	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1009
Epoch: 1009	max: 0.9999819/1.0	min: 1.807861e-05	loss: 34603.671875	train_loss: 34579.20254726403	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1010
Epoch: 1010	max: 0.9999659/1.0	min: 3.4119665e-05	loss: 34603.1015625	train_loss: 34579.20406660318	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1011
Epoch: 1011	max: 0.99998367/1.0	min: 1.636047e-05	loss: 34603.39453125	train_loss: 34579.15096231265	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1012
Epoch: 1012	max: 0.9999765/1.0	min: 2.3449053e-05	loss: 34603.46875	train_loss: 34579.111102401526	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1013
Epoch: 1013	max: 0.9999838/1.0	min: 1.6249078e-05	loss: 34603.5390625	train_loss: 34579.098708658494	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1014
Epoch: 1014	max: 0.9999796/1.0	min: 2.0391944e-05	loss: 34603.09375	train_loss: 34579.10639825653	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1015
Epoch: 1015	max: 0.99996996/1.0	min: 3.0079622e-05	loss: 34603.19140625	train_loss: 34579.0839139725	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1016
Epoch: 1016	max: 0.9999887/1.0	min: 1.1269576e-05	loss: 34603.25390625	train_loss: 34579.03723203502	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1017
Epoch: 1017	max: 0.99998057/1.0	min: 1.9443716e-05	loss: 34603.4140625	train_loss: 34579.01531871284	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1018
Epoch: 1018	max: 0.9999579/1.0	min: 4.202981e-05	loss: 34603.15625	train_loss: 34578.99386361173	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1019
Epoch: 1019	max: 0.9999863/1.0	min: 1.3688872e-05	loss: 34603.3359375	train_loss: 34578.9662130907	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1020
Epoch: 1020	max: 0.9999846/1.0	min: 1.532327e-05	loss: 34603.61328125	train_loss: 34578.97437881286	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1021
Epoch: 1021	max: 0.9999492/1.0	min: 5.0809966e-05	loss: 34603.0546875	train_loss: 34579.010696341196	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1022
Epoch: 1022	max: 0.999977/1.0	min: 2.3034567e-05	loss: 34603.015625	train_loss: 34578.94264881782	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1023
Epoch: 1023	max: 0.999966/1.0	min: 3.4001234e-05	loss: 34602.99609375	train_loss: 34578.86806813607	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1024
Epoch: 1024	max: 0.9999857/1.0	min: 1.4303471e-05	loss: 34603.20703125	train_loss: 34578.910250119996	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1025
Epoch: 1025	max: 0.99998355/1.0	min: 1.6462138e-05	loss: 34602.9765625	train_loss: 34578.87765981125	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1026
Epoch: 1026	max: 0.9999753/1.0	min: 2.4683186e-05	loss: 34603.0859375	train_loss: 34578.83107416311	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1027
Epoch: 1027	max: 0.9999784/1.0	min: 2.1522905e-05	loss: 34603.0859375	train_loss: 34578.78398432661	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1028
Epoch: 1028	max: 0.99994147/1.0	min: 5.8577913e-05	loss: 34602.98828125	train_loss: 34578.76536709943	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1029
Epoch: 1029	max: 0.99997175/1.0	min: 2.824959e-05	loss: 34602.953125	train_loss: 34578.760846339654	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1030
Epoch: 1030	max: 0.99998856/1.0	min: 1.1443759e-05	loss: 34603.28515625	train_loss: 34578.72464832621	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1031
Epoch: 1031	max: 0.9999813/1.0	min: 1.8708164e-05	loss: 34602.93359375	train_loss: 34578.72490671064	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1032
Epoch: 1032	max: 0.9999604/1.0	min: 3.9621053e-05	loss: 34603.4921875	train_loss: 34578.71345408692	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1033
Epoch: 1033	max: 0.9999763/1.0	min: 2.3772975e-05	loss: 34602.88671875	train_loss: 34578.698357468566	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1034
Epoch: 1034	max: 0.9999654/1.0	min: 3.4572906e-05	loss: 34602.88671875	train_loss: 34578.656621609065	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1035
Epoch: 1035	max: 0.9999869/1.0	min: 1.3117196e-05	loss: 34602.796875	train_loss: 34578.631748962594	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1036
Epoch: 1036	max: 0.9999733/1.0	min: 2.6676671e-05	loss: 34602.73046875	train_loss: 34578.59453095968	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1037
Epoch: 1037	max: 0.9999808/1.0	min: 1.9234943e-05	loss: 34602.78125	train_loss: 34578.57920111792	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1038
Epoch: 1038	max: 0.9999827/1.0	min: 1.7306638e-05	loss: 34602.9296875	train_loss: 34578.545212920384	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1039
Epoch: 1039	max: 0.9999759/1.0	min: 2.406547e-05	loss: 34602.80078125	train_loss: 34578.54720789979	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1040
Epoch: 1040	max: 0.99998116/1.0	min: 1.8800592e-05	loss: 34603.0234375	train_loss: 34578.536024305555	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1041
Epoch: 1041	max: 0.9999685/1.0	min: 3.1421503e-05	loss: 34602.64453125	train_loss: 34578.53040952481	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1042
Epoch: 1042	max: 0.9999368/1.0	min: 6.3132975e-05	loss: 34602.81640625	train_loss: 34578.502402878425	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1043
Epoch: 1043	max: 0.9999701/1.0	min: 2.9935252e-05	loss: 34602.63671875	train_loss: 34578.48476789917	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1044
Epoch: 1044	max: 0.9999815/1.0	min: 1.8517245e-05	loss: 34602.98046875	train_loss: 34578.45640512743	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1045
Epoch: 1045	max: 0.9999763/1.0	min: 2.3672457e-05	loss: 34602.76171875	train_loss: 34578.41660521569	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1046
Epoch: 1046	max: 0.99997425/1.0	min: 2.5697285e-05	loss: 34602.7890625	train_loss: 34578.376679014924	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1047
Epoch: 1047	max: 0.99997103/1.0	min: 2.8984372e-05	loss: 34602.6953125	train_loss: 34578.40777030689	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1048
Epoch: 1048	max: 0.9999622/1.0	min: 3.776757e-05	loss: 34602.55859375	train_loss: 34578.33354042797	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1049
Epoch: 1049	max: 0.99997866/1.0	min: 2.1288253e-05	loss: 34602.44140625	train_loss: 34578.3208016885	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1050
Epoch: 1050	max: 0.9999838/1.0	min: 1.6198315e-05	loss: 34602.8984375	train_loss: 34578.32743549099	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1051
Epoch: 1051	max: 0.9999646/1.0	min: 3.5379355e-05	loss: 34602.4921875	train_loss: 34578.30313525796	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1052
Epoch: 1052	max: 0.9999801/1.0	min: 1.9934017e-05	loss: 34602.61328125	train_loss: 34578.25861958844	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1053
Epoch: 1053	max: 0.99997413/1.0	min: 2.58478e-05	loss: 34602.54296875	train_loss: 34578.23634385064	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1054
Epoch: 1054	max: 0.99998546/1.0	min: 1.46011525e-05	loss: 34602.61328125	train_loss: 34578.211790071844	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1055
Epoch: 1055	max: 0.9999652/1.0	min: 3.4788543e-05	loss: 34602.765625	train_loss: 34578.199655680975	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1056
Epoch: 1056	max: 0.9999695/1.0	min: 3.05219e-05	loss: 34602.65625	train_loss: 34578.162817996716	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1057
Epoch: 1057	max: 0.9999802/1.0	min: 1.9746607e-05	loss: 34602.5703125	train_loss: 34578.1398783948	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1058
Epoch: 1058	max: 0.99997854/1.0	min: 2.1466229e-05	loss: 34602.5859375	train_loss: 34578.1309041326	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1059
Epoch: 1059	max: 0.99997103/1.0	min: 2.8943216e-05	loss: 34602.46875	train_loss: 34578.14067967686	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1060
Epoch: 1060	max: 0.99998164/1.0	min: 1.8397623e-05	loss: 34602.484375	train_loss: 34578.08887214713	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1061
Epoch: 1061	max: 0.9999708/1.0	min: 2.9224066e-05	loss: 34602.51171875	train_loss: 34578.06519029481	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1062
Epoch: 1062	max: 0.99995863/1.0	min: 4.1404477e-05	loss: 34602.4921875	train_loss: 34578.05426073021	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1063
Epoch: 1063	max: 0.99998/1.0	min: 2.0049056e-05	loss: 34602.390625	train_loss: 34578.0249036139	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1064
Epoch: 1064	max: 0.99995434/1.0	min: 4.5659108e-05	loss: 34602.48046875	train_loss: 34577.99324571488	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1065
Epoch: 1065	max: 0.9999833/1.0	min: 1.672592e-05	loss: 34602.50390625	train_loss: 34578.04541517636	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1066
Epoch: 1066	max: 0.99996233/1.0	min: 3.7725997e-05	loss: 34602.3359375	train_loss: 34577.96666453766	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1067
Epoch: 1067	max: 0.9999813/1.0	min: 1.8688157e-05	loss: 34602.51171875	train_loss: 34577.94177495587	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1068
Epoch: 1068	max: 0.99995613/1.0	min: 4.3885986e-05	loss: 34602.2109375	train_loss: 34577.97746103911	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1069
Epoch: 1069	max: 0.99998903/1.0	min: 1.096578e-05	loss: 34602.2734375	train_loss: 34577.955959970735	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1070
Epoch: 1070	max: 0.99998367/1.0	min: 1.6390237e-05	loss: 34602.453125	train_loss: 34577.90721531262	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1071
Epoch: 1071	max: 0.99996626/1.0	min: 3.3720753e-05	loss: 34602.4609375	train_loss: 34577.88696261845	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1072
Epoch: 1072	max: 0.99998474/1.0	min: 1.5221248e-05	loss: 34602.40234375	train_loss: 34577.848054471695	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1073
Epoch: 1073	max: 0.999964/1.0	min: 3.59872e-05	loss: 34602.140625	train_loss: 34577.820459595256	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1074
Epoch: 1074	max: 0.9999721/1.0	min: 2.7869619e-05	loss: 34602.1640625	train_loss: 34577.830209010746	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1075
Epoch: 1075	max: 0.9999771/1.0	min: 2.2851867e-05	loss: 34602.09375	train_loss: 34577.780154527434	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1076
Epoch: 1076	max: 0.9999819/1.0	min: 1.8064598e-05	loss: 34602.19921875	train_loss: 34577.85085605568	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1077
Epoch: 1077	max: 0.99996936/1.0	min: 3.067545e-05	loss: 34602.2734375	train_loss: 34577.72663653149	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1078
Epoch: 1078	max: 0.99998736/1.0	min: 1.265204e-05	loss: 34602.12890625	train_loss: 34577.70798301437	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1079
Epoch: 1079	max: 0.99997914/1.0	min: 2.08153e-05	loss: 34602.23046875	train_loss: 34577.70220178372	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1080
Epoch: 1080	max: 0.9999877/1.0	min: 1.2224577e-05	loss: 34602.140625	train_loss: 34577.67546818872	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1081
Epoch: 1081	max: 0.9999856/1.0	min: 1.4430934e-05	loss: 34602.2734375	train_loss: 34577.655959680415	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1082
Epoch: 1082	max: 0.99998605/1.0	min: 1.3970138e-05	loss: 34601.9296875	train_loss: 34577.626718691936	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1083
Epoch: 1083	max: 0.99997497/1.0	min: 2.509049e-05	loss: 34602.12109375	train_loss: 34577.63119977471	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1084
Epoch: 1084	max: 0.99998176/1.0	min: 1.825294e-05	loss: 34602.2578125	train_loss: 34577.589885362475	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1085
Epoch: 1085	max: 0.9999697/1.0	min: 3.0229096e-05	loss: 34602.015625	train_loss: 34577.57383310882	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1086
Epoch: 1086	max: 0.9999745/1.0	min: 2.5476484e-05	loss: 34601.9765625	train_loss: 34577.581125452896	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1087
Epoch: 1087	max: 0.9999856/1.0	min: 1.4417e-05	loss: 34602.06640625	train_loss: 34577.55695489595	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1088
Epoch: 1088	max: 0.9999875/1.0	min: 1.2460809e-05	loss: 34602.5703125	train_loss: 34577.53416238929	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1089
Epoch: 1089	max: 0.9999833/1.0	min: 1.6730883e-05	loss: 34601.96875	train_loss: 34577.49341071318	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1090
Epoch: 1090	max: 0.9999844/1.0	min: 1.5558697e-05	loss: 34601.99609375	train_loss: 34577.46546164685	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1091
Epoch: 1091	max: 0.999985/1.0	min: 1.5016153e-05	loss: 34601.953125	train_loss: 34577.45277855196	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1092
Epoch: 1092	max: 0.99996364/1.0	min: 3.641702e-05	loss: 34602.0703125	train_loss: 34577.42124887743	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1093
Epoch: 1093	max: 0.99997663/1.0	min: 2.3382934e-05	loss: 34601.95703125	train_loss: 34577.424040300226	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1094
Epoch: 1094	max: 0.99998367/1.0	min: 1.6319658e-05	loss: 34601.96875	train_loss: 34577.38338636504	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1095
Epoch: 1095	max: 0.9999864/1.0	min: 1.3533433e-05	loss: 34602.04296875	train_loss: 34577.358754683824	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1096
Epoch: 1096	max: 0.9999738/1.0	min: 2.628089e-05	loss: 34601.82421875	train_loss: 34577.34692416078	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1097
Epoch: 1097	max: 0.9999815/1.0	min: 1.8514278e-05	loss: 34601.87890625	train_loss: 34577.357427439456	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1098
Epoch: 1098	max: 0.99998045/1.0	min: 1.9530205e-05	loss: 34601.94921875	train_loss: 34577.340254068346	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1099
Epoch: 1099	max: 0.9999783/1.0	min: 2.1683785e-05	loss: 34601.92578125	train_loss: 34577.283336430075	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1100
Epoch: 1100	max: 0.99996686/1.0	min: 3.3140794e-05	loss: 34601.7734375	train_loss: 34577.26836464914	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1101
Epoch: 1101	max: 0.9999887/1.0	min: 1.1353372e-05	loss: 34601.98828125	train_loss: 34577.24568730258	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1102
Epoch: 1102	max: 0.999985/1.0	min: 1.5060986e-05	loss: 34601.8046875	train_loss: 34577.24441908987	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1103
Epoch: 1103	max: 0.99996734/1.0	min: 3.263964e-05	loss: 34601.765625	train_loss: 34577.21286909297	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1104
Epoch: 1104	max: 0.99998677/1.0	min: 1.3269476e-05	loss: 34601.8359375	train_loss: 34577.22706039809	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1105
Epoch: 1105	max: 0.999969/1.0	min: 3.1007115e-05	loss: 34601.76171875	train_loss: 34577.170446143784	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1106
Epoch: 1106	max: 0.9999732/1.0	min: 2.687067e-05	loss: 34601.8359375	train_loss: 34577.148779109375	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1107
Epoch: 1107	max: 0.99996924/1.0	min: 3.0782823e-05	loss: 34601.71875	train_loss: 34577.15281261613	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1108
Epoch: 1108	max: 0.9999883/1.0	min: 1.1627805e-05	loss: 34602.35546875	train_loss: 34577.13565279326	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1109
Epoch: 1109	max: 0.99998355/1.0	min: 1.640888e-05	loss: 34601.76171875	train_loss: 34577.14494108448	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1110
Epoch: 1110	max: 0.9999857/1.0	min: 1.4285299e-05	loss: 34601.80078125	train_loss: 34577.11430269107	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1111
Epoch: 1111	max: 0.9999851/1.0	min: 1.4910542e-05	loss: 34601.69921875	train_loss: 34577.07899886195	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1112
Epoch: 1112	max: 0.99998474/1.0	min: 1.520014e-05	loss: 34601.90234375	train_loss: 34577.06367434272	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1113
Epoch: 1113	max: 0.9999759/1.0	min: 2.4085262e-05	loss: 34601.671875	train_loss: 34577.027757455406	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1114
Epoch: 1114	max: 0.9999827/1.0	min: 1.7324439e-05	loss: 34601.6015625	train_loss: 34576.99507230893	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1115
Epoch: 1115	max: 0.9999876/1.0	min: 1.2381209e-05	loss: 34601.6875	train_loss: 34576.97811619364	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1116
Epoch: 1116	max: 0.99998045/1.0	min: 1.9600717e-05	loss: 34601.578125	train_loss: 34576.94961503623	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1117
Epoch: 1117	max: 0.9999832/1.0	min: 1.6762055e-05	loss: 34601.6640625	train_loss: 34576.92082355924	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1118
Epoch: 1118	max: 0.99997973/1.0	min: 2.021987e-05	loss: 34601.921875	train_loss: 34576.90394534637	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1119
Epoch: 1119	max: 0.9999788/1.0	min: 2.1243555e-05	loss: 34601.66015625	train_loss: 34576.898294759536	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1120
Epoch: 1120	max: 0.9999746/1.0	min: 2.5412352e-05	loss: 34601.86328125	train_loss: 34576.89682380698	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1121
Epoch: 1121	max: 0.99998236/1.0	min: 1.7615572e-05	loss: 34601.7109375	train_loss: 34576.94308381333	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1122
Epoch: 1122	max: 0.999972/1.0	min: 2.797717e-05	loss: 34601.71484375	train_loss: 34576.877443039295	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1123
Epoch: 1123	max: 0.9999708/1.0	min: 2.9180508e-05	loss: 34601.51953125	train_loss: 34576.844825634056	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1124
Epoch: 1124	max: 0.99999094/1.0	min: 9.011287e-06	loss: 34601.7265625	train_loss: 34576.81673527886	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1125
Epoch: 1125	max: 0.9999558/1.0	min: 4.4254302e-05	loss: 34601.67578125	train_loss: 34576.79833337204	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1126
Epoch: 1126	max: 0.9999734/1.0	min: 2.6562462e-05	loss: 34601.4765625	train_loss: 34576.78650236514	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1127
Epoch: 1127	max: 0.99997675/1.0	min: 2.3242294e-05	loss: 34601.484375	train_loss: 34576.73826479856	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1128
Epoch: 1128	max: 0.99998975/1.0	min: 1.0265716e-05	loss: 34601.51171875	train_loss: 34576.72051369147	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1129
Epoch: 1129	max: 0.9999926/1.0	min: 7.3482843e-06	loss: 34601.9375	train_loss: 34576.73761545042	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1130
Epoch: 1130	max: 0.999987/1.0	min: 1.2991607e-05	loss: 34601.53125	train_loss: 34576.74166831181	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1131
Epoch: 1131	max: 0.9999801/1.0	min: 1.9926834e-05	loss: 34601.55859375	train_loss: 34576.67841590022	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1132
Epoch: 1132	max: 0.99998486/1.0	min: 1.5181019e-05	loss: 34601.44140625	train_loss: 34576.64165563452	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1133
Epoch: 1133	max: 0.9999932/1.0	min: 6.8283243e-06	loss: 34601.625	train_loss: 34576.62927060108	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1134
Epoch: 1134	max: 0.9999788/1.0	min: 2.1170283e-05	loss: 34601.55078125	train_loss: 34576.63934130358	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1135
Epoch: 1135	max: 0.99997723/1.0	min: 2.2820857e-05	loss: 34601.44921875	train_loss: 34576.602071527006	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1136
Epoch: 1136	max: 0.999982/1.0	min: 1.7951203e-05	loss: 34601.703125	train_loss: 34576.61361124659	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1137
Epoch: 1137	max: 0.99998236/1.0	min: 1.7701745e-05	loss: 34601.48828125	train_loss: 34576.620631658	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1138
Epoch: 1138	max: 0.9999912/1.0	min: 8.850068e-06	loss: 34601.4296875	train_loss: 34576.544115512355	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1139
Epoch: 1139	max: 0.9999883/1.0	min: 1.1642507e-05	loss: 34601.39453125	train_loss: 34576.53845476434	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1140
Epoch: 1140	max: 0.9999778/1.0	min: 2.2198796e-05	loss: 34601.43359375	train_loss: 34576.52010559891	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1141
Epoch: 1141	max: 0.9999857/1.0	min: 1.4307332e-05	loss: 34601.5	train_loss: 34576.47979230537	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1142
Epoch: 1142	max: 0.99997485/1.0	min: 2.5210438e-05	loss: 34601.25	train_loss: 34576.47722297705	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1143
Epoch: 1143	max: 0.9999857/1.0	min: 1.4297292e-05	loss: 34601.6328125	train_loss: 34576.48123616143	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1144
Epoch: 1144	max: 0.9999788/1.0	min: 2.1270924e-05	loss: 34601.50390625	train_loss: 34576.42222725443	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1145
Epoch: 1145	max: 0.9999865/1.0	min: 1.3509257e-05	loss: 34601.59375	train_loss: 34576.42554028475	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1146
Epoch: 1146	max: 0.9999815/1.0	min: 1.8480287e-05	loss: 34601.421875	train_loss: 34576.40468420971	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1147
Epoch: 1147	max: 0.9999865/1.0	min: 1.3521708e-05	loss: 34601.53125	train_loss: 34576.396237845285	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1148
Epoch: 1148	max: 0.9999782/1.0	min: 2.1811418e-05	loss: 34601.62109375	train_loss: 34576.42402288105	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1149
Epoch: 1149	max: 0.9999808/1.0	min: 1.9165143e-05	loss: 34601.20703125	train_loss: 34576.40109392419	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1150
Epoch: 1150	max: 0.99998295/1.0	min: 1.7009625e-05	loss: 34601.140625	train_loss: 34576.38154090022	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1151
Epoch: 1151	max: 0.9999765/1.0	min: 2.3486049e-05	loss: 34601.44921875	train_loss: 34576.32555228462	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1152
Epoch: 1152	max: 0.99998236/1.0	min: 1.7661157e-05	loss: 34601.1953125	train_loss: 34576.31797445962	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1153
Epoch: 1153	max: 0.9999815/1.0	min: 1.8491693e-05	loss: 34601.0859375	train_loss: 34576.27331992057	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1154
Epoch: 1154	max: 0.99995613/1.0	min: 4.384361e-05	loss: 34601.37109375	train_loss: 34576.27532215796	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1155
Epoch: 1155	max: 0.9999604/1.0	min: 3.9551287e-05	loss: 34601.28515625	train_loss: 34576.26979253763	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1156
Epoch: 1156	max: 0.9999827/1.0	min: 1.7258213e-05	loss: 34601.60546875	train_loss: 34576.254041248605	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1157
Epoch: 1157	max: 0.99997544/1.0	min: 2.4546474e-05	loss: 34601.26953125	train_loss: 34576.21401343599	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1158
Epoch: 1158	max: 0.9999857/1.0	min: 1.42488625e-05	loss: 34601.4140625	train_loss: 34576.17646350102	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1159
Epoch: 1159	max: 0.99997115/1.0	min: 2.8791585e-05	loss: 34601.15625	train_loss: 34576.1786365431	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1160
Epoch: 1160	max: 0.99999154/1.0	min: 8.438533e-06	loss: 34601.12109375	train_loss: 34576.14972119642	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1161
Epoch: 1161	max: 0.9999672/1.0	min: 3.2819145e-05	loss: 34601.30859375	train_loss: 34576.13508183142	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1162
Epoch: 1162	max: 0.9999609/1.0	min: 3.9063354e-05	loss: 34601.12890625	train_loss: 34576.10506568965	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1163
Epoch: 1163	max: 0.9999908/1.0	min: 9.185215e-06	loss: 34601.44140625	train_loss: 34576.099689454815	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1164
Epoch: 1164	max: 0.999967/1.0	min: 3.2996046e-05	loss: 34601.12890625	train_loss: 34576.15450324384	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1165
Epoch: 1165	max: 0.9999771/1.0	min: 2.2909388e-05	loss: 34601.16796875	train_loss: 34576.051849142204	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1166
Epoch: 1166	max: 0.9999851/1.0	min: 1.4908423e-05	loss: 34600.94140625	train_loss: 34576.03376368373	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1167
Epoch: 1167	max: 0.99997115/1.0	min: 2.889132e-05	loss: 34601.35546875	train_loss: 34576.03195305726	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1168
Epoch: 1168	max: 0.9999895/1.0	min: 1.0501974e-05	loss: 34601.21484375	train_loss: 34575.99482553729	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1169
Epoch: 1169	max: 0.999987/1.0	min: 1.3005602e-05	loss: 34600.9453125	train_loss: 34576.00109740803	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1170
Epoch: 1170	max: 0.9999902/1.0	min: 9.7896045e-06	loss: 34600.984375	train_loss: 34575.953530963554	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1171
Epoch: 1171	max: 0.99996936/1.0	min: 3.0595744e-05	loss: 34601.0546875	train_loss: 34575.95276210052	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1172
Epoch: 1172	max: 0.99997437/1.0	min: 2.5607653e-05	loss: 34601.25390625	train_loss: 34575.90907335795	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1173
Epoch: 1173	max: 0.99998415/1.0	min: 1.5896032e-05	loss: 34601.23046875	train_loss: 34575.91737262712	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1174
Epoch: 1174	max: 0.9999802/1.0	min: 1.9743651e-05	loss: 34600.890625	train_loss: 34575.88384071519	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1175
Epoch: 1175	max: 0.99997616/1.0	min: 2.3884437e-05	loss: 34601.05859375	train_loss: 34575.85796695002	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1176
Epoch: 1176	max: 0.9999845/1.0	min: 1.5448944e-05	loss: 34601.0546875	train_loss: 34575.82180087173	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1177
Epoch: 1177	max: 0.99996984/1.0	min: 3.0196483e-05	loss: 34601.0	train_loss: 34575.806563932245	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1178
Epoch: 1178	max: 0.9999937/1.0	min: 6.323337e-06	loss: 34601.12890625	train_loss: 34575.86862119488	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1179
Epoch: 1179	max: 0.9999795/1.0	min: 2.0545998e-05	loss: 34601.296875	train_loss: 34575.77870728431	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1180
Epoch: 1180	max: 0.99998116/1.0	min: 1.8875204e-05	loss: 34601.33984375	train_loss: 34575.76110569181	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1181
Epoch: 1181	max: 0.9999728/1.0	min: 2.7214484e-05	loss: 34600.8359375	train_loss: 34575.74485408538	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1182
Epoch: 1182	max: 0.9999913/1.0	min: 8.748806e-06	loss: 34601.171875	train_loss: 34575.73488499474	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1183
Epoch: 1183	max: 0.9999702/1.0	min: 2.9845378e-05	loss: 34600.953125	train_loss: 34575.736996585845	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1184
Epoch: 1184	max: 0.9999665/1.0	min: 3.3455093e-05	loss: 34600.96875	train_loss: 34575.664900072	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1185
Epoch: 1185	max: 0.9999678/1.0	min: 3.2154472e-05	loss: 34600.9453125	train_loss: 34575.65119892311	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1186
Epoch: 1186	max: 0.99999225/1.0	min: 7.73639e-06	loss: 34601.296875	train_loss: 34575.70312983866	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1187
Epoch: 1187	max: 0.99994195/1.0	min: 5.8019297e-05	loss: 34600.92578125	train_loss: 34575.75830991422	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1188
Epoch: 1188	max: 0.99998367/1.0	min: 1.6310185e-05	loss: 34600.73046875	train_loss: 34575.621696647	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1189
Epoch: 1189	max: 0.9999672/1.0	min: 3.278061e-05	loss: 34600.94921875	train_loss: 34575.58395413338	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1190
Epoch: 1190	max: 0.9999937/1.0	min: 6.32946e-06	loss: 34600.91015625	train_loss: 34575.55476878949	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1191
Epoch: 1191	max: 0.999977/1.0	min: 2.2961092e-05	loss: 34600.890625	train_loss: 34575.54759789576	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1192
Epoch: 1192	max: 0.99998355/1.0	min: 1.649835e-05	loss: 34600.984375	train_loss: 34575.51252535458	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1193
Epoch: 1193	max: 0.9999825/1.0	min: 1.755669e-05	loss: 34600.7890625	train_loss: 34575.50591284219	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1194
Epoch: 1194	max: 0.9999931/1.0	min: 6.9672383e-06	loss: 34600.73828125	train_loss: 34575.474288329926	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1195
Epoch: 1195	max: 0.99997616/1.0	min: 2.3786648e-05	loss: 34600.68359375	train_loss: 34575.45759640545	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1196
Epoch: 1196	max: 0.9999906/1.0	min: 9.37635e-06	loss: 34601.13671875	train_loss: 34575.46772226867	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1197
Epoch: 1197	max: 0.999949/1.0	min: 5.09808e-05	loss: 34600.73828125	train_loss: 34575.48587014586	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1198
Epoch: 1198	max: 0.9999753/1.0	min: 2.4669676e-05	loss: 34600.6015625	train_loss: 34575.41941308993	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1199
Epoch: 1199	max: 0.9999707/1.0	min: 2.9373155e-05	loss: 34600.73046875	train_loss: 34575.3723522854	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1200
Epoch: 1200	max: 0.99997497/1.0	min: 2.5076713e-05	loss: 34600.703125	train_loss: 34575.365052199464	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1201
Epoch: 1201	max: 0.99998426/1.0	min: 1.579012e-05	loss: 34600.55078125	train_loss: 34575.35108153722	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1202
Epoch: 1202	max: 0.99997234/1.0	min: 2.767461e-05	loss: 34600.67578125	train_loss: 34575.33810134863	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1203
Epoch: 1203	max: 0.9999809/1.0	min: 1.9059666e-05	loss: 34600.6015625	train_loss: 34575.29845966106	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1204
Epoch: 1204	max: 0.9999789/1.0	min: 2.111385e-05	loss: 34600.55859375	train_loss: 34575.28280127431	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1205
Epoch: 1205	max: 0.9999727/1.0	min: 2.7265243e-05	loss: 34600.765625	train_loss: 34575.283344171934	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1206
Epoch: 1206	max: 0.9999664/1.0	min: 3.3634202e-05	loss: 34600.859375	train_loss: 34575.28338142961	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1207
Epoch: 1207	max: 0.99997914/1.0	min: 2.0812184e-05	loss: 34600.49609375	train_loss: 34575.25811056144	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1208
Epoch: 1208	max: 0.9999777/1.0	min: 2.232141e-05	loss: 34600.58984375	train_loss: 34575.22262189552	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1209
Epoch: 1209	max: 0.99997365/1.0	min: 2.6334803e-05	loss: 34600.640625	train_loss: 34575.18372003902	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1210
Epoch: 1210	max: 0.99998724/1.0	min: 1.2722312e-05	loss: 34600.546875	train_loss: 34575.15768369488	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1211
Epoch: 1211	max: 0.9999783/1.0	min: 2.163706e-05	loss: 34600.56640625	train_loss: 34575.14593736452	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1212
Epoch: 1212	max: 0.99998105/1.0	min: 1.899458e-05	loss: 34600.4140625	train_loss: 34575.13642359176	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1213
Epoch: 1213	max: 0.99996495/1.0	min: 3.503351e-05	loss: 34600.49609375	train_loss: 34575.11315012232	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1214
Epoch: 1214	max: 0.99998677/1.0	min: 1.3260999e-05	loss: 34600.46484375	train_loss: 34575.10893032717	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1215
Epoch: 1215	max: 0.9999902/1.0	min: 9.772349e-06	loss: 34600.6171875	train_loss: 34575.17182080701	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1216
Epoch: 1216	max: 0.999982/1.0	min: 1.7982526e-05	loss: 34600.3046875	train_loss: 34575.068432680695	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1217
Epoch: 1217	max: 0.99998343/1.0	min: 1.6615762e-05	loss: 34600.44140625	train_loss: 34575.039853137	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1218
Epoch: 1218	max: 0.99998164/1.0	min: 1.8316061e-05	loss: 34600.2734375	train_loss: 34575.01170423402	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1219
Epoch: 1219	max: 0.99998844/1.0	min: 1.1560921e-05	loss: 34600.44140625	train_loss: 34575.01318050911	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1220
Epoch: 1220	max: 0.9999727/1.0	min: 2.7318989e-05	loss: 34600.30078125	train_loss: 34574.99256636706	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1221
Epoch: 1221	max: 0.9999893/1.0	min: 1.0774904e-05	loss: 34600.44140625	train_loss: 34574.941151252635	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1222
Epoch: 1222	max: 0.9999722/1.0	min: 2.7719723e-05	loss: 34600.1640625	train_loss: 34574.96310909049	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1223
Epoch: 1223	max: 0.99998784/1.0	min: 1.2122196e-05	loss: 34600.39453125	train_loss: 34574.9046672744	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1224
Epoch: 1224	max: 0.9999852/1.0	min: 1.4816662e-05	loss: 34600.26953125	train_loss: 34574.89767589496	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1225
Epoch: 1225	max: 0.99998474/1.0	min: 1.5256854e-05	loss: 34600.359375	train_loss: 34574.85586068144	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1226
Epoch: 1226	max: 0.9999912/1.0	min: 8.871024e-06	loss: 34600.43359375	train_loss: 34574.86547364672	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1227
Epoch: 1227	max: 0.99994755/1.0	min: 5.2485488e-05	loss: 34600.28125	train_loss: 34574.92921234362	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1228
Epoch: 1228	max: 0.9999964/1.0	min: 3.5503424e-06	loss: 34600.42578125	train_loss: 34574.982959208166	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1229
Epoch: 1229	max: 0.99995625/1.0	min: 4.3773347e-05	loss: 34600.16796875	train_loss: 34574.85880548975	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1230
Epoch: 1230	max: 0.9999926/1.0	min: 7.337402e-06	loss: 34600.48828125	train_loss: 34574.8740729128	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1231
Epoch: 1231	max: 0.9999896/1.0	min: 1.0383911e-05	loss: 34600.3046875	train_loss: 34574.76931689737	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1232
Epoch: 1232	max: 0.99999166/1.0	min: 8.385204e-06	loss: 34600.2265625	train_loss: 34574.73455403041	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1233
Epoch: 1233	max: 0.99995947/1.0	min: 4.0588617e-05	loss: 34600.140625	train_loss: 34574.74678809767	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1234
Epoch: 1234	max: 0.9999641/1.0	min: 3.582961e-05	loss: 34600.19921875	train_loss: 34574.71802613651	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1235
Epoch: 1235	max: 0.99997723/1.0	min: 2.2781065e-05	loss: 34600.19921875	train_loss: 34574.682414568626	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1236
Epoch: 1236	max: 0.9999845/1.0	min: 1.5528267e-05	loss: 34600.3515625	train_loss: 34574.6449251169	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1237
Epoch: 1237	max: 0.9999782/1.0	min: 2.1780343e-05	loss: 34600.08203125	train_loss: 34574.65406195807	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1238
Epoch: 1238	max: 0.9999857/1.0	min: 1.43446705e-05	loss: 34599.8671875	train_loss: 34574.62992478787	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1239
Epoch: 1239	max: 0.99999046/1.0	min: 9.5588375e-06	loss: 34599.94921875	train_loss: 34574.605250526445	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1240
Epoch: 1240	max: 0.9999645/1.0	min: 3.5565783e-05	loss: 34599.89453125	train_loss: 34574.58636281819	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1241
Epoch: 1241	max: 0.9999932/1.0	min: 6.7567703e-06	loss: 34600.0859375	train_loss: 34574.56709962994	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1242
Epoch: 1242	max: 0.9999763/1.0	min: 2.3685285e-05	loss: 34599.984375	train_loss: 34574.548327081786	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1243
Epoch: 1243	max: 0.99997234/1.0	min: 2.759989e-05	loss: 34599.80859375	train_loss: 34574.53450012774	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1244
Epoch: 1244	max: 0.9999795/1.0	min: 2.0512443e-05	loss: 34600.11328125	train_loss: 34574.54226230568	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1245
Epoch: 1245	max: 0.9999931/1.0	min: 6.9717576e-06	loss: 34599.6953125	train_loss: 34574.50402624876	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1246
Epoch: 1246	max: 0.99998295/1.0	min: 1.7019845e-05	loss: 34599.76171875	train_loss: 34574.48756609609	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1247
Epoch: 1247	max: 0.99998486/1.0	min: 1.5179457e-05	loss: 34599.9296875	train_loss: 34574.45290242165	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1248
Epoch: 1248	max: 0.99997854/1.0	min: 2.149665e-05	loss: 34599.78515625	train_loss: 34574.47924069816	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1249
Epoch: 1249	max: 0.9999716/1.0	min: 2.8429748e-05	loss: 34599.91015625	train_loss: 34574.41604538276	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1250
Epoch: 1250	max: 0.9999933/1.0	min: 6.7127235e-06	loss: 34599.98828125	train_loss: 34574.413046865324	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1251
Epoch: 1251	max: 0.9999665/1.0	min: 3.3511737e-05	loss: 34599.734375	train_loss: 34574.389940329645	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1252
Epoch: 1252	max: 0.99997795/1.0	min: 2.2094422e-05	loss: 34599.75390625	train_loss: 34574.38579553372	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1253
Epoch: 1253	max: 0.99997544/1.0	min: 2.4520785e-05	loss: 34599.62890625	train_loss: 34574.365123327756	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1254
Epoch: 1254	max: 0.9999896/1.0	min: 1.0392688e-05	loss: 34599.76171875	train_loss: 34574.31472142868	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1255
Epoch: 1255	max: 0.9999505/1.0	min: 4.9479895e-05	loss: 34599.734375	train_loss: 34574.318312681935	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1256
Epoch: 1256	max: 0.9999758/1.0	min: 2.4223657e-05	loss: 34599.68359375	train_loss: 34574.28887040521	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1257
Epoch: 1257	max: 0.9999831/1.0	min: 1.6939206e-05	loss: 34599.57421875	train_loss: 34574.277903099064	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1258
Epoch: 1258	max: 0.999977/1.0	min: 2.3064833e-05	loss: 34599.9609375	train_loss: 34574.234378870926	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1259
Epoch: 1259	max: 0.9999739/1.0	min: 2.6098962e-05	loss: 34599.46875	train_loss: 34574.26054343955	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1260
Epoch: 1260	max: 0.99998987/1.0	min: 1.0141552e-05	loss: 34599.44140625	train_loss: 34574.249857259536	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1261
Epoch: 1261	max: 0.99997604/1.0	min: 2.3970097e-05	loss: 34599.5	train_loss: 34574.21705114657	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1262
Epoch: 1262	max: 0.9999883/1.0	min: 1.1723486e-05	loss: 34599.453125	train_loss: 34574.16936180014	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1263
Epoch: 1263	max: 0.99997926/1.0	min: 2.0712116e-05	loss: 34599.41796875	train_loss: 34574.14269788183	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1264
Epoch: 1264	max: 0.9999814/1.0	min: 1.8648456e-05	loss: 34600.234375	train_loss: 34574.15010828921	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1265
Epoch: 1265	max: 0.99997747/1.0	min: 2.2587798e-05	loss: 34599.62109375	train_loss: 34574.22472768023	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1266
Epoch: 1266	max: 0.9999821/1.0	min: 1.7897803e-05	loss: 34599.35546875	train_loss: 34574.148060568405	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1267
Epoch: 1267	max: 0.9999851/1.0	min: 1.4905154e-05	loss: 34599.6171875	train_loss: 34574.15007441858	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1268
Epoch: 1268	max: 0.99995315/1.0	min: 4.6843084e-05	loss: 34599.51171875	train_loss: 34574.06548980785	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1269
Epoch: 1269	max: 0.9999794/1.0	min: 2.0668136e-05	loss: 34599.80859375	train_loss: 34574.044914375074	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1270
Epoch: 1270	max: 0.9999689/1.0	min: 3.1148935e-05	loss: 34599.46484375	train_loss: 34574.05884923123	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1271
Epoch: 1271	max: 0.9999745/1.0	min: 2.5480396e-05	loss: 34599.3984375	train_loss: 34573.990840900995	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1272
Epoch: 1272	max: 0.9999876/1.0	min: 1.2417156e-05	loss: 34599.515625	train_loss: 34573.98464790041	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1273
Epoch: 1273	max: 0.9999665/1.0	min: 3.3471082e-05	loss: 34599.3203125	train_loss: 34573.99285958984	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1274
Epoch: 1274	max: 0.9999738/1.0	min: 2.6274523e-05	loss: 34599.37890625	train_loss: 34573.97215786805	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1275
Epoch: 1275	max: 0.9999875/1.0	min: 1.2459074e-05	loss: 34599.44140625	train_loss: 34573.925718347426	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1276
Epoch: 1276	max: 0.9999771/1.0	min: 2.2837143e-05	loss: 34599.55078125	train_loss: 34573.91604296343	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1277
Epoch: 1277	max: 0.99998903/1.0	min: 1.0978892e-05	loss: 34599.33984375	train_loss: 34573.899808776165	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1278
Epoch: 1278	max: 0.9999825/1.0	min: 1.7580382e-05	loss: 34599.171875	train_loss: 34573.903908088694	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1279
Epoch: 1279	max: 0.99998033/1.0	min: 1.9617133e-05	loss: 34599.26171875	train_loss: 34573.84275710702	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1280
Epoch: 1280	max: 0.9999851/1.0	min: 1.4918152e-05	loss: 34599.05078125	train_loss: 34573.85112460129	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1281
Epoch: 1281	max: 0.99998236/1.0	min: 1.760066e-05	loss: 34599.24609375	train_loss: 34573.823623110984	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1282
Epoch: 1282	max: 0.9999486/1.0	min: 5.1385534e-05	loss: 34599.14453125	train_loss: 34573.831321902486	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1283
Epoch: 1283	max: 0.99998236/1.0	min: 1.7672077e-05	loss: 34599.1640625	train_loss: 34573.78403900347	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1284
Epoch: 1284	max: 0.99998665/1.0	min: 1.33459125e-05	loss: 34599.42578125	train_loss: 34573.781414998295	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1285
Epoch: 1285	max: 0.9999815/1.0	min: 1.8462477e-05	loss: 34598.9609375	train_loss: 34573.778100516385	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1286
Epoch: 1286	max: 0.99995375/1.0	min: 4.6278656e-05	loss: 34599.203125	train_loss: 34573.78517560464	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1287
Epoch: 1287	max: 0.9999852/1.0	min: 1.4741736e-05	loss: 34599.12890625	train_loss: 34573.75838926824	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1288
Epoch: 1288	max: 0.9999845/1.0	min: 1.5480373e-05	loss: 34598.88671875	train_loss: 34573.69071867645	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1289
Epoch: 1289	max: 0.9999918/1.0	min: 8.242381e-06	loss: 34598.9453125	train_loss: 34573.66543861483	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1290
Epoch: 1290	max: 0.9999701/1.0	min: 2.9971845e-05	loss: 34598.91015625	train_loss: 34573.65939077403	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1291
Epoch: 1291	max: 0.99997985/1.0	min: 2.0205123e-05	loss: 34599.13671875	train_loss: 34573.62391855955	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1292
Epoch: 1292	max: 0.9999759/1.0	min: 2.4121191e-05	loss: 34598.8828125	train_loss: 34573.613236250465	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1293
Epoch: 1293	max: 0.9999777/1.0	min: 2.2282022e-05	loss: 34598.83984375	train_loss: 34573.60710905565	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1294
Epoch: 1294	max: 0.999979/1.0	min: 2.0980575e-05	loss: 34598.94140625	train_loss: 34573.59402628747	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1295
Epoch: 1295	max: 0.9999807/1.0	min: 1.9329756e-05	loss: 34598.97265625	train_loss: 34573.55022044934	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1296
Epoch: 1296	max: 0.9999925/1.0	min: 7.5044213e-06	loss: 34598.671875	train_loss: 34573.592840815836	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1297
Epoch: 1297	max: 0.99996626/1.0	min: 3.3701657e-05	loss: 34598.9453125	train_loss: 34573.54771982999	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1298
Epoch: 1298	max: 0.99997056/1.0	min: 2.9463521e-05	loss: 34598.7734375	train_loss: 34573.488873985814	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1299
Epoch: 1299	max: 0.99997914/1.0	min: 2.081814e-05	loss: 34598.7734375	train_loss: 34573.479698435374	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1300
Epoch: 1300	max: 0.99999106/1.0	min: 8.990225e-06	loss: 34598.75390625	train_loss: 34573.45593142264	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1301
Epoch: 1301	max: 0.9999809/1.0	min: 1.9044275e-05	loss: 34598.6640625	train_loss: 34573.437140487586	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1302
Epoch: 1302	max: 0.99996734/1.0	min: 3.263681e-05	loss: 34598.6796875	train_loss: 34573.51095714496	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1303
Epoch: 1303	max: 0.9999902/1.0	min: 9.809474e-06	loss: 34599.21484375	train_loss: 34573.464092306145	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1304
Epoch: 1304	max: 0.9999733/1.0	min: 2.6685144e-05	loss: 34598.85546875	train_loss: 34573.45837155874	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1305
Epoch: 1305	max: 0.99996173/1.0	min: 3.829961e-05	loss: 34598.65625	train_loss: 34573.41825132773	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1306
Epoch: 1306	max: 0.9999713/1.0	min: 2.875416e-05	loss: 34598.75	train_loss: 34573.41036092531	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1307
Epoch: 1307	max: 0.999979/1.0	min: 2.0963113e-05	loss: 34598.67578125	train_loss: 34573.35207636566	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1308
Epoch: 1308	max: 0.9999893/1.0	min: 1.0739859e-05	loss: 34598.390625	train_loss: 34573.36120111018	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1309
Epoch: 1309	max: 0.9999901/1.0	min: 9.8783985e-06	loss: 34598.5859375	train_loss: 34573.297183222625	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1310
Epoch: 1310	max: 0.9999738/1.0	min: 2.6185271e-05	loss: 34598.5234375	train_loss: 34573.275338609405	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1311
Epoch: 1311	max: 0.99996996/1.0	min: 3.005012e-05	loss: 34598.59765625	train_loss: 34573.2882960563	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1312
Epoch: 1312	max: 0.9999763/1.0	min: 2.3686911e-05	loss: 34598.7109375	train_loss: 34573.239493334266	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1313
Epoch: 1313	max: 0.99997544/1.0	min: 2.454465e-05	loss: 34598.47265625	train_loss: 34573.26506855413	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1314
Epoch: 1314	max: 0.99998844/1.0	min: 1.1517652e-05	loss: 34598.43359375	train_loss: 34573.20146437198	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1315
Epoch: 1315	max: 0.9999802/1.0	min: 1.9738021e-05	loss: 34598.55859375	train_loss: 34573.186206626255	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1316
Epoch: 1316	max: 0.99997985/1.0	min: 2.014669e-05	loss: 34598.36328125	train_loss: 34573.18445309597	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1317
Epoch: 1317	max: 0.9999857/1.0	min: 1.4361522e-05	loss: 34598.62109375	train_loss: 34573.14670525982	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1318
Epoch: 1318	max: 0.9999778/1.0	min: 2.2204216e-05	loss: 34598.48046875	train_loss: 34573.12274131364	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1319
Epoch: 1319	max: 0.9999758/1.0	min: 2.4206382e-05	loss: 34598.6484375	train_loss: 34573.10854081506	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1320
Epoch: 1320	max: 0.99998355/1.0	min: 1.6465814e-05	loss: 34598.30859375	train_loss: 34573.099370587144	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1321
Epoch: 1321	max: 0.9999645/1.0	min: 3.5538862e-05	loss: 34598.5546875	train_loss: 34573.06572641831	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1322
Epoch: 1322	max: 0.99997985/1.0	min: 2.0193933e-05	loss: 34598.38671875	train_loss: 34573.04928174935	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1323
Epoch: 1323	max: 0.99995315/1.0	min: 4.68187e-05	loss: 34598.734375	train_loss: 34573.06371837452	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1324
Epoch: 1324	max: 0.9999827/1.0	min: 1.7309692e-05	loss: 34598.26171875	train_loss: 34573.05414460238	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1325
Epoch: 1325	max: 0.9999839/1.0	min: 1.6110302e-05	loss: 34598.38671875	train_loss: 34572.998620981976	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1326
Epoch: 1326	max: 0.9999782/1.0	min: 2.1825943e-05	loss: 34598.171875	train_loss: 34572.96566680602	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1327
Epoch: 1327	max: 0.99997604/1.0	min: 2.3976407e-05	loss: 34598.6640625	train_loss: 34572.96653970023	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1328
Epoch: 1328	max: 0.999977/1.0	min: 2.301399e-05	loss: 34598.1796875	train_loss: 34572.94549927227	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1329
Epoch: 1329	max: 0.99998844/1.0	min: 1.1541356e-05	loss: 34598.11328125	train_loss: 34572.92040985383	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1330
Epoch: 1330	max: 0.9999881/1.0	min: 1.1890738e-05	loss: 34598.1484375	train_loss: 34572.88842340982	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1331
Epoch: 1331	max: 0.99996483/1.0	min: 3.51671e-05	loss: 34598.171875	train_loss: 34572.884459095905	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1332
Epoch: 1332	max: 0.99999/1.0	min: 1.0073077e-05	loss: 34598.0234375	train_loss: 34572.90581355289	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1333
Epoch: 1333	max: 0.9999844/1.0	min: 1.5661597e-05	loss: 34598.359375	train_loss: 34572.890085973304	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1334
Epoch: 1334	max: 0.9999858/1.0	min: 1.4198728e-05	loss: 34598.296875	train_loss: 34572.82801177536	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1335
Epoch: 1335	max: 0.9999881/1.0	min: 1.1926205e-05	loss: 34598.046875	train_loss: 34572.795638238575	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1336
Epoch: 1336	max: 0.99996936/1.0	min: 3.0660885e-05	loss: 34598.046875	train_loss: 34572.77822874086	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1337
Epoch: 1337	max: 0.99998295/1.0	min: 1.7096729e-05	loss: 34598.06640625	train_loss: 34572.826655982906	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1338
Epoch: 1338	max: 0.99998045/1.0	min: 1.9507532e-05	loss: 34598.03515625	train_loss: 34572.748897753314	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1339
Epoch: 1339	max: 0.9999554/1.0	min: 4.4641594e-05	loss: 34597.99609375	train_loss: 34572.74013929534	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1340
Epoch: 1340	max: 0.9999707/1.0	min: 2.9305445e-05	loss: 34597.984375	train_loss: 34572.82883241205	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1341
Epoch: 1341	max: 0.9999875/1.0	min: 1.2484955e-05	loss: 34598.0859375	train_loss: 34572.69336252013	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1342
Epoch: 1342	max: 0.99998176/1.0	min: 1.8200324e-05	loss: 34597.96875	train_loss: 34572.6737364324	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1343
Epoch: 1343	max: 0.9999559/1.0	min: 4.413815e-05	loss: 34597.8515625	train_loss: 34572.66113075607	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1344
Epoch: 1344	max: 0.9999888/1.0	min: 1.1246858e-05	loss: 34598.234375	train_loss: 34572.65965980351	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1345
Epoch: 1345	max: 0.9999552/1.0	min: 4.480067e-05	loss: 34598.01171875	train_loss: 34572.69558007788	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1346
Epoch: 1346	max: 0.99999106/1.0	min: 8.9433115e-06	loss: 34597.875	train_loss: 34572.64334481063	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1347
Epoch: 1347	max: 0.99997926/1.0	min: 2.0778907e-05	loss: 34597.8359375	train_loss: 34572.59506853478	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1348
Epoch: 1348	max: 0.9999751/1.0	min: 2.4921177e-05	loss: 34598.01953125	train_loss: 34572.57411858974	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1349
Epoch: 1349	max: 0.9999616/1.0	min: 3.8436086e-05	loss: 34597.875	train_loss: 34572.603041194416	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1350
Epoch: 1350	max: 0.9999808/1.0	min: 1.916964e-05	loss: 34598.0859375	train_loss: 34572.54245004568	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1351
Epoch: 1351	max: 0.99995863/1.0	min: 4.139338e-05	loss: 34597.80859375	train_loss: 34572.52028220999	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1352
Epoch: 1352	max: 0.99999464/1.0	min: 5.3550434e-06	loss: 34598.0	train_loss: 34572.47871812291	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1353
Epoch: 1353	max: 0.9999672/1.0	min: 3.2726228e-05	loss: 34597.65234375	train_loss: 34572.57081765607	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1354
Epoch: 1354	max: 0.99997187/1.0	min: 2.813283e-05	loss: 34597.87890625	train_loss: 34572.43316601248	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1355
Epoch: 1355	max: 0.99998796/1.0	min: 1.1992297e-05	loss: 34597.48828125	train_loss: 34572.42527609393	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1356
Epoch: 1356	max: 0.99998736/1.0	min: 1.2625379e-05	loss: 34597.7890625	train_loss: 34572.40730144076	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1357
Epoch: 1357	max: 0.9999801/1.0	min: 1.9923204e-05	loss: 34597.55859375	train_loss: 34572.45203775316	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1358
Epoch: 1358	max: 0.9999858/1.0	min: 1.42175895e-05	loss: 34597.703125	train_loss: 34572.408404171314	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1359
Epoch: 1359	max: 0.99997294/1.0	min: 2.7045795e-05	loss: 34597.46484375	train_loss: 34572.350786862844	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1360
Epoch: 1360	max: 0.99999034/1.0	min: 9.658995e-06	loss: 34597.5546875	train_loss: 34572.33764457915	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1361
Epoch: 1361	max: 0.9999825/1.0	min: 1.7573642e-05	loss: 34597.65625	train_loss: 34572.30448959882	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1362
Epoch: 1362	max: 0.9999888/1.0	min: 1.1160068e-05	loss: 34597.38671875	train_loss: 34572.3210532988	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1363
Epoch: 1363	max: 0.99997485/1.0	min: 2.5205172e-05	loss: 34597.6328125	train_loss: 34572.30780214527	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1364
Epoch: 1364	max: 0.9999876/1.0	min: 1.2352101e-05	loss: 34597.53125	train_loss: 34572.282006766385	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1365
Epoch: 1365	max: 0.99997544/1.0	min: 2.4608235e-05	loss: 34597.74609375	train_loss: 34572.23927849777	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1366
Epoch: 1366	max: 0.99997103/1.0	min: 2.8910556e-05	loss: 34597.44921875	train_loss: 34572.256316870276	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1367
Epoch: 1367	max: 0.999992/1.0	min: 8.028277e-06	loss: 34597.625	train_loss: 34572.22163916373	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1368
Epoch: 1368	max: 0.9999883/1.0	min: 1.1675219e-05	loss: 34597.45703125	train_loss: 34572.252316266415	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1369
Epoch: 1369	max: 0.99998033/1.0	min: 1.962666e-05	loss: 34597.37109375	train_loss: 34572.20802123978	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1370
Epoch: 1370	max: 0.9999864/1.0	min: 1.3599508e-05	loss: 34597.796875	train_loss: 34572.1410914468	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1371
Epoch: 1371	max: 0.9999709/1.0	min: 2.9091847e-05	loss: 34597.62890625	train_loss: 34572.18435100025	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1372
Epoch: 1372	max: 0.99997413/1.0	min: 2.5918596e-05	loss: 34597.375	train_loss: 34572.13915307971	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1373
Epoch: 1373	max: 0.9999809/1.0	min: 1.9014298e-05	loss: 34597.3359375	train_loss: 34572.08207141088	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1374
Epoch: 1374	max: 0.9999635/1.0	min: 3.6509722e-05	loss: 34597.23828125	train_loss: 34572.06205242398	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1375
Epoch: 1375	max: 0.9999925/1.0	min: 7.5561416e-06	loss: 34597.37890625	train_loss: 34572.10654922272	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1376
Epoch: 1376	max: 0.9999888/1.0	min: 1.1155685e-05	loss: 34597.09765625	train_loss: 34572.080955615944	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1377
Epoch: 1377	max: 0.99997234/1.0	min: 2.7634365e-05	loss: 34597.140625	train_loss: 34572.031750317416	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1378
Epoch: 1378	max: 0.99999154/1.0	min: 8.453394e-06	loss: 34597.47265625	train_loss: 34572.00188078704	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1379
Epoch: 1379	max: 0.99996567/1.0	min: 3.43788e-05	loss: 34597.1953125	train_loss: 34572.00647848151	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1380
Epoch: 1380	max: 0.9999864/1.0	min: 1.360942e-05	loss: 34597.24609375	train_loss: 34572.030970809334	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1381
Epoch: 1381	max: 0.9999901/1.0	min: 9.8473965e-06	loss: 34597.01953125	train_loss: 34571.976715401644	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1382
Epoch: 1382	max: 0.9999938/1.0	min: 6.1541964e-06	loss: 34597.1328125	train_loss: 34571.939095306116	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1383
Epoch: 1383	max: 0.99997926/1.0	min: 2.0726186e-05	loss: 34597.05859375	train_loss: 34571.91138672117	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1384
Epoch: 1384	max: 0.99998915/1.0	min: 1.0857723e-05	loss: 34597.34765625	train_loss: 34571.924540133776	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1385
Epoch: 1385	max: 0.99997926/1.0	min: 2.07754e-05	loss: 34596.96875	train_loss: 34571.914242982006	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1386
Epoch: 1386	max: 0.99999094/1.0	min: 9.076717e-06	loss: 34597.16015625	train_loss: 34571.86079804983	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1387
Epoch: 1387	max: 0.99998486/1.0	min: 1.5095841e-05	loss: 34596.92578125	train_loss: 34571.84041713118	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1388
Epoch: 1388	max: 0.999974/1.0	min: 2.5956091e-05	loss: 34597.12109375	train_loss: 34571.86526268116	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1389
Epoch: 1389	max: 0.9999548/1.0	min: 4.518011e-05	loss: 34596.98046875	train_loss: 34571.84315678032	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1390
Epoch: 1390	max: 0.9999887/1.0	min: 1.1341231e-05	loss: 34597.21484375	train_loss: 34571.86653573254	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1391
Epoch: 1391	max: 0.99996066/1.0	min: 3.930988e-05	loss: 34596.96875	train_loss: 34571.797384027006	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1392
Epoch: 1392	max: 0.9999832/1.0	min: 1.6808799e-05	loss: 34597.015625	train_loss: 34571.75188949663	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1393
Epoch: 1393	max: 0.99999154/1.0	min: 8.5190695e-06	loss: 34596.93359375	train_loss: 34571.74508005079	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1394
Epoch: 1394	max: 0.99995744/1.0	min: 4.258488e-05	loss: 34596.88671875	train_loss: 34571.72552509135	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1395
Epoch: 1395	max: 0.9999924/1.0	min: 7.6138795e-06	loss: 34596.8515625	train_loss: 34571.72235431763	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1396
Epoch: 1396	max: 0.9999882/1.0	min: 1.1820572e-05	loss: 34596.9453125	train_loss: 34571.690729321504	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1397
Epoch: 1397	max: 0.9999895/1.0	min: 1.04358505e-05	loss: 34596.90625	train_loss: 34571.66387137294	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1398
Epoch: 1398	max: 0.9999734/1.0	min: 2.6595768e-05	loss: 34596.765625	train_loss: 34571.646991708476	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1399
Epoch: 1399	max: 0.9999795/1.0	min: 2.0450698e-05	loss: 34596.8203125	train_loss: 34571.723968494516	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1400
Epoch: 1400	max: 0.99997973/1.0	min: 2.0314286e-05	loss: 34596.7109375	train_loss: 34571.631600415734	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1401
Epoch: 1401	max: 0.99999046/1.0	min: 9.478121e-06	loss: 34596.83984375	train_loss: 34571.618706355286	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1402
Epoch: 1402	max: 0.9999863/1.0	min: 1.3734024e-05	loss: 34596.92578125	train_loss: 34571.60406118388	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1403
Epoch: 1403	max: 0.9999703/1.0	min: 2.9738043e-05	loss: 34596.87109375	train_loss: 34571.58558089078	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1404
Epoch: 1404	max: 0.9999783/1.0	min: 2.1721871e-05	loss: 34596.67578125	train_loss: 34571.555286526076	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1405
Epoch: 1405	max: 0.999972/1.0	min: 2.8055481e-05	loss: 34596.56640625	train_loss: 34571.54618403939	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1406
Epoch: 1406	max: 0.9999826/1.0	min: 1.740019e-05	loss: 34596.83984375	train_loss: 34571.512165842156	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1407
Epoch: 1407	max: 0.99999475/1.0	min: 5.302679e-06	loss: 34596.5703125	train_loss: 34571.50087773288	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1408
Epoch: 1408	max: 0.999946/1.0	min: 5.403458e-05	loss: 34596.703125	train_loss: 34571.50280206785	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1409
Epoch: 1409	max: 0.9999907/1.0	min: 9.3187455e-06	loss: 34596.453125	train_loss: 34571.47180754908	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1410
Epoch: 1410	max: 0.9999782/1.0	min: 2.1795284e-05	loss: 34596.67578125	train_loss: 34571.433270043664	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1411
Epoch: 1411	max: 0.999961/1.0	min: 3.897959e-05	loss: 34596.51953125	train_loss: 34571.43345971913	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1412
Epoch: 1412	max: 0.99998605/1.0	min: 1.39097165e-05	loss: 34596.37109375	train_loss: 34571.43767757881	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1413
Epoch: 1413	max: 0.99998295/1.0	min: 1.70038e-05	loss: 34596.484375	train_loss: 34571.40295535659	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1414
Epoch: 1414	max: 0.99998903/1.0	min: 1.0948559e-05	loss: 34596.39453125	train_loss: 34571.3747682282	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1415
Epoch: 1415	max: 0.9999765/1.0	min: 2.350254e-05	loss: 34596.671875	train_loss: 34571.37186358076	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1416
Epoch: 1416	max: 0.99997246/1.0	min: 2.7554604e-05	loss: 34596.49609375	train_loss: 34571.34447386349	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1417
Epoch: 1417	max: 0.9999815/1.0	min: 1.8455929e-05	loss: 34596.421875	train_loss: 34571.36685992274	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1418
Epoch: 1418	max: 0.99998224/1.0	min: 1.7731243e-05	loss: 34596.4296875	train_loss: 34571.35835452667	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1419
Epoch: 1419	max: 0.9999788/1.0	min: 2.1229866e-05	loss: 34596.74609375	train_loss: 34571.339194401866	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1420
Epoch: 1420	max: 0.9999887/1.0	min: 1.1351997e-05	loss: 34596.484375	train_loss: 34571.299062558064	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1421
Epoch: 1421	max: 0.99999106/1.0	min: 8.954491e-06	loss: 34596.44921875	train_loss: 34571.26637257293	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1422
Epoch: 1422	max: 0.99995756/1.0	min: 4.2474323e-05	loss: 34596.453125	train_loss: 34571.31574770841	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1423
Epoch: 1423	max: 0.99999046/1.0	min: 9.492068e-06	loss: 34596.328125	train_loss: 34571.29487469807	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1424
Epoch: 1424	max: 0.9999665/1.0	min: 3.3555072e-05	loss: 34596.37109375	train_loss: 34571.20725818314	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1425
Epoch: 1425	max: 0.99998534/1.0	min: 1.4660757e-05	loss: 34596.2734375	train_loss: 34571.2010317958	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1426
Epoch: 1426	max: 0.9999814/1.0	min: 1.8630948e-05	loss: 34596.25	train_loss: 34571.175600767994	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1427
Epoch: 1427	max: 0.9999691/1.0	min: 3.090144e-05	loss: 34596.35546875	train_loss: 34571.183601007986	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1428
Epoch: 1428	max: 0.9999902/1.0	min: 9.761711e-06	loss: 34596.23046875	train_loss: 34571.15840562291	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1429
Epoch: 1429	max: 0.99997985/1.0	min: 2.0194202e-05	loss: 34596.28125	train_loss: 34571.116621860674	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1430
Epoch: 1430	max: 0.9999856/1.0	min: 1.436878e-05	loss: 34596.33203125	train_loss: 34571.11874941936	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1431
Epoch: 1431	max: 0.9999913/1.0	min: 8.749141e-06	loss: 34596.13671875	train_loss: 34571.08946246361	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1432
Epoch: 1432	max: 0.9999815/1.0	min: 1.843612e-05	loss: 34596.234375	train_loss: 34571.07549905936	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1433
Epoch: 1433	max: 0.9999814/1.0	min: 1.8575274e-05	loss: 34596.29296875	train_loss: 34571.07506503159	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1434
Epoch: 1434	max: 0.999982/1.0	min: 1.798544e-05	loss: 34596.08984375	train_loss: 34571.03719187415	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1435
Epoch: 1435	max: 0.99994195/1.0	min: 5.8108726e-05	loss: 34596.265625	train_loss: 34571.027041333764	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1436
Epoch: 1436	max: 0.9999857/1.0	min: 1.4303484e-05	loss: 34595.96484375	train_loss: 34571.01704659823	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1437
Epoch: 1437	max: 0.99998474/1.0	min: 1.5278389e-05	loss: 34595.984375	train_loss: 34570.98863689149	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1438
Epoch: 1438	max: 0.99996305/1.0	min: 3.691302e-05	loss: 34596.2109375	train_loss: 34571.01588822309	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1439
Epoch: 1439	max: 0.99998987/1.0	min: 1.0158201e-05	loss: 34596.05859375	train_loss: 34570.948125212904	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1440
Epoch: 1440	max: 0.9999825/1.0	min: 1.7559185e-05	loss: 34595.9609375	train_loss: 34570.94434428419	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1441
Epoch: 1441	max: 0.99998844/1.0	min: 1.158959e-05	loss: 34596.078125	train_loss: 34570.91974695745	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1442
Epoch: 1442	max: 0.9999913/1.0	min: 8.65925e-06	loss: 34595.94921875	train_loss: 34570.90765417906	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1443
Epoch: 1443	max: 0.99995697/1.0	min: 4.307439e-05	loss: 34596.0234375	train_loss: 34570.90312906447	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1444
Epoch: 1444	max: 0.99998915/1.0	min: 1.0803795e-05	loss: 34595.9140625	train_loss: 34570.94412315744	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1445
Epoch: 1445	max: 0.9999747/1.0	min: 2.5312895e-05	loss: 34595.98828125	train_loss: 34570.85584326227	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1446
Epoch: 1446	max: 0.99998236/1.0	min: 1.7608905e-05	loss: 34595.8984375	train_loss: 34570.84886252787	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1447
Epoch: 1447	max: 0.99998367/1.0	min: 1.6280534e-05	loss: 34595.8515625	train_loss: 34570.857514051466	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1448
Epoch: 1448	max: 0.9999516/1.0	min: 4.838706e-05	loss: 34596.265625	train_loss: 34570.81691043834	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1449
Epoch: 1449	max: 0.9999937/1.0	min: 6.3477887e-06	loss: 34595.90234375	train_loss: 34570.807187151615	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1450
Epoch: 1450	max: 0.9999932/1.0	min: 6.7570086e-06	loss: 34595.734375	train_loss: 34570.771698485696	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1451
Epoch: 1451	max: 0.9999813/1.0	min: 1.8706274e-05	loss: 34596.11328125	train_loss: 34570.76058166497	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1452
Epoch: 1452	max: 0.99995875/1.0	min: 4.1200805e-05	loss: 34595.91015625	train_loss: 34570.762033746745	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1453
Epoch: 1453	max: 0.99999404/1.0	min: 6.0099906e-06	loss: 34595.66015625	train_loss: 34570.731137936644	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1454
Epoch: 1454	max: 0.9999882/1.0	min: 1.1785048e-05	loss: 34595.92578125	train_loss: 34570.72146255265	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1455
Epoch: 1455	max: 0.9999893/1.0	min: 1.0770672e-05	loss: 34595.8046875	train_loss: 34570.67907831274	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1456
Epoch: 1456	max: 0.9999814/1.0	min: 1.8588478e-05	loss: 34595.73046875	train_loss: 34570.7424434651	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1457
Epoch: 1457	max: 0.99997616/1.0	min: 2.389207e-05	loss: 34595.65625	train_loss: 34570.64754379955	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1458
Epoch: 1458	max: 0.9999777/1.0	min: 2.2251315e-05	loss: 34595.7734375	train_loss: 34570.65819417348	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1459
Epoch: 1459	max: 0.99998546/1.0	min: 1.4538958e-05	loss: 34595.578125	train_loss: 34570.610490794934	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1460
Epoch: 1460	max: 0.9999763/1.0	min: 2.3717474e-05	loss: 34595.6640625	train_loss: 34570.59978671188	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1461
Epoch: 1461	max: 0.99999154/1.0	min: 8.509521e-06	loss: 34595.6640625	train_loss: 34570.5687341292	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1462
Epoch: 1462	max: 0.99997497/1.0	min: 2.5071333e-05	loss: 34595.58984375	train_loss: 34570.59822092159	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1463
Epoch: 1463	max: 0.9999888/1.0	min: 1.1256278e-05	loss: 34595.765625	train_loss: 34570.60045589852	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1464
Epoch: 1464	max: 0.99997675/1.0	min: 2.324677e-05	loss: 34595.484375	train_loss: 34570.520719140965	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1465
Epoch: 1465	max: 0.99998987/1.0	min: 1.0104133e-05	loss: 34595.5078125	train_loss: 34570.50707460439	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1466
Epoch: 1466	max: 0.99997663/1.0	min: 2.3310973e-05	loss: 34595.66015625	train_loss: 34570.51720095147	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1467
Epoch: 1467	max: 0.9999937/1.0	min: 6.319575e-06	loss: 34595.546875	train_loss: 34570.538029930016	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1468
Epoch: 1468	max: 0.99996424/1.0	min: 3.5734407e-05	loss: 34595.546875	train_loss: 34570.539924749166	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1469
Epoch: 1469	max: 0.99997866/1.0	min: 2.1280133e-05	loss: 34595.81640625	train_loss: 34570.50078724994	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1470
Epoch: 1470	max: 0.9999887/1.0	min: 1.1363555e-05	loss: 34595.46875	train_loss: 34570.43828386287	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1471
Epoch: 1471	max: 0.99998736/1.0	min: 1.25988445e-05	loss: 34595.265625	train_loss: 34570.41108140174	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1472
Epoch: 1472	max: 0.99997354/1.0	min: 2.6418465e-05	loss: 34595.4453125	train_loss: 34570.40247632928	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1473
Epoch: 1473	max: 0.9999838/1.0	min: 1.6249327e-05	loss: 34595.1796875	train_loss: 34570.377014334044	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1474
Epoch: 1474	max: 0.9999894/1.0	min: 1.0588934e-05	loss: 34595.37109375	train_loss: 34570.41325541156	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1475
Epoch: 1475	max: 0.9999825/1.0	min: 1.7464026e-05	loss: 34595.20703125	train_loss: 34570.33910875759	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1476
Epoch: 1476	max: 0.99999106/1.0	min: 8.93281e-06	loss: 34595.40625	train_loss: 34570.38593682259	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1477
Epoch: 1477	max: 0.9999825/1.0	min: 1.7569488e-05	loss: 34595.16015625	train_loss: 34570.32351666047	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1478
Epoch: 1478	max: 0.99997866/1.0	min: 2.136876e-05	loss: 34595.08984375	train_loss: 34570.297709668805	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1479
Epoch: 1479	max: 0.9999727/1.0	min: 2.7354e-05	loss: 34595.36328125	train_loss: 34570.309706157874	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1480
Epoch: 1480	max: 0.99999344/1.0	min: 6.572037e-06	loss: 34595.20703125	train_loss: 34570.26859884027	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1481
Epoch: 1481	max: 0.99994874/1.0	min: 5.1275692e-05	loss: 34595.359375	train_loss: 34570.2653932282	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1482
Epoch: 1482	max: 0.99998283/1.0	min: 1.7150389e-05	loss: 34595.17578125	train_loss: 34570.2636967941	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1483
Epoch: 1483	max: 0.9999901/1.0	min: 9.905775e-06	loss: 34595.11328125	train_loss: 34570.22706378515	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1484
Epoch: 1484	max: 0.99998593/1.0	min: 1.4054418e-05	loss: 34595.19140625	train_loss: 34570.20296774356	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1485
Epoch: 1485	max: 0.99996233/1.0	min: 3.7725742e-05	loss: 34595.35546875	train_loss: 34570.18612533677	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1486
Epoch: 1486	max: 0.9999845/1.0	min: 1.5529526e-05	loss: 34595.0390625	train_loss: 34570.161305431684	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1487
Epoch: 1487	max: 0.9999492/1.0	min: 5.0831484e-05	loss: 34595.3359375	train_loss: 34570.167079888204	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1488
Epoch: 1488	max: 0.9999957/1.0	min: 4.3064574e-06	loss: 34595.55078125	train_loss: 34570.16967050663	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1489
Epoch: 1489	max: 0.99994504/1.0	min: 5.5005337e-05	loss: 34595.2265625	train_loss: 34570.18292262789	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1490
Epoch: 1490	max: 0.9999912/1.0	min: 8.87937e-06	loss: 34595.6015625	train_loss: 34570.13694568314	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1491
Epoch: 1491	max: 0.99997616/1.0	min: 2.3834196e-05	loss: 34595.015625	train_loss: 34570.16009770222	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1492
Epoch: 1492	max: 0.99996006/1.0	min: 3.9886767e-05	loss: 34595.25390625	train_loss: 34570.06909509321	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1493
Epoch: 1493	max: 0.99999547/1.0	min: 4.4949966e-06	loss: 34595.171875	train_loss: 34570.069334606866	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1494
Epoch: 1494	max: 0.99998975/1.0	min: 1.0293028e-05	loss: 34594.94921875	train_loss: 34570.08271495262	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1495
Epoch: 1495	max: 0.99998045/1.0	min: 1.9506044e-05	loss: 34594.953125	train_loss: 34570.05914680881	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1496
Epoch: 1496	max: 0.9999895/1.0	min: 1.0481812e-05	loss: 34595.09375	train_loss: 34569.99659261582	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1497
Epoch: 1497	max: 0.9999751/1.0	min: 2.486662e-05	loss: 34595.03515625	train_loss: 34569.9828421126	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1498
Epoch: 1498	max: 0.9999924/1.0	min: 7.679395e-06	loss: 34595.1015625	train_loss: 34569.96631518642	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1499
Epoch: 1499	max: 0.9999714/1.0	min: 2.8600543e-05	loss: 34594.98046875	train_loss: 34569.99548698207	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1500
Epoch: 1500	max: 0.99994993/1.0	min: 5.007047e-05	loss: 34594.98828125	train_loss: 34569.94226898303	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1501
Epoch: 1501	max: 0.99999213/1.0	min: 7.869335e-06	loss: 34594.75390625	train_loss: 34569.93411293819	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1502
Epoch: 1502	max: 0.99996805/1.0	min: 3.198608e-05	loss: 34595.0390625	train_loss: 34569.898111374336	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1503
Epoch: 1503	max: 0.99996066/1.0	min: 3.9334256e-05	loss: 34595.09375	train_loss: 34569.913353152486	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1504
Epoch: 1504	max: 0.99997437/1.0	min: 2.56678e-05	loss: 34594.94921875	train_loss: 34569.898773302986	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1505
Epoch: 1505	max: 0.9999881/1.0	min: 1.193228e-05	loss: 34595.0859375	train_loss: 34569.861807878115	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1506
Epoch: 1506	max: 0.99996686/1.0	min: 3.3102537e-05	loss: 34594.828125	train_loss: 34569.85519488186	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1507
Epoch: 1507	max: 0.9999945/1.0	min: 5.4258708e-06	loss: 34594.81640625	train_loss: 34569.84266855955	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1508
Epoch: 1508	max: 0.99998/1.0	min: 2.0039306e-05	loss: 34594.88671875	train_loss: 34569.82373004537	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1509
Epoch: 1509	max: 0.9999764/1.0	min: 2.360591e-05	loss: 34594.69921875	train_loss: 34569.79322858603	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1510
Epoch: 1510	max: 0.9999844/1.0	min: 1.5667616e-05	loss: 34594.890625	train_loss: 34569.777609876284	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1511
Epoch: 1511	max: 0.99995685/1.0	min: 4.3185897e-05	loss: 34594.80859375	train_loss: 34569.79131586383	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1512
Epoch: 1512	max: 0.9999596/1.0	min: 4.039912e-05	loss: 34594.80078125	train_loss: 34569.77461232658	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1513
Epoch: 1513	max: 0.9999887/1.0	min: 1.1365516e-05	loss: 34594.875	train_loss: 34569.76902125526	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1514
Epoch: 1514	max: 0.9999759/1.0	min: 2.4123101e-05	loss: 34594.80078125	train_loss: 34569.74885372151	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1515
Epoch: 1515	max: 0.9999783/1.0	min: 2.1647504e-05	loss: 34594.671875	train_loss: 34569.70638915985	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1516
Epoch: 1516	max: 0.99998236/1.0	min: 1.7594166e-05	loss: 34594.53515625	train_loss: 34569.67702188235	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1517
Epoch: 1517	max: 0.99998796/1.0	min: 1.2048766e-05	loss: 34594.63671875	train_loss: 34569.65795175663	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1518
Epoch: 1518	max: 0.999984/1.0	min: 1.6009708e-05	loss: 34594.578125	train_loss: 34569.64983490493	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1519
Epoch: 1519	max: 0.99995923/1.0	min: 4.0802686e-05	loss: 34594.85546875	train_loss: 34569.65807030379	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1520
Epoch: 1520	max: 0.99998844/1.0	min: 1.1536856e-05	loss: 34594.64453125	train_loss: 34569.61960344281	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1521
Epoch: 1521	max: 0.999992/1.0	min: 7.990895e-06	loss: 34594.5390625	train_loss: 34569.6032361924	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1522
Epoch: 1522	max: 0.9999641/1.0	min: 3.584232e-05	loss: 34594.5859375	train_loss: 34569.59299274975	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1523
Epoch: 1523	max: 0.99999416/1.0	min: 5.7959915e-06	loss: 34594.5546875	train_loss: 34569.56005067044	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1524
Epoch: 1524	max: 0.99997497/1.0	min: 2.5002208e-05	loss: 34594.5078125	train_loss: 34569.54937078069	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1525
Epoch: 1525	max: 0.99998665/1.0	min: 1.3336244e-05	loss: 34594.58203125	train_loss: 34569.61209432677	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1526
Epoch: 1526	max: 0.9999906/1.0	min: 9.404434e-06	loss: 34594.8046875	train_loss: 34569.55496136814	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1527
Epoch: 1527	max: 0.9999906/1.0	min: 9.428951e-06	loss: 34594.39453125	train_loss: 34569.50306238775	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1528
Epoch: 1528	max: 0.9999573/1.0	min: 4.2636773e-05	loss: 34594.49609375	train_loss: 34569.50238449151	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1529
Epoch: 1529	max: 0.9999846/1.0	min: 1.5331807e-05	loss: 34594.6484375	train_loss: 34569.47721426746	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1530
Epoch: 1530	max: 0.9999858/1.0	min: 1.4190335e-05	loss: 34594.515625	train_loss: 34569.4685424215	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1531
Epoch: 1531	max: 0.99996924/1.0	min: 3.0793977e-05	loss: 34594.40234375	train_loss: 34569.45484804673	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1532
Epoch: 1532	max: 0.9999676/1.0	min: 3.2390464e-05	loss: 34594.5	train_loss: 34569.47426703983	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1533
Epoch: 1533	max: 0.9999907/1.0	min: 9.298124e-06	loss: 34594.4140625	train_loss: 34569.42576721789	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1534
Epoch: 1534	max: 0.9999882/1.0	min: 1.1850133e-05	loss: 34594.328125	train_loss: 34569.4183171335	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1535
Epoch: 1535	max: 0.99998426/1.0	min: 1.5772934e-05	loss: 34594.36328125	train_loss: 34569.365056554256	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1536
