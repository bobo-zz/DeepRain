Epoch: 0	max: 0.56611735/1.0	min: 0.43388262	loss: 36465.08984375	train_loss: 36811.97336946845	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1
Epoch: 1	max: 0.6482861/1.0	min: 0.35171393	loss: 35962.71875	train_loss: 36249.005749295495	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_2
Epoch: 2	max: 0.71630657/1.0	min: 0.28369346	loss: 35596.3359375	train_loss: 35832.1921073718	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_3
Epoch: 3	max: 0.7701068/1.0	min: 0.22989321	loss: 35333.4609375	train_loss: 35534.44153689381	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_4
Epoch: 4	max: 0.81228834/1.0	min: 0.18771163	loss: 35144.46484375	train_loss: 35324.34630190914	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_5
Epoch: 5	max: 0.84528226/1.0	min: 0.15471773	loss: 35007.4140625	train_loss: 35175.53005968971	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_6
Epoch: 6	max: 0.871736/1.0	min: 0.12826404	loss: 34905.75	train_loss: 35069.50088111994	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_7
Epoch: 7	max: 0.89250976/1.0	min: 0.107490264	loss: 34831.63671875	train_loss: 34993.672910473186	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_8
Epoch: 8	max: 0.9086563/1.0	min: 0.09134364	loss: 34778.27734375	train_loss: 34940.84526498436	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_9
Epoch: 9	max: 0.92085713/1.0	min: 0.079142876	loss: 34740.80078125	train_loss: 34905.2409546095	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_10
Epoch: 10	max: 0.92983294/1.0	min: 0.07016706	loss: 34715.25390625	train_loss: 34882.12362243357	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_11
Epoch: 11	max: 0.9364358/1.0	min: 0.063564174	loss: 34697.67578125	train_loss: 34867.334933961974	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_12
Epoch: 12	max: 0.9415016/1.0	min: 0.058498338	loss: 34685.140625	train_loss: 34857.73574095364	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_13
Epoch: 13	max: 0.9454817/1.0	min: 0.05451828	loss: 34675.87890625	train_loss: 34851.4556831994	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_14
Epoch: 14	max: 0.94837785/1.0	min: 0.051622164	loss: 34669.46875	train_loss: 34847.133178302676	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_15
Epoch: 15	max: 0.9505871/1.0	min: 0.049412854	loss: 34664.76953125	train_loss: 34844.23813609021	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_16
Epoch: 16	max: 0.9522414/1.0	min: 0.047758594	loss: 34661.3046875	train_loss: 34842.07240522034	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_17
Epoch: 17	max: 0.9535001/1.0	min: 0.046499893	loss: 34658.671875	train_loss: 34840.38071300554	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_18
Epoch: 18	max: 0.9544559/1.0	min: 0.04554406	loss: 34656.62109375	train_loss: 34838.92736349173	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_19
Epoch: 19	max: 0.95519525/1.0	min: 0.04480468	loss: 34654.953125	train_loss: 34837.5788657988	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_20
Epoch: 20	max: 0.9557844/1.0	min: 0.04421557	loss: 34653.53515625	train_loss: 34836.26722659637	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_21
Epoch: 21	max: 0.9562167/1.0	min: 0.043783277	loss: 34652.35546875	train_loss: 34834.9473815109	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_22
Epoch: 22	max: 0.95655113/1.0	min: 0.04344888	loss: 34651.30859375	train_loss: 34833.5812904512	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_23
Epoch: 23	max: 0.95673376/1.0	min: 0.043266237	loss: 34650.46875	train_loss: 34832.14773250728	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_24
Epoch: 24	max: 0.9569628/1.0	min: 0.043037113	loss: 34649.5234375	train_loss: 34830.61582009476	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_25
Epoch: 25	max: 0.9571308/1.0	min: 0.042869203	loss: 34648.62109375	train_loss: 34828.98205728199	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_26
Epoch: 26	max: 0.95736/1.0	min: 0.042640004	loss: 34647.5859375	train_loss: 34827.21716485507	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_27
Epoch: 27	max: 0.9574161/1.0	min: 0.042583853	loss: 34646.734375	train_loss: 34825.28897056547	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_28
Epoch: 28	max: 0.9575794/1.0	min: 0.04242056	loss: 34645.66015625	train_loss: 34823.15602984098	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_29
Epoch: 29	max: 0.9576998/1.0	min: 0.042300284	loss: 34644.5703125	train_loss: 34820.80088721665	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_30
Epoch: 30	max: 0.95775276/1.0	min: 0.042247273	loss: 34643.46875	train_loss: 34818.12597111901	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_31
Epoch: 31	max: 0.9579347/1.0	min: 0.042065296	loss: 34642.0390625	train_loss: 34815.09004697371	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_32
Epoch: 32	max: 0.9582346/1.0	min: 0.041765373	loss: 34640.25390625	train_loss: 34811.60149379103	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_33
Epoch: 33	max: 0.9585261/1.0	min: 0.04147389	loss: 34638.23046875	train_loss: 34807.48688432894	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_34
Epoch: 34	max: 0.95882136/1.0	min: 0.041178618	loss: 34635.8359375	train_loss: 34802.4954424664	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_35
Epoch: 35	max: 0.959083/1.0	min: 0.040916987	loss: 34632.9765625	train_loss: 34796.366912664125	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_36
Epoch: 36	max: 0.9596911/1.0	min: 0.040308967	loss: 34628.86328125	train_loss: 34788.54721612551	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_37
Epoch: 37	max: 0.96026576/1.0	min: 0.039734278	loss: 34623.4765625	train_loss: 34778.34803753639	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_38
Epoch: 38	max: 0.96096826/1.0	min: 0.039031707	loss: 34615.58984375	train_loss: 34764.16582667534	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_39
Epoch: 39	max: 0.96252847/1.0	min: 0.037471555	loss: 34603.203125	train_loss: 34744.38134203131	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_40
Epoch: 40	max: 0.96557885/1.0	min: 0.03442122	loss: 34585.80078125	train_loss: 34719.077891292734	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_41
Epoch: 41	max: 0.9697759/1.0	min: 0.030224089	loss: 34565.55078125	train_loss: 34690.174904484855	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_42
Epoch: 42	max: 0.9738753/1.0	min: 0.026124738	loss: 34544.6796875	train_loss: 34659.34433644556	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_43
Epoch: 43	max: 0.9778072/1.0	min: 0.022192836	loss: 34525.0390625	train_loss: 34627.90442582528	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_44
Epoch: 44	max: 0.98138374/1.0	min: 0.018616242	loss: 34510.03125	train_loss: 34601.26718691936	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_45
Epoch: 45	max: 0.9839796/1.0	min: 0.016020412	loss: 34499.35546875	train_loss: 34583.09668755032	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_46
Epoch: 46	max: 0.98605967/1.0	min: 0.013940365	loss: 34491.81640625	train_loss: 34570.854025377805	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_47
Epoch: 47	max: 0.98741144/1.0	min: 0.012588527	loss: 34484.8359375	train_loss: 34561.832786080915	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_48
Epoch: 48	max: 0.9886059/1.0	min: 0.011394127	loss: 34479.4296875	train_loss: 34554.66175252385	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_49
Epoch: 49	max: 0.9895359/1.0	min: 0.010464004	loss: 34474.2890625	train_loss: 34548.599913484766	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_50
Epoch: 50	max: 0.9903054/1.0	min: 0.009694526	loss: 34469.43359375	train_loss: 34543.23747270996	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_51
Epoch: 51	max: 0.9910137/1.0	min: 0.008986304	loss: 34465.2421875	train_loss: 34538.38972888022	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_52
Epoch: 52	max: 0.9915788/1.0	min: 0.0084212	loss: 34461.16015625	train_loss: 34533.89273417178	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_53
Epoch: 53	max: 0.99209994/1.0	min: 0.007900042	loss: 34457.828125	train_loss: 34529.722042707945	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_54
Epoch: 54	max: 0.99248636/1.0	min: 0.0075136023	loss: 34454.23828125	train_loss: 34525.76182181345	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_55
Epoch: 55	max: 0.992767/1.0	min: 0.0072330236	loss: 34450.5703125	train_loss: 34521.97194206382	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_56
Epoch: 56	max: 0.9931195/1.0	min: 0.0068805898	loss: 34447.8359375	train_loss: 34518.30864891072	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_57
Epoch: 57	max: 0.99334747/1.0	min: 0.0066525037	loss: 34444.6953125	train_loss: 34514.69511363108	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_58
Epoch: 58	max: 0.9935628/1.0	min: 0.006437166	loss: 34441.61328125	train_loss: 34511.14191305122	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_59
Epoch: 59	max: 0.99376136/1.0	min: 0.0062386603	loss: 34438.80078125	train_loss: 34507.623775335225	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_60
Epoch: 60	max: 0.99387956/1.0	min: 0.0061203646	loss: 34435.59375	train_loss: 34504.115172198224	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_61
Epoch: 61	max: 0.99405766/1.0	min: 0.0059424047	loss: 34432.88671875	train_loss: 34500.62713239734	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_62
Epoch: 62	max: 0.99419665/1.0	min: 0.005803377	loss: 34429.90625	train_loss: 34497.15427582683	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_63
Epoch: 63	max: 0.99435896/1.0	min: 0.005641042	loss: 34427.23046875	train_loss: 34493.660775598444	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_64
Epoch: 64	max: 0.9945431/1.0	min: 0.0054569426	loss: 34424.63671875	train_loss: 34490.19911568655	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_65
Epoch: 65	max: 0.9947478/1.0	min: 0.0052522006	loss: 34422.0546875	train_loss: 34486.70310274216	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_66
Epoch: 66	max: 0.99501944/1.0	min: 0.0049805683	loss: 34420.125	train_loss: 34483.28387981156	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_67
Epoch: 67	max: 0.9951159/1.0	min: 0.0048840707	loss: 34416.71875	train_loss: 34479.959550740125	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_68
Epoch: 68	max: 0.99534154/1.0	min: 0.004658532	loss: 34414.5390625	train_loss: 34476.77666053124	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_69
Epoch: 69	max: 0.9955355/1.0	min: 0.004464553	loss: 34412.21875	train_loss: 34473.68717919686	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_70
Epoch: 70	max: 0.9957222/1.0	min: 0.004277837	loss: 34410.05078125	train_loss: 34470.70725673154	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_71
Epoch: 71	max: 0.9959335/1.0	min: 0.004066533	loss: 34408.19140625	train_loss: 34467.85885194088	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_72
Epoch: 72	max: 0.99610317/1.0	min: 0.0038969049	loss: 34406.0234375	train_loss: 34465.10773275889	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_73
Epoch: 73	max: 0.996296/1.0	min: 0.00370401	loss: 34404.37109375	train_loss: 34462.45863720116	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_74
Epoch: 74	max: 0.9963894/1.0	min: 0.003610607	loss: 34402.1484375	train_loss: 34460.031845639016	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_75
Epoch: 75	max: 0.9965305/1.0	min: 0.003469515	loss: 34400.49609375	train_loss: 34457.709204292085	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_76
Epoch: 76	max: 0.9966664/1.0	min: 0.0033336717	loss: 34399.0390625	train_loss: 34455.60196168943	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_77
Epoch: 77	max: 0.996757/1.0	min: 0.003243055	loss: 34397.3828125	train_loss: 34453.66444910891	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_78
Epoch: 78	max: 0.99690187/1.0	min: 0.0030981929	loss: 34396.24609375	train_loss: 34451.83876666435	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_79
Epoch: 79	max: 0.996988/1.0	min: 0.0030119766	loss: 34394.875	train_loss: 34450.08982487923	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_80
Epoch: 80	max: 0.9969981/1.0	min: 0.0030019842	loss: 34393.1484375	train_loss: 34448.41093914514	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_81
Epoch: 81	max: 0.99714005/1.0	min: 0.0028600078	loss: 34392.3046875	train_loss: 34446.80162946705	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_82
Epoch: 82	max: 0.9971998/1.0	min: 0.0028002653	loss: 34390.99609375	train_loss: 34445.24059461322	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_83
Epoch: 83	max: 0.99728906/1.0	min: 0.0027109121	loss: 34390.078125	train_loss: 34443.71970611916	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_84
Epoch: 84	max: 0.9973623/1.0	min: 0.002637673	loss: 34389.05078125	train_loss: 34442.25416850536	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_85
Epoch: 85	max: 0.99738353/1.0	min: 0.0026164127	loss: 34387.9140625	train_loss: 34440.81208145593	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_86
Epoch: 86	max: 0.9973826/1.0	min: 0.0026174108	loss: 34386.46484375	train_loss: 34439.40828175322	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_87
Epoch: 87	max: 0.9974389/1.0	min: 0.0025610314	loss: 34385.56640625	train_loss: 34438.023535724795	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_88
Epoch: 88	max: 0.99750084/1.0	min: 0.0024992016	loss: 34384.69140625	train_loss: 34436.66300428512	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_89
Epoch: 89	max: 0.9975006/1.0	min: 0.0024994165	loss: 34383.5	train_loss: 34435.36237158197	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_90
Epoch: 90	max: 0.9975516/1.0	min: 0.0024483614	loss: 34382.69140625	train_loss: 34434.0129729306	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_91
Epoch: 91	max: 0.9975943/1.0	min: 0.002405711	loss: 34381.84375	train_loss: 34432.71907806113	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_92
Epoch: 92	max: 0.9975253/1.0	min: 0.0024747788	loss: 34380.390625	train_loss: 34431.43852482813	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_93
Epoch: 93	max: 0.997612/1.0	min: 0.0023880112	loss: 34379.77734375	train_loss: 34430.17750139353	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_94
Epoch: 94	max: 0.9975702/1.0	min: 0.0024298145	loss: 34378.53125	train_loss: 34428.92476851852	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_95
Epoch: 95	max: 0.9975998/1.0	min: 0.002400261	loss: 34377.6875	train_loss: 34427.68880692199	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_96
Epoch: 96	max: 0.99758327/1.0	min: 0.002416668	loss: 34376.67578125	train_loss: 34426.483602749904	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_97
Epoch: 97	max: 0.99764663/1.0	min: 0.0023533178	loss: 34375.92578125	train_loss: 34425.293758903135	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_98
Epoch: 98	max: 0.9976012/1.0	min: 0.0023988169	loss: 34374.7890625	train_loss: 34424.134260226994	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_99
Epoch: 99	max: 0.99760455/1.0	min: 0.0023954883	loss: 34373.765625	train_loss: 34422.99097106094	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_100
Epoch: 100	max: 0.9977087/1.0	min: 0.0022913567	loss: 34373.09375	train_loss: 34421.89638929534	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_101
Epoch: 101	max: 0.9977235/1.0	min: 0.0022765084	loss: 34372.19140625	train_loss: 34420.79308874876	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_102
Epoch: 102	max: 0.99777824/1.0	min: 0.0022217499	loss: 34371.4609375	train_loss: 34419.74702761133	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_103
Epoch: 103	max: 0.99782217/1.0	min: 0.0021778138	loss: 34370.67578125	train_loss: 34418.72259431516	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_104
Epoch: 104	max: 0.997846/1.0	min: 0.002153955	loss: 34369.94921875	train_loss: 34417.73364000759	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_105
Epoch: 105	max: 0.99785453/1.0	min: 0.0021453977	loss: 34369.00390625	train_loss: 34416.76775401028	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_106
Epoch: 106	max: 0.9978137/1.0	min: 0.002186267	loss: 34368.078125	train_loss: 34415.83788167348	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_107
Epoch: 107	max: 0.9979056/1.0	min: 0.0020944183	loss: 34367.52734375	train_loss: 34414.941951083085	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_108
Epoch: 108	max: 0.99777704/1.0	min: 0.0022229552	loss: 34366.34375	train_loss: 34414.098281888706	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_109
Epoch: 109	max: 0.9980521/1.0	min: 0.0019479294	loss: 34366.62109375	train_loss: 34413.2973612853	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_110
Epoch: 110	max: 0.99793833/1.0	min: 0.0020616918	loss: 34365.30859375	train_loss: 34412.48819463799	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_111
Epoch: 111	max: 0.9978982/1.0	min: 0.0021017923	loss: 34364.453125	train_loss: 34411.70599480908	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_112
Epoch: 112	max: 0.99810165/1.0	min: 0.0018983885	loss: 34364.57421875	train_loss: 34410.98056745866	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_113
Epoch: 113	max: 0.99801505/1.0	min: 0.0019849876	loss: 34363.51953125	train_loss: 34410.25954522405	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_114
Epoch: 114	max: 0.99800617/1.0	min: 0.0019939023	loss: 34362.7109375	train_loss: 34409.56139291466	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_115
Epoch: 115	max: 0.9980399/1.0	min: 0.0019601265	loss: 34362.23828125	train_loss: 34408.902750681285	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_116
Epoch: 116	max: 0.9981248/1.0	min: 0.0018752195	loss: 34362.00390625	train_loss: 34408.26093440326	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_117
Epoch: 117	max: 0.9980274/1.0	min: 0.0019726136	loss: 34360.9765625	train_loss: 34407.642124984515	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_118
Epoch: 118	max: 0.99818856/1.0	min: 0.0018114746	loss: 34361.015625	train_loss: 34407.0551795917	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_119
Epoch: 119	max: 0.99803895/1.0	min: 0.0019611185	loss: 34359.91015625	train_loss: 34406.489848975754	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_120
Epoch: 120	max: 0.9982016/1.0	min: 0.0017983819	loss: 34359.91015625	train_loss: 34405.907848693176	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_121
Epoch: 121	max: 0.99813735/1.0	min: 0.0018626748	loss: 34359.14453125	train_loss: 34405.352122816796	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_122
Epoch: 122	max: 0.99819857/1.0	min: 0.0018014385	loss: 34358.875	train_loss: 34404.79890433389	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_123
Epoch: 123	max: 0.99816257/1.0	min: 0.0018374713	loss: 34358.05859375	train_loss: 34404.254956239165	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_124
Epoch: 124	max: 0.9982345/1.0	min: 0.0017654636	loss: 34357.96484375	train_loss: 34403.76489387851	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_125
Epoch: 125	max: 0.9982405/1.0	min: 0.0017595766	loss: 34357.359375	train_loss: 34403.240086553946	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_126
Epoch: 126	max: 0.99824023/1.0	min: 0.0017597886	loss: 34356.94921875	train_loss: 34402.75818991546	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_127
Epoch: 127	max: 0.9982658/1.0	min: 0.0017341649	loss: 34356.578125	train_loss: 34402.30372799378	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_128
Epoch: 128	max: 0.99826413/1.0	min: 0.0017359045	loss: 34356.19921875	train_loss: 34401.87733223399	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_129
Epoch: 129	max: 0.998292/1.0	min: 0.0017079219	loss: 34355.921875	train_loss: 34401.37339404884	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_130
Epoch: 130	max: 0.9983329/1.0	min: 0.0016670582	loss: 34355.73828125	train_loss: 34400.963143928835	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_131
Epoch: 131	max: 0.99825305/1.0	min: 0.0017468899	loss: 34354.91015625	train_loss: 34400.50787491871	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_132
Epoch: 132	max: 0.9982918/1.0	min: 0.0017081917	loss: 34354.6484375	train_loss: 34400.09498047117	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_133
Epoch: 133	max: 0.9982779/1.0	min: 0.0017221055	loss: 34354.1484375	train_loss: 34399.687744836185	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_134
Epoch: 134	max: 0.99839514/1.0	min: 0.0016048867	loss: 34354.3046875	train_loss: 34399.3057795855	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_135
Epoch: 135	max: 0.99831104/1.0	min: 0.0016889442	loss: 34353.38671875	train_loss: 34398.917487303355	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_136
Epoch: 136	max: 0.99839324/1.0	min: 0.0016067704	loss: 34353.34765625	train_loss: 34398.54388857922	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_137
Epoch: 137	max: 0.9983907/1.0	min: 0.0016093986	loss: 34352.90625	train_loss: 34398.15386792782	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_138
Epoch: 138	max: 0.99839884/1.0	min: 0.0016011449	loss: 34352.5390625	train_loss: 34397.793136167624	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_139
Epoch: 139	max: 0.9984427/1.0	min: 0.0015572839	loss: 34352.37890625	train_loss: 34397.44532362892	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_140
Epoch: 140	max: 0.9984383/1.0	min: 0.0015617501	loss: 34351.90625	train_loss: 34397.0891426282	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_141
Epoch: 141	max: 0.99848783/1.0	min: 0.0015121663	loss: 34351.73828125	train_loss: 34396.74895678496	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_142
Epoch: 142	max: 0.9985195/1.0	min: 0.0014805263	loss: 34351.484375	train_loss: 34396.430074592776	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_143
Epoch: 143	max: 0.9985103/1.0	min: 0.0014896598	loss: 34351.078125	train_loss: 34396.102401523596	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_144
Epoch: 144	max: 0.998509/1.0	min: 0.0014910351	loss: 34350.6640625	train_loss: 34395.7727862164	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_145
Epoch: 145	max: 0.9985366/1.0	min: 0.0014634087	loss: 34350.4375	train_loss: 34395.4570554433	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_146
Epoch: 146	max: 0.9985764/1.0	min: 0.0014235921	loss: 34350.31640625	train_loss: 34395.14217772591	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_147
Epoch: 147	max: 0.9985752/1.0	min: 0.0014247326	loss: 34349.8984375	train_loss: 34394.84264581785	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_148
Epoch: 148	max: 0.99857926/1.0	min: 0.0014206857	loss: 34349.59375	train_loss: 34394.54165457002	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_149
Epoch: 149	max: 0.9986222/1.0	min: 0.0013777823	loss: 34349.40625	train_loss: 34394.25550639477	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_150
Epoch: 150	max: 0.9985863/1.0	min: 0.0014137257	loss: 34348.98828125	train_loss: 34393.963101832494	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_151
Epoch: 151	max: 0.99861765/1.0	min: 0.0013823392	loss: 34348.78125	train_loss: 34393.688849986065	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_152
Epoch: 152	max: 0.99869496/1.0	min: 0.0013050484	loss: 34348.90625	train_loss: 34393.44296913709	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_153
Epoch: 153	max: 0.99867344/1.0	min: 0.0013265678	loss: 34348.40625	train_loss: 34393.14533011272	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_154
Epoch: 154	max: 0.9986481/1.0	min: 0.0013518783	loss: 34348.00390625	train_loss: 34392.883699426326	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_155
Epoch: 155	max: 0.99869895/1.0	min: 0.0013010225	loss: 34347.90625	train_loss: 34392.643885288926	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_156
Epoch: 156	max: 0.9986683/1.0	min: 0.0013316972	loss: 34347.5234375	train_loss: 34392.37031956444	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_157
Epoch: 157	max: 0.9987338/1.0	min: 0.0012662255	loss: 34347.51171875	train_loss: 34392.132082346245	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_158
Epoch: 158	max: 0.99872965/1.0	min: 0.0012703587	loss: 34347.265625	train_loss: 34391.87130229623	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_159
Epoch: 159	max: 0.9987664/1.0	min: 0.001233594	loss: 34347.1640625	train_loss: 34391.638549698844	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_160
Epoch: 160	max: 0.99872774/1.0	min: 0.0012722245	loss: 34346.7109375	train_loss: 34391.39307191023	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_161
Epoch: 161	max: 0.9988129/1.0	min: 0.0011870525	loss: 34346.88671875	train_loss: 34391.16956695931	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_162
Epoch: 162	max: 0.99874806/1.0	min: 0.0012519408	loss: 34346.23828125	train_loss: 34390.93425567865	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_163
Epoch: 163	max: 0.9987772/1.0	min: 0.0012227579	loss: 34346.15625	train_loss: 34390.71641970147	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_164
Epoch: 164	max: 0.99873215/1.0	min: 0.0012678811	loss: 34345.7265625	train_loss: 34390.489205917875	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_165
Epoch: 165	max: 0.99883944/1.0	min: 0.0011605644	loss: 34345.9296875	train_loss: 34390.293552292365	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_166
Epoch: 166	max: 0.9987974/1.0	min: 0.0012025657	loss: 34345.5	train_loss: 34390.09677996872	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_167
Epoch: 167	max: 0.9988005/1.0	min: 0.0011995262	loss: 34345.30078125	train_loss: 34389.86159642868	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_168
Epoch: 168	max: 0.9988223/1.0	min: 0.0011776608	loss: 34345.16015625	train_loss: 34389.65605306655	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_169
Epoch: 169	max: 0.9988826/1.0	min: 0.0011173615	loss: 34345.203125	train_loss: 34389.43506421869	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_170
Epoch: 170	max: 0.99883574/1.0	min: 0.0011642472	loss: 34344.78125	train_loss: 34389.24905162269	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_171
Epoch: 171	max: 0.99886715/1.0	min: 0.0011328992	loss: 34344.6484375	train_loss: 34389.03896475907	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_172
Epoch: 172	max: 0.99888057/1.0	min: 0.001119376	loss: 34344.4609375	train_loss: 34388.863333991394	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_173
Epoch: 173	max: 0.99886656/1.0	min: 0.0011334837	loss: 34344.265625	train_loss: 34388.65608548557	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_174
Epoch: 174	max: 0.9988926/1.0	min: 0.001107452	loss: 34344.0859375	train_loss: 34388.463572634086	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_175
Epoch: 175	max: 0.9989267/1.0	min: 0.0010732878	loss: 34344.11328125	train_loss: 34388.28250176127	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_176
Epoch: 176	max: 0.998896/1.0	min: 0.0011039284	loss: 34343.7734375	train_loss: 34388.11015450808	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_177
Epoch: 177	max: 0.99894506/1.0	min: 0.0010549664	loss: 34343.671875	train_loss: 34387.91446991515	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_178
Epoch: 178	max: 0.9989083/1.0	min: 0.0010917167	loss: 34343.4140625	train_loss: 34387.75455269494	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_179
Epoch: 179	max: 0.99898654/1.0	min: 0.0010134594	loss: 34343.5390625	train_loss: 34387.560894532704	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_180
Epoch: 180	max: 0.99903095/1.0	min: 0.00096904306	loss: 34343.57421875	train_loss: 34387.38639891459	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_181
Epoch: 181	max: 0.99890554/1.0	min: 0.0010944136	loss: 34342.93359375	train_loss: 34387.23396516552	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_182
Epoch: 182	max: 0.99899286/1.0	min: 0.0010071689	loss: 34342.953125	train_loss: 34387.06273564273	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_183
Epoch: 183	max: 0.99894446/1.0	min: 0.0010555112	loss: 34342.61328125	train_loss: 34386.87624740648	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_184
Epoch: 184	max: 0.99903905/1.0	min: 0.00096095743	loss: 34342.828125	train_loss: 34386.71525939087	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_185
Epoch: 185	max: 0.99898523/1.0	min: 0.0010147295	loss: 34342.2890625	train_loss: 34386.57685727115	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_186
Epoch: 186	max: 0.9990068/1.0	min: 0.0009932634	loss: 34342.2890625	train_loss: 34386.38548827883	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_187
Epoch: 187	max: 0.9989949/1.0	min: 0.001005165	loss: 34342.1015625	train_loss: 34386.230459556544	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_188
Epoch: 188	max: 0.9990214/1.0	min: 0.0009786433	loss: 34342.0	train_loss: 34386.08262301808	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_189
Epoch: 189	max: 0.99907815/1.0	min: 0.0009218538	loss: 34342.046875	train_loss: 34385.92049356265	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_190
Epoch: 190	max: 0.99902284/1.0	min: 0.0009772024	loss: 34341.6484375	train_loss: 34385.776074569556	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_191
Epoch: 191	max: 0.9990746/1.0	min: 0.0009254237	loss: 34341.72265625	train_loss: 34385.62582837854	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_192
Epoch: 192	max: 0.99902594/1.0	min: 0.00097401044	loss: 34341.41015625	train_loss: 34385.46372553574	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_193
Epoch: 193	max: 0.99907/1.0	min: 0.0009300578	loss: 34341.3359375	train_loss: 34385.32645614626	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_194
Epoch: 194	max: 0.99905556/1.0	min: 0.0009444611	loss: 34341.171875	train_loss: 34385.17698897947	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_195
Epoch: 195	max: 0.99914515/1.0	min: 0.00085483777	loss: 34341.375	train_loss: 34385.04596871903	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_196
Epoch: 196	max: 0.99900657/1.0	min: 0.0009935097	loss: 34340.796875	train_loss: 34384.927795584044	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_197
Epoch: 197	max: 0.9990822/1.0	min: 0.00091777375	loss: 34340.8515625	train_loss: 34384.76727014431	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_198
Epoch: 198	max: 0.99914217/1.0	min: 0.00085784023	loss: 34340.9140625	train_loss: 34384.61476139601	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_199
Epoch: 199	max: 0.999132/1.0	min: 0.0008680472	loss: 34340.6640625	train_loss: 34384.483928875576	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_200
Epoch: 200	max: 0.99916697/1.0	min: 0.00083311205	loss: 34340.6796875	train_loss: 34384.350047031774	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_201
Epoch: 201	max: 0.99908876/1.0	min: 0.00091120915	loss: 34340.2890625	train_loss: 34384.20767575948	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_202
Epoch: 202	max: 0.9990753/1.0	min: 0.0009246287	loss: 34340.078125	train_loss: 34384.09371806485	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_203
Epoch: 203	max: 0.9991486/1.0	min: 0.00085133757	loss: 34340.2265625	train_loss: 34383.96951063731	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_204
Epoch: 204	max: 0.9992151/1.0	min: 0.0007848985	loss: 34340.28515625	train_loss: 34383.823219566766	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_205
Epoch: 205	max: 0.9991899/1.0	min: 0.00081009476	loss: 34339.9765625	train_loss: 34383.70908477719	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_206
Epoch: 206	max: 0.9991328/1.0	min: 0.00086720055	loss: 34339.7109375	train_loss: 34383.56701301793	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_207
Epoch: 207	max: 0.999204/1.0	min: 0.0007960868	loss: 34339.81640625	train_loss: 34383.443361552396	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_208
Epoch: 208	max: 0.999186/1.0	min: 0.0008139807	loss: 34339.5234375	train_loss: 34383.3092208403	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_209
Epoch: 209	max: 0.9991968/1.0	min: 0.00080320373	loss: 34339.51953125	train_loss: 34383.204921594355	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_210
Epoch: 210	max: 0.99924505/1.0	min: 0.00075500616	loss: 34339.51171875	train_loss: 34383.088403281	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_211
Epoch: 211	max: 0.9991978/1.0	min: 0.00080225366	loss: 34339.30859375	train_loss: 34382.95927396879	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_212
Epoch: 212	max: 0.99920255/1.0	min: 0.0007974872	loss: 34339.1484375	train_loss: 34382.84210824275	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_213
Epoch: 213	max: 0.99922574/1.0	min: 0.0007742517	loss: 34339.1953125	train_loss: 34382.71581003035	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_214
Epoch: 214	max: 0.9992754/1.0	min: 0.0007245819	loss: 34339.18359375	train_loss: 34382.60043218909	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_215
Epoch: 215	max: 0.99920744/1.0	min: 0.00079253234	loss: 34338.78515625	train_loss: 34382.48905979035	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_216
Epoch: 216	max: 0.99924064/1.0	min: 0.00075934554	loss: 34338.76171875	train_loss: 34382.38911243497	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_217
Epoch: 217	max: 0.99926895/1.0	min: 0.0007309994	loss: 34338.7734375	train_loss: 34382.27157993853	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_218
Epoch: 218	max: 0.9992592/1.0	min: 0.00074078224	loss: 34338.68359375	train_loss: 34382.15367680076	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_219
Epoch: 219	max: 0.9992687/1.0	min: 0.00073128624	loss: 34338.453125	train_loss: 34382.0881458643	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_220
Epoch: 220	max: 0.99920577/1.0	min: 0.000794275	loss: 34338.34375	train_loss: 34381.935925500125	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_221
Epoch: 221	max: 0.99928844/1.0	min: 0.00071158627	loss: 34338.3984375	train_loss: 34381.84599900904	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_222
Epoch: 222	max: 0.9993531/1.0	min: 0.0006469064	loss: 34338.50390625	train_loss: 34381.72807845209	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_223
Epoch: 223	max: 0.99931216/1.0	min: 0.0006878866	loss: 34338.31640625	train_loss: 34381.64015371454	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_224
Epoch: 224	max: 0.999286/1.0	min: 0.00071402633	loss: 34338.0390625	train_loss: 34381.520410434474	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_225
Epoch: 225	max: 0.9993149/1.0	min: 0.0006850772	loss: 34337.96484375	train_loss: 34381.4037145423	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_226
Epoch: 226	max: 0.9992557/1.0	min: 0.0007442651	loss: 34337.76171875	train_loss: 34381.317758655394	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_227
Epoch: 227	max: 0.999297/1.0	min: 0.0007030034	loss: 34337.69921875	train_loss: 34381.22038014446	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_228
Epoch: 228	max: 0.9993043/1.0	min: 0.0006956553	loss: 34337.7109375	train_loss: 34381.10262071488	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_229
Epoch: 229	max: 0.99930584/1.0	min: 0.0006941857	loss: 34337.5	train_loss: 34381.008159431905	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_230
Epoch: 230	max: 0.99931383/1.0	min: 0.0006862116	loss: 34337.49609375	train_loss: 34380.91927567199	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_231
Epoch: 231	max: 0.99931717/1.0	min: 0.0006828929	loss: 34337.41015625	train_loss: 34380.808404558404	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_232
Epoch: 232	max: 0.9993344/1.0	min: 0.0006656148	loss: 34337.4375	train_loss: 34380.71201071473	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_233
Epoch: 233	max: 0.9993544/1.0	min: 0.0006456209	loss: 34337.24609375	train_loss: 34380.63052913648	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_234
Epoch: 234	max: 0.9994029/1.0	min: 0.00059714273	loss: 34337.3828125	train_loss: 34380.521227684105	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_235
Epoch: 235	max: 0.99934536/1.0	min: 0.0006546692	loss: 34337.1015625	train_loss: 34380.42533948037	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_236
Epoch: 236	max: 0.999343/1.0	min: 0.0006570519	loss: 34336.91796875	train_loss: 34380.323391823054	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_237
Epoch: 237	max: 0.99932647/1.0	min: 0.0006735736	loss: 34336.8515625	train_loss: 34380.27465103586	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_238
Epoch: 238	max: 0.9994142/1.0	min: 0.00058578944	loss: 34337.0703125	train_loss: 34380.16644650765	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_239
Epoch: 239	max: 0.9994312/1.0	min: 0.0005687664	loss: 34337.0859375	train_loss: 34380.09245952945	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_240
Epoch: 240	max: 0.9993457/1.0	min: 0.0006542269	loss: 34336.609375	train_loss: 34379.996016331446	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_241
Epoch: 241	max: 0.9994086/1.0	min: 0.00059143436	loss: 34336.6953125	train_loss: 34379.871270844946	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_242
Epoch: 242	max: 0.9994481/1.0	min: 0.00055192894	loss: 34336.95703125	train_loss: 34379.79284681578	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_243
Epoch: 243	max: 0.99938715/1.0	min: 0.0006128159	loss: 34336.46875	train_loss: 34379.74247007773	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_244
Epoch: 244	max: 0.9993703/1.0	min: 0.0006297472	loss: 34336.31640625	train_loss: 34379.624195330885	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_245
Epoch: 245	max: 0.9993544/1.0	min: 0.0006455828	loss: 34336.2109375	train_loss: 34379.522670572434	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_246
Epoch: 246	max: 0.99941826/1.0	min: 0.00058180356	loss: 34336.234375	train_loss: 34379.44201253406	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_247
Epoch: 247	max: 0.9994128/1.0	min: 0.00058727514	loss: 34336.2265625	train_loss: 34379.36201835981	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_248
Epoch: 248	max: 0.99939585/1.0	min: 0.0006041891	loss: 34336.02734375	train_loss: 34379.26804094281	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_249
Epoch: 249	max: 0.9994236/1.0	min: 0.0005764239	loss: 34336.08984375	train_loss: 34379.18825531478	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_250
Epoch: 250	max: 0.999445/1.0	min: 0.00055496604	loss: 34336.0859375	train_loss: 34379.10525004258	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_251
Epoch: 251	max: 0.999469/1.0	min: 0.00053104106	loss: 34336.03125	train_loss: 34379.03221724808	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_252
Epoch: 252	max: 0.9994918/1.0	min: 0.0005081151	loss: 34336.2734375	train_loss: 34378.93541792472	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_253
Epoch: 253	max: 0.99943644/1.0	min: 0.00056356983	loss: 34335.73046875	train_loss: 34378.89228320869	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_254
Epoch: 254	max: 0.9994085/1.0	min: 0.0005915053	loss: 34335.59375	train_loss: 34378.77669488573	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_255
Epoch: 255	max: 0.99944323/1.0	min: 0.0005568107	loss: 34335.66015625	train_loss: 34378.70371821968	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_256
Epoch: 256	max: 0.99941516/1.0	min: 0.000584884	loss: 34335.484375	train_loss: 34378.63047784668	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_257
Epoch: 257	max: 0.999464/1.0	min: 0.0005360528	loss: 34335.4609375	train_loss: 34378.54039603462	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_258
Epoch: 258	max: 0.99948657/1.0	min: 0.00051338284	loss: 34335.67578125	train_loss: 34378.459068809614	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_259
Epoch: 259	max: 0.9994186/1.0	min: 0.0005814446	loss: 34335.22265625	train_loss: 34378.39046484036	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_260
Epoch: 260	max: 0.99946076/1.0	min: 0.00053930405	loss: 34335.2890625	train_loss: 34378.305283139016	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_261
Epoch: 261	max: 0.99948174/1.0	min: 0.00051828823	loss: 34335.33203125	train_loss: 34378.22719926762	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_262
Epoch: 262	max: 0.999448/1.0	min: 0.00055196206	loss: 34335.03515625	train_loss: 34378.15144714635	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_263
Epoch: 263	max: 0.99947375/1.0	min: 0.0005262174	loss: 34335.1015625	train_loss: 34378.069998470986	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_264
Epoch: 264	max: 0.9994764/1.0	min: 0.0005236477	loss: 34335.015625	train_loss: 34377.99646245587	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_265
Epoch: 265	max: 0.99948883/1.0	min: 0.00051115244	loss: 34334.9453125	train_loss: 34377.92131032841	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_266
Epoch: 266	max: 0.99949634/1.0	min: 0.0005036293	loss: 34334.90625	train_loss: 34377.84771866871	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_267
Epoch: 267	max: 0.99951327/1.0	min: 0.0004867344	loss: 34334.87109375	train_loss: 34377.77419716958	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_268
Epoch: 268	max: 0.99952126/1.0	min: 0.00047880269	loss: 34334.87890625	train_loss: 34377.69188043865	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_269
Epoch: 269	max: 0.99952173/1.0	min: 0.00047831758	loss: 34334.80859375	train_loss: 34377.641463055865	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_270
Epoch: 270	max: 0.9995011/1.0	min: 0.00049885386	loss: 34334.55078125	train_loss: 34377.5563369991	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_271
Epoch: 271	max: 0.9995542/1.0	min: 0.00044581766	loss: 34334.87109375	train_loss: 34377.48578643704	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_272
Epoch: 272	max: 0.99953055/1.0	min: 0.00046948146	loss: 34334.4921875	train_loss: 34377.4253404481	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_273
Epoch: 273	max: 0.9995559/1.0	min: 0.00044409916	loss: 34334.6484375	train_loss: 34377.32671936935	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_274
Epoch: 274	max: 0.99953854/1.0	min: 0.0004614312	loss: 34334.390625	train_loss: 34377.30340477131	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_275
Epoch: 275	max: 0.99953675/1.0	min: 0.0004632986	loss: 34334.3828125	train_loss: 34377.19759537966	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_276
Epoch: 276	max: 0.99957675/1.0	min: 0.00042319976	loss: 34334.5078125	train_loss: 34377.120494723924	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_277
Epoch: 277	max: 0.9996013/1.0	min: 0.00039872172	loss: 34334.65625	train_loss: 34377.05495217469	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_278
Epoch: 278	max: 0.99960274/1.0	min: 0.0003972989	loss: 34334.57421875	train_loss: 34377.02927389136	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_279
Epoch: 279	max: 0.9996014/1.0	min: 0.00039853892	loss: 34334.484375	train_loss: 34376.955903358416	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_280
Epoch: 280	max: 0.9995716/1.0	min: 0.00042840565	loss: 34334.15625	train_loss: 34376.88036462204	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_281
Epoch: 281	max: 0.9995665/1.0	min: 0.0004335414	loss: 34334.11328125	train_loss: 34376.811563235475	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_282
Epoch: 282	max: 0.99953485/1.0	min: 0.00046521155	loss: 34333.80078125	train_loss: 34376.72115771708	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_283
Epoch: 283	max: 0.99957997/1.0	min: 0.00042007497	loss: 34333.9296875	train_loss: 34376.67207048185	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_284
Epoch: 284	max: 0.9996088/1.0	min: 0.00039126226	loss: 34333.98828125	train_loss: 34376.591062608386	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_285
Epoch: 285	max: 0.99960095/1.0	min: 0.00039902946	loss: 34334.0078125	train_loss: 34376.56274870711	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_286
Epoch: 286	max: 0.9996165/1.0	min: 0.00038347175	loss: 34333.94921875	train_loss: 34376.45037712514	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_287
Epoch: 287	max: 0.99961144/1.0	min: 0.00038856658	loss: 34333.890625	train_loss: 34376.40158166109	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_288
Epoch: 288	max: 0.9996062/1.0	min: 0.00039389034	loss: 34333.765625	train_loss: 34376.32167845364	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_289
Epoch: 289	max: 0.99957985/1.0	min: 0.00042015704	loss: 34333.484375	train_loss: 34376.24980645361	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_290
Epoch: 290	max: 0.99958175/1.0	min: 0.00041824687	loss: 34333.51171875	train_loss: 34376.20488627214	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_291
Epoch: 291	max: 0.99962354/1.0	min: 0.00037640886	loss: 34333.62890625	train_loss: 34376.152094559024	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_292
Epoch: 292	max: 0.9996309/1.0	min: 0.0003690349	loss: 34333.55078125	train_loss: 34376.07423907237	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_293
Epoch: 293	max: 0.99959093/1.0	min: 0.0004090557	loss: 34333.296875	train_loss: 34376.02681972315	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_294
Epoch: 294	max: 0.99962413/1.0	min: 0.00037585938	loss: 34333.4609375	train_loss: 34375.96344392574	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_295
Epoch: 295	max: 0.99960285/1.0	min: 0.0003971885	loss: 34333.25390625	train_loss: 34375.91492329757	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_296
Epoch: 296	max: 0.99960953/1.0	min: 0.00039045906	loss: 34333.24609375	train_loss: 34375.828238708506	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_297
Epoch: 297	max: 0.9996345/1.0	min: 0.00036553043	loss: 34333.30078125	train_loss: 34375.76540532485	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_298
Epoch: 298	max: 0.99963844/1.0	min: 0.00036156076	loss: 34333.24609375	train_loss: 34375.740021232035	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_299
Epoch: 299	max: 0.9996393/1.0	min: 0.00036067338	loss: 34333.19921875	train_loss: 34375.63831212065	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_300
Epoch: 300	max: 0.9996458/1.0	min: 0.00035415433	loss: 34333.1796875	train_loss: 34375.5740808482	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_301
Epoch: 301	max: 0.99963963/1.0	min: 0.0003603464	loss: 34332.953125	train_loss: 34375.53301369147	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_302
Epoch: 302	max: 0.99963915/1.0	min: 0.00036078188	loss: 34332.9453125	train_loss: 34375.46530826134	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_303
Epoch: 303	max: 0.9996407/1.0	min: 0.00035931112	loss: 34332.92578125	train_loss: 34375.41207671405	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_304
Epoch: 304	max: 0.99965966/1.0	min: 0.00034033408	loss: 34332.953125	train_loss: 34375.357769532704	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_305
Epoch: 305	max: 0.9996549/1.0	min: 0.00034506214	loss: 34332.90625	train_loss: 34375.29835127509	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_306
Epoch: 306	max: 0.99967766/1.0	min: 0.0003223077	loss: 34333.01171875	train_loss: 34375.235924822715	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_307
Epoch: 307	max: 0.9996457/1.0	min: 0.00035430407	loss: 34332.7890625	train_loss: 34375.181210710085	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_308
Epoch: 308	max: 0.9996948/1.0	min: 0.00030518306	loss: 34332.9609375	train_loss: 34375.119085222344	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_309
Epoch: 309	max: 0.9996661/1.0	min: 0.00033393042	loss: 34332.58984375	train_loss: 34375.11005676715	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_310
Epoch: 310	max: 0.99967515/1.0	min: 0.00032490634	loss: 34332.71875	train_loss: 34375.01960721696	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_311
Epoch: 311	max: 0.9996525/1.0	min: 0.00034754537	loss: 34332.4140625	train_loss: 34374.94464718429	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_312
Epoch: 312	max: 0.99966323/1.0	min: 0.0003367423	loss: 34332.55859375	train_loss: 34374.884928929765	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_313
Epoch: 313	max: 0.9996624/1.0	min: 0.00033765094	loss: 34332.4609375	train_loss: 34374.8357241151	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_314
Epoch: 314	max: 0.9996908/1.0	min: 0.00030922386	loss: 34332.6640625	train_loss: 34374.78021791388	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_315
Epoch: 315	max: 0.9996754/1.0	min: 0.00032461033	loss: 34332.36328125	train_loss: 34374.77438055478	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_316
Epoch: 316	max: 0.9996809/1.0	min: 0.00031912565	loss: 34332.30859375	train_loss: 34374.67151064892	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_317
Epoch: 317	max: 0.99967504/1.0	min: 0.00032492864	loss: 34332.4296875	train_loss: 34374.66293170522	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_318
Epoch: 318	max: 0.99968326/1.0	min: 0.00031674537	loss: 34332.265625	train_loss: 34374.571587002974	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_319
Epoch: 319	max: 0.9996804/1.0	min: 0.00031963145	loss: 34332.1015625	train_loss: 34374.51451791466	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_320
Epoch: 320	max: 0.9996706/1.0	min: 0.00032939127	loss: 34331.984375	train_loss: 34374.46287489936	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_321
Epoch: 321	max: 0.9997186/1.0	min: 0.00028138922	loss: 34332.359375	train_loss: 34374.406651608755	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_322
Epoch: 322	max: 0.9996911/1.0	min: 0.00030893984	loss: 34332.0	train_loss: 34374.36367995556	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_323
Epoch: 323	max: 0.9996916/1.0	min: 0.00030845628	loss: 34332.11328125	train_loss: 34374.2893412068	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_324
Epoch: 324	max: 0.9996762/1.0	min: 0.00032382802	loss: 34331.96875	train_loss: 34374.247248254214	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_325
Epoch: 325	max: 0.99968946/1.0	min: 0.0003105566	loss: 34331.85546875	train_loss: 34374.2290026361	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_326
Epoch: 326	max: 0.99969757/1.0	min: 0.00030248248	loss: 34331.875	train_loss: 34374.13940856094	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_327
Epoch: 327	max: 0.9997204/1.0	min: 0.0002795668	loss: 34332.01171875	train_loss: 34374.084365419454	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_328
Epoch: 328	max: 0.9996737/1.0	min: 0.00032626494	loss: 34331.71875	train_loss: 34374.05050496253	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_329
Epoch: 329	max: 0.99971503/1.0	min: 0.0002849702	loss: 34331.79296875	train_loss: 34373.99229104732	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_330
Epoch: 330	max: 0.99971145/1.0	min: 0.00028849556	loss: 34331.76953125	train_loss: 34373.93717193887	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_331
Epoch: 331	max: 0.99973136/1.0	min: 0.0002686539	loss: 34331.84375	train_loss: 34373.87335824275	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_332
Epoch: 332	max: 0.9997533/1.0	min: 0.0002467066	loss: 34332.046875	train_loss: 34373.834715254554	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_333
Epoch: 333	max: 0.99975234/1.0	min: 0.0002476833	loss: 34331.80078125	train_loss: 34373.82372085191	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_334
Epoch: 334	max: 0.999716/1.0	min: 0.0002840477	loss: 34331.5625	train_loss: 34373.7606677931	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_335
Epoch: 335	max: 0.99970824/1.0	min: 0.000291742	loss: 34331.38671875	train_loss: 34373.69720828688	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_336
Epoch: 336	max: 0.99971265/1.0	min: 0.000287292	loss: 34331.44140625	train_loss: 34373.64216514539	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_337
Epoch: 337	max: 0.99974805/1.0	min: 0.0002519524	loss: 34331.6484375	train_loss: 34373.57500987087	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_338
Epoch: 338	max: 0.99972075/1.0	min: 0.00027924342	loss: 34331.40625	train_loss: 34373.5678723639	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_339
Epoch: 339	max: 0.9997335/1.0	min: 0.0002665244	loss: 34331.3671875	train_loss: 34373.50309867769	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_340
Epoch: 340	max: 0.9997428/1.0	min: 0.00025715106	loss: 34331.3515625	train_loss: 34373.44525588768	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_341
Epoch: 341	max: 0.9997379/1.0	min: 0.00026208884	loss: 34331.2734375	train_loss: 34373.38812341292	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_342
Epoch: 342	max: 0.9997414/1.0	min: 0.00025860436	loss: 34331.19140625	train_loss: 34373.33866311703	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_343
Epoch: 343	max: 0.9997341/1.0	min: 0.00026583255	loss: 34331.26953125	train_loss: 34373.28419625991	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_344
Epoch: 344	max: 0.9997589/1.0	min: 0.00024109505	loss: 34331.30078125	train_loss: 34373.25343302908	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_345
Epoch: 345	max: 0.99972516/1.0	min: 0.00027477278	loss: 34331.046875	train_loss: 34373.19477153784	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_346
Epoch: 346	max: 0.99974746/1.0	min: 0.00025251272	loss: 34331.13671875	train_loss: 34373.146456552706	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_347
Epoch: 347	max: 0.99975127/1.0	min: 0.00024870128	loss: 34331.17578125	train_loss: 34373.09763399216	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_348
Epoch: 348	max: 0.9997402/1.0	min: 0.00025979453	loss: 34330.90625	train_loss: 34373.07240618807	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_349
Epoch: 349	max: 0.9997539/1.0	min: 0.0002461235	loss: 34331.04296875	train_loss: 34373.03163418958	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_350
Epoch: 350	max: 0.99974924/1.0	min: 0.0002507728	loss: 34330.83984375	train_loss: 34372.96259716029	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_351
Epoch: 351	max: 0.9997495/1.0	min: 0.00025047886	loss: 34330.99609375	train_loss: 34372.92820928945	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_352
Epoch: 352	max: 0.99976724/1.0	min: 0.00023276827	loss: 34330.98828125	train_loss: 34372.87768932708	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_353
Epoch: 353	max: 0.9997732/1.0	min: 0.00022681835	loss: 34330.93359375	train_loss: 34372.845564013536	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_354
Epoch: 354	max: 0.9997534/1.0	min: 0.00024660642	loss: 34330.74609375	train_loss: 34372.79026393921	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_355
Epoch: 355	max: 0.99976665/1.0	min: 0.00023338296	loss: 34330.859375	train_loss: 34372.73164357658	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_356
Epoch: 356	max: 0.99975854/1.0	min: 0.00024146911	loss: 34330.671875	train_loss: 34372.70234307259	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_357
Epoch: 357	max: 0.99975985/1.0	min: 0.00024019429	loss: 34330.55078125	train_loss: 34372.67472013192	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_358
Epoch: 358	max: 0.9997347/1.0	min: 0.00026531	loss: 34330.57421875	train_loss: 34372.62203196612	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_359
Epoch: 359	max: 0.9997373/1.0	min: 0.00026266248	loss: 34330.53125	train_loss: 34372.584372193574	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_360
Epoch: 360	max: 0.9997522/1.0	min: 0.00024781132	loss: 34330.56640625	train_loss: 34372.532036766075	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_361
Epoch: 361	max: 0.9997428/1.0	min: 0.00025714198	loss: 34330.3984375	train_loss: 34372.49209217841	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_362
Epoch: 362	max: 0.9997522/1.0	min: 0.00024781036	loss: 34330.4453125	train_loss: 34372.45903590673	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_363
Epoch: 363	max: 0.9997708/1.0	min: 0.00022913412	loss: 34330.41796875	train_loss: 34372.44278768735	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_364
Epoch: 364	max: 0.9997781/1.0	min: 0.00022194965	loss: 34330.37890625	train_loss: 34372.34052503329	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_365
Epoch: 365	max: 0.99978036/1.0	min: 0.00021959544	loss: 34330.36328125	train_loss: 34372.30095108696	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_366
Epoch: 366	max: 0.99977237/1.0	min: 0.00022767768	loss: 34330.35546875	train_loss: 34372.271024460395	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_367
Epoch: 367	max: 0.99978954/1.0	min: 0.00021046342	loss: 34330.4296875	train_loss: 34372.2371422295	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_368
Epoch: 368	max: 0.9998104/1.0	min: 0.0001896297	loss: 34330.51171875	train_loss: 34372.22233980165	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_369
Epoch: 369	max: 0.999803/1.0	min: 0.00019696346	loss: 34330.37890625	train_loss: 34372.17363094962	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_370
Epoch: 370	max: 0.99978/1.0	min: 0.00022000623	loss: 34330.25390625	train_loss: 34372.10610842082	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_371
Epoch: 371	max: 0.9997719/1.0	min: 0.00022810744	loss: 34330.10546875	train_loss: 34372.057691339964	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_372
Epoch: 372	max: 0.9997789/1.0	min: 0.00022113053	loss: 34330.14453125	train_loss: 34372.018861095625	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_373
Epoch: 373	max: 0.9997789/1.0	min: 0.00022113304	loss: 34330.0390625	train_loss: 34371.998482112445	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_374
Epoch: 374	max: 0.9998055/1.0	min: 0.00019448518	loss: 34330.26171875	train_loss: 34371.98867463304	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_375
Epoch: 375	max: 0.99979836/1.0	min: 0.00020163454	loss: 34330.171875	train_loss: 34371.90879126409	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_376
Epoch: 376	max: 0.9997954/1.0	min: 0.00020468816	loss: 34330.03125	train_loss: 34371.859224517684	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_377
Epoch: 377	max: 0.9997956/1.0	min: 0.00020445877	loss: 34329.9140625	train_loss: 34371.81820429595	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_378
Epoch: 378	max: 0.99978167/1.0	min: 0.00021838797	loss: 34329.89453125	train_loss: 34371.778561640655	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_379
Epoch: 379	max: 0.99978167/1.0	min: 0.00021829929	loss: 34329.984375	train_loss: 34371.75048386597	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_380
Epoch: 380	max: 0.9997813/1.0	min: 0.00021869532	loss: 34329.89453125	train_loss: 34371.71110298216	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_381
Epoch: 381	max: 0.9997929/1.0	min: 0.00020720118	loss: 34329.859375	train_loss: 34371.666465378425	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_382
Epoch: 382	max: 0.9998049/1.0	min: 0.00019512266	loss: 34329.88671875	train_loss: 34371.64522317834	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_383
Epoch: 383	max: 0.9998161/1.0	min: 0.00018388167	loss: 34329.90234375	train_loss: 34371.59717577109	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_384
Epoch: 384	max: 0.99982244/1.0	min: 0.00017754271	loss: 34329.953125	train_loss: 34371.56933944553	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_385
Epoch: 385	max: 0.99978966/1.0	min: 0.00021039421	loss: 34329.65625	train_loss: 34371.519584959125	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_386
Epoch: 386	max: 0.99979573/1.0	min: 0.00020432175	loss: 34329.67578125	train_loss: 34371.48263114703	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_387
Epoch: 387	max: 0.9997987/1.0	min: 0.00020136307	loss: 34329.60546875	train_loss: 34371.441193348976	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_388
Epoch: 388	max: 0.99982053/1.0	min: 0.00017945026	loss: 34329.73046875	train_loss: 34371.41828616608	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_389
Epoch: 389	max: 0.9997993/1.0	min: 0.00020072685	loss: 34329.59375	train_loss: 34371.369249736774	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_390
Epoch: 390	max: 0.9997912/1.0	min: 0.00020883609	loss: 34329.5	train_loss: 34371.32700194708	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_391
Epoch: 391	max: 0.99982315/1.0	min: 0.00017690462	loss: 34329.67578125	train_loss: 34371.30796617583	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_392
Epoch: 392	max: 0.99979585/1.0	min: 0.00020421795	loss: 34329.38671875	train_loss: 34371.26289841524	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_393
Epoch: 393	max: 0.999803/1.0	min: 0.00019703637	loss: 34329.3828125	train_loss: 34371.22714168757	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_394
Epoch: 394	max: 0.9998204/1.0	min: 0.0001796129	loss: 34329.4609375	train_loss: 34371.19631942509	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_395
Epoch: 395	max: 0.99980956/1.0	min: 0.00019046925	loss: 34329.42578125	train_loss: 34371.1939629978	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_396
Epoch: 396	max: 0.9998004/1.0	min: 0.00019961716	loss: 34329.28515625	train_loss: 34371.11687976124	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_397
Epoch: 397	max: 0.99982363/1.0	min: 0.00017634548	loss: 34329.4609375	train_loss: 34371.07870999396	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_398
Epoch: 398	max: 0.9998098/1.0	min: 0.00019023058	loss: 34329.453125	train_loss: 34371.05062012263	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_399
Epoch: 399	max: 0.99980444/1.0	min: 0.00019559693	loss: 34329.26171875	train_loss: 34371.0183951327	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_400
Epoch: 400	max: 0.99981755/1.0	min: 0.00018244504	loss: 34329.31640625	train_loss: 34370.98123422597	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_401
Epoch: 401	max: 0.9998293/1.0	min: 0.00017071758	loss: 34329.3984375	train_loss: 34370.93886692137	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_402
Epoch: 402	max: 0.99982005/1.0	min: 0.00018002818	loss: 34329.26953125	train_loss: 34370.8988071736	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_403
Epoch: 403	max: 0.9998204/1.0	min: 0.00017963516	loss: 34329.09765625	train_loss: 34370.86686911619	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_404
Epoch: 404	max: 0.99982315/1.0	min: 0.00017688372	loss: 34329.1484375	train_loss: 34370.82937676127	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_405
Epoch: 405	max: 0.9998098/1.0	min: 0.00019021046	loss: 34328.96875	train_loss: 34370.79731822123	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_406
Epoch: 406	max: 0.99982375/1.0	min: 0.0001763048	loss: 34329.05859375	train_loss: 34370.790077166945	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_407
Epoch: 407	max: 0.9998197/1.0	min: 0.00018037405	loss: 34329.02734375	train_loss: 34370.72479251827	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_408
Epoch: 408	max: 0.99981886/1.0	min: 0.00018114151	loss: 34328.9140625	train_loss: 34370.69184076165	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_409
Epoch: 409	max: 0.9998098/1.0	min: 0.00019027956	loss: 34328.88671875	train_loss: 34370.66579086926	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_410
Epoch: 410	max: 0.9998172/1.0	min: 0.00018284244	loss: 34328.93359375	train_loss: 34370.63102461523	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_411
Epoch: 411	max: 0.9998216/1.0	min: 0.00017843676	loss: 34328.98046875	train_loss: 34370.590756321224	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_412
Epoch: 412	max: 0.99983025/1.0	min: 0.00016969316	loss: 34328.9140625	train_loss: 34370.56070147018	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_413
Epoch: 413	max: 0.9998235/1.0	min: 0.0001765107	loss: 34328.87109375	train_loss: 34370.52601215084	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_414
Epoch: 414	max: 0.9998203/1.0	min: 0.00017975955	loss: 34328.78125	train_loss: 34370.52742455562	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_415
Epoch: 415	max: 0.9998198/1.0	min: 0.00018020815	loss: 34328.7734375	train_loss: 34370.48404161634	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_416
Epoch: 416	max: 0.9998311/1.0	min: 0.00016889752	loss: 34328.75390625	train_loss: 34370.42680607813	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_417
Epoch: 417	max: 0.9998541/1.0	min: 0.00014589138	loss: 34328.82421875	train_loss: 34370.39353496996	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_418
Epoch: 418	max: 0.9998646/1.0	min: 0.00013535908	loss: 34328.91015625	train_loss: 34370.36835845566	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_419
Epoch: 419	max: 0.99984515/1.0	min: 0.00015480795	loss: 34328.859375	train_loss: 34370.341008415395	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_420
Epoch: 420	max: 0.9998369/1.0	min: 0.00016300303	loss: 34328.67578125	train_loss: 34370.30216220349	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_421
Epoch: 421	max: 0.9998517/1.0	min: 0.00014827625	loss: 34328.6640625	train_loss: 34370.290754579306	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_422
Epoch: 422	max: 0.99985635/1.0	min: 0.00014366192	loss: 34328.61328125	train_loss: 34370.23947833442	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_423
Epoch: 423	max: 0.9998184/1.0	min: 0.00018161177	loss: 34328.66015625	train_loss: 34370.207857209214	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_424
Epoch: 424	max: 0.99983776/1.0	min: 0.00016225221	loss: 34328.546875	train_loss: 34370.17993136845	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_425
Epoch: 425	max: 0.99985933/1.0	min: 0.00014067556	loss: 34328.5859375	train_loss: 34370.137835512665	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_426
Epoch: 426	max: 0.99984527/1.0	min: 0.00015475924	loss: 34328.609375	train_loss: 34370.114978651836	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_427
Epoch: 427	max: 0.9998659/1.0	min: 0.00013407707	loss: 34328.62109375	train_loss: 34370.07480519556	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_428
Epoch: 428	max: 0.99985516/1.0	min: 0.00014482193	loss: 34328.5625	train_loss: 34370.05087608773	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_429
Epoch: 429	max: 0.9998628/1.0	min: 0.00013723342	loss: 34328.41015625	train_loss: 34370.017240628484	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_430
Epoch: 430	max: 0.99986875/1.0	min: 0.00013128205	loss: 34328.5234375	train_loss: 34370.00428414933	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_431
Epoch: 431	max: 0.99984765/1.0	min: 0.0001523337	loss: 34328.2890625	train_loss: 34369.9615220101	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_432
Epoch: 432	max: 0.99985695/1.0	min: 0.00014306439	loss: 34328.38671875	train_loss: 34369.94179914917	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_433
Epoch: 433	max: 0.99987817/1.0	min: 0.00012185324	loss: 34328.4609375	train_loss: 34369.90785740276	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_434
Epoch: 434	max: 0.9998634/1.0	min: 0.00013656271	loss: 34328.3359375	train_loss: 34369.86978392481	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_435
Epoch: 435	max: 0.9998627/1.0	min: 0.00013733984	loss: 34328.234375	train_loss: 34369.83742103307	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_436
Epoch: 436	max: 0.99987555/1.0	min: 0.00012439047	loss: 34328.4453125	train_loss: 34369.80412911867	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_437
Epoch: 437	max: 0.99987376/1.0	min: 0.00012617138	loss: 34328.3671875	train_loss: 34369.793028265514	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_438
Epoch: 438	max: 0.9998574/1.0	min: 0.00014260963	loss: 34328.30078125	train_loss: 34369.75646638486	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_439
Epoch: 439	max: 0.9998698/1.0	min: 0.00013019348	loss: 34328.2734375	train_loss: 34369.71346231265	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_440
Epoch: 440	max: 0.9998609/1.0	min: 0.00013909003	loss: 34328.10546875	train_loss: 34369.69012594064	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_441
Epoch: 441	max: 0.9998584/1.0	min: 0.00014165387	loss: 34328.03125	train_loss: 34369.692143177876	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_442
Epoch: 442	max: 0.9998399/1.0	min: 0.00016005333	loss: 34327.9453125	train_loss: 34369.62368291682	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_443
Epoch: 443	max: 0.9998683/1.0	min: 0.00013171566	loss: 34327.9296875	train_loss: 34369.652436652264	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_444
Epoch: 444	max: 0.99986076/1.0	min: 0.00013924464	loss: 34328.0234375	train_loss: 34369.57716065511	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_445
Epoch: 445	max: 0.9998485/1.0	min: 0.00015154773	loss: 34328.01171875	train_loss: 34369.54877998034	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_446
Epoch: 446	max: 0.99988663/1.0	min: 0.00011332327	loss: 34327.9375	train_loss: 34369.54925513672	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_447
Epoch: 447	max: 0.9998714/1.0	min: 0.00012860977	loss: 34327.83203125	train_loss: 34369.50965264229	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_448
Epoch: 448	max: 0.9998573/1.0	min: 0.00014272769	loss: 34328.015625	train_loss: 34369.47619960052	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_449
Epoch: 449	max: 0.99988115/1.0	min: 0.00011878752	loss: 34327.890625	train_loss: 34369.43632807661	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_450
Epoch: 450	max: 0.99988604/1.0	min: 0.000113956004	loss: 34327.93359375	train_loss: 34369.405968390005	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_451
Epoch: 451	max: 0.9998745/1.0	min: 0.00012545541	loss: 34327.91015625	train_loss: 34369.36844071287	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_452
Epoch: 452	max: 0.99987996/1.0	min: 0.000120071316	loss: 34327.7734375	train_loss: 34369.34957574632	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_453
Epoch: 453	max: 0.9998642/1.0	min: 0.00013577766	loss: 34327.80078125	train_loss: 34369.330421427905	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_454
Epoch: 454	max: 0.99986064/1.0	min: 0.00013934639	loss: 34327.78125	train_loss: 34369.31758059272	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_455
Epoch: 455	max: 0.9998684/1.0	min: 0.00013160906	loss: 34327.70703125	train_loss: 34369.27223364146	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_456
Epoch: 456	max: 0.9998807/1.0	min: 0.000119305834	loss: 34327.73828125	train_loss: 34369.24483231141	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_457
Epoch: 457	max: 0.9998666/1.0	min: 0.00013340564	loss: 34327.82421875	train_loss: 34369.214103435064	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_458
Epoch: 458	max: 0.9998981/1.0	min: 0.000101910584	loss: 34327.703125	train_loss: 34369.191741085255	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_459
Epoch: 459	max: 0.99990714/1.0	min: 9.280326e-05	loss: 34327.7578125	train_loss: 34369.1686882587	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_460
Epoch: 460	max: 0.9999136/1.0	min: 8.636702e-05	loss: 34327.703125	train_loss: 34369.13655181624	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_461
Epoch: 461	max: 0.9999201/1.0	min: 7.9908124e-05	loss: 34327.86328125	train_loss: 34369.156178387835	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_462
Epoch: 462	max: 0.9999113/1.0	min: 8.872943e-05	loss: 34327.71875	train_loss: 34369.157151442305	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_463
Epoch: 463	max: 0.99990106/1.0	min: 9.893891e-05	loss: 34327.58984375	train_loss: 34369.0566186091	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_464
Epoch: 464	max: 0.99987733/1.0	min: 0.0001226911	loss: 34327.53515625	train_loss: 34369.039891846274	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_465
Epoch: 465	max: 0.99990344/1.0	min: 9.651467e-05	loss: 34327.70703125	train_loss: 34369.0138787277	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_466
Epoch: 466	max: 0.9999083/1.0	min: 9.162793e-05	loss: 34327.68359375	train_loss: 34368.99352393782	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_467
Epoch: 467	max: 0.99991894/1.0	min: 8.105934e-05	loss: 34327.53125	train_loss: 34368.95820220566	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_468
Epoch: 468	max: 0.999907/1.0	min: 9.2998074e-05	loss: 34327.484375	train_loss: 34368.93466357767	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_469
Epoch: 469	max: 0.9999113/1.0	min: 8.866954e-05	loss: 34327.671875	train_loss: 34368.909141583055	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_470
Epoch: 470	max: 0.9999124/1.0	min: 8.755174e-05	loss: 34327.5390625	train_loss: 34368.888622762606	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_471
Epoch: 471	max: 0.9999026/1.0	min: 9.7428834e-05	loss: 34327.40234375	train_loss: 34368.864123660656	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_472
Epoch: 472	max: 0.9999069/1.0	min: 9.313083e-05	loss: 34327.375	train_loss: 34368.839310045834	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_473
Epoch: 473	max: 0.99988496/1.0	min: 0.00011503557	loss: 34327.32421875	train_loss: 34368.80553474932	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_474
Epoch: 474	max: 0.9998909/1.0	min: 0.0001090638	loss: 34327.203125	train_loss: 34368.786099788646	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_475
Epoch: 475	max: 0.99990046/1.0	min: 9.954902e-05	loss: 34327.234375	train_loss: 34368.761804878144	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_476
Epoch: 476	max: 0.999892/1.0	min: 0.00010797426	loss: 34327.23828125	train_loss: 34368.73209163648	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_477
Epoch: 477	max: 0.99988806/1.0	min: 0.00011196334	loss: 34327.28125	train_loss: 34368.71888354701	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_478
Epoch: 478	max: 0.9999014/1.0	min: 9.8618555e-05	loss: 34327.06640625	train_loss: 34368.685071476684	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_479
Epoch: 479	max: 0.99990153/1.0	min: 9.8419194e-05	loss: 34327.171875	train_loss: 34368.667911653814	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_480
Epoch: 480	max: 0.99989605/1.0	min: 0.00010389154	loss: 34327.31640625	train_loss: 34368.637568902515	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_481
Epoch: 481	max: 0.99992526/1.0	min: 7.474252e-05	loss: 34327.23828125	train_loss: 34368.61494768441	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_482
Epoch: 482	max: 0.9999114/1.0	min: 8.8551926e-05	loss: 34327.140625	train_loss: 34368.60017428852	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_483
Epoch: 483	max: 0.999887/1.0	min: 0.00011300419	loss: 34327.00390625	train_loss: 34368.572114416886	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_484
Epoch: 484	max: 0.9999089/1.0	min: 9.112673e-05	loss: 34327.16015625	train_loss: 34368.57554938143	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_485
Epoch: 485	max: 0.99992144/1.0	min: 7.8597e-05	loss: 34327.18359375	train_loss: 34368.52124945807	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_486
Epoch: 486	max: 0.99991894/1.0	min: 8.101111e-05	loss: 34327.109375	train_loss: 34368.492300240774	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_487
Epoch: 487	max: 0.9999254/1.0	min: 7.463249e-05	loss: 34327.10546875	train_loss: 34368.46490713644	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_488
Epoch: 488	max: 0.9999318/1.0	min: 6.815281e-05	loss: 34327.1484375	train_loss: 34368.44897342995	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_489
Epoch: 489	max: 0.9999168/1.0	min: 8.318911e-05	loss: 34327.12890625	train_loss: 34368.444255736715	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_490
Epoch: 490	max: 0.9999112/1.0	min: 8.8799854e-05	loss: 34326.91015625	train_loss: 34368.40893642388	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_491
Epoch: 491	max: 0.9999267/1.0	min: 7.326637e-05	loss: 34327.015625	train_loss: 34368.38070961848	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_492
Epoch: 492	max: 0.9999131/1.0	min: 8.684827e-05	loss: 34327.06640625	train_loss: 34368.35937064521	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_493
Epoch: 493	max: 0.99990666/1.0	min: 9.33225e-05	loss: 34326.87109375	train_loss: 34368.338633601204	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_494
Epoch: 494	max: 0.99992514/1.0	min: 7.483873e-05	loss: 34326.953125	train_loss: 34368.312809190356	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_495
Epoch: 495	max: 0.99995077/1.0	min: 4.922401e-05	loss: 34327.05078125	train_loss: 34368.29323632788	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_496
Epoch: 496	max: 0.99993706/1.0	min: 6.297995e-05	loss: 34326.828125	train_loss: 34368.31174710455	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_497
Epoch: 497	max: 0.99991965/1.0	min: 8.0356214e-05	loss: 34326.87109375	train_loss: 34368.26643354004	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_498
Epoch: 498	max: 0.9999176/1.0	min: 8.2336985e-05	loss: 34326.8046875	train_loss: 34368.23922188545	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_499
Epoch: 499	max: 0.99990034/1.0	min: 9.967564e-05	loss: 34326.8203125	train_loss: 34368.19674184008	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_500
Epoch: 500	max: 0.9999026/1.0	min: 9.740877e-05	loss: 34326.78125	train_loss: 34368.19788957017	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_501
Epoch: 501	max: 0.99993217/1.0	min: 6.780477e-05	loss: 34327.0390625	train_loss: 34368.16275557801	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_502
Epoch: 502	max: 0.9999362/1.0	min: 6.375121e-05	loss: 34326.75390625	train_loss: 34368.13923243373	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_503
Epoch: 503	max: 0.9999205/1.0	min: 7.9478436e-05	loss: 34326.62109375	train_loss: 34368.11843103555	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_504
Epoch: 504	max: 0.9999392/1.0	min: 6.084721e-05	loss: 34326.765625	train_loss: 34368.11844700313	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_505
Epoch: 505	max: 0.9999269/1.0	min: 7.301451e-05	loss: 34326.96484375	train_loss: 34368.090441808345	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_506
Epoch: 506	max: 0.99992406/1.0	min: 7.595755e-05	loss: 34326.63671875	train_loss: 34368.06170887913	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_507
Epoch: 507	max: 0.999933/1.0	min: 6.7033034e-05	loss: 34326.68359375	train_loss: 34368.017300627864	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_508
Epoch: 508	max: 0.9999299/1.0	min: 7.0078095e-05	loss: 34326.67578125	train_loss: 34368.01823981172	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_509
Epoch: 509	max: 0.9999422/1.0	min: 5.7807996e-05	loss: 34326.71484375	train_loss: 34367.982453084354	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_510
Epoch: 510	max: 0.9999434/1.0	min: 5.6578858e-05	loss: 34326.8203125	train_loss: 34367.968040652486	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_511
Epoch: 511	max: 0.99994147/1.0	min: 5.8559144e-05	loss: 34326.61328125	train_loss: 34367.96685856791	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_512
Epoch: 512	max: 0.99994814/1.0	min: 5.1838193e-05	loss: 34326.671875	train_loss: 34367.92971846742	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_513
Epoch: 513	max: 0.9999422/1.0	min: 5.7833695e-05	loss: 34326.671875	train_loss: 34367.90059699384	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_514
Epoch: 514	max: 0.9999341/1.0	min: 6.593283e-05	loss: 34326.65625	train_loss: 34367.885527471975	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_515
Epoch: 515	max: 0.9999279/1.0	min: 7.2080504e-05	loss: 34326.45703125	train_loss: 34367.86608235012	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_516
Epoch: 516	max: 0.9999254/1.0	min: 7.465839e-05	loss: 34326.515625	train_loss: 34367.86547074353	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_517
Epoch: 517	max: 0.99991786/1.0	min: 8.216334e-05	loss: 34326.29296875	train_loss: 34367.82452600489	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_518
Epoch: 518	max: 0.99990964/1.0	min: 9.03922e-05	loss: 34326.4609375	train_loss: 34367.825034548034	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_519
Epoch: 519	max: 0.9999194/1.0	min: 8.053172e-05	loss: 34326.2890625	train_loss: 34367.79107538245	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_520
Epoch: 520	max: 0.9999256/1.0	min: 7.4350755e-05	loss: 34326.44921875	train_loss: 34367.78417545367	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_521
Epoch: 521	max: 0.99994266/1.0	min: 5.7366095e-05	loss: 34326.33984375	train_loss: 34367.74182218119	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_522
Epoch: 522	max: 0.99994624/1.0	min: 5.372362e-05	loss: 34326.578125	train_loss: 34367.71356198904	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_523
Epoch: 523	max: 0.9999293/1.0	min: 7.070114e-05	loss: 34326.26953125	train_loss: 34367.68919401477	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_524
Epoch: 524	max: 0.999925/1.0	min: 7.500663e-05	loss: 34326.35546875	train_loss: 34367.68258827651	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_525
Epoch: 525	max: 0.99993825/1.0	min: 6.17395e-05	loss: 34326.203125	train_loss: 34367.683589879074	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_526
Epoch: 526	max: 0.9999497/1.0	min: 5.0287385e-05	loss: 34326.26171875	train_loss: 34367.64656397095	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_527
Epoch: 527	max: 0.9999391/1.0	min: 6.096681e-05	loss: 34326.25	train_loss: 34367.623450177285	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_528
Epoch: 528	max: 0.9999255/1.0	min: 7.4559364e-05	loss: 34326.2109375	train_loss: 34367.60351151214	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_529
Epoch: 529	max: 0.9999393/1.0	min: 6.0711645e-05	loss: 34326.296875	train_loss: 34367.57275457156	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_530
Epoch: 530	max: 0.999956/1.0	min: 4.3982727e-05	loss: 34326.43359375	train_loss: 34367.55837601031	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_531
Epoch: 531	max: 0.9999523/1.0	min: 4.773715e-05	loss: 34326.21875	train_loss: 34367.54700806314	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_532
Epoch: 532	max: 0.9999449/1.0	min: 5.508975e-05	loss: 34326.11328125	train_loss: 34367.517128371575	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_533
Epoch: 533	max: 0.9999399/1.0	min: 6.005818e-05	loss: 34326.12890625	train_loss: 34367.50939280627	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_534
Epoch: 534	max: 0.9999509/1.0	min: 4.9066868e-05	loss: 34326.390625	train_loss: 34367.47422107256	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_535
Epoch: 535	max: 0.9999509/1.0	min: 4.9149054e-05	loss: 34326.375	train_loss: 34367.49563988372	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_536
Epoch: 536	max: 0.9999684/1.0	min: 3.1610973e-05	loss: 34326.57421875	train_loss: 34367.469414831845	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_537
Epoch: 537	max: 0.99996364/1.0	min: 3.6312977e-05	loss: 34326.28125	train_loss: 34367.45936106466	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_538
Epoch: 538	max: 0.99996126/1.0	min: 3.8717408e-05	loss: 34326.3515625	train_loss: 34367.42544593088	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_539
Epoch: 539	max: 0.99994946/1.0	min: 5.0527637e-05	loss: 34326.15625	train_loss: 34367.40785933823	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_540
Epoch: 540	max: 0.99992824/1.0	min: 7.174529e-05	loss: 34326.0859375	train_loss: 34367.361033692556	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_541
Epoch: 541	max: 0.9999542/1.0	min: 4.5768313e-05	loss: 34326.13671875	train_loss: 34367.345497723894	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_542
Epoch: 542	max: 0.99995494/1.0	min: 4.5011697e-05	loss: 34326.2265625	train_loss: 34367.34627094172	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_543
Epoch: 543	max: 0.99993277/1.0	min: 6.721956e-05	loss: 34326.01953125	train_loss: 34367.32933466493	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_544
Epoch: 544	max: 0.99993765/1.0	min: 6.237259e-05	loss: 34325.9765625	train_loss: 34367.29853466029	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_545
Epoch: 545	max: 0.9999608/1.0	min: 3.9265975e-05	loss: 34326.18359375	train_loss: 34367.27383814102	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_546
Epoch: 546	max: 0.9999317/1.0	min: 6.826013e-05	loss: 34325.76171875	train_loss: 34367.29950384383	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_547
Epoch: 547	max: 0.99995804/1.0	min: 4.190686e-05	loss: 34325.98828125	train_loss: 34367.245344725474	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_548
Epoch: 548	max: 0.99995303/1.0	min: 4.693743e-05	loss: 34325.80859375	train_loss: 34367.22723749303	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_549
Epoch: 549	max: 0.9999505/1.0	min: 4.945951e-05	loss: 34325.74609375	train_loss: 34367.189511914716	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_550
Epoch: 550	max: 0.9999466/1.0	min: 5.339633e-05	loss: 34325.8046875	train_loss: 34367.18824612133	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_551
Epoch: 551	max: 0.99995816/1.0	min: 4.179599e-05	loss: 34325.890625	train_loss: 34367.17175306578	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_552
Epoch: 552	max: 0.99995923/1.0	min: 4.0722956e-05	loss: 34325.9609375	train_loss: 34367.13334813963	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_553
Epoch: 553	max: 0.9999478/1.0	min: 5.2167026e-05	loss: 34325.80078125	train_loss: 34367.133804909114	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_554
Epoch: 554	max: 0.99994195/1.0	min: 5.8063575e-05	loss: 34325.8046875	train_loss: 34367.111613847854	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_555
Epoch: 555	max: 0.9999311/1.0	min: 6.886314e-05	loss: 34325.73828125	train_loss: 34367.1129101248	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_556
Epoch: 556	max: 0.99994683/1.0	min: 5.3127234e-05	loss: 34325.63671875	train_loss: 34367.10318103168	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_557
Epoch: 557	max: 0.9999347/1.0	min: 6.5361404e-05	loss: 34325.69921875	train_loss: 34367.07938789019	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_558
Epoch: 558	max: 0.99995816/1.0	min: 4.1855343e-05	loss: 34325.640625	train_loss: 34367.047485154995	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_559
Epoch: 559	max: 0.99993503/1.0	min: 6.5003995e-05	loss: 34325.6484375	train_loss: 34367.04266004351	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_560
Epoch: 560	max: 0.9999436/1.0	min: 5.64373e-05	loss: 34325.8046875	train_loss: 34367.00775830701	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_561
Epoch: 561	max: 0.99995136/1.0	min: 4.8624403e-05	loss: 34325.87109375	train_loss: 34366.98740158166	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_562
Epoch: 562	max: 0.9999448/1.0	min: 5.515777e-05	loss: 34325.640625	train_loss: 34366.958603330546	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_563
Epoch: 563	max: 0.99995625/1.0	min: 4.3734537e-05	loss: 34325.69140625	train_loss: 34366.95637416001	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_564
Epoch: 564	max: 0.9999615/1.0	min: 3.8499184e-05	loss: 34325.80078125	train_loss: 34366.92181838768	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_565
Epoch: 565	max: 0.99995065/1.0	min: 4.9370454e-05	loss: 34325.4375	train_loss: 34366.90238439474	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_566
Epoch: 566	max: 0.99995184/1.0	min: 4.81131e-05	loss: 34325.6953125	train_loss: 34366.89277191332	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_567
Epoch: 567	max: 0.9999465/1.0	min: 5.3513268e-05	loss: 34325.70703125	train_loss: 34366.86309447773	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_568
Epoch: 568	max: 0.999964/1.0	min: 3.5960886e-05	loss: 34325.671875	train_loss: 34366.85049751099	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_569
Epoch: 569	max: 0.9999664/1.0	min: 3.3614928e-05	loss: 34325.53515625	train_loss: 34366.828594349994	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_570
Epoch: 570	max: 0.9999552/1.0	min: 4.4763252e-05	loss: 34325.48828125	train_loss: 34366.809529546794	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_571
Epoch: 571	max: 0.9999733/1.0	min: 2.6727143e-05	loss: 34325.62109375	train_loss: 34366.790772482345	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_572
Epoch: 572	max: 0.99997425/1.0	min: 2.5729261e-05	loss: 34325.7109375	train_loss: 34366.78671768549	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_573
Epoch: 573	max: 0.9999479/1.0	min: 5.205492e-05	loss: 34325.44140625	train_loss: 34366.772760571504	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_574
Epoch: 574	max: 0.99996674/1.0	min: 3.3211218e-05	loss: 34325.453125	train_loss: 34366.74311120014	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_575
Epoch: 575	max: 0.9999486/1.0	min: 5.1339004e-05	loss: 34325.53515625	train_loss: 34366.71565664483	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_576
Epoch: 576	max: 0.9999356/1.0	min: 6.435697e-05	loss: 34325.66796875	train_loss: 34366.73724964775	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_577
Epoch: 577	max: 0.9999435/1.0	min: 5.64905e-05	loss: 34325.4453125	train_loss: 34366.70223081568	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_578
Epoch: 578	max: 0.9999647/1.0	min: 3.530915e-05	loss: 34325.66015625	train_loss: 34366.66619634894	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_579
Epoch: 579	max: 0.9999565/1.0	min: 4.355839e-05	loss: 34325.328125	train_loss: 34366.671875483866	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_580
Epoch: 580	max: 0.9999579/1.0	min: 4.2035383e-05	loss: 34325.36328125	train_loss: 34366.64174708519	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_581
Epoch: 581	max: 0.9999473/1.0	min: 5.2707284e-05	loss: 34325.32421875	train_loss: 34366.6106732124	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_582
Epoch: 582	max: 0.9999527/1.0	min: 4.734337e-05	loss: 34325.31640625	train_loss: 34366.6027257138	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_583
Epoch: 583	max: 0.999969/1.0	min: 3.1018622e-05	loss: 34325.37109375	train_loss: 34366.569737667225	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_584
Epoch: 584	max: 0.99995923/1.0	min: 4.072618e-05	loss: 34325.37890625	train_loss: 34366.543366971695	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_585
Epoch: 585	max: 0.99996793/1.0	min: 3.2062915e-05	loss: 34325.3828125	train_loss: 34366.531232580826	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_586
Epoch: 586	max: 0.99996316/1.0	min: 3.6873833e-05	loss: 34325.203125	train_loss: 34366.511099401556	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_587
Epoch: 587	max: 0.9999727/1.0	min: 2.7258171e-05	loss: 34325.33984375	train_loss: 34366.51381437353	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_588
Epoch: 588	max: 0.9999682/1.0	min: 3.1831438e-05	loss: 34325.2890625	train_loss: 34366.471710292026	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_589
Epoch: 589	max: 0.99995613/1.0	min: 4.383796e-05	loss: 34325.2734375	train_loss: 34366.453292417624	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_590
Epoch: 590	max: 0.9999584/1.0	min: 4.157576e-05	loss: 34325.25390625	train_loss: 34366.43886353431	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_591
Epoch: 591	max: 0.99997807/1.0	min: 2.199037e-05	loss: 34325.47265625	train_loss: 34366.414853137	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_592
Epoch: 592	max: 0.99997413/1.0	min: 2.5836442e-05	loss: 34325.2265625	train_loss: 34366.44928745897	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_593
Epoch: 593	max: 0.99995995/1.0	min: 3.9994102e-05	loss: 34325.140625	train_loss: 34366.37383485074	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_594
Epoch: 594	max: 0.9999665/1.0	min: 3.348858e-05	loss: 34325.17578125	train_loss: 34366.38658810619	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_595
Epoch: 595	max: 0.9999678/1.0	min: 3.215251e-05	loss: 34325.1796875	train_loss: 34366.35680034916	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_596
Epoch: 596	max: 0.99996173/1.0	min: 3.8288035e-05	loss: 34324.9453125	train_loss: 34366.34227082172	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_597
Epoch: 597	max: 0.99996996/1.0	min: 3.0040606e-05	loss: 34324.99609375	train_loss: 34366.3209865253	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_598
Epoch: 598	max: 0.99995995/1.0	min: 4.006522e-05	loss: 34324.94921875	train_loss: 34366.291690859965	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_599
Epoch: 599	max: 0.999969/1.0	min: 3.1021347e-05	loss: 34325.00390625	train_loss: 34366.276233761455	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_600
Epoch: 600	max: 0.9999578/1.0	min: 4.2141462e-05	loss: 34324.97265625	train_loss: 34366.254621887776	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_601
Epoch: 601	max: 0.9999585/1.0	min: 4.149765e-05	loss: 34324.86328125	train_loss: 34366.246893096584	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_602
Epoch: 602	max: 0.9999665/1.0	min: 3.349385e-05	loss: 34324.9140625	train_loss: 34366.27604505373	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_603
Epoch: 603	max: 0.9999722/1.0	min: 2.7792119e-05	loss: 34325.11328125	train_loss: 34366.19135399247	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_604
Epoch: 604	max: 0.9999598/1.0	min: 4.0193037e-05	loss: 34324.96875	train_loss: 34366.18214408754	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_605
Epoch: 605	max: 0.999974/1.0	min: 2.5956808e-05	loss: 34325.05859375	train_loss: 34366.1686427753	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_606
Epoch: 606	max: 0.99996114/1.0	min: 3.8827257e-05	loss: 34324.8359375	train_loss: 34366.117583302366	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_607
Epoch: 607	max: 0.9999728/1.0	min: 2.7226219e-05	loss: 34325.09375	train_loss: 34366.12890721773	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_608
Epoch: 608	max: 0.9999702/1.0	min: 2.9802544e-05	loss: 34324.9453125	train_loss: 34366.11155771941	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_609
Epoch: 609	max: 0.99997544/1.0	min: 2.4569637e-05	loss: 34325.07421875	train_loss: 34366.065670289856	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_610
Epoch: 610	max: 0.9999882/1.0	min: 1.176883e-05	loss: 34325.26171875	train_loss: 34366.05832520439	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_611
Epoch: 611	max: 0.9999733/1.0	min: 2.6691738e-05	loss: 34324.8515625	train_loss: 34366.05043044717	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_612
Epoch: 612	max: 0.99996984/1.0	min: 3.0147798e-05	loss: 34324.6796875	train_loss: 34366.03303788477	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_613
Epoch: 613	max: 0.9999677/1.0	min: 3.2252257e-05	loss: 34324.88671875	train_loss: 34366.03275191998	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_614
Epoch: 614	max: 0.99996984/1.0	min: 3.0161342e-05	loss: 34324.7890625	train_loss: 34365.9602378298	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_615
Epoch: 615	max: 0.99995697/1.0	min: 4.3032018e-05	loss: 34324.8203125	train_loss: 34365.9536838652	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_616
Epoch: 616	max: 0.999961/1.0	min: 3.8925875e-05	loss: 34324.8359375	train_loss: 34365.97106336322	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_617
Epoch: 617	max: 0.99998236/1.0	min: 1.7611927e-05	loss: 34325.171875	train_loss: 34365.91310928403	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_618
Epoch: 618	max: 0.99995923/1.0	min: 4.081989e-05	loss: 34324.88671875	train_loss: 34365.89482350505	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_619
Epoch: 619	max: 0.9999652/1.0	min: 3.4820805e-05	loss: 34324.8125	train_loss: 34365.87380388332	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_620
Epoch: 620	max: 0.99998415/1.0	min: 1.5834543e-05	loss: 34325.00390625	train_loss: 34365.85124121299	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_621
Epoch: 621	max: 0.99997747/1.0	min: 2.2586246e-05	loss: 34324.734375	train_loss: 34365.838029736464	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_622
Epoch: 622	max: 0.99996376/1.0	min: 3.626111e-05	loss: 34324.6953125	train_loss: 34365.82728549254	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_623
Epoch: 623	max: 0.9999591/1.0	min: 4.088128e-05	loss: 34324.81640625	train_loss: 34365.79981061486	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_624
Epoch: 624	max: 0.9999747/1.0	min: 2.5258349e-05	loss: 34324.7890625	train_loss: 34365.75947264415	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_625
Epoch: 625	max: 0.99997914/1.0	min: 2.0837368e-05	loss: 34324.80078125	train_loss: 34365.73385581181	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_626
Epoch: 626	max: 0.99998343/1.0	min: 1.6564216e-05	loss: 34325.140625	train_loss: 34365.7080323687	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_627
Epoch: 627	max: 0.99997354/1.0	min: 2.6466629e-05	loss: 34324.67578125	train_loss: 34365.7132653792	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_628
Epoch: 628	max: 0.9999802/1.0	min: 1.9794443e-05	loss: 34324.68359375	train_loss: 34365.67637011489	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_629
Epoch: 629	max: 0.99998343/1.0	min: 1.6523778e-05	loss: 34324.6484375	train_loss: 34365.650212804256	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_630
Epoch: 630	max: 0.9999782/1.0	min: 2.181583e-05	loss: 34324.55078125	train_loss: 34365.64956393999	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_631
Epoch: 631	max: 0.9999771/1.0	min: 2.2859955e-05	loss: 34324.71484375	train_loss: 34365.61741878794	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_632
Epoch: 632	max: 0.9999795/1.0	min: 2.0468766e-05	loss: 34324.69921875	train_loss: 34365.58889005017	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_633
Epoch: 633	max: 0.9999654/1.0	min: 3.4530698e-05	loss: 34324.51953125	train_loss: 34365.56834461709	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_634
Epoch: 634	max: 0.9999666/1.0	min: 3.333134e-05	loss: 34324.4453125	train_loss: 34365.56896541713	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_635
Epoch: 635	max: 0.99997365/1.0	min: 2.640333e-05	loss: 34324.453125	train_loss: 34365.5434608417	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_636
Epoch: 636	max: 0.9999777/1.0	min: 2.2272843e-05	loss: 34324.62109375	train_loss: 34365.50707266893	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_637
Epoch: 637	max: 0.99997354/1.0	min: 2.6518448e-05	loss: 34324.49609375	train_loss: 34365.48484967252	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_638
Epoch: 638	max: 0.99997187/1.0	min: 2.8123683e-05	loss: 34324.42578125	train_loss: 34365.467196790225	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_639
Epoch: 639	max: 0.99997735/1.0	min: 2.2652599e-05	loss: 34324.40625	train_loss: 34365.43004072216	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_640
Epoch: 640	max: 0.9999802/1.0	min: 1.9820094e-05	loss: 34324.43359375	train_loss: 34365.413508957325	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_641
Epoch: 641	max: 0.999959/1.0	min: 4.105635e-05	loss: 34324.28125	train_loss: 34365.388131154774	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_642
Epoch: 642	max: 0.9999734/1.0	min: 2.6536685e-05	loss: 34324.46875	train_loss: 34365.4499866453	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_643
Epoch: 643	max: 0.99997663/1.0	min: 2.3373035e-05	loss: 34324.6484375	train_loss: 34365.38144654636	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_644
Epoch: 644	max: 0.99998176/1.0	min: 1.825214e-05	loss: 34324.671875	train_loss: 34365.33902214558	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_645
Epoch: 645	max: 0.99997723/1.0	min: 2.2798193e-05	loss: 34324.5703125	train_loss: 34365.316958824944	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_646
Epoch: 646	max: 0.99998116/1.0	min: 1.879016e-05	loss: 34324.63671875	train_loss: 34365.28360449182	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_647
Epoch: 647	max: 0.99998593/1.0	min: 1.4033309e-05	loss: 34324.48046875	train_loss: 34365.29964610043	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_648
Epoch: 648	max: 0.9999807/1.0	min: 1.9311827e-05	loss: 34324.546875	train_loss: 34365.29452147591	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_649
Epoch: 649	max: 0.999974/1.0	min: 2.5955722e-05	loss: 34324.33984375	train_loss: 34365.2292571496	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_650
Epoch: 650	max: 0.9999733/1.0	min: 2.6719803e-05	loss: 34324.34375	train_loss: 34365.19404622275	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_651
Epoch: 651	max: 0.99998045/1.0	min: 1.9562567e-05	loss: 34324.3203125	train_loss: 34365.16536845426	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_652
Epoch: 652	max: 0.9999852/1.0	min: 1.4814967e-05	loss: 34324.4609375	train_loss: 34365.14841282283	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_653
Epoch: 653	max: 0.9999759/1.0	min: 2.4021125e-05	loss: 34324.171875	train_loss: 34365.13754180602	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_654
Epoch: 654	max: 0.9999809/1.0	min: 1.908011e-05	loss: 34324.21875	train_loss: 34365.10665954416	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_655
Epoch: 655	max: 0.9999795/1.0	min: 2.046949e-05	loss: 34324.43359375	train_loss: 34365.07717130017	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_656
Epoch: 656	max: 0.99997723/1.0	min: 2.2729027e-05	loss: 34324.15625	train_loss: 34365.053107677595	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_657
Epoch: 657	max: 0.99997663/1.0	min: 2.3390965e-05	loss: 34324.24609375	train_loss: 34365.07539696364	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_658
Epoch: 658	max: 0.9999726/1.0	min: 2.7387723e-05	loss: 34324.30078125	train_loss: 34365.04115522034	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_659
Epoch: 659	max: 0.9999794/1.0	min: 2.0592372e-05	loss: 34324.17578125	train_loss: 34365.01939576753	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_660
Epoch: 660	max: 0.99998677/1.0	min: 1.3254855e-05	loss: 34324.17578125	train_loss: 34364.97541089899	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_661
Epoch: 661	max: 0.9999802/1.0	min: 1.9841142e-05	loss: 34324.21484375	train_loss: 34364.94548136922	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_662
Epoch: 662	max: 0.9999845/1.0	min: 1.5492455e-05	loss: 34324.265625	train_loss: 34364.918712452	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_663
Epoch: 663	max: 0.99998367/1.0	min: 1.6295895e-05	loss: 34324.1875	train_loss: 34364.89753363836	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_664
Epoch: 664	max: 0.9999814/1.0	min: 1.8651319e-05	loss: 34324.09375	train_loss: 34364.90069328317	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_665
Epoch: 665	max: 0.9999746/1.0	min: 2.5408232e-05	loss: 34324.04296875	train_loss: 34364.863449635355	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_666
Epoch: 666	max: 0.9999863/1.0	min: 1.3650987e-05	loss: 34324.24609375	train_loss: 34364.86616605893	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_667
Epoch: 667	max: 0.99998546/1.0	min: 1.4509565e-05	loss: 34324.1484375	train_loss: 34364.823221986095	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_668
Epoch: 668	max: 0.99998045/1.0	min: 1.9535832e-05	loss: 34323.99609375	train_loss: 34364.78510447634	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_669
Epoch: 669	max: 0.9999758/1.0	min: 2.4208783e-05	loss: 34324.0625	train_loss: 34364.76077037269	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_670
Epoch: 670	max: 0.9999763/1.0	min: 2.373193e-05	loss: 34323.8359375	train_loss: 34364.741049447235	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_671
Epoch: 671	max: 0.99998784/1.0	min: 1.21619705e-05	loss: 34324.19140625	train_loss: 34364.74843856451	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_672
Epoch: 672	max: 0.99998486/1.0	min: 1.5131673e-05	loss: 34324.16015625	train_loss: 34364.725543478264	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_673
Epoch: 673	max: 0.99998546/1.0	min: 1.4536753e-05	loss: 34324.15625	train_loss: 34364.67894960439	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_674
Epoch: 674	max: 0.99998045/1.0	min: 1.9601071e-05	loss: 34323.94921875	train_loss: 34364.653283901585	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_675
Epoch: 675	max: 0.9999771/1.0	min: 2.2869746e-05	loss: 34324.01953125	train_loss: 34364.63339894556	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_676
Epoch: 676	max: 0.9999778/1.0	min: 2.2139344e-05	loss: 34323.9453125	train_loss: 34364.604561985165	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_677
Epoch: 677	max: 0.9999865/1.0	min: 1.3529499e-05	loss: 34323.91015625	train_loss: 34364.58511686331	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_678
Epoch: 678	max: 0.9999838/1.0	min: 1.6206335e-05	loss: 34324.18359375	train_loss: 34364.55568910256	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_679
Epoch: 679	max: 0.9999776/1.0	min: 2.2406593e-05	loss: 34323.875	train_loss: 34364.54986674331	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_680
Epoch: 680	max: 0.99998546/1.0	min: 1.4528326e-05	loss: 34323.9375	train_loss: 34364.52113429797	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_681
Epoch: 681	max: 0.9999783/1.0	min: 2.1750975e-05	loss: 34323.90625	train_loss: 34364.48832770113	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_682
Epoch: 682	max: 0.999982/1.0	min: 1.795264e-05	loss: 34323.80859375	train_loss: 34364.46672114998	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_683
Epoch: 683	max: 0.99997556/1.0	min: 2.447014e-05	loss: 34323.765625	train_loss: 34364.462886028276	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_684
Epoch: 684	max: 0.99997604/1.0	min: 2.3975263e-05	loss: 34323.7265625	train_loss: 34364.4504985755	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_685
Epoch: 685	max: 0.9999869/1.0	min: 1.3166752e-05	loss: 34323.87890625	train_loss: 34364.43543292456	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_686
Epoch: 686	max: 0.99998736/1.0	min: 1.26617815e-05	loss: 34323.87109375	train_loss: 34364.404614533014	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_687
Epoch: 687	max: 0.99998796/1.0	min: 1.209401e-05	loss: 34324.11328125	train_loss: 34364.374577585004	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_688
Epoch: 688	max: 0.99998343/1.0	min: 1.6572054e-05	loss: 34323.80078125	train_loss: 34364.349946871516	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_689
Epoch: 689	max: 0.9999838/1.0	min: 1.61861e-05	loss: 34323.69140625	train_loss: 34364.31350547349	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_690
Epoch: 690	max: 0.9999851/1.0	min: 1.4873872e-05	loss: 34323.87890625	train_loss: 34364.29053974282	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_691
Epoch: 691	max: 0.99998844/1.0	min: 1.1559136e-05	loss: 34323.76953125	train_loss: 34364.27379410922	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_692
Epoch: 692	max: 0.99998176/1.0	min: 1.8198763e-05	loss: 34323.57421875	train_loss: 34364.24447328286	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_693
Epoch: 693	max: 0.9999846/1.0	min: 1.539948e-05	loss: 34323.71484375	train_loss: 34364.28200821798	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_694
Epoch: 694	max: 0.99998176/1.0	min: 1.8220711e-05	loss: 34323.70703125	train_loss: 34364.19767715301	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_695
Epoch: 695	max: 0.9999846/1.0	min: 1.5424144e-05	loss: 34323.9296875	train_loss: 34364.18520550756	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_696
Epoch: 696	max: 0.9999831/1.0	min: 1.6878688e-05	loss: 34323.8203125	train_loss: 34364.171767581756	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_697
Epoch: 697	max: 0.99998665/1.0	min: 1.3385746e-05	loss: 34323.76171875	train_loss: 34364.153938088384	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_698
Epoch: 698	max: 0.9999846/1.0	min: 1.5408441e-05	loss: 34323.53515625	train_loss: 34364.11408882231	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_699
Epoch: 699	max: 0.999987/1.0	min: 1.2959854e-05	loss: 34323.73828125	train_loss: 34364.090193101234	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_700
Epoch: 700	max: 0.99998415/1.0	min: 1.5825455e-05	loss: 34323.6796875	train_loss: 34364.072294415026	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_701
Epoch: 701	max: 0.9999819/1.0	min: 1.8104161e-05	loss: 34323.671875	train_loss: 34364.04985077574	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_702
Epoch: 702	max: 0.999979/1.0	min: 2.0922631e-05	loss: 34323.51953125	train_loss: 34364.049733196305	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_703
Epoch: 703	max: 0.99999094/1.0	min: 9.000448e-06	loss: 34323.69921875	train_loss: 34364.02670649852	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_704
Epoch: 704	max: 0.9999902/1.0	min: 9.7260645e-06	loss: 34323.765625	train_loss: 34363.990358970485	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_705
Epoch: 705	max: 0.9999846/1.0	min: 1.5422907e-05	loss: 34323.4453125	train_loss: 34363.96690453518	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_706
Epoch: 706	max: 0.9999827/1.0	min: 1.7266315e-05	loss: 34323.56640625	train_loss: 34363.94697264415	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_707
Epoch: 707	max: 0.9999839/1.0	min: 1.6136011e-05	loss: 34323.62890625	train_loss: 34363.92896750743	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_708
Epoch: 708	max: 0.9999813/1.0	min: 1.8746598e-05	loss: 34323.53515625	train_loss: 34363.908214011986	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_709
Epoch: 709	max: 0.9999862/1.0	min: 1.38334135e-05	loss: 34323.46875	train_loss: 34363.88167831816	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_710
Epoch: 710	max: 0.9999865/1.0	min: 1.3457102e-05	loss: 34323.54296875	train_loss: 34363.86385414731	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_711
Epoch: 711	max: 0.9999908/1.0	min: 9.134707e-06	loss: 34323.7421875	train_loss: 34363.835317183824	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_712
Epoch: 712	max: 0.9999814/1.0	min: 1.8563214e-05	loss: 34323.48046875	train_loss: 34363.825959699774	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_713
Epoch: 713	max: 0.99998605/1.0	min: 1.3945312e-05	loss: 34323.671875	train_loss: 34363.81311209046	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_714
Epoch: 714	max: 0.9999788/1.0	min: 2.1200003e-05	loss: 34323.44921875	train_loss: 34363.78272046869	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_715
Epoch: 715	max: 0.9999809/1.0	min: 1.911577e-05	loss: 34323.296875	train_loss: 34363.76036731234	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_716
Epoch: 716	max: 0.9999857/1.0	min: 1.43018615e-05	loss: 34323.42578125	train_loss: 34363.73740013006	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_717
Epoch: 717	max: 0.9999881/1.0	min: 1.19011065e-05	loss: 34323.5703125	train_loss: 34363.720881913476	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_718
Epoch: 718	max: 0.99997926/1.0	min: 2.0758724e-05	loss: 34323.5	train_loss: 34363.69539137015	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_719
Epoch: 719	max: 0.9999757/1.0	min: 2.4371047e-05	loss: 34323.23828125	train_loss: 34363.712808609715	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_720
Epoch: 720	max: 0.99998367/1.0	min: 1.6361939e-05	loss: 34323.20703125	train_loss: 34363.67223354468	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_721
Epoch: 721	max: 0.99998796/1.0	min: 1.2050628e-05	loss: 34323.37890625	train_loss: 34363.63433716168	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_722
Epoch: 722	max: 0.99998915/1.0	min: 1.0817559e-05	loss: 34323.2734375	train_loss: 34363.61575138579	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_723
Epoch: 723	max: 0.99998975/1.0	min: 1.0265638e-05	loss: 34323.4375	train_loss: 34363.593960481696	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_724
Epoch: 724	max: 0.9999908/1.0	min: 9.1231805e-06	loss: 34323.36328125	train_loss: 34363.59283065465	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_725
Epoch: 725	max: 0.99998903/1.0	min: 1.0992741e-05	loss: 34323.2734375	train_loss: 34363.5638238573	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_726
Epoch: 726	max: 0.9999875/1.0	min: 1.2457672e-05	loss: 34323.16796875	train_loss: 34363.527463264894	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_727
Epoch: 727	max: 0.9999863/1.0	min: 1.3756269e-05	loss: 34323.34375	train_loss: 34363.52660730599	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_728
Epoch: 728	max: 0.9999924/1.0	min: 7.652293e-06	loss: 34323.3984375	train_loss: 34363.49263410829	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_729
Epoch: 729	max: 0.9999858/1.0	min: 1.4234792e-05	loss: 34323.109375	train_loss: 34363.4917694398	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_730
Epoch: 730	max: 0.99998593/1.0	min: 1.4013435e-05	loss: 34323.25	train_loss: 34363.48601772498	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_731
Epoch: 731	max: 0.9999838/1.0	min: 1.6187365e-05	loss: 34323.37109375	train_loss: 34363.457893499166	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_732
Epoch: 732	max: 0.999987/1.0	min: 1.2996514e-05	loss: 34323.16015625	train_loss: 34363.43532405472	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_733
Epoch: 733	max: 0.99998903/1.0	min: 1.0947974e-05	loss: 34323.3671875	train_loss: 34363.39971780936	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_734
Epoch: 734	max: 0.99998546/1.0	min: 1.4511889e-05	loss: 34322.84375	train_loss: 34363.37320292178	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_735
Epoch: 735	max: 0.99998283/1.0	min: 1.7139531e-05	loss: 34322.9921875	train_loss: 34363.393887708255	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_736
Epoch: 736	max: 0.9999877/1.0	min: 1.2282069e-05	loss: 34323.1640625	train_loss: 34363.39051371082	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_737
Epoch: 737	max: 0.9999881/1.0	min: 1.1867649e-05	loss: 34323.1875	train_loss: 34363.32027524232	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_738
Epoch: 738	max: 0.9999914/1.0	min: 8.554263e-06	loss: 34323.5078125	train_loss: 34363.30656296451	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_739
Epoch: 739	max: 0.9999869/1.0	min: 1.310012e-05	loss: 34323.21875	train_loss: 34363.30719005481	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_740
Epoch: 740	max: 0.9999924/1.0	min: 7.62811e-06	loss: 34323.3359375	train_loss: 34363.262637611486	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_741
Epoch: 741	max: 0.99998915/1.0	min: 1.0810248e-05	loss: 34323.078125	train_loss: 34363.254744305865	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_742
Epoch: 742	max: 0.9999871/1.0	min: 1.2933754e-05	loss: 34322.9296875	train_loss: 34363.221652711974	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_743
Epoch: 743	max: 0.9999888/1.0	min: 1.1201344e-05	loss: 34323.19921875	train_loss: 34363.24942565109	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_744
Epoch: 744	max: 0.9999877/1.0	min: 1.2329059e-05	loss: 34323.23828125	train_loss: 34363.19603587963	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_745
Epoch: 745	max: 0.9999933/1.0	min: 6.6837106e-06	loss: 34323.24609375	train_loss: 34363.18559550353	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_746
Epoch: 746	max: 0.9999931/1.0	min: 6.90552e-06	loss: 34323.421875	train_loss: 34363.15358147916	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_747
Epoch: 747	max: 0.99999213/1.0	min: 7.901807e-06	loss: 34323.2890625	train_loss: 34363.15106731156	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_748
Epoch: 748	max: 0.9999908/1.0	min: 9.237626e-06	loss: 34323.453125	train_loss: 34363.13548392404	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_749
Epoch: 749	max: 0.99998975/1.0	min: 1.0198619e-05	loss: 34323.015625	train_loss: 34363.142064985135	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_750
Epoch: 750	max: 0.99998236/1.0	min: 1.761228e-05	loss: 34322.80859375	train_loss: 34363.09128228354	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_751
Epoch: 751	max: 0.9999912/1.0	min: 8.85831e-06	loss: 34323.15625	train_loss: 34363.09356129227	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_752
Epoch: 752	max: 0.9999839/1.0	min: 1.6092414e-05	loss: 34322.890625	train_loss: 34363.04226666047	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_753
Epoch: 753	max: 0.9999883/1.0	min: 1.1710747e-05	loss: 34323.0390625	train_loss: 34363.047186609685	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_754
Epoch: 754	max: 0.99999297/1.0	min: 7.0704386e-06	loss: 34323.05078125	train_loss: 34363.01016941115	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_755
Epoch: 755	max: 0.99998856/1.0	min: 1.1426734e-05	loss: 34322.828125	train_loss: 34362.987472226094	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_756
Epoch: 756	max: 0.9999901/1.0	min: 9.914309e-06	loss: 34323.07421875	train_loss: 34362.97220770624	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_757
Epoch: 757	max: 0.99999094/1.0	min: 9.059482e-06	loss: 34323.09375	train_loss: 34362.97649572649	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_758
Epoch: 758	max: 0.9999914/1.0	min: 8.599677e-06	loss: 34323.05078125	train_loss: 34362.936970650626	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_759
Epoch: 759	max: 0.9999914/1.0	min: 8.555291e-06	loss: 34322.94921875	train_loss: 34362.921720162885	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_760
Epoch: 760	max: 0.9999919/1.0	min: 8.076379e-06	loss: 34322.96484375	train_loss: 34362.914781524836	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_761
Epoch: 761	max: 0.99999094/1.0	min: 9.013067e-06	loss: 34322.98828125	train_loss: 34362.89586478462	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_762
Epoch: 762	max: 0.9999902/1.0	min: 9.783557e-06	loss: 34322.84375	train_loss: 34362.86715556485	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_763
Epoch: 763	max: 0.99999154/1.0	min: 8.501263e-06	loss: 34322.9296875	train_loss: 34362.85368328456	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_764
Epoch: 764	max: 0.9999901/1.0	min: 9.906889e-06	loss: 34322.796875	train_loss: 34362.833395752044	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_765
Epoch: 765	max: 0.99998796/1.0	min: 1.2015731e-05	loss: 34322.93359375	train_loss: 34362.81375514833	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_766
Epoch: 766	max: 0.99998724/1.0	min: 1.2697173e-05	loss: 34322.8046875	train_loss: 34362.79919900827	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_767
Epoch: 767	max: 0.99999106/1.0	min: 8.99398e-06	loss: 34323.2265625	train_loss: 34362.81478336352	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_768
Epoch: 768	max: 0.99998856/1.0	min: 1.1425972e-05	loss: 34323.0	train_loss: 34362.7795961461	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_769
Epoch: 769	max: 0.9999901/1.0	min: 9.867137e-06	loss: 34323.0234375	train_loss: 34362.74454150796	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_770
Epoch: 770	max: 0.9999889/1.0	min: 1.1057192e-05	loss: 34322.69140625	train_loss: 34362.737055617494	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_771
Epoch: 771	max: 0.99998856/1.0	min: 1.1482644e-05	loss: 34322.6171875	train_loss: 34362.71792355692	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_772
Epoch: 772	max: 0.9999933/1.0	min: 6.649442e-06	loss: 34322.8203125	train_loss: 34362.7273545886	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_773
Epoch: 773	max: 0.9999889/1.0	min: 1.11378795e-05	loss: 34322.6171875	train_loss: 34362.68295649852	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_774
Epoch: 774	max: 0.9999894/1.0	min: 1.0668118e-05	loss: 34322.68359375	train_loss: 34362.662721223525	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_775
Epoch: 775	max: 0.99998987/1.0	min: 1.0097851e-05	loss: 34322.84375	train_loss: 34362.654990980736	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_776
Epoch: 776	max: 0.9999938/1.0	min: 6.21756e-06	loss: 34323.140625	train_loss: 34362.676966721636	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_777
Epoch: 777	max: 0.9999914/1.0	min: 8.572074e-06	loss: 34322.703125	train_loss: 34362.63072994085	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_778
Epoch: 778	max: 0.99999356/1.0	min: 6.464153e-06	loss: 34322.8359375	train_loss: 34362.60236862071	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_779
Epoch: 779	max: 0.9999919/1.0	min: 8.141275e-06	loss: 34322.7265625	train_loss: 34362.59257904434	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_780
Epoch: 780	max: 0.99999034/1.0	min: 9.62568e-06	loss: 34322.7734375	train_loss: 34362.57594711926	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_781
Epoch: 781	max: 0.9999945/1.0	min: 5.4995025e-06	loss: 34322.76171875	train_loss: 34362.532395794624	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_782
Epoch: 782	max: 0.99999297/1.0	min: 7.0448755e-06	loss: 34322.6953125	train_loss: 34362.54228504738	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_783
Epoch: 783	max: 0.999992/1.0	min: 7.944164e-06	loss: 34323.1015625	train_loss: 34362.53010226991	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_784
Epoch: 784	max: 0.9999894/1.0	min: 1.05878635e-05	loss: 34322.7265625	train_loss: 34362.49701986947	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_785
Epoch: 785	max: 0.9999901/1.0	min: 9.894784e-06	loss: 34322.84375	train_loss: 34362.480310525825	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_786
Epoch: 786	max: 0.9999908/1.0	min: 9.13185e-06	loss: 34322.7890625	train_loss: 34362.4603786348	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_787
Epoch: 787	max: 0.99999225/1.0	min: 7.734045e-06	loss: 34322.94140625	train_loss: 34362.44515234036	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_788
Epoch: 788	max: 0.999992/1.0	min: 7.936108e-06	loss: 34322.50390625	train_loss: 34362.51570048309	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_789
Epoch: 789	max: 0.99999213/1.0	min: 7.816447e-06	loss: 34322.7265625	train_loss: 34362.40882755404	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_790
Epoch: 790	max: 0.9999932/1.0	min: 6.7463975e-06	loss: 34322.5390625	train_loss: 34362.38608924037	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_791
Epoch: 791	max: 0.9999926/1.0	min: 7.37753e-06	loss: 34322.84375	train_loss: 34362.37729255698	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_792
Epoch: 792	max: 0.9999924/1.0	min: 7.604953e-06	loss: 34322.66015625	train_loss: 34362.35395134631	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_793
Epoch: 793	max: 0.99999404/1.0	min: 5.9951067e-06	loss: 34322.7109375	train_loss: 34362.35328070807	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_794
Epoch: 794	max: 0.99999297/1.0	min: 7.0895194e-06	loss: 34322.54296875	train_loss: 34362.32968691936	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_795
Epoch: 795	max: 0.99999166/1.0	min: 8.325268e-06	loss: 34322.3359375	train_loss: 34362.32663130574	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_796
Epoch: 796	max: 0.99999356/1.0	min: 6.4512205e-06	loss: 34322.49609375	train_loss: 34362.321208135916	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_797
Epoch: 797	max: 0.99999356/1.0	min: 6.4865076e-06	loss: 34322.8984375	train_loss: 34362.28363400765	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_798
Epoch: 798	max: 0.99999166/1.0	min: 8.315531e-06	loss: 34322.484375	train_loss: 34362.26739885266	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_799
Epoch: 799	max: 0.9999918/1.0	min: 8.175384e-06	loss: 34322.4140625	train_loss: 34362.25617848461	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_800
Epoch: 800	max: 0.99999356/1.0	min: 6.427969e-06	loss: 34322.4296875	train_loss: 34362.232981466	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_801
Epoch: 801	max: 0.9999944/1.0	min: 5.567258e-06	loss: 34322.875	train_loss: 34362.21110298216	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_802
Epoch: 802	max: 0.99999356/1.0	min: 6.390574e-06	loss: 34322.40234375	train_loss: 34362.21575148257	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_803
Epoch: 803	max: 0.99999464/1.0	min: 5.3190174e-06	loss: 34323.0078125	train_loss: 34362.18083232689	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_804
Epoch: 804	max: 0.9999925/1.0	min: 7.502496e-06	loss: 34322.296875	train_loss: 34362.18070942494	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_805
Epoch: 805	max: 0.9999926/1.0	min: 7.417615e-06	loss: 34322.3671875	train_loss: 34362.1630429944	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_806
Epoch: 806	max: 0.99999344/1.0	min: 6.6098014e-06	loss: 34322.828125	train_loss: 34362.13032155797	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_807
Epoch: 807	max: 0.99999404/1.0	min: 6.004365e-06	loss: 34322.83203125	train_loss: 34362.12201745014	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_808
Epoch: 808	max: 0.9999927/1.0	min: 7.3139568e-06	loss: 34322.6953125	train_loss: 34362.13138993404	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_809
Epoch: 809	max: 0.99999416/1.0	min: 5.7898924e-06	loss: 34322.67578125	train_loss: 34362.08969568701	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_810
Epoch: 810	max: 0.9999938/1.0	min: 6.1611786e-06	loss: 34322.44140625	train_loss: 34362.07584453967	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_811
Epoch: 811	max: 0.9999931/1.0	min: 6.928661e-06	loss: 34322.59375	train_loss: 34362.06154920336	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_812
Epoch: 812	max: 0.9999944/1.0	min: 5.5758337e-06	loss: 34322.6796875	train_loss: 34362.05625135482	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_813
Epoch: 813	max: 0.999995/1.0	min: 5.006358e-06	loss: 34322.5859375	train_loss: 34362.05458540428	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_814
Epoch: 814	max: 0.9999944/1.0	min: 5.55301e-06	loss: 34322.61328125	train_loss: 34362.00766734021	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_815
Epoch: 815	max: 0.99999285/1.0	min: 7.200009e-06	loss: 34322.15625	train_loss: 34361.99877291589	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_816
Epoch: 816	max: 0.99999475/1.0	min: 5.202874e-06	loss: 34322.2890625	train_loss: 34361.980770198505	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_817
Epoch: 817	max: 0.99999225/1.0	min: 7.73932e-06	loss: 34322.26171875	train_loss: 34361.96782339666	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_818
Epoch: 818	max: 0.9999949/1.0	min: 5.173633e-06	loss: 34322.51171875	train_loss: 34361.957298344016	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_819
Epoch: 819	max: 0.999995/1.0	min: 4.998739e-06	loss: 34322.23828125	train_loss: 34361.93004410922	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_820
Epoch: 820	max: 0.9999951/1.0	min: 4.927826e-06	loss: 34322.43359375	train_loss: 34361.91853487319	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_821
Epoch: 821	max: 0.99999297/1.0	min: 7.0051874e-06	loss: 34322.4140625	train_loss: 34361.89052967841	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_822
Epoch: 822	max: 0.9999932/1.0	min: 6.847588e-06	loss: 34322.3359375	train_loss: 34361.884233614364	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_823
Epoch: 823	max: 0.9999937/1.0	min: 6.3718066e-06	loss: 34322.42578125	train_loss: 34361.86327592748	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_824
Epoch: 824	max: 0.9999938/1.0	min: 6.169681e-06	loss: 34322.37109375	train_loss: 34361.851757497985	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_825
Epoch: 825	max: 0.99999356/1.0	min: 6.4493624e-06	loss: 34322.34375	train_loss: 34361.84146131395	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_826
Epoch: 826	max: 0.99999356/1.0	min: 6.4441247e-06	loss: 34322.36328125	train_loss: 34361.80920148566	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_827
Epoch: 827	max: 0.99999416/1.0	min: 5.868324e-06	loss: 34322.453125	train_loss: 34361.8031033228	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_828
Epoch: 828	max: 0.99999225/1.0	min: 7.742576e-06	loss: 34322.41015625	train_loss: 34361.77504635436	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_829
Epoch: 829	max: 0.9999937/1.0	min: 6.3476555e-06	loss: 34322.41015625	train_loss: 34361.77055898133	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_830
Epoch: 830	max: 0.99999344/1.0	min: 6.5907284e-06	loss: 34322.1015625	train_loss: 34361.739415915705	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_831
Epoch: 831	max: 0.99999416/1.0	min: 5.877896e-06	loss: 34322.17578125	train_loss: 34361.73554934272	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_832
Epoch: 832	max: 0.99999523/1.0	min: 4.716015e-06	loss: 34322.59375	train_loss: 34361.71876693531	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_833
Epoch: 833	max: 0.9999951/1.0	min: 4.829325e-06	loss: 34322.21875	train_loss: 34361.705659006104	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_834
Epoch: 834	max: 0.9999943/1.0	min: 5.7402135e-06	loss: 34322.1015625	train_loss: 34361.66962212003	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_835
Epoch: 835	max: 0.9999956/1.0	min: 4.4219046e-06	loss: 34322.1640625	train_loss: 34361.66117140081	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_836
Epoch: 836	max: 0.99999523/1.0	min: 4.826066e-06	loss: 34322.3984375	train_loss: 34361.64279852595	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_837
Epoch: 837	max: 0.9999949/1.0	min: 5.1827046e-06	loss: 34322.05859375	train_loss: 34361.6746393263	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_838
Epoch: 838	max: 0.999995/1.0	min: 4.9603586e-06	loss: 34322.09375	train_loss: 34361.61542477626	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_839
Epoch: 839	max: 0.99999523/1.0	min: 4.7221893e-06	loss: 34322.2734375	train_loss: 34361.59137083101	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_840
Epoch: 840	max: 0.99999475/1.0	min: 5.2679e-06	loss: 34322.43359375	train_loss: 34361.591971308684	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_841
Epoch: 841	max: 0.9999949/1.0	min: 5.0867534e-06	loss: 34322.37890625	train_loss: 34361.57032798371	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_842
Epoch: 842	max: 0.99999344/1.0	min: 6.5425334e-06	loss: 34321.921875	train_loss: 34361.54110054348	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_843
Epoch: 843	max: 0.9999933/1.0	min: 6.7265146e-06	loss: 34321.8984375	train_loss: 34361.54727128623	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_844
Epoch: 844	max: 0.9999939/1.0	min: 6.1378555e-06	loss: 34322.5859375	train_loss: 34361.55140301777	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_845
Epoch: 845	max: 0.9999943/1.0	min: 5.7506354e-06	loss: 34322.23828125	train_loss: 34361.505259623125	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_846
Epoch: 846	max: 0.9999938/1.0	min: 6.1743367e-06	loss: 34321.9453125	train_loss: 34361.47764345659	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_847
Epoch: 847	max: 0.9999924/1.0	min: 7.6123765e-06	loss: 34321.7578125	train_loss: 34361.474599455745	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_848
Epoch: 848	max: 0.99999416/1.0	min: 5.8003484e-06	loss: 34321.94921875	train_loss: 34361.46587970705	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_849
Epoch: 849	max: 0.9999919/1.0	min: 8.0783975e-06	loss: 34322.30078125	train_loss: 34361.46505036077	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_850
Epoch: 850	max: 0.99999404/1.0	min: 5.9389527e-06	loss: 34322.47265625	train_loss: 34361.48636320528	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_851
Epoch: 851	max: 0.99999154/1.0	min: 8.452354e-06	loss: 34321.7890625	train_loss: 34361.44525056516	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_852
Epoch: 852	max: 0.99999404/1.0	min: 5.943213e-06	loss: 34322.1015625	train_loss: 34361.3950688251	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_853
Epoch: 853	max: 0.9999926/1.0	min: 7.387323e-06	loss: 34321.9453125	train_loss: 34361.372507122505	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_854
Epoch: 854	max: 0.9999927/1.0	min: 7.2648495e-06	loss: 34321.9296875	train_loss: 34361.353693445744	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_855
Epoch: 855	max: 0.9999937/1.0	min: 6.285333e-06	loss: 34321.90625	train_loss: 34361.342370981976	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_856
Epoch: 856	max: 0.999992/1.0	min: 7.960349e-06	loss: 34321.765625	train_loss: 34361.326846142234	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_857
Epoch: 857	max: 0.99999547/1.0	min: 4.481223e-06	loss: 34322.0546875	train_loss: 34361.310572277966	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_858
Epoch: 858	max: 0.9999926/1.0	min: 7.4274194e-06	loss: 34321.94921875	train_loss: 34361.31992395563	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_859
Epoch: 859	max: 0.9999914/1.0	min: 8.573006e-06	loss: 34322.046875	train_loss: 34361.297366607825	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_860
Epoch: 860	max: 0.999992/1.0	min: 8.031118e-06	loss: 34321.89453125	train_loss: 34361.27948727626	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_861
Epoch: 861	max: 0.9999931/1.0	min: 6.939373e-06	loss: 34322.0234375	train_loss: 34361.26878706413	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_862
Epoch: 862	max: 0.99999404/1.0	min: 5.9510744e-06	loss: 34321.89453125	train_loss: 34361.236438204505	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_863
Epoch: 863	max: 0.99999356/1.0	min: 6.4603387e-06	loss: 34321.96484375	train_loss: 34361.22896295909	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_864
Epoch: 864	max: 0.999995/1.0	min: 5.062677e-06	loss: 34322.24609375	train_loss: 34361.2156600319	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_865
Epoch: 865	max: 0.9999937/1.0	min: 6.279474e-06	loss: 34321.78125	train_loss: 34361.211369108445	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_866
Epoch: 866	max: 0.99999297/1.0	min: 7.0709243e-06	loss: 34321.7734375	train_loss: 34361.1837302002	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_867
Epoch: 867	max: 0.9999958/1.0	min: 4.150139e-06	loss: 34322.26171875	train_loss: 34361.20420692432	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_868
Epoch: 868	max: 0.99999475/1.0	min: 5.1937077e-06	loss: 34321.89453125	train_loss: 34361.17118645872	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_869
Epoch: 869	max: 0.99999404/1.0	min: 6.0170505e-06	loss: 34321.8046875	train_loss: 34361.1533448687	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_870
Epoch: 870	max: 0.9999938/1.0	min: 6.2005715e-06	loss: 34321.8828125	train_loss: 34361.12482145346	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_871
Epoch: 871	max: 0.99999297/1.0	min: 6.9894386e-06	loss: 34321.7734375	train_loss: 34361.12235518859	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_872
Epoch: 872	max: 0.9999944/1.0	min: 5.5882215e-06	loss: 34322.1171875	train_loss: 34361.10758711523	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_873
Epoch: 873	max: 0.99999464/1.0	min: 5.315255e-06	loss: 34321.94921875	train_loss: 34361.094956761735	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_874
Epoch: 874	max: 0.999992/1.0	min: 8.021069e-06	loss: 34321.37890625	train_loss: 34361.085796695	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_875
Epoch: 875	max: 0.99999535/1.0	min: 4.628444e-06	loss: 34322.0390625	train_loss: 34361.1192579625	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_876
Epoch: 876	max: 0.99999464/1.0	min: 5.3590584e-06	loss: 34321.88671875	train_loss: 34361.064855459554	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_877
Epoch: 877	max: 0.99999416/1.0	min: 5.8083747e-06	loss: 34321.80078125	train_loss: 34361.03327255977	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_878
Epoch: 878	max: 0.99999547/1.0	min: 4.4766352e-06	loss: 34321.8203125	train_loss: 34361.02519296575	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_879
Epoch: 879	max: 0.99999285/1.0	min: 7.1009545e-06	loss: 34321.48828125	train_loss: 34361.00920651787	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_880
Epoch: 880	max: 0.9999945/1.0	min: 5.4934694e-06	loss: 34321.78125	train_loss: 34361.0120671335	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_881
Epoch: 881	max: 0.99999404/1.0	min: 5.9940553e-06	loss: 34321.50390625	train_loss: 34360.98858318237	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_882
Epoch: 882	max: 0.999995/1.0	min: 4.963662e-06	loss: 34321.890625	train_loss: 34360.98796576939	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_883
Epoch: 883	max: 0.99999595/1.0	min: 3.993571e-06	loss: 34322.015625	train_loss: 34360.97978504738	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_884
Epoch: 884	max: 0.99999356/1.0	min: 6.4963883e-06	loss: 34321.83984375	train_loss: 34360.97383591524	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_885
Epoch: 885	max: 0.9999924/1.0	min: 7.5725015e-06	loss: 34321.67578125	train_loss: 34360.9392191758	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_886
Epoch: 886	max: 0.9999937/1.0	min: 6.371752e-06	loss: 34321.58984375	train_loss: 34360.925505446394	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_887
Epoch: 887	max: 0.9999937/1.0	min: 6.371904e-06	loss: 34321.453125	train_loss: 34360.90104360213	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_888
Epoch: 888	max: 0.99999404/1.0	min: 5.930361e-06	loss: 34321.55859375	train_loss: 34360.89712428775	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_889
Epoch: 889	max: 0.99999475/1.0	min: 5.2142195e-06	loss: 34321.796875	train_loss: 34360.887504548344	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_890
Epoch: 890	max: 0.9999963/1.0	min: 3.7303514e-06	loss: 34321.5625	train_loss: 34360.875739347204	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_891
Epoch: 891	max: 0.9999956/1.0	min: 4.417095e-06	loss: 34321.53125	train_loss: 34360.86071240555	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_892
Epoch: 892	max: 0.99999416/1.0	min: 5.8431215e-06	loss: 34321.75390625	train_loss: 34360.84434757448	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_893
Epoch: 893	max: 0.99999464/1.0	min: 5.3883005e-06	loss: 34321.92578125	train_loss: 34360.85345586755	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_894
Epoch: 894	max: 0.99999547/1.0	min: 4.5410525e-06	loss: 34322.00390625	train_loss: 34360.84266226929	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_895
Epoch: 895	max: 0.99999166/1.0	min: 8.3770265e-06	loss: 34321.79296875	train_loss: 34360.82009137325	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_896
Epoch: 896	max: 0.9999901/1.0	min: 9.894879e-06	loss: 34321.48828125	train_loss: 34360.82447568283	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_897
Epoch: 897	max: 0.9999927/1.0	min: 7.235126e-06	loss: 34321.7421875	train_loss: 34360.795890332745	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_898
Epoch: 898	max: 0.9999933/1.0	min: 6.7185197e-06	loss: 34322.12890625	train_loss: 34360.77964356497	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_899
Epoch: 899	max: 0.9999938/1.0	min: 6.1851633e-06	loss: 34322.00390625	train_loss: 34360.78303401384	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_900
Epoch: 900	max: 0.9999938/1.0	min: 6.147005e-06	loss: 34321.71875	train_loss: 34360.76331502385	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_901
Epoch: 901	max: 0.99999416/1.0	min: 5.850839e-06	loss: 34321.796875	train_loss: 34360.73887446968	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_902
Epoch: 902	max: 0.99999464/1.0	min: 5.4063826e-06	loss: 34321.62890625	train_loss: 34360.729059732286	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_903
Epoch: 903	max: 0.99999356/1.0	min: 6.3894895e-06	loss: 34321.6484375	train_loss: 34360.710443956705	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_904
Epoch: 904	max: 0.999995/1.0	min: 4.9909745e-06	loss: 34321.98828125	train_loss: 34360.72888070188	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_905
Epoch: 905	max: 0.9999945/1.0	min: 5.488913e-06	loss: 34321.58203125	train_loss: 34360.708543331166	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_906
Epoch: 906	max: 0.99999535/1.0	min: 4.6538853e-06	loss: 34321.75	train_loss: 34360.68572663121	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_907
Epoch: 907	max: 0.99999595/1.0	min: 4.01178e-06	loss: 34321.55078125	train_loss: 34360.6747104546	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_908
Epoch: 908	max: 0.99999547/1.0	min: 4.523327e-06	loss: 34321.71484375	train_loss: 34360.66689892233	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_909
Epoch: 909	max: 0.99999523/1.0	min: 4.8012766e-06	loss: 34321.69921875	train_loss: 34360.64466334541	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_910
Epoch: 910	max: 0.9999945/1.0	min: 5.463151e-06	loss: 34321.57421875	train_loss: 34360.63109864672	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_911
Epoch: 911	max: 0.9999945/1.0	min: 5.50158e-06	loss: 34321.7421875	train_loss: 34360.61374092267	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_912
Epoch: 912	max: 0.9999931/1.0	min: 6.9221096e-06	loss: 34321.32421875	train_loss: 34360.61267786913	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_913
Epoch: 913	max: 0.9999957/1.0	min: 4.2985425e-06	loss: 34321.53125	train_loss: 34360.59804431051	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_914
Epoch: 914	max: 0.9999949/1.0	min: 5.1393667e-06	loss: 34321.50390625	train_loss: 34360.58788167348	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_915
Epoch: 915	max: 0.99999523/1.0	min: 4.763167e-06	loss: 34321.65234375	train_loss: 34360.57714081661	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_916
Epoch: 916	max: 0.9999944/1.0	min: 5.6406298e-06	loss: 34321.68359375	train_loss: 34360.57563889663	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_917
Epoch: 917	max: 0.9999945/1.0	min: 5.430944e-06	loss: 34321.2421875	train_loss: 34360.54877175461	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_918
Epoch: 918	max: 0.9999962/1.0	min: 3.8057071e-06	loss: 34321.2109375	train_loss: 34360.54954352084	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_919
Epoch: 919	max: 0.99999535/1.0	min: 4.603519e-06	loss: 34321.79296875	train_loss: 34360.54180166528	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_920
Epoch: 920	max: 0.9999944/1.0	min: 5.5622163e-06	loss: 34321.73828125	train_loss: 34360.54805902004	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_921
Epoch: 921	max: 0.99999523/1.0	min: 4.7569933e-06	loss: 34321.75390625	train_loss: 34360.50215610678	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_922
Epoch: 922	max: 0.99999404/1.0	min: 5.946218e-06	loss: 34321.27734375	train_loss: 34360.51075343738	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_923
Epoch: 923	max: 0.99999404/1.0	min: 5.9353683e-06	loss: 34321.4296875	train_loss: 34360.50699283104	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_924
Epoch: 924	max: 0.9999944/1.0	min: 5.609013e-06	loss: 34321.38671875	train_loss: 34360.47780022916	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_925
Epoch: 925	max: 0.99999595/1.0	min: 4.0565387e-06	loss: 34321.671875	train_loss: 34360.460883790875	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_926
Epoch: 926	max: 0.9999962/1.0	min: 3.7562183e-06	loss: 34321.53125	train_loss: 34360.488409474485	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_927
Epoch: 927	max: 0.9999963/1.0	min: 3.7420168e-06	loss: 34321.6484375	train_loss: 34360.447266834664	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_928
Epoch: 928	max: 0.99999547/1.0	min: 4.5415113e-06	loss: 34321.66796875	train_loss: 34360.461164917004	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_929
Epoch: 929	max: 0.9999944/1.0	min: 5.615398e-06	loss: 34321.17578125	train_loss: 34360.47224206073	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_930
Epoch: 930	max: 0.99999344/1.0	min: 6.5439995e-06	loss: 34321.4140625	train_loss: 34360.42989846556	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_931
Epoch: 931	max: 0.9999956/1.0	min: 4.3846403e-06	loss: 34321.32421875	train_loss: 34360.41923938205	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_932
Epoch: 932	max: 0.99999475/1.0	min: 5.2825803e-06	loss: 34321.61328125	train_loss: 34360.39503785767	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_933
Epoch: 933	max: 0.99999475/1.0	min: 5.206547e-06	loss: 34321.515625	train_loss: 34360.392534818995	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_934
Epoch: 934	max: 0.99999547/1.0	min: 4.4955627e-06	loss: 34321.43359375	train_loss: 34360.360093057105	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_935
Epoch: 935	max: 0.99999523/1.0	min: 4.793654e-06	loss: 34321.32421875	train_loss: 34360.350871055525	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_936
Epoch: 936	max: 0.99999523/1.0	min: 4.790318e-06	loss: 34321.55078125	train_loss: 34360.33458557847	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_937
Epoch: 937	max: 0.9999969/1.0	min: 3.1142424e-06	loss: 34321.65234375	train_loss: 34360.329956916576	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_938
Epoch: 938	max: 0.9999951/1.0	min: 4.917648e-06	loss: 34321.484375	train_loss: 34360.33172109191	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_939
Epoch: 939	max: 0.9999949/1.0	min: 5.149729e-06	loss: 34321.35546875	train_loss: 34360.309871640035	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_940
Epoch: 940	max: 0.99999607/1.0	min: 3.921345e-06	loss: 34321.55859375	train_loss: 34360.30626683854	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_941
Epoch: 941	max: 0.9999937/1.0	min: 6.279222e-06	loss: 34321.35546875	train_loss: 34360.28915007974	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_942
Epoch: 942	max: 0.99999535/1.0	min: 4.6018863e-06	loss: 34321.4296875	train_loss: 34360.28593624195	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_943
Epoch: 943	max: 0.999995/1.0	min: 5.032855e-06	loss: 34321.375	train_loss: 34360.26602370556	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_944
Epoch: 944	max: 0.99999547/1.0	min: 4.5880215e-06	loss: 34321.19921875	train_loss: 34360.26491662022	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_945
Epoch: 945	max: 0.9999957/1.0	min: 4.3160207e-06	loss: 34321.3984375	train_loss: 34360.25016257897	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_946
Epoch: 946	max: 0.99999475/1.0	min: 5.239312e-06	loss: 34321.39453125	train_loss: 34360.237096746096	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_947
Epoch: 947	max: 0.9999951/1.0	min: 4.8881157e-06	loss: 34321.18359375	train_loss: 34360.22048611111	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_948
Epoch: 948	max: 0.9999949/1.0	min: 5.0704507e-06	loss: 34321.47265625	train_loss: 34360.2176109795	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_949
Epoch: 949	max: 0.99999475/1.0	min: 5.2198216e-06	loss: 34321.13671875	train_loss: 34360.2088883276	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_950
Epoch: 950	max: 0.99999416/1.0	min: 5.840614e-06	loss: 34321.140625	train_loss: 34360.1942615431	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_951
Epoch: 951	max: 0.99999356/1.0	min: 6.460271e-06	loss: 34321.1796875	train_loss: 34360.203869669735	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_952
Epoch: 952	max: 0.9999949/1.0	min: 5.118276e-06	loss: 34321.125	train_loss: 34360.19900004258	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_953
Epoch: 953	max: 0.99999666/1.0	min: 3.360638e-06	loss: 34321.41796875	train_loss: 34360.17484932414	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_954
Epoch: 954	max: 0.9999964/1.0	min: 3.576346e-06	loss: 34321.3203125	train_loss: 34360.152801971075	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_955
Epoch: 955	max: 0.9999949/1.0	min: 5.066777e-06	loss: 34321.046875	train_loss: 34360.14158692556	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_956
Epoch: 956	max: 0.99999547/1.0	min: 4.51961e-06	loss: 34321.515625	train_loss: 34360.132919918244	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_957
Epoch: 957	max: 0.9999938/1.0	min: 6.1910764e-06	loss: 34321.00390625	train_loss: 34360.13279314536	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_958
Epoch: 958	max: 0.99999535/1.0	min: 4.615221e-06	loss: 34321.23046875	train_loss: 34360.1118862644	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_959
Epoch: 959	max: 0.9999918/1.0	min: 8.207288e-06	loss: 34321.20703125	train_loss: 34360.09502305138	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_960
Epoch: 960	max: 0.9999937/1.0	min: 6.348267e-06	loss: 34321.4765625	train_loss: 34360.10220749334	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_961
Epoch: 961	max: 0.9999945/1.0	min: 5.493862e-06	loss: 34321.17578125	train_loss: 34360.08075045677	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_962
Epoch: 962	max: 0.9999963/1.0	min: 3.66234e-06	loss: 34321.0703125	train_loss: 34360.062374194844	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_963
Epoch: 963	max: 0.99999547/1.0	min: 4.5044762e-06	loss: 34321.01953125	train_loss: 34360.05454234021	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_964
Epoch: 964	max: 0.9999957/1.0	min: 4.3455348e-06	loss: 34321.30859375	train_loss: 34360.05553813638	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_965
Epoch: 965	max: 0.99999475/1.0	min: 5.244951e-06	loss: 34321.02734375	train_loss: 34360.03667558915	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_966
Epoch: 966	max: 0.9999963/1.0	min: 3.672273e-06	loss: 34321.4609375	train_loss: 34360.06912847996	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_967
Epoch: 967	max: 0.99999535/1.0	min: 4.7022595e-06	loss: 34321.4609375	train_loss: 34360.03888685665	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_968
Epoch: 968	max: 0.9999956/1.0	min: 4.3764026e-06	loss: 34321.109375	train_loss: 34360.01186681299	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_969
Epoch: 969	max: 0.99999356/1.0	min: 6.48187e-06	loss: 34321.0390625	train_loss: 34359.98855511814	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_970
Epoch: 970	max: 0.9999957/1.0	min: 4.2727165e-06	loss: 34321.1015625	train_loss: 34360.00720911913	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_971
Epoch: 971	max: 0.99999547/1.0	min: 4.5176666e-06	loss: 34321.31640625	train_loss: 34359.97589282949	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_972
Epoch: 972	max: 0.99999595/1.0	min: 4.0605178e-06	loss: 34321.2421875	train_loss: 34359.96594212576	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_973
Epoch: 973	max: 0.99999595/1.0	min: 4.0674167e-06	loss: 34321.2734375	train_loss: 34359.96290925384	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_974
Epoch: 974	max: 0.9999943/1.0	min: 5.709258e-06	loss: 34320.9765625	train_loss: 34359.93576727595	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_975
Epoch: 975	max: 0.9999937/1.0	min: 6.2784916e-06	loss: 34321.0390625	train_loss: 34359.936413237025	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_976
Epoch: 976	max: 0.9999958/1.0	min: 4.213613e-06	loss: 34320.9296875	train_loss: 34359.91587215874	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_977
Epoch: 977	max: 0.99999475/1.0	min: 5.2227497e-06	loss: 34321.30859375	train_loss: 34359.92340353261	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_978
Epoch: 978	max: 0.99999654/1.0	min: 3.4905e-06	loss: 34321.56640625	train_loss: 34359.909896897836	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_979
Epoch: 979	max: 0.99999464/1.0	min: 5.4127026e-06	loss: 34321.08984375	train_loss: 34359.88229718274	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_980
Epoch: 980	max: 0.99999607/1.0	min: 3.9781585e-06	loss: 34321.078125	train_loss: 34359.86657299021	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_981
Epoch: 981	max: 0.9999943/1.0	min: 5.7591974e-06	loss: 34321.12109375	train_loss: 34359.86612444646	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_982
Epoch: 982	max: 0.9999962/1.0	min: 3.8144678e-06	loss: 34321.1484375	train_loss: 34359.860050960764	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_983
Epoch: 983	max: 0.9999975/1.0	min: 2.4909154e-06	loss: 34321.39453125	train_loss: 34359.83941504475	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_984
Epoch: 984	max: 0.9999949/1.0	min: 5.1112615e-06	loss: 34321.07421875	train_loss: 34359.8594006449	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_985
Epoch: 985	max: 0.9999949/1.0	min: 5.1260577e-06	loss: 34321.046875	train_loss: 34359.822363123996	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_986
Epoch: 986	max: 0.99999356/1.0	min: 6.4355754e-06	loss: 34321.2109375	train_loss: 34359.81394627539	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_987
Epoch: 987	max: 0.99999404/1.0	min: 5.978584e-06	loss: 34320.85546875	train_loss: 34359.81329789499	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_988
Epoch: 988	max: 0.9999933/1.0	min: 6.664965e-06	loss: 34321.01171875	train_loss: 34359.81177129784	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_989
Epoch: 989	max: 0.99999464/1.0	min: 5.408358e-06	loss: 34321.1640625	train_loss: 34359.777676165926	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_990
Epoch: 990	max: 0.9999969/1.0	min: 3.1186585e-06	loss: 34321.265625	train_loss: 34359.781312902574	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_991
Epoch: 991	max: 0.99999356/1.0	min: 6.4048877e-06	loss: 34320.89453125	train_loss: 34359.77219009352	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_992
Epoch: 992	max: 0.9999956/1.0	min: 4.440541e-06	loss: 34321.2734375	train_loss: 34359.760200862445	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_993
Epoch: 993	max: 0.9999949/1.0	min: 5.1781544e-06	loss: 34320.9296875	train_loss: 34359.73930849746	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_994
Epoch: 994	max: 0.99999475/1.0	min: 5.271031e-06	loss: 34320.87109375	train_loss: 34359.741968308714	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_995
Epoch: 995	max: 0.99999666/1.0	min: 3.318376e-06	loss: 34321.30859375	train_loss: 34359.749425167225	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_996
Epoch: 996	max: 0.9999924/1.0	min: 7.633394e-06	loss: 34321.17578125	train_loss: 34359.722997859375	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_997
Epoch: 997	max: 0.9999957/1.0	min: 4.344806e-06	loss: 34321.25390625	train_loss: 34359.714538914435	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_998
Epoch: 998	max: 0.9999957/1.0	min: 4.233995e-06	loss: 34321.140625	train_loss: 34359.697483122756	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_999
Epoch: 999	max: 0.99999547/1.0	min: 4.4978915e-06	loss: 34321.1875	train_loss: 34359.678588640374	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1000
Epoch: 1000	max: 0.999995/1.0	min: 5.053063e-06	loss: 34321.1953125	train_loss: 34359.66765326939	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1001
Epoch: 1001	max: 0.99999416/1.0	min: 5.863765e-06	loss: 34321.28515625	train_loss: 34359.65303325901	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1002
Epoch: 1002	max: 0.9999937/1.0	min: 6.341544e-06	loss: 34320.78125	train_loss: 34359.65790191843	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1003
Epoch: 1003	max: 0.999995/1.0	min: 4.9979194e-06	loss: 34320.90625	train_loss: 34359.6720569336	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1004
Epoch: 1004	max: 0.9999944/1.0	min: 5.5757064e-06	loss: 34320.8984375	train_loss: 34359.62319324446	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1005
Epoch: 1005	max: 0.99999404/1.0	min: 5.914496e-06	loss: 34320.921875	train_loss: 34359.64598478338	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1006
Epoch: 1006	max: 0.99999607/1.0	min: 3.986799e-06	loss: 34321.3984375	train_loss: 34359.657934337454	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1007
Epoch: 1007	max: 0.9999933/1.0	min: 6.6543203e-06	loss: 34321.0234375	train_loss: 34359.6183734555	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1008
Epoch: 1008	max: 0.9999944/1.0	min: 5.6529398e-06	loss: 34321.05078125	train_loss: 34359.60909145454	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1009
Epoch: 1009	max: 0.99999654/1.0	min: 3.4445547e-06	loss: 34321.16015625	train_loss: 34359.6548748529	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1010
Epoch: 1010	max: 0.99999666/1.0	min: 3.3281312e-06	loss: 34321.08984375	train_loss: 34359.57885805695	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1011
Epoch: 1011	max: 0.9999951/1.0	min: 4.8906427e-06	loss: 34321.13671875	train_loss: 34359.57105087947	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1012
Epoch: 1012	max: 0.9999958/1.0	min: 4.170103e-06	loss: 34320.98828125	train_loss: 34359.55379041249	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1013
Epoch: 1013	max: 0.99999344/1.0	min: 6.556737e-06	loss: 34320.8359375	train_loss: 34359.541071027656	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1014
Epoch: 1014	max: 0.9999945/1.0	min: 5.4313796e-06	loss: 34320.99609375	train_loss: 34359.53372352285	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1015
Epoch: 1015	max: 0.99999464/1.0	min: 5.4033985e-06	loss: 34320.94140625	train_loss: 34359.51884512805	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1016
Epoch: 1016	max: 0.9999963/1.0	min: 3.736593e-06	loss: 34320.9765625	train_loss: 34359.51521081073	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1017
Epoch: 1017	max: 0.99999523/1.0	min: 4.797148e-06	loss: 34320.93359375	train_loss: 34359.52252638037	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1018
Epoch: 1018	max: 0.99999523/1.0	min: 4.719471e-06	loss: 34321.36328125	train_loss: 34359.50506268968	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1019
Epoch: 1019	max: 0.99999523/1.0	min: 4.8270463e-06	loss: 34321.046875	train_loss: 34359.49590165521	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1020
Epoch: 1020	max: 0.9999944/1.0	min: 5.586884e-06	loss: 34320.85546875	train_loss: 34359.49566068996	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1021
Epoch: 1021	max: 0.9999962/1.0	min: 3.817969e-06	loss: 34320.9609375	train_loss: 34359.46119878763	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1022
Epoch: 1022	max: 0.99999166/1.0	min: 8.317616e-06	loss: 34320.6640625	train_loss: 34359.468949352784	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1023
Epoch: 1023	max: 0.999995/1.0	min: 5.0601184e-06	loss: 34320.83984375	train_loss: 34359.52408297721	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1024
Epoch: 1024	max: 0.9999957/1.0	min: 4.2588927e-06	loss: 34321.15234375	train_loss: 34359.4344540637	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1025
Epoch: 1025	max: 0.9999956/1.0	min: 4.4075814e-06	loss: 34320.91796875	train_loss: 34359.438256766385	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1026
Epoch: 1026	max: 0.99999535/1.0	min: 4.6631885e-06	loss: 34320.8984375	train_loss: 34359.423257405084	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1027
Epoch: 1027	max: 0.99999285/1.0	min: 7.1993704e-06	loss: 34320.8359375	train_loss: 34359.43168102781	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1028
Epoch: 1028	max: 0.99999547/1.0	min: 4.573544e-06	loss: 34320.9140625	train_loss: 34359.41165139586	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1029
Epoch: 1029	max: 0.9999962/1.0	min: 3.8614935e-06	loss: 34320.87109375	train_loss: 34359.40566258671	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1030
Epoch: 1030	max: 0.99999535/1.0	min: 4.695417e-06	loss: 34320.78515625	train_loss: 34359.39655284204	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1031
Epoch: 1031	max: 0.99999404/1.0	min: 5.949485e-06	loss: 34321.0	train_loss: 34359.39229385374	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1032
Epoch: 1032	max: 0.99999475/1.0	min: 5.2615537e-06	loss: 34321.13671875	train_loss: 34359.37008924424	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1033
Epoch: 1033	max: 0.9999945/1.0	min: 5.4687707e-06	loss: 34321.07421875	train_loss: 34359.36891877245	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1034
Epoch: 1034	max: 0.9999945/1.0	min: 5.434083e-06	loss: 34320.921875	train_loss: 34359.34414967329	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1035
Epoch: 1035	max: 0.9999951/1.0	min: 4.858312e-06	loss: 34321.01953125	train_loss: 34359.34199405038	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1036
Epoch: 1036	max: 0.99999547/1.0	min: 4.484669e-06	loss: 34320.9765625	train_loss: 34359.330764488885	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1037
Epoch: 1037	max: 0.9999944/1.0	min: 5.5500404e-06	loss: 34320.8203125	train_loss: 34359.33109642094	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1038
Epoch: 1038	max: 0.99999547/1.0	min: 4.4872313e-06	loss: 34320.9296875	train_loss: 34359.31488110445	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1039
Epoch: 1039	max: 0.9999956/1.0	min: 4.3613113e-06	loss: 34320.8984375	train_loss: 34359.31060372925	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1040
Epoch: 1040	max: 0.9999958/1.0	min: 4.1497356e-06	loss: 34321.1796875	train_loss: 34359.30214188112	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1041
Epoch: 1041	max: 0.99999595/1.0	min: 4.0163354e-06	loss: 34321.4140625	train_loss: 34359.32021137201	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1042
Epoch: 1042	max: 0.9999957/1.0	min: 4.3350833e-06	loss: 34321.4609375	train_loss: 34359.32450519866	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1043
Epoch: 1043	max: 0.999995/1.0	min: 4.9600467e-06	loss: 34321.19140625	train_loss: 34359.34690529001	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1044
Epoch: 1044	max: 0.9999962/1.0	min: 3.8311873e-06	loss: 34321.2265625	train_loss: 34359.3538192509	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1045
Epoch: 1045	max: 0.99999607/1.0	min: 3.9400734e-06	loss: 34321.12890625	train_loss: 34359.326023086214	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1046
Epoch: 1046	max: 0.9999956/1.0	min: 4.4473727e-06	loss: 34321.03125	train_loss: 34359.26084585579	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1047
Epoch: 1047	max: 0.99999523/1.0	min: 4.797542e-06	loss: 34321.00390625	train_loss: 34359.23498031633	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1048
Epoch: 1048	max: 0.999995/1.0	min: 5.0488725e-06	loss: 34320.86328125	train_loss: 34359.23116600086	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1049
Epoch: 1049	max: 0.9999938/1.0	min: 6.24049e-06	loss: 34320.6796875	train_loss: 34359.21718420971	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1050
Epoch: 1050	max: 0.99999416/1.0	min: 5.838309e-06	loss: 34320.7890625	train_loss: 34359.23289098306	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1051
Epoch: 1051	max: 0.9999956/1.0	min: 4.3518344e-06	loss: 34320.67578125	train_loss: 34359.21519552056	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1052
Epoch: 1052	max: 0.9999963/1.0	min: 3.7245286e-06	loss: 34321.171875	train_loss: 34359.19753779961	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1053
Epoch: 1053	max: 0.99999416/1.0	min: 5.840102e-06	loss: 34320.78515625	train_loss: 34359.219109512414	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1054
Epoch: 1054	max: 0.99999356/1.0	min: 6.4633646e-06	loss: 34320.77734375	train_loss: 34359.190488356246	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1055
Epoch: 1055	max: 0.99999464/1.0	min: 5.3699714e-06	loss: 34321.00390625	train_loss: 34359.17944653475	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1056
Epoch: 1056	max: 0.999995/1.0	min: 5.05746e-06	loss: 34320.6953125	train_loss: 34359.169414541524	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1057
Epoch: 1057	max: 0.999995/1.0	min: 5.0426456e-06	loss: 34320.90625	train_loss: 34359.15911351883	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1058
Epoch: 1058	max: 0.9999937/1.0	min: 6.343504e-06	loss: 34320.64453125	train_loss: 34359.150383125074	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1059
Epoch: 1059	max: 0.99999404/1.0	min: 5.9077256e-06	loss: 34320.484375	train_loss: 34359.199526972625	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1060
Epoch: 1060	max: 0.99999523/1.0	min: 4.7597614e-06	loss: 34320.5234375	train_loss: 34359.186919844695	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1061
Epoch: 1061	max: 0.99999547/1.0	min: 4.57105e-06	loss: 34321.00390625	train_loss: 34359.137251486434	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1062
Epoch: 1062	max: 0.99999475/1.0	min: 5.248574e-06	loss: 34320.73828125	train_loss: 34359.14276997786	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1063
Epoch: 1063	max: 0.9999945/1.0	min: 5.470575e-06	loss: 34320.7734375	train_loss: 34359.13979468599	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1064
Epoch: 1064	max: 0.99999523/1.0	min: 4.7935077e-06	loss: 34320.87890625	train_loss: 34359.12327985647	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1065
Epoch: 1065	max: 0.9999956/1.0	min: 4.4253134e-06	loss: 34320.69140625	train_loss: 34359.09038374443	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1066
Epoch: 1066	max: 0.9999939/1.0	min: 6.0737225e-06	loss: 34320.71484375	train_loss: 34359.10077283073	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1067
Epoch: 1067	max: 0.9999937/1.0	min: 6.3343823e-06	loss: 34320.76953125	train_loss: 34359.105611490464	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1068
Epoch: 1068	max: 0.99999607/1.0	min: 3.9147462e-06	loss: 34320.94921875	train_loss: 34359.082563986434	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1069
Epoch: 1069	max: 0.9999958/1.0	min: 4.179802e-06	loss: 34320.859375	train_loss: 34359.085611374336	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1070
Epoch: 1070	max: 0.99999523/1.0	min: 4.7522144e-06	loss: 34320.94140625	train_loss: 34359.07426084634	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1071
Epoch: 1071	max: 0.9999956/1.0	min: 4.3616437e-06	loss: 34320.86328125	train_loss: 34359.07435568407	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1072
Epoch: 1072	max: 0.9999956/1.0	min: 4.436308e-06	loss: 34320.98046875	train_loss: 34359.06303999443	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1073
Epoch: 1073	max: 0.9999956/1.0	min: 4.3858277e-06	loss: 34321.328125	train_loss: 34359.06666463443	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1074
Epoch: 1074	max: 0.9999945/1.0	min: 5.5249243e-06	loss: 34320.90234375	train_loss: 34359.055601038956	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1075
Epoch: 1075	max: 0.9999951/1.0	min: 4.9067467e-06	loss: 34320.7734375	train_loss: 34359.029285988014	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1076
Epoch: 1076	max: 0.9999945/1.0	min: 5.443513e-06	loss: 34320.6796875	train_loss: 34359.03588591989	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1077
Epoch: 1077	max: 0.99999464/1.0	min: 5.3660347e-06	loss: 34320.640625	train_loss: 34359.00123627756	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1078
Epoch: 1078	max: 0.9999956/1.0	min: 4.3795753e-06	loss: 34320.53125	train_loss: 34359.00200562446	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1079
Epoch: 1079	max: 0.9999949/1.0	min: 5.0814683e-06	loss: 34320.48828125	train_loss: 34358.999853872476	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1080
Epoch: 1080	max: 0.99999535/1.0	min: 4.6142177e-06	loss: 34320.59375	train_loss: 34358.99855856327	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1081
Epoch: 1081	max: 0.9999945/1.0	min: 5.429898e-06	loss: 34320.4921875	train_loss: 34359.004752047724	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1082
Epoch: 1082	max: 0.99999595/1.0	min: 3.9937963e-06	loss: 34320.87109375	train_loss: 34358.975095902235	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1083
Epoch: 1083	max: 0.99999344/1.0	min: 6.5146087e-06	loss: 34320.59375	train_loss: 34358.97201077279	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1084
Epoch: 1084	max: 0.9999931/1.0	min: 6.971459e-06	loss: 34320.64453125	train_loss: 34358.963684890994	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1085
Epoch: 1085	max: 0.99999464/1.0	min: 5.3907725e-06	loss: 34320.6015625	train_loss: 34358.95235129831	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1086
Epoch: 1086	max: 0.99999523/1.0	min: 4.724144e-06	loss: 34320.58984375	train_loss: 34358.93861047241	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1087
Epoch: 1087	max: 0.9999963/1.0	min: 3.7172333e-06	loss: 34320.8046875	train_loss: 34358.9455457234	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1088
Epoch: 1088	max: 0.9999933/1.0	min: 6.6830157e-06	loss: 34320.43359375	train_loss: 34358.935988886566	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1089
Epoch: 1089	max: 0.99999547/1.0	min: 4.5461397e-06	loss: 34320.40625	train_loss: 34358.95160275765	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1090
Epoch: 1090	max: 0.9999968/1.0	min: 3.1593015e-06	loss: 34320.671875	train_loss: 34358.92189048371	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1091
Epoch: 1091	max: 0.9999958/1.0	min: 4.2024244e-06	loss: 34320.80859375	train_loss: 34358.952185816146	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1092
Epoch: 1092	max: 0.9999951/1.0	min: 4.8833076e-06	loss: 34320.4609375	train_loss: 34358.92824945033	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1093
Epoch: 1093	max: 0.9999949/1.0	min: 5.1618345e-06	loss: 34320.6171875	train_loss: 34358.89987845287	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1094
Epoch: 1094	max: 0.99999535/1.0	min: 4.6537434e-06	loss: 34320.62890625	train_loss: 34358.89147612025	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1095
Epoch: 1095	max: 0.9999951/1.0	min: 4.85613e-06	loss: 34320.56640625	train_loss: 34358.88130767683	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1096
Epoch: 1096	max: 0.9999958/1.0	min: 4.1398457e-06	loss: 34320.9296875	train_loss: 34358.87121471649	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1097
Epoch: 1097	max: 0.9999963/1.0	min: 3.7435163e-06	loss: 34320.9765625	train_loss: 34358.89756025099	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1098
Epoch: 1098	max: 0.99999607/1.0	min: 3.9737865e-06	loss: 34320.8203125	train_loss: 34358.88453409513	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1099
Epoch: 1099	max: 0.9999969/1.0	min: 3.1216343e-06	loss: 34320.765625	train_loss: 34358.85807727146	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1100
Epoch: 1100	max: 0.9999963/1.0	min: 3.7019358e-06	loss: 34320.55078125	train_loss: 34358.843627098046	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1101
Epoch: 1101	max: 0.9999957/1.0	min: 4.3093332e-06	loss: 34320.39453125	train_loss: 34358.848012375354	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1102
Epoch: 1102	max: 0.9999956/1.0	min: 4.424355e-06	loss: 34320.71484375	train_loss: 34358.82687565806	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1103
Epoch: 1103	max: 0.9999958/1.0	min: 4.1817557e-06	loss: 34320.5390625	train_loss: 34358.82185167766	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1104
Epoch: 1104	max: 0.9999958/1.0	min: 4.1215712e-06	loss: 34320.66015625	train_loss: 34358.83634878608	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1105
Epoch: 1105	max: 0.9999968/1.0	min: 3.2151736e-06	loss: 34320.85546875	train_loss: 34358.826110665956	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1106
Epoch: 1106	max: 0.9999963/1.0	min: 3.681165e-06	loss: 34320.875	train_loss: 34358.821680389105	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1107
Epoch: 1107	max: 0.9999944/1.0	min: 5.6576373e-06	loss: 34320.71875	train_loss: 34358.81409095132	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1108
Epoch: 1108	max: 0.99999547/1.0	min: 4.553855e-06	loss: 34320.74609375	train_loss: 34358.79315407067	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1109
Epoch: 1109	max: 0.99999464/1.0	min: 5.3501226e-06	loss: 34320.484375	train_loss: 34358.7841367444	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1110
Epoch: 1110	max: 0.9999957/1.0	min: 4.245838e-06	loss: 34320.62109375	train_loss: 34358.77577070172	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1111
Epoch: 1111	max: 0.9999958/1.0	min: 4.1156163e-06	loss: 34320.984375	train_loss: 34358.76051924625	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1112
Epoch: 1112	max: 0.99999416/1.0	min: 5.8151923e-06	loss: 34320.46875	train_loss: 34358.79817659947	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1113
Epoch: 1113	max: 0.9999963/1.0	min: 3.7442444e-06	loss: 34320.44921875	train_loss: 34358.764370335535	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1114
Epoch: 1114	max: 0.99999666/1.0	min: 3.3826989e-06	loss: 34320.4921875	train_loss: 34358.75844007417	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1115
Epoch: 1115	max: 0.99999595/1.0	min: 4.1087496e-06	loss: 34320.46875	train_loss: 34358.743594098385	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1116
Epoch: 1116	max: 0.9999956/1.0	min: 4.372556e-06	loss: 34320.4609375	train_loss: 34358.72900941023	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1117
Epoch: 1117	max: 0.99999523/1.0	min: 4.7123417e-06	loss: 34320.70703125	train_loss: 34358.738886082465	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1118
Epoch: 1118	max: 0.9999951/1.0	min: 4.8556763e-06	loss: 34320.44140625	train_loss: 34358.72164351852	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1119
Epoch: 1119	max: 0.99999523/1.0	min: 4.7407348e-06	loss: 34320.59375	train_loss: 34358.69560136799	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1120
Epoch: 1120	max: 0.999995/1.0	min: 5.047659e-06	loss: 34320.7890625	train_loss: 34358.699326168244	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1121
Epoch: 1121	max: 0.9999956/1.0	min: 4.4005083e-06	loss: 34320.4375	train_loss: 34358.67572802474	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1122
Epoch: 1122	max: 0.999995/1.0	min: 5.0337476e-06	loss: 34320.19921875	train_loss: 34358.63587392001	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1123
Epoch: 1123	max: 0.99999285/1.0	min: 7.1151217e-06	loss: 34320.3046875	train_loss: 34358.685691308994	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1124
Epoch: 1124	max: 0.9999951/1.0	min: 4.8970137e-06	loss: 34320.40625	train_loss: 34358.643674323364	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1125
Epoch: 1125	max: 0.9999968/1.0	min: 3.1745928e-06	loss: 34320.58984375	train_loss: 34358.593435003255	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1126
Epoch: 1126	max: 0.99999607/1.0	min: 3.974018e-06	loss: 34320.3359375	train_loss: 34358.586689911586	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1127
Epoch: 1127	max: 0.99999475/1.0	min: 5.2065175e-06	loss: 34320.265625	train_loss: 34358.55632054766	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1128
Epoch: 1128	max: 0.9999963/1.0	min: 3.7184495e-06	loss: 34320.3203125	train_loss: 34358.54817127694	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1129
Epoch: 1129	max: 0.99999654/1.0	min: 3.5125963e-06	loss: 34320.26953125	train_loss: 34358.54997270996	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1130
Epoch: 1130	max: 0.9999964/1.0	min: 3.519869e-06	loss: 34320.34375	train_loss: 34358.5399653939	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1131
Epoch: 1131	max: 0.99999475/1.0	min: 5.2390224e-06	loss: 34320.30078125	train_loss: 34358.518955449494	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1132
Epoch: 1132	max: 0.9999956/1.0	min: 4.380131e-06	loss: 34320.578125	train_loss: 34358.515631290255	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1133
Epoch: 1133	max: 0.99999607/1.0	min: 3.97268e-06	loss: 34320.32421875	train_loss: 34358.515914351854	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1134
Epoch: 1134	max: 0.9999975/1.0	min: 2.468709e-06	loss: 34320.30859375	train_loss: 34358.48552805262	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1135
Epoch: 1135	max: 0.9999949/1.0	min: 5.160205e-06	loss: 34320.1640625	train_loss: 34358.48012133423	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1136
Epoch: 1136	max: 0.999995/1.0	min: 5.0199505e-06	loss: 34320.23828125	train_loss: 34358.45958122368	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1137
Epoch: 1137	max: 0.99999654/1.0	min: 3.4630393e-06	loss: 34320.328125	train_loss: 34358.46623002601	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1138
Epoch: 1138	max: 0.99999475/1.0	min: 5.1889797e-06	loss: 34320.296875	train_loss: 34358.437562902574	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1139
Epoch: 1139	max: 0.9999957/1.0	min: 4.258795e-06	loss: 34320.4296875	train_loss: 34358.44016900471	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1140
Epoch: 1140	max: 0.9999958/1.0	min: 4.1572057e-06	loss: 34320.12890625	train_loss: 34358.41376153537	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1141
Epoch: 1141	max: 0.99999523/1.0	min: 4.8231764e-06	loss: 34320.2109375	train_loss: 34358.42819332187	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1142
Epoch: 1142	max: 0.99999595/1.0	min: 4.031793e-06	loss: 34320.32421875	train_loss: 34358.40081666899	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1143
Epoch: 1143	max: 0.99999595/1.0	min: 4.041086e-06	loss: 34320.21875	train_loss: 34358.38472522219	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1144
Epoch: 1144	max: 0.9999964/1.0	min: 3.5827945e-06	loss: 34320.3984375	train_loss: 34358.378670123406	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1145
Epoch: 1145	max: 0.9999957/1.0	min: 4.3370887e-06	loss: 34320.234375	train_loss: 34358.366672666605	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1146
Epoch: 1146	max: 0.999995/1.0	min: 4.952739e-06	loss: 34320.359375	train_loss: 34358.34966574539	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1147
Epoch: 1147	max: 0.99999547/1.0	min: 4.571643e-06	loss: 34320.296875	train_loss: 34358.336948779885	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1148
Epoch: 1148	max: 0.99999535/1.0	min: 4.608711e-06	loss: 34320.265625	train_loss: 34358.33196108943	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1149
Epoch: 1149	max: 0.99999475/1.0	min: 5.287308e-06	loss: 34320.15234375	train_loss: 34358.31786558977	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1150
Epoch: 1150	max: 0.99999404/1.0	min: 5.9815666e-06	loss: 34320.03125	train_loss: 34358.32569405735	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1151
Epoch: 1151	max: 0.9999944/1.0	min: 5.568973e-06	loss: 34320.08203125	train_loss: 34358.341935986464	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1152
Epoch: 1152	max: 0.9999956/1.0	min: 4.44432e-06	loss: 34320.38671875	train_loss: 34358.3028759058	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1153
Epoch: 1153	max: 0.99999523/1.0	min: 4.7545627e-06	loss: 34320.578125	train_loss: 34358.29972980924	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1154
Epoch: 1154	max: 0.9999958/1.0	min: 4.216467e-06	loss: 34320.30078125	train_loss: 34358.31701688886	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1155
Epoch: 1155	max: 0.9999957/1.0	min: 4.3297578e-06	loss: 34320.30078125	train_loss: 34358.26645337854	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1156
Epoch: 1156	max: 0.9999957/1.0	min: 4.255811e-06	loss: 34320.6015625	train_loss: 34358.273249276135	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1157
Epoch: 1157	max: 0.9999974/1.0	min: 2.581523e-06	loss: 34320.375	train_loss: 34358.28381932832	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1158
Epoch: 1158	max: 0.99999547/1.0	min: 4.5738498e-06	loss: 34320.46484375	train_loss: 34358.33318962514	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1159
Epoch: 1159	max: 0.9999958/1.0	min: 4.219146e-06	loss: 34320.109375	train_loss: 34358.28742364595	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1160
Epoch: 1160	max: 0.99999547/1.0	min: 4.4729145e-06	loss: 34320.203125	train_loss: 34358.23287453162	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1161
Epoch: 1161	max: 0.9999951/1.0	min: 4.8927236e-06	loss: 34319.9921875	train_loss: 34358.21416585377	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1162
Epoch: 1162	max: 0.9999968/1.0	min: 3.170962e-06	loss: 34320.08203125	train_loss: 34358.19328123065	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1163
Epoch: 1163	max: 0.99999523/1.0	min: 4.795012e-06	loss: 34320.01171875	train_loss: 34358.19603007324	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1164
Epoch: 1164	max: 0.99999535/1.0	min: 4.632489e-06	loss: 34320.40625	train_loss: 34358.184146324944	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1165
Epoch: 1165	max: 0.9999964/1.0	min: 3.548403e-06	loss: 34320.43359375	train_loss: 34358.183167947944	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1166
Epoch: 1166	max: 0.99999404/1.0	min: 6.0158054e-06	loss: 34319.9453125	train_loss: 34358.157288860246	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1167
Epoch: 1167	max: 0.9999933/1.0	min: 6.698374e-06	loss: 34319.890625	train_loss: 34358.15889481141	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1168
Epoch: 1168	max: 0.99999464/1.0	min: 5.3636145e-06	loss: 34320.11328125	train_loss: 34358.15305164592	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1169
Epoch: 1169	max: 0.99999285/1.0	min: 7.0944625e-06	loss: 34319.92578125	train_loss: 34358.135836178466	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1170
Epoch: 1170	max: 0.9999926/1.0	min: 7.3985266e-06	loss: 34319.8984375	train_loss: 34358.134996671004	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1171
Epoch: 1171	max: 0.99999344/1.0	min: 6.5187414e-06	loss: 34320.0859375	train_loss: 34358.11352753778	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1172
Epoch: 1172	max: 0.9999945/1.0	min: 5.5134083e-06	loss: 34320.296875	train_loss: 34358.09305952326	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1173
Epoch: 1173	max: 0.9999957/1.0	min: 4.313313e-06	loss: 34320.296875	train_loss: 34358.1016592732	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1174
Epoch: 1174	max: 0.9999951/1.0	min: 4.921758e-06	loss: 34320.12109375	train_loss: 34358.088099413166	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1175
Epoch: 1175	max: 0.99999714/1.0	min: 2.9117075e-06	loss: 34319.90625	train_loss: 34358.08257801855	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1176
Epoch: 1176	max: 0.9999964/1.0	min: 3.57012e-06	loss: 34320.05859375	train_loss: 34358.05840262294	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1177
Epoch: 1177	max: 0.9999981/1.0	min: 1.8828571e-06	loss: 34320.28515625	train_loss: 34358.03770428822	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1178
Epoch: 1178	max: 0.99999714/1.0	min: 2.8615616e-06	loss: 34319.96875	train_loss: 34358.024924904	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1179
Epoch: 1179	max: 0.9999933/1.0	min: 6.622123e-06	loss: 34319.88671875	train_loss: 34358.02677714294	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1180
Epoch: 1180	max: 0.999997/1.0	min: 3.0252834e-06	loss: 34319.87109375	train_loss: 34358.01743175554	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1181
Epoch: 1181	max: 0.9999943/1.0	min: 5.720071e-06	loss: 34320.0546875	train_loss: 34357.990478485386	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1182
Epoch: 1182	max: 0.99999607/1.0	min: 3.9308443e-06	loss: 34319.96875	train_loss: 34357.98071842484	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1183
Epoch: 1183	max: 0.9999975/1.0	min: 2.4948833e-06	loss: 34319.82421875	train_loss: 34357.95602384104	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1184
Epoch: 1184	max: 0.9999944/1.0	min: 5.6617773e-06	loss: 34320.00390625	train_loss: 34357.95309354871	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1185
Epoch: 1185	max: 0.9999944/1.0	min: 5.5894316e-06	loss: 34319.81640625	train_loss: 34357.96575003097	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1186
Epoch: 1186	max: 0.9999963/1.0	min: 3.6911415e-06	loss: 34319.953125	train_loss: 34357.92806171033	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1187
Epoch: 1187	max: 0.99999416/1.0	min: 5.833979e-06	loss: 34319.94921875	train_loss: 34357.914170885975	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1188
Epoch: 1188	max: 0.9999964/1.0	min: 3.604791e-06	loss: 34320.1875	train_loss: 34357.897903795834	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1189
Epoch: 1189	max: 0.99999535/1.0	min: 4.613874e-06	loss: 34319.953125	train_loss: 34357.95404144215	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1190
Epoch: 1190	max: 0.9999945/1.0	min: 5.4741868e-06	loss: 34320.08203125	train_loss: 34357.88854776338	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1191
Epoch: 1191	max: 0.99999523/1.0	min: 4.817168e-06	loss: 34319.87109375	train_loss: 34357.88693987675	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1192
Epoch: 1192	max: 0.9999964/1.0	min: 3.6152846e-06	loss: 34319.9296875	train_loss: 34357.858959843	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1193
Epoch: 1193	max: 0.9999931/1.0	min: 6.8653335e-06	loss: 34319.765625	train_loss: 34357.85071863775	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1194
Epoch: 1194	max: 0.9999956/1.0	min: 4.3841133e-06	loss: 34319.8359375	train_loss: 34357.83974649294	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1195
Epoch: 1195	max: 0.9999963/1.0	min: 3.7443804e-06	loss: 34319.82421875	train_loss: 34357.823368597485	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1196
Epoch: 1196	max: 0.99999905/1.0	min: 9.656302e-07	loss: 34320.45703125	train_loss: 34357.822693120586	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1197
Epoch: 1197	max: 0.99999845/1.0	min: 1.5782026e-06	loss: 34319.8515625	train_loss: 34357.84784737706	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1198
Epoch: 1198	max: 0.9999956/1.0	min: 4.357237e-06	loss: 34319.73828125	train_loss: 34357.79762837932	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1199
Epoch: 1199	max: 0.9999989/1.0	min: 1.0839574e-06	loss: 34320.03515625	train_loss: 34357.77189493528	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1200
Epoch: 1200	max: 0.9999982/1.0	min: 1.8044343e-06	loss: 34319.98828125	train_loss: 34357.77509087003	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1201
Epoch: 1201	max: 0.9999951/1.0	min: 4.93106e-06	loss: 34319.875	train_loss: 34357.776864722684	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1202
Epoch: 1202	max: 0.99999535/1.0	min: 4.608276e-06	loss: 34319.6796875	train_loss: 34357.73670481466	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1203
Epoch: 1203	max: 0.99999785/1.0	min: 2.1034832e-06	loss: 34320.07421875	train_loss: 34357.738228508606	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1204
Epoch: 1204	max: 0.99999833/1.0	min: 1.6441255e-06	loss: 34320.03125	train_loss: 34357.72434349065	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1205
Epoch: 1205	max: 0.9999982/1.0	min: 1.8092867e-06	loss: 34319.98046875	train_loss: 34357.71053202031	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1206
Epoch: 1206	max: 0.99999547/1.0	min: 4.5277293e-06	loss: 34319.84375	train_loss: 34357.70746769711	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1207
Epoch: 1207	max: 0.9999943/1.0	min: 5.7420148e-06	loss: 34319.765625	train_loss: 34357.67814009662	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1208
Epoch: 1208	max: 0.9999974/1.0	min: 2.5733134e-06	loss: 34319.89453125	train_loss: 34357.67951621144	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1209
Epoch: 1209	max: 0.99999523/1.0	min: 4.72922e-06	loss: 34319.9453125	train_loss: 34357.67108194367	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1210
Epoch: 1210	max: 0.9999908/1.0	min: 9.224095e-06	loss: 34319.72265625	train_loss: 34357.64405077109	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1211
Epoch: 1211	max: 0.99999416/1.0	min: 5.839517e-06	loss: 34319.73828125	train_loss: 34357.637876641274	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1212
Epoch: 1212	max: 0.9999964/1.0	min: 3.5187547e-06	loss: 34319.96484375	train_loss: 34357.625209513964	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1213
Epoch: 1213	max: 0.99999416/1.0	min: 5.877341e-06	loss: 34319.875	train_loss: 34357.595441111574	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1214
Epoch: 1214	max: 0.99999666/1.0	min: 3.3153078e-06	loss: 34319.7109375	train_loss: 34357.59470950622	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1215
Epoch: 1215	max: 0.9999962/1.0	min: 3.7640718e-06	loss: 34319.6953125	train_loss: 34357.57394439799	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1216
Epoch: 1216	max: 0.99999607/1.0	min: 3.952907e-06	loss: 34319.72265625	train_loss: 34357.56569206382	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1217
Epoch: 1217	max: 0.9999913/1.0	min: 8.75631e-06	loss: 34319.6640625	train_loss: 34357.566103833764	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1218
Epoch: 1218	max: 0.9999964/1.0	min: 3.6145057e-06	loss: 34319.65625	train_loss: 34357.551006247675	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1219
Epoch: 1219	max: 0.99999404/1.0	min: 5.905878e-06	loss: 34319.453125	train_loss: 34357.54899288136	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1220
Epoch: 1220	max: 0.9999968/1.0	min: 3.212152e-06	loss: 34319.59375	train_loss: 34357.592160984146	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1221
Epoch: 1221	max: 0.9999944/1.0	min: 5.545342e-06	loss: 34319.921875	train_loss: 34357.507048959495	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1222
Epoch: 1222	max: 0.99999666/1.0	min: 3.3317453e-06	loss: 34319.91796875	train_loss: 34357.491923793044	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1223
Epoch: 1223	max: 0.99999404/1.0	min: 5.979223e-06	loss: 34319.69140625	train_loss: 34357.47443881224	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1224
Epoch: 1224	max: 0.999997/1.0	min: 2.9319006e-06	loss: 34319.859375	train_loss: 34357.46838710052	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1225
Epoch: 1225	max: 0.99999654/1.0	min: 3.451279e-06	loss: 34319.4453125	train_loss: 34357.44229124086	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1226
Epoch: 1226	max: 0.9999951/1.0	min: 4.8375023e-06	loss: 34319.69140625	train_loss: 34357.44334413322	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1227
Epoch: 1227	max: 0.9999931/1.0	min: 6.9726225e-06	loss: 34319.5390625	train_loss: 34357.43362278196	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1228
Epoch: 1228	max: 0.99999356/1.0	min: 6.455159e-06	loss: 34319.4296875	train_loss: 34357.409399483615	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1229
Epoch: 1229	max: 0.99999344/1.0	min: 6.555918e-06	loss: 34319.515625	train_loss: 34357.392011759875	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1230
Epoch: 1230	max: 0.9999944/1.0	min: 5.6174867e-06	loss: 34319.71875	train_loss: 34357.370277951966	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1231
Epoch: 1231	max: 0.9999975/1.0	min: 2.5214385e-06	loss: 34319.68359375	train_loss: 34357.35785808018	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1232
Epoch: 1232	max: 0.9999963/1.0	min: 3.6652261e-06	loss: 34319.82421875	train_loss: 34357.37582886241	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1233
Epoch: 1233	max: 0.99999464/1.0	min: 5.4197376e-06	loss: 34319.71484375	train_loss: 34357.34639529527	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1234
Epoch: 1234	max: 0.99999475/1.0	min: 5.2447112e-06	loss: 34319.6640625	train_loss: 34357.34347322866	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1235
Epoch: 1235	max: 0.999997/1.0	min: 2.9888033e-06	loss: 34319.4609375	train_loss: 34357.30819456057	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1236
Epoch: 1236	max: 0.9999963/1.0	min: 3.6645865e-06	loss: 34319.546875	train_loss: 34357.29724370587	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1237
Epoch: 1237	max: 0.9999975/1.0	min: 2.5112613e-06	loss: 34319.74609375	train_loss: 34357.28716622925	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1238
Epoch: 1238	max: 0.9999976/1.0	min: 2.3388295e-06	loss: 34319.79296875	train_loss: 34357.28751219342	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1239
Epoch: 1239	max: 0.9999943/1.0	min: 5.6902763e-06	loss: 34319.7734375	train_loss: 34357.26119327155	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1240
Epoch: 1240	max: 0.9999939/1.0	min: 6.101432e-06	loss: 34319.609375	train_loss: 34357.2622534219	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1241
Epoch: 1241	max: 0.9999964/1.0	min: 3.566683e-06	loss: 34319.6015625	train_loss: 34357.23383403784	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1242
Epoch: 1242	max: 0.999997/1.0	min: 2.9666023e-06	loss: 34319.5390625	train_loss: 34357.238047542734	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1243
Epoch: 1243	max: 0.99999595/1.0	min: 4.037419e-06	loss: 34319.75	train_loss: 34357.24347555122	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1244
Epoch: 1244	max: 0.9999964/1.0	min: 3.5969201e-06	loss: 34319.37109375	train_loss: 34357.23081955283	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1245
Epoch: 1245	max: 0.9999937/1.0	min: 6.2968525e-06	loss: 34319.6796875	train_loss: 34357.198976333144	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1246
Epoch: 1246	max: 0.9999956/1.0	min: 4.416914e-06	loss: 34319.87109375	train_loss: 34357.1963561989	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1247
Epoch: 1247	max: 0.99999297/1.0	min: 7.0067103e-06	loss: 34319.4453125	train_loss: 34357.33615475582	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1248
Epoch: 1248	max: 0.999992/1.0	min: 8.021177e-06	loss: 34319.34375	train_loss: 34357.228747638736	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1249
Epoch: 1249	max: 0.9999981/1.0	min: 1.937493e-06	loss: 34319.609375	train_loss: 34357.18502115462	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1250
Epoch: 1250	max: 0.9999963/1.0	min: 3.7191196e-06	loss: 34319.38671875	train_loss: 34357.15590451969	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1251
Epoch: 1251	max: 0.9999975/1.0	min: 2.5420145e-06	loss: 34319.4140625	train_loss: 34357.13852018302	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1252
Epoch: 1252	max: 0.9999943/1.0	min: 5.7678094e-06	loss: 34319.53515625	train_loss: 34357.13685423247	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1253
Epoch: 1253	max: 0.9999943/1.0	min: 5.7349057e-06	loss: 34319.55859375	train_loss: 34357.12513209541	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1254
Epoch: 1254	max: 0.999995/1.0	min: 5.034194e-06	loss: 34319.62890625	train_loss: 34357.1087479097	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1255
Epoch: 1255	max: 0.99999523/1.0	min: 4.824538e-06	loss: 34319.3359375	train_loss: 34357.08695942494	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1256
Epoch: 1256	max: 0.9999964/1.0	min: 3.5373005e-06	loss: 34319.60546875	train_loss: 34357.08320946364	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1257
Epoch: 1257	max: 0.9999939/1.0	min: 6.1046744e-06	loss: 34319.5546875	train_loss: 34357.09133647653	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1258
Epoch: 1258	max: 0.99999726/1.0	min: 2.7184242e-06	loss: 34319.43359375	train_loss: 34357.08377510297	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1259
Epoch: 1259	max: 0.99999654/1.0	min: 3.4925279e-06	loss: 34319.390625	train_loss: 34357.064619816825	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1260
Epoch: 1260	max: 0.99999344/1.0	min: 6.5363906e-06	loss: 34319.296875	train_loss: 34357.05527394556	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1261
Epoch: 1261	max: 0.9999895/1.0	min: 1.0473648e-05	loss: 34319.30078125	train_loss: 34357.050910442216	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1262
Epoch: 1262	max: 0.99999225/1.0	min: 7.774378e-06	loss: 34319.31640625	train_loss: 34357.08632652824	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1263
Epoch: 1263	max: 0.99999607/1.0	min: 3.9804922e-06	loss: 34319.40625	train_loss: 34357.05786649944	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1264
Epoch: 1264	max: 0.99999845/1.0	min: 1.5146569e-06	loss: 34319.5625	train_loss: 34357.03068678001	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1265
Epoch: 1265	max: 0.99999404/1.0	min: 5.9195913e-06	loss: 34319.1953125	train_loss: 34357.03377239332	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1266
Epoch: 1266	max: 0.99999154/1.0	min: 8.498046e-06	loss: 34319.2890625	train_loss: 34357.04309842608	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1267
Epoch: 1267	max: 0.9999933/1.0	min: 6.705577e-06	loss: 34319.31640625	train_loss: 34357.02313072897	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1268
Epoch: 1268	max: 0.9999962/1.0	min: 3.827696e-06	loss: 34319.609375	train_loss: 34356.99780324848	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1269
Epoch: 1269	max: 0.999992/1.0	min: 7.962771e-06	loss: 34319.51953125	train_loss: 34356.98967042921	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1270
Epoch: 1270	max: 0.9999949/1.0	min: 5.0973204e-06	loss: 34319.3203125	train_loss: 34356.96494003933	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1271
Epoch: 1271	max: 0.9999968/1.0	min: 3.1845052e-06	loss: 34319.40625	train_loss: 34356.97324027623	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1272
Epoch: 1272	max: 0.9999939/1.0	min: 6.0560583e-06	loss: 34319.3515625	train_loss: 34356.9567070598	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1273
Epoch: 1273	max: 0.99999523/1.0	min: 4.7599433e-06	loss: 34319.30078125	train_loss: 34356.94823263115	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1274
Epoch: 1274	max: 0.9999951/1.0	min: 4.8701736e-06	loss: 34319.453125	train_loss: 34356.9408701265	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1275
Epoch: 1275	max: 0.9999957/1.0	min: 4.2422e-06	loss: 34319.3359375	train_loss: 34356.93198296017	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1276
Epoch: 1276	max: 0.99999225/1.0	min: 7.763338e-06	loss: 34319.25390625	train_loss: 34356.925826249535	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1277
Epoch: 1277	max: 0.9999968/1.0	min: 3.2478436e-06	loss: 34319.43359375	train_loss: 34356.91830939164	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1278
Epoch: 1278	max: 0.9999958/1.0	min: 4.119551e-06	loss: 34319.19140625	train_loss: 34356.92755510266	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1279
Epoch: 1279	max: 0.9999906/1.0	min: 9.378138e-06	loss: 34319.23046875	train_loss: 34356.90468179038	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1280
Epoch: 1280	max: 0.99999654/1.0	min: 3.4361751e-06	loss: 34319.37890625	train_loss: 34356.89335690728	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1281
Epoch: 1281	max: 0.99999666/1.0	min: 3.3783178e-06	loss: 34319.50390625	train_loss: 34356.8848573176	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1282
Epoch: 1282	max: 0.9999949/1.0	min: 5.069861e-06	loss: 34319.39453125	train_loss: 34356.88634375387	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1283
Epoch: 1283	max: 0.9999943/1.0	min: 5.681563e-06	loss: 34319.2265625	train_loss: 34356.86736265948	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1284
Epoch: 1284	max: 0.99999714/1.0	min: 2.820445e-06	loss: 34319.6015625	train_loss: 34356.86238029156	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1285
Epoch: 1285	max: 0.9999912/1.0	min: 8.857676e-06	loss: 34319.4375	train_loss: 34356.871899386846	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1286
Epoch: 1286	max: 0.9999925/1.0	min: 7.5196594e-06	loss: 34319.51953125	train_loss: 34356.853050387865	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1287
Epoch: 1287	max: 0.99999654/1.0	min: 3.4835032e-06	loss: 34319.234375	train_loss: 34356.84399193298	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1288
Epoch: 1288	max: 0.9999974/1.0	min: 2.6510922e-06	loss: 34319.171875	train_loss: 34356.82455600458	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1289
Epoch: 1289	max: 0.9999944/1.0	min: 5.5627784e-06	loss: 34319.21484375	train_loss: 34356.84808253592	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1290
Epoch: 1290	max: 0.99999404/1.0	min: 5.9924205e-06	loss: 34319.390625	train_loss: 34356.81658721587	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1291
Epoch: 1291	max: 0.9999975/1.0	min: 2.4623487e-06	loss: 34319.265625	train_loss: 34356.807090378425	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1292
Epoch: 1292	max: 0.9999932/1.0	min: 6.740815e-06	loss: 34319.3984375	train_loss: 34356.80207897854	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1293
Epoch: 1293	max: 0.9999963/1.0	min: 3.67083e-06	loss: 34319.3046875	train_loss: 34356.80304138796	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1294
Epoch: 1294	max: 0.99999285/1.0	min: 7.123799e-06	loss: 34319.2734375	train_loss: 34356.78721751904	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1295
Epoch: 1295	max: 0.9999976/1.0	min: 2.3832467e-06	loss: 34319.125	train_loss: 34356.779809531	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1296
Epoch: 1296	max: 0.9999963/1.0	min: 3.6559682e-06	loss: 34319.09375	train_loss: 34356.771608970485	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1297
Epoch: 1297	max: 0.99999475/1.0	min: 5.217443e-06	loss: 34319.32421875	train_loss: 34356.78503479964	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1298
Epoch: 1298	max: 0.99999344/1.0	min: 6.5124473e-06	loss: 34319.3359375	train_loss: 34356.74387086972	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1299
Epoch: 1299	max: 0.9999962/1.0	min: 3.764603e-06	loss: 34319.23828125	train_loss: 34356.74539214434	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1300
Epoch: 1300	max: 0.9999949/1.0	min: 5.1756465e-06	loss: 34319.29296875	train_loss: 34356.736329334664	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1301
Epoch: 1301	max: 0.99999666/1.0	min: 3.3786077e-06	loss: 34319.28125	train_loss: 34356.73817721882	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1302
Epoch: 1302	max: 0.9999969/1.0	min: 3.0894355e-06	loss: 34319.609375	train_loss: 34356.723679626535	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1303
Epoch: 1303	max: 0.99999464/1.0	min: 5.347796e-06	loss: 34319.3125	train_loss: 34356.74038751858	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1304
Epoch: 1304	max: 0.9999962/1.0	min: 3.8067963e-06	loss: 34319.25	train_loss: 34356.70611577558	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1305
Epoch: 1305	max: 0.99999666/1.0	min: 3.3337858e-06	loss: 34319.1484375	train_loss: 34356.70368967159	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1306
Epoch: 1306	max: 0.99999607/1.0	min: 3.9542947e-06	loss: 34319.30078125	train_loss: 34356.690999318715	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1307
Epoch: 1307	max: 0.99999464/1.0	min: 5.3413637e-06	loss: 34319.1953125	train_loss: 34356.6872909699	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1308
Epoch: 1308	max: 0.99999654/1.0	min: 3.449453e-06	loss: 34319.5703125	train_loss: 34356.67904347439	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1309
Epoch: 1309	max: 0.9999949/1.0	min: 5.1195843e-06	loss: 34319.11328125	train_loss: 34356.6801752369	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1310
Epoch: 1310	max: 0.9999912/1.0	min: 8.823067e-06	loss: 34319.0234375	train_loss: 34356.667782945464	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1311
Epoch: 1311	max: 0.9999968/1.0	min: 3.223448e-06	loss: 34319.43359375	train_loss: 34356.66914018952	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1312
Epoch: 1312	max: 0.9999975/1.0	min: 2.477766e-06	loss: 34319.46484375	train_loss: 34356.641576280505	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1313
Epoch: 1313	max: 0.9999956/1.0	min: 4.423507e-06	loss: 34319.23828125	train_loss: 34356.67097839635	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1314
Epoch: 1314	max: 0.9999949/1.0	min: 5.075981e-06	loss: 34319.25390625	train_loss: 34356.62346808033	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1315
Epoch: 1315	max: 0.9999976/1.0	min: 2.4249298e-06	loss: 34319.28125	train_loss: 34356.62498354856	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1316
Epoch: 1316	max: 0.99999666/1.0	min: 3.3564581e-06	loss: 34319.44140625	train_loss: 34356.608162915734	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1317
Epoch: 1317	max: 0.99999535/1.0	min: 4.614182e-06	loss: 34319.1953125	train_loss: 34356.610074186334	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1318
Epoch: 1318	max: 0.9999968/1.0	min: 3.19155e-06	loss: 34319.29296875	train_loss: 34356.59983074368	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1319
Epoch: 1319	max: 0.99999595/1.0	min: 4.0876453e-06	loss: 34319.21484375	train_loss: 34356.59266275316	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1320
Epoch: 1320	max: 0.9999962/1.0	min: 3.8312714e-06	loss: 34319.4296875	train_loss: 34356.59915671838	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1321
Epoch: 1321	max: 0.99999714/1.0	min: 2.8868562e-06	loss: 34319.19921875	train_loss: 34356.590490678806	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1322
Epoch: 1322	max: 0.9999956/1.0	min: 4.384264e-06	loss: 34318.9453125	train_loss: 34356.586739749786	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1323
Epoch: 1323	max: 0.99998736/1.0	min: 1.2671046e-05	loss: 34319.125	train_loss: 34356.58877730939	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1324
Epoch: 1324	max: 0.9999963/1.0	min: 3.6586468e-06	loss: 34319.12109375	train_loss: 34356.56064389013	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1325
Epoch: 1325	max: 0.99999464/1.0	min: 5.3504796e-06	loss: 34319.08984375	train_loss: 34356.54599775099	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1326
Epoch: 1326	max: 0.9999989/1.0	min: 1.0499053e-06	loss: 34319.046875	train_loss: 34356.54058764555	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1327
Epoch: 1327	max: 0.9999963/1.0	min: 3.6800418e-06	loss: 34319.2109375	train_loss: 34356.5395942687	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1328
Epoch: 1328	max: 0.99999535/1.0	min: 4.6067953e-06	loss: 34319.25390625	train_loss: 34356.530493233615	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1329
Epoch: 1329	max: 0.999997/1.0	min: 2.929472e-06	loss: 34319.12890625	train_loss: 34356.52788906695	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1330
Epoch: 1330	max: 0.99999416/1.0	min: 5.8833807e-06	loss: 34318.93359375	train_loss: 34356.516610634986	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1331
Epoch: 1331	max: 0.99999523/1.0	min: 4.762872e-06	loss: 34319.234375	train_loss: 34356.525347318995	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1332
Epoch: 1332	max: 0.9999962/1.0	min: 3.782301e-06	loss: 34319.2421875	train_loss: 34356.502053043325	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1333
Epoch: 1333	max: 0.9999968/1.0	min: 3.268781e-06	loss: 34319.140625	train_loss: 34356.500978377	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1334
Epoch: 1334	max: 0.9999949/1.0	min: 5.1623856e-06	loss: 34319.36328125	train_loss: 34356.55457330763	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1335
Epoch: 1335	max: 0.999998/1.0	min: 2.0276536e-06	loss: 34319.44921875	train_loss: 34356.5069536379	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1336
Epoch: 1336	max: 0.9999981/1.0	min: 1.9142667e-06	loss: 34319.3359375	train_loss: 34356.48863302056	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1337
Epoch: 1337	max: 0.9999951/1.0	min: 4.9314176e-06	loss: 34319.1171875	train_loss: 34356.472422542734	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1338
Epoch: 1338	max: 0.9999951/1.0	min: 4.8396346e-06	loss: 34319.0859375	train_loss: 34356.46682421343	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1339
Epoch: 1339	max: 0.99999654/1.0	min: 3.411298e-06	loss: 34318.99609375	train_loss: 34356.46684211647	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1340
Epoch: 1340	max: 0.9999964/1.0	min: 3.6222143e-06	loss: 34318.80078125	train_loss: 34356.45223081568	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1341
Epoch: 1341	max: 0.99999154/1.0	min: 8.483858e-06	loss: 34319.140625	train_loss: 34356.48080068206	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1342
Epoch: 1342	max: 0.9999883/1.0	min: 1.1646016e-05	loss: 34319.0703125	train_loss: 34356.46654792596	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1343
Epoch: 1343	max: 0.9999987/1.0	min: 1.2562748e-06	loss: 34319.5234375	train_loss: 34356.4184366484	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1344
Epoch: 1344	max: 0.99999666/1.0	min: 3.348692e-06	loss: 34319.1328125	train_loss: 34356.47310624536	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1345
Epoch: 1345	max: 0.9999987/1.0	min: 1.290546e-06	loss: 34319.19140625	train_loss: 34356.42221225458	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1346
Epoch: 1346	max: 0.99999535/1.0	min: 4.6612145e-06	loss: 34319.12890625	train_loss: 34356.40083650749	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1347
Epoch: 1347	max: 0.99999404/1.0	min: 5.9851727e-06	loss: 34319.0078125	train_loss: 34356.40556871671	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1348
Epoch: 1348	max: 0.9999933/1.0	min: 6.647489e-06	loss: 34318.9609375	train_loss: 34356.39594075158	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1349
Epoch: 1349	max: 0.9999895/1.0	min: 1.0511543e-05	loss: 34318.828125	train_loss: 34356.43988884631	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1350
Epoch: 1350	max: 0.9999975/1.0	min: 2.5320846e-06	loss: 34319.16015625	train_loss: 34356.37637030843	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1351
Epoch: 1351	max: 0.99999416/1.0	min: 5.8337782e-06	loss: 34319.19140625	train_loss: 34356.35841017125	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1352
Epoch: 1352	max: 0.99999607/1.0	min: 3.961179e-06	loss: 34318.9609375	train_loss: 34356.35375586445	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1353
Epoch: 1353	max: 0.99999654/1.0	min: 3.4715674e-06	loss: 34319.125	train_loss: 34356.34460450731	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1354
Epoch: 1354	max: 0.9999962/1.0	min: 3.7678103e-06	loss: 34319.1640625	train_loss: 34356.34106744704	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1355
Epoch: 1355	max: 0.99999654/1.0	min: 3.4965035e-06	loss: 34318.984375	train_loss: 34356.353998765175	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1356
Epoch: 1356	max: 0.999995/1.0	min: 4.9597156e-06	loss: 34319.109375	train_loss: 34356.35351973786	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1357
Epoch: 1357	max: 0.99999607/1.0	min: 3.964694e-06	loss: 34319.00390625	train_loss: 34356.3219392574	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1358
Epoch: 1358	max: 0.99999845/1.0	min: 1.508369e-06	loss: 34319.109375	train_loss: 34356.30558458751	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1359
Epoch: 1359	max: 0.99999774/1.0	min: 2.3098914e-06	loss: 34319.16015625	train_loss: 34356.30470346758	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1360
Epoch: 1360	max: 0.9999958/1.0	min: 4.1553826e-06	loss: 34319.171875	train_loss: 34356.29542678914	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1361
Epoch: 1361	max: 0.9999951/1.0	min: 4.9222367e-06	loss: 34318.9296875	train_loss: 34356.2942030921	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1362
Epoch: 1362	max: 0.9999944/1.0	min: 5.592833e-06	loss: 34318.984375	train_loss: 34356.28856508578	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1363
Epoch: 1363	max: 0.9999964/1.0	min: 3.6012725e-06	loss: 34318.9609375	train_loss: 34356.29426405921	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1364
Epoch: 1364	max: 0.999997/1.0	min: 2.9921573e-06	loss: 34318.83203125	train_loss: 34356.292189725784	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1365
Epoch: 1365	max: 0.9999968/1.0	min: 3.2368605e-06	loss: 34318.91015625	train_loss: 34356.26282825468	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1366
Epoch: 1366	max: 0.999997/1.0	min: 2.9836658e-06	loss: 34318.98828125	train_loss: 34356.24517343692	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1367
Epoch: 1367	max: 0.99999833/1.0	min: 1.7261208e-06	loss: 34319.16015625	train_loss: 34356.26366534281	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1368
Epoch: 1368	max: 0.99999523/1.0	min: 4.806912e-06	loss: 34319.05078125	train_loss: 34356.26278373901	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1369
Epoch: 1369	max: 0.99999666/1.0	min: 3.3819636e-06	loss: 34318.93359375	train_loss: 34356.24096138363	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1370
Epoch: 1370	max: 0.99999535/1.0	min: 4.678672e-06	loss: 34318.76171875	train_loss: 34356.23697045708	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1371
Epoch: 1371	max: 0.999998/1.0	min: 2.040577e-06	loss: 34319.15625	train_loss: 34356.2313774503	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1372
Epoch: 1372	max: 0.9999969/1.0	min: 3.0912922e-06	loss: 34319.2109375	train_loss: 34356.21358763393	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1373
Epoch: 1373	max: 0.99999785/1.0	min: 2.1540868e-06	loss: 34319.21484375	train_loss: 34356.19832843661	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1374
Epoch: 1374	max: 0.99999297/1.0	min: 7.0434917e-06	loss: 34318.87890625	train_loss: 34356.21406424192	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1375
Epoch: 1375	max: 0.99999654/1.0	min: 3.4188506e-06	loss: 34318.8984375	train_loss: 34356.19807247151	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1376
Epoch: 1376	max: 0.9999918/1.0	min: 8.21266e-06	loss: 34318.90625	train_loss: 34356.178962668775	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1377
Epoch: 1377	max: 0.99999404/1.0	min: 5.9472954e-06	loss: 34319.046875	train_loss: 34356.19342735817	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1378
Epoch: 1378	max: 0.9999988/1.0	min: 1.2481019e-06	loss: 34319.1640625	train_loss: 34356.17488513022	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1379
Epoch: 1379	max: 0.9999975/1.0	min: 2.486546e-06	loss: 34319.09375	train_loss: 34356.16984324678	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1380
Epoch: 1380	max: 0.9999968/1.0	min: 3.2551184e-06	loss: 34319.140625	train_loss: 34356.15666225381	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1381
Epoch: 1381	max: 0.9999981/1.0	min: 1.8824153e-06	loss: 34319.06640625	train_loss: 34356.15647354608	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1382
Epoch: 1382	max: 0.9999974/1.0	min: 2.5799675e-06	loss: 34318.9296875	train_loss: 34356.145873494206	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1383
Epoch: 1383	max: 0.9999956/1.0	min: 4.3674463e-06	loss: 34318.7265625	train_loss: 34356.13190815449	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1384
Epoch: 1384	max: 0.99999845/1.0	min: 1.5577793e-06	loss: 34319.0390625	train_loss: 34356.15796143395	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1385
Epoch: 1385	max: 0.99999034/1.0	min: 9.621137e-06	loss: 34318.8125	train_loss: 34356.12788480893	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1386
Epoch: 1386	max: 0.999998/1.0	min: 2.036549e-06	loss: 34318.796875	train_loss: 34356.13109284033	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1387
Epoch: 1387	max: 0.9999968/1.0	min: 3.2197302e-06	loss: 34318.8828125	train_loss: 34356.114090273906	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1388
Epoch: 1388	max: 0.9999951/1.0	min: 4.8570932e-06	loss: 34319.11328125	train_loss: 34356.1006596061	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1389
Epoch: 1389	max: 0.9999958/1.0	min: 4.224404e-06	loss: 34318.80078125	train_loss: 34356.097842054536	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1390
Epoch: 1390	max: 0.99999416/1.0	min: 5.847414e-06	loss: 34318.74609375	train_loss: 34356.108939036756	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1391
Epoch: 1391	max: 0.99999607/1.0	min: 3.93174e-06	loss: 34318.859375	train_loss: 34356.10192249629	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1392
Epoch: 1392	max: 0.99999464/1.0	min: 5.3572344e-06	loss: 34318.828125	train_loss: 34356.0817056082	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1393
Epoch: 1393	max: 0.9999902/1.0	min: 9.7755365e-06	loss: 34319.19140625	train_loss: 34356.09305565233	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1394
Epoch: 1394	max: 0.99999356/1.0	min: 6.3985685e-06	loss: 34319.0390625	train_loss: 34356.084386709554	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1395
Epoch: 1395	max: 0.9999981/1.0	min: 1.9583995e-06	loss: 34318.91796875	train_loss: 34356.05415621516	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1396
Epoch: 1396	max: 0.99999905/1.0	min: 9.635725e-07	loss: 34319.0703125	train_loss: 34356.036303012355	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1397
Epoch: 1397	max: 0.99999726/1.0	min: 2.7287801e-06	loss: 34319.078125	train_loss: 34356.06218451939	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1398
Epoch: 1398	max: 0.999995/1.0	min: 5.0318376e-06	loss: 34318.9375	train_loss: 34356.03788138316	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1399
Epoch: 1399	max: 0.9999976/1.0	min: 2.330036e-06	loss: 34318.99609375	train_loss: 34356.01545419531	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1400
Epoch: 1400	max: 0.99999785/1.0	min: 2.1388896e-06	loss: 34318.921875	train_loss: 34356.0139314691	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1401
Epoch: 1401	max: 0.99999356/1.0	min: 6.486013e-06	loss: 34318.9765625	train_loss: 34356.000101611855	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1402
Epoch: 1402	max: 0.99999607/1.0	min: 3.9607107e-06	loss: 34318.94140625	train_loss: 34356.00243674904	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1403
Epoch: 1403	max: 0.9999962/1.0	min: 3.8337457e-06	loss: 34318.76171875	train_loss: 34355.98965301003	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1404
Epoch: 1404	max: 0.99999714/1.0	min: 2.8152824e-06	loss: 34318.8515625	train_loss: 34355.99078767574	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1405
Epoch: 1405	max: 0.999995/1.0	min: 5.0296308e-06	loss: 34318.859375	train_loss: 34355.970710624926	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1406
Epoch: 1406	max: 0.9999949/1.0	min: 5.0869767e-06	loss: 34319.22265625	train_loss: 34355.97667378918	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1407
Epoch: 1407	max: 0.99999654/1.0	min: 3.466846e-06	loss: 34319.17578125	train_loss: 34355.96455052722	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1408
Epoch: 1408	max: 0.9999951/1.0	min: 4.896626e-06	loss: 34319.01953125	train_loss: 34355.96407972563	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1409
Epoch: 1409	max: 0.9999962/1.0	min: 3.8130713e-06	loss: 34318.8515625	train_loss: 34355.944364606556	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1410
Epoch: 1410	max: 0.99999535/1.0	min: 4.6112964e-06	loss: 34318.80859375	train_loss: 34355.95622174223	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1411
Epoch: 1411	max: 0.9999924/1.0	min: 7.617177e-06	loss: 34318.953125	train_loss: 34355.94511943748	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1412
Epoch: 1412	max: 0.99999857/1.0	min: 1.4151195e-06	loss: 34319.015625	train_loss: 34355.939049822715	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1413
Epoch: 1413	max: 0.99999917/1.0	min: 8.210922e-07	loss: 34318.9296875	train_loss: 34355.93739354949	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1414
Epoch: 1414	max: 0.9999987/1.0	min: 1.2614922e-06	loss: 34319.0390625	train_loss: 34355.91175784637	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1415
Epoch: 1415	max: 0.9999982/1.0	min: 1.7594855e-06	loss: 34318.81640625	train_loss: 34355.91330863682	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1416
Epoch: 1416	max: 0.99999714/1.0	min: 2.8963618e-06	loss: 34318.94921875	train_loss: 34355.905094528054	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1417
Epoch: 1417	max: 0.99999857/1.0	min: 1.4413207e-06	loss: 34318.80859375	train_loss: 34355.894217220986	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1418
Epoch: 1418	max: 0.99999666/1.0	min: 3.2921632e-06	loss: 34318.9921875	train_loss: 34355.89259094745	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1419
Epoch: 1419	max: 0.9999988/1.0	min: 1.2019167e-06	loss: 34319.2265625	train_loss: 34355.8909491902	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1420
Epoch: 1420	max: 0.99999845/1.0	min: 1.5908232e-06	loss: 34318.99609375	train_loss: 34355.962445226374	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1421
Epoch: 1421	max: 0.9999993/1.0	min: 7.6548093e-07	loss: 34319.11328125	train_loss: 34355.874138718566	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1422
Epoch: 1422	max: 0.9999981/1.0	min: 1.9095044e-06	loss: 34318.765625	train_loss: 34355.87625756767	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1423
Epoch: 1423	max: 0.9999958/1.0	min: 4.1840694e-06	loss: 34318.7421875	train_loss: 34355.85406892574	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1424
Epoch: 1424	max: 0.999998/1.0	min: 2.0111531e-06	loss: 34318.8125	train_loss: 34355.87668046652	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1425
Epoch: 1425	max: 0.9999982/1.0	min: 1.8462617e-06	loss: 34318.7421875	train_loss: 34355.83011949554	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1426
Epoch: 1426	max: 0.99999833/1.0	min: 1.6752152e-06	loss: 34318.7578125	train_loss: 34355.83108916295	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1427
Epoch: 1427	max: 0.9999962/1.0	min: 3.7626646e-06	loss: 34318.68359375	train_loss: 34355.83256253484	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1428
Epoch: 1428	max: 0.9999968/1.0	min: 3.1909474e-06	loss: 34318.8203125	train_loss: 34355.83492767171	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1429
Epoch: 1429	max: 0.99999917/1.0	min: 8.1428686e-07	loss: 34318.75	train_loss: 34355.812730320205	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1430
Epoch: 1430	max: 0.9999988/1.0	min: 1.1801228e-06	loss: 34319.00390625	train_loss: 34355.80364041404	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1431
Epoch: 1431	max: 0.9999964/1.0	min: 3.6148708e-06	loss: 34318.81640625	train_loss: 34355.790142488855	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1432
Epoch: 1432	max: 0.9999987/1.0	min: 1.3103953e-06	loss: 34318.87109375	train_loss: 34355.784527224234	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1433
Epoch: 1433	max: 0.9999975/1.0	min: 2.55687e-06	loss: 34319.09375	train_loss: 34355.792927137525	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1434
Epoch: 1434	max: 0.99999523/1.0	min: 4.736614e-06	loss: 34318.9296875	train_loss: 34355.800646251395	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1435
Epoch: 1435	max: 0.999995/1.0	min: 5.0110057e-06	loss: 34318.71875	train_loss: 34355.778373900655	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1436
Epoch: 1436	max: 0.999997/1.0	min: 2.9922942e-06	loss: 34318.7109375	train_loss: 34355.7754595759	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1437
Epoch: 1437	max: 0.99999726/1.0	min: 2.697992e-06	loss: 34318.68359375	train_loss: 34355.759191518024	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1438
Epoch: 1438	max: 0.99999774/1.0	min: 2.2669947e-06	loss: 34318.640625	train_loss: 34355.74700922442	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1439
Epoch: 1439	max: 0.9999995/1.0	min: 5.1697975e-07	loss: 34318.765625	train_loss: 34355.751403211325	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1440
Epoch: 1440	max: 0.99999976/1.0	min: 2.0543536e-07	loss: 34319.078125	train_loss: 34355.74330039174	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1441
Epoch: 1441	max: 0.9999975/1.0	min: 2.4614753e-06	loss: 34318.8515625	train_loss: 34355.76246148427	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1442
Epoch: 1442	max: 0.999997/1.0	min: 2.9343678e-06	loss: 34318.890625	train_loss: 34355.72560928403	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1443
Epoch: 1443	max: 0.99999857/1.0	min: 1.4386758e-06	loss: 34319.1640625	train_loss: 34355.72952666295	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1444
Epoch: 1444	max: 0.9999958/1.0	min: 4.22049e-06	loss: 34318.58203125	train_loss: 34355.70675931732	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1445
Epoch: 1445	max: 0.99999833/1.0	min: 1.6626353e-06	loss: 34318.83984375	train_loss: 34355.718935804536	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1446
Epoch: 1446	max: 0.9999963/1.0	min: 3.6869058e-06	loss: 34319.08984375	train_loss: 34355.70353241515	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1447
Epoch: 1447	max: 0.9999974/1.0	min: 2.6760267e-06	loss: 34318.9140625	train_loss: 34355.72394333349	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1448
Epoch: 1448	max: 0.99999845/1.0	min: 1.5413951e-06	loss: 34318.8203125	train_loss: 34355.68416761504	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1449
Epoch: 1449	max: 0.99999857/1.0	min: 1.4282615e-06	loss: 34318.65625	train_loss: 34355.67517399821	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1450
Epoch: 1450	max: 0.9999976/1.0	min: 2.3477887e-06	loss: 34318.9140625	train_loss: 34355.69269333349	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1451
Epoch: 1451	max: 0.9999969/1.0	min: 3.144249e-06	loss: 34318.88671875	train_loss: 34355.66726037022	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1452
Epoch: 1452	max: 0.9999956/1.0	min: 4.3542796e-06	loss: 34318.62890625	train_loss: 34355.662920092436	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1453
Epoch: 1453	max: 0.9999982/1.0	min: 1.7899788e-06	loss: 34318.609375	train_loss: 34355.65856868574	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1454
Epoch: 1454	max: 0.99999833/1.0	min: 1.6673306e-06	loss: 34318.859375	train_loss: 34355.6475031548	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1455
Epoch: 1455	max: 0.999998/1.0	min: 1.9859754e-06	loss: 34318.765625	train_loss: 34355.631402514555	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1456
Epoch: 1456	max: 0.9999975/1.0	min: 2.547854e-06	loss: 34318.7421875	train_loss: 34355.626927722034	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1457
Epoch: 1457	max: 0.99999917/1.0	min: 8.2936043e-07	loss: 34318.71875	train_loss: 34355.62482677598	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1458
Epoch: 1458	max: 0.9999988/1.0	min: 1.2134732e-06	loss: 34318.6796875	train_loss: 34355.62101342825	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1459
Epoch: 1459	max: 0.99999654/1.0	min: 3.4983382e-06	loss: 34318.58984375	train_loss: 34355.62732884693	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1460
Epoch: 1460	max: 0.99999774/1.0	min: 2.302304e-06	loss: 34318.73828125	train_loss: 34355.62589176499	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1461
Epoch: 1461	max: 0.99999845/1.0	min: 1.5271103e-06	loss: 34318.703125	train_loss: 34355.59915478292	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1462
Epoch: 1462	max: 0.99999785/1.0	min: 2.151734e-06	loss: 34318.625	train_loss: 34355.59441870278	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1463
Epoch: 1463	max: 0.9999956/1.0	min: 4.4282638e-06	loss: 34318.80078125	train_loss: 34355.605653586805	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1464
Epoch: 1464	max: 0.99999857/1.0	min: 1.4169913e-06	loss: 34318.828125	train_loss: 34355.61006015422	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1465
Epoch: 1465	max: 0.99999833/1.0	min: 1.6506865e-06	loss: 34318.7734375	train_loss: 34355.5719150641	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1466
Epoch: 1466	max: 0.999997/1.0	min: 3.0184822e-06	loss: 34318.765625	train_loss: 34355.55993405874	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1467
Epoch: 1467	max: 0.9999988/1.0	min: 1.1504513e-06	loss: 34318.67578125	train_loss: 34355.54854336988	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1468
Epoch: 1468	max: 0.9999982/1.0	min: 1.8367099e-06	loss: 34318.6015625	train_loss: 34355.5487833674	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1469
Epoch: 1469	max: 0.9999974/1.0	min: 2.6492953e-06	loss: 34318.546875	train_loss: 34355.558198915365	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1470
Epoch: 1470	max: 0.9999995/1.0	min: 4.175616e-07	loss: 34319.05078125	train_loss: 34355.5551283019	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1471
Epoch: 1471	max: 0.99999833/1.0	min: 1.7284896e-06	loss: 34318.82421875	train_loss: 34355.52764471463	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1472
Epoch: 1472	max: 0.9999981/1.0	min: 1.9623537e-06	loss: 34318.98828125	train_loss: 34355.56231613093	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1473
Epoch: 1473	max: 0.999997/1.0	min: 2.9310509e-06	loss: 34318.65625	train_loss: 34355.53567543819	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1474
Epoch: 1474	max: 0.99999905/1.0	min: 1.0089806e-06	loss: 34318.87109375	train_loss: 34355.508131851544	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1475
Epoch: 1475	max: 0.99999654/1.0	min: 3.4274497e-06	loss: 34318.67578125	train_loss: 34355.50171288555	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1476
Epoch: 1476	max: 0.99999917/1.0	min: 7.8797643e-07	loss: 34318.6484375	train_loss: 34355.50097498993	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1477
Epoch: 1477	max: 0.9999975/1.0	min: 2.540982e-06	loss: 34318.8359375	train_loss: 34355.49054380729	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1478
Epoch: 1478	max: 0.99999535/1.0	min: 4.68144e-06	loss: 34318.5859375	train_loss: 34355.53181951025	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1479
Epoch: 1479	max: 0.9999987/1.0	min: 1.3075778e-06	loss: 34318.88671875	train_loss: 34355.51292309241	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1480
Epoch: 1480	max: 0.999998/1.0	min: 2.0527625e-06	loss: 34318.96875	train_loss: 34355.48757722501	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1481
Epoch: 1481	max: 0.99999595/1.0	min: 4.039961e-06	loss: 34318.68359375	train_loss: 34355.462662966056	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1482
Epoch: 1482	max: 0.9999988/1.0	min: 1.2200085e-06	loss: 34318.7265625	train_loss: 34355.464648752015	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1483
Epoch: 1483	max: 0.9999995/1.0	min: 4.197223e-07	loss: 34318.8203125	train_loss: 34355.45869961988	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1484
Epoch: 1484	max: 0.99999905/1.0	min: 9.5011296e-07	loss: 34318.55859375	train_loss: 34355.448463919085	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1485
Epoch: 1485	max: 0.99999785/1.0	min: 2.18177e-06	loss: 34318.6875	train_loss: 34355.43125038709	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1486
Epoch: 1486	max: 0.99999833/1.0	min: 1.6317633e-06	loss: 34318.98828125	train_loss: 34355.432090378425	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1487
Epoch: 1487	max: 0.9999982/1.0	min: 1.7599267e-06	loss: 34318.734375	train_loss: 34355.44358364688	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1488
Epoch: 1488	max: 0.99999857/1.0	min: 1.3903319e-06	loss: 34318.91015625	train_loss: 34355.41873422597	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1489
Epoch: 1489	max: 0.99999964/1.0	min: 3.1906808e-07	loss: 34318.953125	train_loss: 34355.44624200653	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1490
Epoch: 1490	max: 0.9999988/1.0	min: 1.2180612e-06	loss: 34318.63671875	train_loss: 34355.40334825576	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1491
Epoch: 1491	max: 0.9999995/1.0	min: 4.5636617e-07	loss: 34318.78515625	train_loss: 34355.40967625495	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1492
Epoch: 1492	max: 0.99999976/1.0	min: 2.3725697e-07	loss: 34318.6484375	train_loss: 34355.384299904	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1493
Epoch: 1493	max: 0.99999917/1.0	min: 8.374538e-07	loss: 34318.75	train_loss: 34355.38757954757	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1494
Epoch: 1494	max: 0.99999857/1.0	min: 1.390922e-06	loss: 34318.7265625	train_loss: 34355.36743814257	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1495
Epoch: 1495	max: 0.99999845/1.0	min: 1.544914e-06	loss: 34318.56640625	train_loss: 34355.36555687167	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1496
Epoch: 1496	max: 0.9999993/1.0	min: 7.356105e-07	loss: 34318.5703125	train_loss: 34355.38221637712	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1497
Epoch: 1497	max: 0.99999785/1.0	min: 2.1466774e-06	loss: 34318.640625	train_loss: 34355.35401279729	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1498
Epoch: 1498	max: 0.9999988/1.0	min: 1.2269696e-06	loss: 34318.85546875	train_loss: 34355.35032186765	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1499
Epoch: 1499	max: 0.99999535/1.0	min: 4.679931e-06	loss: 34318.80078125	train_loss: 34355.33448735368	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1500
Epoch: 1500	max: 0.9999993/1.0	min: 7.710029e-07	loss: 34318.7890625	train_loss: 34355.333181399415	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1501
Epoch: 1501	max: 0.9999993/1.0	min: 7.5738217e-07	loss: 34318.62109375	train_loss: 34355.323725206705	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1502
Epoch: 1502	max: 0.9999993/1.0	min: 7.0173843e-07	loss: 34318.48046875	train_loss: 34355.31343192586	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1503
Epoch: 1503	max: 0.99999595/1.0	min: 4.105812e-06	loss: 34318.70703125	train_loss: 34355.31843703549	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1504
Epoch: 1504	max: 0.99999905/1.0	min: 9.386731e-07	loss: 34318.4921875	train_loss: 34355.35224862195	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1505
Epoch: 1505	max: 0.9999994/1.0	min: 5.689423e-07	loss: 34319.0	train_loss: 34355.322406671934	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1506
Epoch: 1506	max: 0.99999917/1.0	min: 7.90786e-07	loss: 34318.58984375	train_loss: 34355.29965384228	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1507
Epoch: 1507	max: 0.9999981/1.0	min: 1.9617419e-06	loss: 34318.8984375	train_loss: 34355.28121661325	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1508
Epoch: 1508	max: 0.9999969/1.0	min: 3.1060026e-06	loss: 34318.5625	train_loss: 34355.27148606853	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1509
Epoch: 1509	max: 0.9999993/1.0	min: 6.585399e-07	loss: 34318.75	train_loss: 34355.26422227254	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1510
Epoch: 1510	max: 0.9999982/1.0	min: 1.7604169e-06	loss: 34318.44921875	train_loss: 34355.255925906575	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1511
Epoch: 1511	max: 0.99999964/1.0	min: 3.3540954e-07	loss: 34318.796875	train_loss: 34355.27407088056	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1512
Epoch: 1512	max: 0.9999975/1.0	min: 2.503239e-06	loss: 34318.6640625	train_loss: 34355.24542843429	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1513
Epoch: 1513	max: 0.99999785/1.0	min: 2.1108965e-06	loss: 34318.7734375	train_loss: 34355.24536795104	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1514
Epoch: 1514	max: 0.999997/1.0	min: 3.031918e-06	loss: 34318.48828125	train_loss: 34355.22431445869	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1515
Epoch: 1515	max: 0.99999964/1.0	min: 3.412612e-07	loss: 34319.07421875	train_loss: 34355.26419565992	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1516
Epoch: 1516	max: 0.9999989/1.0	min: 1.025283e-06	loss: 34319.015625	train_loss: 34355.23356742769	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1517
Epoch: 1517	max: 0.99999917/1.0	min: 7.8478615e-07	loss: 34318.63671875	train_loss: 34355.21464391335	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1518
Epoch: 1518	max: 0.9999995/1.0	min: 4.731002e-07	loss: 34318.43359375	train_loss: 34355.19807924563	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1519
Epoch: 1519	max: 0.99999714/1.0	min: 2.8671698e-06	loss: 34318.546875	train_loss: 34355.19803666543	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1520
Epoch: 1520	max: 0.9999993/1.0	min: 7.337566e-07	loss: 34318.49609375	train_loss: 34355.20212726836	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1521
Epoch: 1521	max: 0.9999994/1.0	min: 5.480437e-07	loss: 34318.60546875	train_loss: 34355.16705375945	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1522
Epoch: 1522	max: 0.9999987/1.0	min: 1.3442252e-06	loss: 34318.6640625	train_loss: 34355.1773126858	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1523
Epoch: 1523	max: 0.9999987/1.0	min: 1.2679245e-06	loss: 34318.9765625	train_loss: 34355.16492668463	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1524
Epoch: 1524	max: 0.99999905/1.0	min: 9.0613224e-07	loss: 34318.87109375	train_loss: 34355.1802192687	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1525
Epoch: 1525	max: 0.9999995/1.0	min: 4.3411217e-07	loss: 34318.45703125	train_loss: 34355.16817052211	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1526
Epoch: 1526	max: 0.99999833/1.0	min: 1.6901729e-06	loss: 34318.71484375	train_loss: 34355.14537753159	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1527
Epoch: 1527	max: 0.99999774/1.0	min: 2.2867632e-06	loss: 34318.5859375	train_loss: 34355.12449242459	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1528
Epoch: 1528	max: 0.9999995/1.0	min: 5.030236e-07	loss: 34318.7265625	train_loss: 34355.12603837638	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1529
Epoch: 1529	max: 0.9999975/1.0	min: 2.5134486e-06	loss: 34318.84375	train_loss: 34355.12193470906	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1530
Epoch: 1530	max: 0.99999917/1.0	min: 7.751699e-07	loss: 34318.6640625	train_loss: 34355.10266087576	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1531
Epoch: 1531	max: 0.9999989/1.0	min: 1.0504651e-06	loss: 34318.5234375	train_loss: 34355.093157264186	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1532
Epoch: 1532	max: 0.9999999/1.0	min: 1.3932038e-07	loss: 34319.01171875	train_loss: 34355.095555303946	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1533
Epoch: 1533	max: 0.99999714/1.0	min: 2.8382858e-06	loss: 34318.55859375	train_loss: 34355.17345675787	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1534
Epoch: 1534	max: 0.99999917/1.0	min: 7.765039e-07	loss: 34318.6015625	train_loss: 34355.070459595256	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1535
Epoch: 1535	max: 0.99999857/1.0	min: 1.4431336e-06	loss: 34318.61328125	train_loss: 34355.04576355986	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1536
