Epoch: 0	max: 0.62257075/1.0	min: 0.37742928	loss: 36256.421875	train_loss: 36509.875362415616	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1
Epoch: 1	max: 0.6971174/1.0	min: 0.30288258	loss: 35946.49609375	train_loss: 36135.275580542395	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_2
Epoch: 2	max: 0.75361127/1.0	min: 0.24638876	loss: 35757.26171875	train_loss: 35899.3557247151	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_3
Epoch: 3	max: 0.7943547/1.0	min: 0.20564532	loss: 35648.15625	train_loss: 35762.65863110445	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_4
Epoch: 4	max: 0.82285017/1.0	min: 0.17714983	loss: 35586.92578125	train_loss: 35687.2161235755	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_5
Epoch: 5	max: 0.8422961/1.0	min: 0.15770394	loss: 35553.546875	train_loss: 35647.07611937554	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_6
Epoch: 6	max: 0.85559356/1.0	min: 0.14440641	loss: 35535.2265625	train_loss: 35626.74905065496	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_7
Epoch: 7	max: 0.86433953/1.0	min: 0.13566047	loss: 35525.26171875	train_loss: 35616.12111020144	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_8
Epoch: 8	max: 0.87021697/1.0	min: 0.12978306	loss: 35519.390625	train_loss: 35610.32424633036	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_9
Epoch: 9	max: 0.87398493/1.0	min: 0.12601504	loss: 35515.71484375	train_loss: 35606.68744871021	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_10
Epoch: 10	max: 0.87632453/1.0	min: 0.12367547	loss: 35513.109375	train_loss: 35603.79086973941	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_11
Epoch: 11	max: 0.8776338/1.0	min: 0.12236627	loss: 35511.03125	train_loss: 35601.019384154744	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_12
Epoch: 12	max: 0.8782648/1.0	min: 0.12173522	loss: 35509.140625	train_loss: 35598.08385639245	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_13
Epoch: 13	max: 0.8789002/1.0	min: 0.121099874	loss: 35507.05859375	train_loss: 35594.826259696674	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_14
Epoch: 14	max: 0.8788796/1.0	min: 0.12112042	loss: 35505.03125	train_loss: 35591.16339186176	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_15
Epoch: 15	max: 0.87952244/1.0	min: 0.120477535	loss: 35502.37890625	train_loss: 35586.96857919531	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_16
Epoch: 16	max: 0.88028556/1.0	min: 0.1197145	loss: 35499.265625	train_loss: 35582.06626447727	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_17
Epoch: 17	max: 0.88042367/1.0	min: 0.11957631	loss: 35495.85546875	train_loss: 35576.33082303667	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_18
Epoch: 18	max: 0.88114285/1.0	min: 0.11885711	loss: 35491.44140625	train_loss: 35569.41763488248	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_19
Epoch: 19	max: 0.8816838/1.0	min: 0.11831613	loss: 35485.91015625	train_loss: 35560.96064911588	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_20
Epoch: 20	max: 0.88269657/1.0	min: 0.11730343	loss: 35478.4609375	train_loss: 35550.11066305122	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_21
Epoch: 21	max: 0.8833751/1.0	min: 0.11662482	loss: 35468.11328125	train_loss: 35535.71564212885	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_22
Epoch: 22	max: 0.88554615/1.0	min: 0.1144538	loss: 35452.25390625	train_loss: 35515.28123306469	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_23
Epoch: 23	max: 0.8895327/1.0	min: 0.11046736	loss: 35427.29296875	train_loss: 35485.115224455745	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_24
Epoch: 24	max: 0.89866036/1.0	min: 0.1013396	loss: 35388.08984375	train_loss: 35440.08615282036	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_25
Epoch: 25	max: 0.9111065/1.0	min: 0.08889344	loss: 35332.11328125	train_loss: 35376.8053174935	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_26
Epoch: 26	max: 0.926511/1.0	min: 0.073489055	loss: 35260.91015625	train_loss: 35297.34050035613	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_27
Epoch: 27	max: 0.9433201/1.0	min: 0.056679904	loss: 35182.13671875	train_loss: 35207.48367774914	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_28
Epoch: 28	max: 0.95803356/1.0	min: 0.041966412	loss: 35117.953125	train_loss: 35122.75253061904	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_29
Epoch: 29	max: 0.9676125/1.0	min: 0.032387525	loss: 35082.15625	train_loss: 35067.88665439583	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_30
Epoch: 30	max: 0.97307545/1.0	min: 0.026924549	loss: 35060.51953125	train_loss: 35038.555966357766	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_31
Epoch: 31	max: 0.97632056/1.0	min: 0.02367937	loss: 35043.8125	train_loss: 35020.333693329616	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_32
Epoch: 32	max: 0.9794008/1.0	min: 0.020599207	loss: 35033.87890625	train_loss: 35006.64952910163	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_33
Epoch: 33	max: 0.98113304/1.0	min: 0.018866913	loss: 35020.40625	train_loss: 34995.29502372879	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_34
Epoch: 34	max: 0.9832063/1.0	min: 0.016793642	loss: 35013.41015625	train_loss: 34985.53641914019	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_35
Epoch: 35	max: 0.98466116/1.0	min: 0.01533883	loss: 35005.21875	train_loss: 34977.153042936334	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_36
Epoch: 36	max: 0.9857529/1.0	min: 0.014247162	loss: 34997.78515625	train_loss: 34969.89391722408	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_37
Epoch: 37	max: 0.9867513/1.0	min: 0.0132486345	loss: 34992.36328125	train_loss: 34963.41214542301	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_38
Epoch: 38	max: 0.9873152/1.0	min: 0.012684779	loss: 34985.39453125	train_loss: 34957.582937047104	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_39
Epoch: 39	max: 0.98797965/1.0	min: 0.012020363	loss: 34980.37109375	train_loss: 34952.02039785396	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_40
Epoch: 40	max: 0.98778546/1.0	min: 0.012214552	loss: 34971.73828125	train_loss: 34946.77345975784	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_41
Epoch: 41	max: 0.9888235/1.0	min: 0.011176545	loss: 34968.953125	train_loss: 34941.61146191394	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_42
Epoch: 42	max: 0.98896235/1.0	min: 0.01103767	loss: 34962.46484375	train_loss: 34936.45414789267	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_43
Epoch: 43	max: 0.9897461/1.0	min: 0.010253855	loss: 34959.87890625	train_loss: 34931.34938316766	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_44
Epoch: 44	max: 0.98967034/1.0	min: 0.010329624	loss: 34952.31640625	train_loss: 34926.4430799424	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_45
Epoch: 45	max: 0.9901196/1.0	min: 0.009880358	loss: 34948.14453125	train_loss: 34921.40321712808	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_46
Epoch: 46	max: 0.989988/1.0	min: 0.010011945	loss: 34940.99609375	train_loss: 34916.42792816332	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_47
Epoch: 47	max: 0.9905087/1.0	min: 0.009491343	loss: 34937.36328125	train_loss: 34911.43604066023	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_48
Epoch: 48	max: 0.9904998/1.0	min: 0.009500186	loss: 34931.13671875	train_loss: 34906.38716729376	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_49
Epoch: 49	max: 0.99064714/1.0	min: 0.009352784	loss: 34925.66015625	train_loss: 34901.35276539081	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_50
Epoch: 50	max: 0.990875/1.0	min: 0.0091249645	loss: 34920.90625	train_loss: 34896.25835297829	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_51
Epoch: 51	max: 0.9913776/1.0	min: 0.008622426	loss: 34917.74609375	train_loss: 34891.04991512991	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_52
Epoch: 52	max: 0.9913174/1.0	min: 0.008682645	loss: 34911.51953125	train_loss: 34886.01569951536	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_53
Epoch: 53	max: 0.9910719/1.0	min: 0.00892811	loss: 34905.3046875	train_loss: 34880.84154066797	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_54
Epoch: 54	max: 0.9917692/1.0	min: 0.008230831	loss: 34902.7109375	train_loss: 34875.834865253004	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_55
Epoch: 55	max: 0.99159265/1.0	min: 0.0084073385	loss: 34896.71484375	train_loss: 34870.83778780348	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_56
Epoch: 56	max: 0.99164844/1.0	min: 0.008351584	loss: 34891.890625	train_loss: 34865.7822695056	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_57
Epoch: 57	max: 0.9921726/1.0	min: 0.00782745	loss: 34889.16796875	train_loss: 34860.66070011535	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_58
Epoch: 58	max: 0.99175733/1.0	min: 0.00824266	loss: 34882.484375	train_loss: 34855.75738379475	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_59
Epoch: 59	max: 0.99268264/1.0	min: 0.007317331	loss: 34879.9140625	train_loss: 34851.11587573935	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_60
Epoch: 60	max: 0.99299884/1.0	min: 0.0070011723	loss: 34875.17578125	train_loss: 34846.60100024774	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_61
Epoch: 61	max: 0.9934469/1.0	min: 0.0065530455	loss: 34871.41796875	train_loss: 34842.23933898102	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_62
Epoch: 62	max: 0.9937727/1.0	min: 0.0062273415	loss: 34867.24609375	train_loss: 34838.12891157252	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_63
Epoch: 63	max: 0.9941847/1.0	min: 0.0058153453	loss: 34863.87109375	train_loss: 34834.1189536108	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_64
Epoch: 64	max: 0.99454075/1.0	min: 0.0054593184	loss: 34860.37109375	train_loss: 34830.3878606737	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_65
Epoch: 65	max: 0.9947077/1.0	min: 0.0052922824	loss: 34855.984375	train_loss: 34826.73040729902	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_66
Epoch: 66	max: 0.99531484/1.0	min: 0.004685206	loss: 34855.19140625	train_loss: 34823.29332052056	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_67
Epoch: 67	max: 0.9954159/1.0	min: 0.0045841187	loss: 34850.859375	train_loss: 34820.23473935108	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_68
Epoch: 68	max: 0.99557483/1.0	min: 0.0044251354	loss: 34847.609375	train_loss: 34817.28079903691	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_69
Epoch: 69	max: 0.99586844/1.0	min: 0.0041316254	loss: 34845.640625	train_loss: 34814.72536831878	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_70
Epoch: 70	max: 0.99595624/1.0	min: 0.0040437425	loss: 34842.5390625	train_loss: 34812.34869704571	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_71
Epoch: 71	max: 0.9962393/1.0	min: 0.0037607446	loss: 34841.21875	train_loss: 34810.0734721448	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_72
Epoch: 72	max: 0.99637395/1.0	min: 0.0036260553	loss: 34838.87890625	train_loss: 34807.814349819615	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_73
Epoch: 73	max: 0.996415/1.0	min: 0.003584972	loss: 34835.890625	train_loss: 34805.71373763239	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_74
Epoch: 74	max: 0.9966204/1.0	min: 0.0033795696	loss: 34834.61328125	train_loss: 34803.8261455043	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_75
Epoch: 75	max: 0.9967108/1.0	min: 0.0032892176	loss: 34832.44921875	train_loss: 34801.723916236995	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_76
Epoch: 76	max: 0.99672806/1.0	min: 0.0032719607	loss: 34829.91796875	train_loss: 34799.80499088397	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_77
Epoch: 77	max: 0.9968303/1.0	min: 0.0031697645	loss: 34828.171875	train_loss: 34797.87785674471	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_78
Epoch: 78	max: 0.99684566/1.0	min: 0.0031543467	loss: 34825.9140625	train_loss: 34796.01654870014	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_79
Epoch: 79	max: 0.99681073/1.0	min: 0.003189242	loss: 34823.58984375	train_loss: 34794.25028790026	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_80
Epoch: 80	max: 0.99688596/1.0	min: 0.003114018	loss: 34821.73828125	train_loss: 34792.46802129784	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_81
Epoch: 81	max: 0.99693716/1.0	min: 0.0030628666	loss: 34820.11328125	train_loss: 34790.64844282252	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_82
Epoch: 82	max: 0.9969881/1.0	min: 0.003011902	loss: 34818.40625	train_loss: 34788.8477486684	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_83
Epoch: 83	max: 0.9972402/1.0	min: 0.0027597577	loss: 34818.609375	train_loss: 34787.14690703193	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_84
Epoch: 84	max: 0.9972408/1.0	min: 0.0027592373	loss: 34816.6484375	train_loss: 34785.62621063266	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_85
Epoch: 85	max: 0.9972288/1.0	min: 0.0027711405	loss: 34814.671875	train_loss: 34783.718909191906	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_86
Epoch: 86	max: 0.99696594/1.0	min: 0.0030341148	loss: 34811.15234375	train_loss: 34782.03253176096	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_87
Epoch: 87	max: 0.9971296/1.0	min: 0.0028703788	loss: 34810.32421875	train_loss: 34780.36433414236	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_88
Epoch: 88	max: 0.99733645/1.0	min: 0.0026635907	loss: 34810.51953125	train_loss: 34778.720757559924	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_89
Epoch: 89	max: 0.99726534/1.0	min: 0.002734677	loss: 34808.2890625	train_loss: 34777.14553430416	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_90
Epoch: 90	max: 0.99710137/1.0	min: 0.0028986353	loss: 34805.296875	train_loss: 34775.38980533104	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_91
Epoch: 91	max: 0.99725693/1.0	min: 0.0027430842	loss: 34805.11328125	train_loss: 34773.817240918805	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_92
Epoch: 92	max: 0.9971482/1.0	min: 0.0028517868	loss: 34802.76171875	train_loss: 34772.19607555664	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_93
Epoch: 93	max: 0.9968591/1.0	min: 0.0031409813	loss: 34799.734375	train_loss: 34770.49462086198	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_94
Epoch: 94	max: 0.99702233/1.0	min: 0.0029776688	loss: 34799.09375	train_loss: 34768.92596221587	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_95
Epoch: 95	max: 0.9969177/1.0	min: 0.003082281	loss: 34797.25390625	train_loss: 34767.303886217946	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_96
Epoch: 96	max: 0.9969188/1.0	min: 0.003081198	loss: 34795.94140625	train_loss: 34765.7265866933	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_97
Epoch: 97	max: 0.9967535/1.0	min: 0.0032464913	loss: 34793.890625	train_loss: 34764.163554440725	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_98
Epoch: 98	max: 0.99670726/1.0	min: 0.003292735	loss: 34792.33203125	train_loss: 34762.66829052087	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_99
Epoch: 99	max: 0.9966474/1.0	min: 0.003352521	loss: 34790.984375	train_loss: 34761.087109907254	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_100
Epoch: 100	max: 0.99642205/1.0	min: 0.0035779164	loss: 34788.984375	train_loss: 34759.58027288105	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_101
Epoch: 101	max: 0.99671835/1.0	min: 0.0032816257	loss: 34789.09375	train_loss: 34758.02897292673	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_102
Epoch: 102	max: 0.9964702/1.0	min: 0.0035297624	loss: 34786.9609375	train_loss: 34756.50940828998	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_103
Epoch: 103	max: 0.99625/1.0	min: 0.0037500048	loss: 34785.0234375	train_loss: 34755.037592515175	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_104
Epoch: 104	max: 0.9962/1.0	min: 0.003800008	loss: 34783.69140625	train_loss: 34753.553619607796	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_105
Epoch: 105	max: 0.99604493/1.0	min: 0.0039550066	loss: 34781.875	train_loss: 34752.15304245247	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_106
Epoch: 106	max: 0.9961377/1.0	min: 0.0038623123	loss: 34780.81640625	train_loss: 34750.748775335225	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_107
Epoch: 107	max: 0.996075/1.0	min: 0.0039249444	loss: 34779.2265625	train_loss: 34749.230076334694	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_108
Epoch: 108	max: 0.99630594/1.0	min: 0.0036940144	loss: 34778.81640625	train_loss: 34747.918944707664	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_109
Epoch: 109	max: 0.9962058/1.0	min: 0.0037941816	loss: 34777.125	train_loss: 34746.3861144014	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_110
Epoch: 110	max: 0.9962437/1.0	min: 0.0037562735	loss: 34775.90625	train_loss: 34745.04515872739	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_111
Epoch: 111	max: 0.9961591/1.0	min: 0.0038409454	loss: 34774.25390625	train_loss: 34743.609305807164	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_112
Epoch: 112	max: 0.9964371/1.0	min: 0.0035629505	loss: 34774.4921875	train_loss: 34742.28486883361	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_113
Epoch: 113	max: 0.99620396/1.0	min: 0.0037960566	loss: 34771.88671875	train_loss: 34740.86500913539	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_114
Epoch: 114	max: 0.996232/1.0	min: 0.0037680368	loss: 34770.734375	train_loss: 34739.50691250929	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_115
Epoch: 115	max: 0.9964958/1.0	min: 0.0035042563	loss: 34771.0	train_loss: 34738.15685676793	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_116
Epoch: 116	max: 0.99649566/1.0	min: 0.0035043976	loss: 34769.60546875	train_loss: 34736.883591524216	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_117
Epoch: 117	max: 0.9964527/1.0	min: 0.0035472785	loss: 34768.26171875	train_loss: 34735.722692539945	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_118
Epoch: 118	max: 0.99624133/1.0	min: 0.0037586978	loss: 34765.9296875	train_loss: 34734.42769735925	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_119
Epoch: 119	max: 0.996102/1.0	min: 0.0038979927	loss: 34764.19921875	train_loss: 34733.25484446612	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_120
Epoch: 120	max: 0.9962025/1.0	min: 0.003797474	loss: 34763.4765625	train_loss: 34732.03448851496	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_121
Epoch: 121	max: 0.9961987/1.0	min: 0.003801297	loss: 34762.3046875	train_loss: 34730.8094540637	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_122
Epoch: 122	max: 0.99627656/1.0	min: 0.003723463	loss: 34761.53125	train_loss: 34729.63885695374	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_123
Epoch: 123	max: 0.99614114/1.0	min: 0.0038588184	loss: 34759.8984375	train_loss: 34728.49602600876	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_124
Epoch: 124	max: 0.9962249/1.0	min: 0.0037751677	loss: 34759.11328125	train_loss: 34727.32751823207	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_125
Epoch: 125	max: 0.99639004/1.0	min: 0.0036099453	loss: 34758.76171875	train_loss: 34726.163427667845	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_126
Epoch: 126	max: 0.9961771/1.0	min: 0.003822876	loss: 34756.859375	train_loss: 34725.020173824014	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_127
Epoch: 127	max: 0.99615866/1.0	min: 0.0038413925	loss: 34755.55078125	train_loss: 34723.92653124226	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_128
Epoch: 128	max: 0.9964881/1.0	min: 0.003511937	loss: 34756.02734375	train_loss: 34722.82107120185	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_129
Epoch: 129	max: 0.9961659/1.0	min: 0.0038341058	loss: 34753.4609375	train_loss: 34721.696699259875	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_130
Epoch: 130	max: 0.99623424/1.0	min: 0.0037658217	loss: 34752.66015625	train_loss: 34720.50351867336	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_131
Epoch: 131	max: 0.9963477/1.0	min: 0.0036523289	loss: 34752.109375	train_loss: 34719.36578138548	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_132
Epoch: 132	max: 0.9964134/1.0	min: 0.003586638	loss: 34751.51171875	train_loss: 34718.296009363774	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_133
Epoch: 133	max: 0.99639624/1.0	min: 0.003603807	loss: 34750.36328125	train_loss: 34717.209452031464	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_134
Epoch: 134	max: 0.99627244/1.0	min: 0.003727537	loss: 34748.84375	train_loss: 34716.1265841772	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_135
Epoch: 135	max: 0.9963187/1.0	min: 0.0036813305	loss: 34747.98828125	train_loss: 34715.107824209554	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_136
Epoch: 136	max: 0.996099/1.0	min: 0.0039010271	loss: 34746.26953125	train_loss: 34714.13268572711	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_137
Epoch: 137	max: 0.99620855/1.0	min: 0.0037914468	loss: 34745.7109375	train_loss: 34713.15517388208	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_138
Epoch: 138	max: 0.9963198/1.0	min: 0.0036802078	loss: 34745.18359375	train_loss: 34712.05354364084	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_139
Epoch: 139	max: 0.9963497/1.0	min: 0.0036502366	loss: 34744.46484375	train_loss: 34711.10907984176	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_140
Epoch: 140	max: 0.99606365/1.0	min: 0.003936355	loss: 34742.62109375	train_loss: 34710.16312621934	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_141
Epoch: 141	max: 0.99601316/1.0	min: 0.003986859	loss: 34741.58984375	train_loss: 34709.26558145206	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_142
Epoch: 142	max: 0.996403/1.0	min: 0.0035969845	loss: 34741.9765625	train_loss: 34708.405610813046	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_143
Epoch: 143	max: 0.9964288/1.0	min: 0.0035712456	loss: 34741.18359375	train_loss: 34707.53201547597	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_144
Epoch: 144	max: 0.99629563/1.0	min: 0.003704376	loss: 34739.87890625	train_loss: 34706.64369174254	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_145
Epoch: 145	max: 0.99635726/1.0	min: 0.0036426762	loss: 34739.3046875	train_loss: 34705.83439445141	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_146
Epoch: 146	max: 0.9959628/1.0	min: 0.0040372396	loss: 34737.6015625	train_loss: 34704.98196002493	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_147
Epoch: 147	max: 0.99646425/1.0	min: 0.0035356928	loss: 34738.015625	train_loss: 34704.25564671591	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_148
Epoch: 148	max: 0.996241/1.0	min: 0.0037590154	loss: 34736.62109375	train_loss: 34703.42284805447	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_149
Epoch: 149	max: 0.99650997/1.0	min: 0.0034899681	loss: 34736.5390625	train_loss: 34702.64035742212	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_150
Epoch: 150	max: 0.99648935/1.0	min: 0.0035106423	loss: 34735.81640625	train_loss: 34701.95815865772	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_151
Epoch: 151	max: 0.99629647/1.0	min: 0.0037035174	loss: 34734.5234375	train_loss: 34701.29483502106	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_152
Epoch: 152	max: 0.99626726/1.0	min: 0.0037327823	loss: 34733.7265625	train_loss: 34700.509294581476	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_153
Epoch: 153	max: 0.9963883/1.0	min: 0.0036117502	loss: 34733.328125	train_loss: 34699.78075258578	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_154
Epoch: 154	max: 0.99633396/1.0	min: 0.0036660384	loss: 34732.5234375	train_loss: 34699.07374746454	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_155
Epoch: 155	max: 0.9963477/1.0	min: 0.0036523219	loss: 34731.80078125	train_loss: 34698.42974508005	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_156
Epoch: 156	max: 0.9964007/1.0	min: 0.0035992926	loss: 34731.296875	train_loss: 34697.74714761009	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_157
Epoch: 157	max: 0.99689984/1.0	min: 0.0031001845	loss: 34732.15625	train_loss: 34697.1232338892	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_158
Epoch: 158	max: 0.9961671/1.0	min: 0.003832875	loss: 34729.56640625	train_loss: 34696.68322988279	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_159
Epoch: 159	max: 0.99674207/1.0	min: 0.0032579792	loss: 34730.19140625	train_loss: 34695.91658828038	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_160
Epoch: 160	max: 0.99646735/1.0	min: 0.0035326132	loss: 34728.8203125	train_loss: 34695.29647435898	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_161
Epoch: 161	max: 0.99617225/1.0	min: 0.0038277332	loss: 34727.76171875	train_loss: 34694.69112173681	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_162
Epoch: 162	max: 0.9960247/1.0	min: 0.0039753183	loss: 34727.0546875	train_loss: 34694.12882108959	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_163
Epoch: 163	max: 0.9967397/1.0	min: 0.0032603552	loss: 34727.55078125	train_loss: 34693.62113729794	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_164
Epoch: 164	max: 0.99683136/1.0	min: 0.0031686816	loss: 34727.30859375	train_loss: 34692.95639932104	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_165
Epoch: 165	max: 0.9965544/1.0	min: 0.0034455778	loss: 34725.96875	train_loss: 34692.413930888455	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_166
Epoch: 166	max: 0.99656135/1.0	min: 0.0034386755	loss: 34725.3515625	train_loss: 34691.81586238465	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_167
Epoch: 167	max: 0.9966577/1.0	min: 0.0033422792	loss: 34725.05078125	train_loss: 34691.293172457576	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_168
Epoch: 168	max: 0.99676824/1.0	min: 0.0032317427	loss: 34724.75	train_loss: 34690.780848391245	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_169
Epoch: 169	max: 0.99646425/1.0	min: 0.0035357012	loss: 34723.56640625	train_loss: 34690.293342778394	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_170
Epoch: 170	max: 0.9966258/1.0	min: 0.0033742674	loss: 34723.23046875	train_loss: 34689.72606508578	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_171
Epoch: 171	max: 0.99661463/1.0	min: 0.0033853867	loss: 34722.58984375	train_loss: 34689.25205449492	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_172
Epoch: 172	max: 0.9967512/1.0	min: 0.003248887	loss: 34722.3203125	train_loss: 34688.79760128282	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_173
Epoch: 173	max: 0.996221/1.0	min: 0.0037790614	loss: 34721.1953125	train_loss: 34688.22457913338	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_174
Epoch: 174	max: 0.9970379/1.0	min: 0.0029621809	loss: 34722.01171875	train_loss: 34687.89536640267	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_175
Epoch: 175	max: 0.99682224/1.0	min: 0.0031777539	loss: 34721.01171875	train_loss: 34687.27607021476	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_176
Epoch: 176	max: 0.99656653/1.0	min: 0.0034333866	loss: 34719.98828125	train_loss: 34686.822887634706	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_177
Epoch: 177	max: 0.9971353/1.0	min: 0.0028647278	loss: 34720.85546875	train_loss: 34686.31355289236	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_178
Epoch: 178	max: 0.99690944/1.0	min: 0.0030906145	loss: 34719.60546875	train_loss: 34685.89010581181	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_179
Epoch: 179	max: 0.99687445/1.0	min: 0.0031254902	loss: 34719.015625	train_loss: 34685.381777026814	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_180
Epoch: 180	max: 0.99643135/1.0	min: 0.0035685734	loss: 34717.92578125	train_loss: 34684.94441250929	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_181
Epoch: 181	max: 0.99689627/1.0	min: 0.0031037426	loss: 34718.05859375	train_loss: 34684.557483761455	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_182
Epoch: 182	max: 0.9966767/1.0	min: 0.0033232707	loss: 34717.234375	train_loss: 34684.08684571643	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_183
Epoch: 183	max: 0.9970456/1.0	min: 0.0029544113	loss: 34717.53125	train_loss: 34683.63786406076	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_184
Epoch: 184	max: 0.9966972/1.0	min: 0.0033027797	loss: 34716.390625	train_loss: 34683.1921272103	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_185
Epoch: 185	max: 0.99708146/1.0	min: 0.0029185084	loss: 34716.5859375	train_loss: 34682.79724806066	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_186
Epoch: 186	max: 0.9965565/1.0	min: 0.0034434914	loss: 34715.24609375	train_loss: 34682.39904862273	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_187
Epoch: 187	max: 0.9971374/1.0	min: 0.0028625517	loss: 34715.703125	train_loss: 34682.13116493636	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_188
Epoch: 188	max: 0.9967435/1.0	min: 0.0032565175	loss: 34714.50390625	train_loss: 34681.642708043015	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_189
Epoch: 189	max: 0.9968087/1.0	min: 0.0031913137	loss: 34714.21875	train_loss: 34681.16376056763	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_190
Epoch: 190	max: 0.9968093/1.0	min: 0.0031907235	loss: 34713.71875	train_loss: 34680.776613596245	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_191
Epoch: 191	max: 0.99700564/1.0	min: 0.0029943616	loss: 34713.72265625	train_loss: 34680.37768255296	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_192
Epoch: 192	max: 0.99665475/1.0	min: 0.003345267	loss: 34712.6796875	train_loss: 34679.969588055865	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_193
Epoch: 193	max: 0.9972608/1.0	min: 0.0027392257	loss: 34713.37890625	train_loss: 34679.813402410036	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_194
Epoch: 194	max: 0.99723995/1.0	min: 0.002760028	loss: 34712.96875	train_loss: 34679.231624221946	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_195
Epoch: 195	max: 0.996931/1.0	min: 0.003069049	loss: 34711.73046875	train_loss: 34678.868212812	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_196
Epoch: 196	max: 0.9971842/1.0	min: 0.002815728	loss: 34711.82421875	train_loss: 34678.43454454664	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_197
Epoch: 197	max: 0.9969421/1.0	min: 0.0030578878	loss: 34710.87109375	train_loss: 34678.0639603075	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_198
Epoch: 198	max: 0.99705875/1.0	min: 0.0029413246	loss: 34710.65234375	train_loss: 34677.63628665769	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_199
Epoch: 199	max: 0.9970805/1.0	min: 0.0029194811	loss: 34710.2734375	train_loss: 34677.22372269061	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_200
Epoch: 200	max: 0.9971535/1.0	min: 0.0028464901	loss: 34709.83984375	train_loss: 34676.77755810263	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_201
Epoch: 201	max: 0.9968136/1.0	min: 0.0031863686	loss: 34708.84375	train_loss: 34676.38817857364	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_202
Epoch: 202	max: 0.9971136/1.0	min: 0.0028863635	loss: 34708.75390625	train_loss: 34675.844084835255	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_203
Epoch: 203	max: 0.9971008/1.0	min: 0.002899225	loss: 34708.2109375	train_loss: 34675.365152359715	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_204
Epoch: 204	max: 0.9971644/1.0	min: 0.0028355643	loss: 34707.74609375	train_loss: 34674.89938297411	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_205
Epoch: 205	max: 0.9967991/1.0	min: 0.0032008672	loss: 34706.89453125	train_loss: 34674.40881448966	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_206
Epoch: 206	max: 0.99734265/1.0	min: 0.0026574084	loss: 34707.234375	train_loss: 34673.90406389353	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_207
Epoch: 207	max: 0.99733293/1.0	min: 0.0026671318	loss: 34706.73828125	train_loss: 34673.43417003437	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_208
Epoch: 208	max: 0.9973206/1.0	min: 0.002679415	loss: 34706.1484375	train_loss: 34672.867633624424	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_209
Epoch: 209	max: 0.9971812/1.0	min: 0.002818891	loss: 34705.4609375	train_loss: 34672.376000150965	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_210
Epoch: 210	max: 0.9972294/1.0	min: 0.0027705939	loss: 34705.0546875	train_loss: 34671.83850973151	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_211
Epoch: 211	max: 0.9975413/1.0	min: 0.0024587347	loss: 34705.4140625	train_loss: 34671.34556352966	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_212
Epoch: 212	max: 0.9966821/1.0	min: 0.0033178183	loss: 34703.80078125	train_loss: 34670.9411289948	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_213
Epoch: 213	max: 0.9976841/1.0	min: 0.0023159005	loss: 34704.875	train_loss: 34670.50123192277	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_214
Epoch: 214	max: 0.99716574/1.0	min: 0.0028342323	loss: 34703.12890625	train_loss: 34669.934852769264	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_215
Epoch: 215	max: 0.99715674/1.0	min: 0.0028432503	loss: 34702.69921875	train_loss: 34669.431499578066	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_216
Epoch: 216	max: 0.99740916/1.0	min: 0.0025908337	loss: 34702.62890625	train_loss: 34668.92242805881	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_217
Epoch: 217	max: 0.9975249/1.0	min: 0.0024751294	loss: 34702.5234375	train_loss: 34668.48463822309	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_218
Epoch: 218	max: 0.997207/1.0	min: 0.002792971	loss: 34701.5390625	train_loss: 34668.007304440725	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_219
Epoch: 219	max: 0.99733114/1.0	min: 0.002668865	loss: 34701.25390625	train_loss: 34667.58836553945	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_220
Epoch: 220	max: 0.9972727/1.0	min: 0.0027273693	loss: 34700.78125	train_loss: 34667.13029881627	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_221
Epoch: 221	max: 0.997474/1.0	min: 0.0025260071	loss: 34700.69140625	train_loss: 34666.7173763045	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_222
Epoch: 222	max: 0.9969015/1.0	min: 0.0030984813	loss: 34699.90625	train_loss: 34666.408540621516	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_223
Epoch: 223	max: 0.99741095/1.0	min: 0.0025890502	loss: 34699.66015625	train_loss: 34666.18918627292	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_224
Epoch: 224	max: 0.9977781/1.0	min: 0.002221861	loss: 34700.359375	train_loss: 34665.56323837947	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_225
Epoch: 225	max: 0.99726474/1.0	min: 0.0027352686	loss: 34698.82421875	train_loss: 34665.26765965642	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_226
Epoch: 226	max: 0.9968637/1.0	min: 0.0031362965	loss: 34698.51171875	train_loss: 34664.859908704166	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_227
Epoch: 227	max: 0.9978257/1.0	min: 0.0021743237	loss: 34699.09765625	train_loss: 34664.640897416546	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_228
Epoch: 228	max: 0.9975363/1.0	min: 0.0024636374	loss: 34698.03125	train_loss: 34664.17496690357	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_229
Epoch: 229	max: 0.99763095/1.0	min: 0.0023690579	loss: 34697.85546875	train_loss: 34663.74589536495	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_230
Epoch: 230	max: 0.99770087/1.0	min: 0.0022991486	loss: 34697.64453125	train_loss: 34663.40412873158	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_231
Epoch: 231	max: 0.99769104/1.0	min: 0.0023090127	loss: 34697.15625	train_loss: 34663.110460795244	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_232
Epoch: 232	max: 0.99778557/1.0	min: 0.0022144578	loss: 34697.15625	train_loss: 34662.77079220473	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_233
Epoch: 233	max: 0.997572/1.0	min: 0.0024279775	loss: 34696.265625	train_loss: 34662.48758061207	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_234
Epoch: 234	max: 0.9974751/1.0	min: 0.0025249068	loss: 34695.8515625	train_loss: 34662.117390239844	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_235
Epoch: 235	max: 0.99755955/1.0	min: 0.0024404388	loss: 34695.65625	train_loss: 34661.79928271708	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_236
Epoch: 236	max: 0.9975758/1.0	min: 0.0024241435	loss: 34695.3046875	train_loss: 34661.501692079306	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_237
Epoch: 237	max: 0.99754936/1.0	min: 0.0024506103	loss: 34694.953125	train_loss: 34661.19760457311	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_238
Epoch: 238	max: 0.99769646/1.0	min: 0.0023035344	loss: 34694.76171875	train_loss: 34660.88386684396	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_239
Epoch: 239	max: 0.9975585/1.0	min: 0.0024414952	loss: 34694.30859375	train_loss: 34660.57928143968	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_240
Epoch: 240	max: 0.99741733/1.0	min: 0.0025826846	loss: 34693.94921875	train_loss: 34660.28923233696	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_241
Epoch: 241	max: 0.9978594/1.0	min: 0.002140532	loss: 34694.1015625	train_loss: 34660.01105827295	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_242
Epoch: 242	max: 0.99772805/1.0	min: 0.0022720215	loss: 34693.55078125	train_loss: 34659.70637512774	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_243
Epoch: 243	max: 0.997783/1.0	min: 0.0022169983	loss: 34693.34375	train_loss: 34659.46074346975	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_244
Epoch: 244	max: 0.99775225/1.0	min: 0.0022477114	loss: 34692.98046875	train_loss: 34659.15878013517	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_245
Epoch: 245	max: 0.9979208/1.0	min: 0.0020791998	loss: 34692.88671875	train_loss: 34658.876179181374	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_246
Epoch: 246	max: 0.9978667/1.0	min: 0.0021333322	loss: 34692.515625	train_loss: 34658.61375785798	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_247
Epoch: 247	max: 0.9979603/1.0	min: 0.0020396914	loss: 34692.38671875	train_loss: 34658.3276841981	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_248
Epoch: 248	max: 0.9977811/1.0	min: 0.0022189422	loss: 34691.74609375	train_loss: 34658.06701253406	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_249
Epoch: 249	max: 0.9979855/1.0	min: 0.0020145455	loss: 34691.765625	train_loss: 34657.81932880048	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_250
Epoch: 250	max: 0.9975293/1.0	min: 0.0024707129	loss: 34691.0	train_loss: 34657.5969807731	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_251
Epoch: 251	max: 0.99746644/1.0	min: 0.0025335758	loss: 34690.82421875	train_loss: 34657.29898610724	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_252
Epoch: 252	max: 0.99764353/1.0	min: 0.0023564603	loss: 34690.49609375	train_loss: 34657.075041322154	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_253
Epoch: 253	max: 0.99768794/1.0	min: 0.0023121259	loss: 34690.22265625	train_loss: 34656.838128445124	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_254
Epoch: 254	max: 0.997959/1.0	min: 0.002040974	loss: 34690.19140625	train_loss: 34656.51513194057	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_255
Epoch: 255	max: 0.9980332/1.0	min: 0.0019667486	loss: 34690.00390625	train_loss: 34656.26552774294	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_256
Epoch: 256	max: 0.9976936/1.0	min: 0.0023063933	loss: 34689.37890625	train_loss: 34655.99719889988	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_257
Epoch: 257	max: 0.9977106/1.0	min: 0.00228937	loss: 34689.14453125	train_loss: 34655.76119085222	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_258
Epoch: 258	max: 0.998071/1.0	min: 0.0019290707	loss: 34689.23828125	train_loss: 34655.519285446084	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_259
Epoch: 259	max: 0.9980242/1.0	min: 0.00197577	loss: 34688.94921875	train_loss: 34655.279975497026	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_260
Epoch: 260	max: 0.99808455/1.0	min: 0.0019154605	loss: 34688.69921875	train_loss: 34655.0630375751	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_261
Epoch: 261	max: 0.9979552/1.0	min: 0.002044773	loss: 34688.19921875	train_loss: 34654.80449976	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_262
Epoch: 262	max: 0.9980171/1.0	min: 0.0019829746	loss: 34688.015625	train_loss: 34654.58815650935	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_263
Epoch: 263	max: 0.99810165/1.0	min: 0.0018983369	loss: 34687.87890625	train_loss: 34654.34604110538	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_264
Epoch: 264	max: 0.9977247/1.0	min: 0.0022753032	loss: 34687.3359375	train_loss: 34654.1682731017	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_265
Epoch: 265	max: 0.9979328/1.0	min: 0.0020671878	loss: 34687.12890625	train_loss: 34653.936285496406	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_266
Epoch: 266	max: 0.9979352/1.0	min: 0.0020648749	loss: 34686.87890625	train_loss: 34653.735145314626	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_267
Epoch: 267	max: 0.9974694/1.0	min: 0.0025305478	loss: 34686.78515625	train_loss: 34653.55816504475	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_268
Epoch: 268	max: 0.9980331/1.0	min: 0.0019668487	loss: 34686.390625	train_loss: 34653.2991970728	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_269
Epoch: 269	max: 0.9981242/1.0	min: 0.0018757961	loss: 34686.26171875	train_loss: 34653.031666124734	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_270
Epoch: 270	max: 0.9978606/1.0	min: 0.0021393734	loss: 34685.87890625	train_loss: 34652.7869663926	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_271
Epoch: 271	max: 0.9980405/1.0	min: 0.0019595763	loss: 34685.703125	train_loss: 34652.60977515716	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_272
Epoch: 272	max: 0.99814534/1.0	min: 0.0018547272	loss: 34685.5625	train_loss: 34652.363232863405	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_273
Epoch: 273	max: 0.99787927/1.0	min: 0.0021207896	loss: 34685.140625	train_loss: 34652.17550738186	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_274
Epoch: 274	max: 0.99800044/1.0	min: 0.0019995063	loss: 34684.94921875	train_loss: 34651.9658192238	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_275
Epoch: 275	max: 0.9980597/1.0	min: 0.0019402611	loss: 34684.76953125	train_loss: 34651.765777901644	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_276
Epoch: 276	max: 0.99827766/1.0	min: 0.001722391	loss: 34684.78125	train_loss: 34651.548742722654	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_277
Epoch: 277	max: 0.9981061/1.0	min: 0.0018938304	loss: 34684.359375	train_loss: 34651.3317312531	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_278
Epoch: 278	max: 0.9981279/1.0	min: 0.0018720886	loss: 34684.07421875	train_loss: 34651.186574364394	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_279
Epoch: 279	max: 0.9981298/1.0	min: 0.0018701899	loss: 34683.86328125	train_loss: 34651.02517990137	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_280
Epoch: 280	max: 0.9982337/1.0	min: 0.0017663233	loss: 34683.69921875	train_loss: 34650.73184051003	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_281
Epoch: 281	max: 0.9980014/1.0	min: 0.0019985368	loss: 34683.3359375	train_loss: 34650.54358084046	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_282
Epoch: 282	max: 0.99810505/1.0	min: 0.0018949584	loss: 34683.12109375	train_loss: 34650.42255579942	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_283
Epoch: 283	max: 0.9981205/1.0	min: 0.0018795166	loss: 34682.9453125	train_loss: 34650.13964468754	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_284
Epoch: 284	max: 0.9981401/1.0	min: 0.0018599436	loss: 34682.73828125	train_loss: 34649.999957419794	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_285
Epoch: 285	max: 0.9982917/1.0	min: 0.001708273	loss: 34682.65625	train_loss: 34649.76137859222	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_286
Epoch: 286	max: 0.9982686/1.0	min: 0.0017314152	loss: 34682.41015625	train_loss: 34649.65512646321	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_287
Epoch: 287	max: 0.998429/1.0	min: 0.0015710195	loss: 34682.48828125	train_loss: 34649.38735842082	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_288
Epoch: 288	max: 0.9985135/1.0	min: 0.0014864985	loss: 34682.421875	train_loss: 34649.289544914376	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_289
Epoch: 289	max: 0.99851245/1.0	min: 0.001487591	loss: 34682.2109375	train_loss: 34649.08146270748	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_290
Epoch: 290	max: 0.9984686/1.0	min: 0.0015313792	loss: 34681.80859375	train_loss: 34649.01298309179	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_291
Epoch: 291	max: 0.9985581/1.0	min: 0.0014418734	loss: 34681.8515625	train_loss: 34648.65859868543	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_292
Epoch: 292	max: 0.9985702/1.0	min: 0.0014298176	loss: 34681.63671875	train_loss: 34648.53218192586	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_293
Epoch: 293	max: 0.9981262/1.0	min: 0.0018737671	loss: 34680.78515625	train_loss: 34648.366927180105	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_294
Epoch: 294	max: 0.9979401/1.0	min: 0.002059904	loss: 34680.63671875	train_loss: 34648.20045744689	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_295
Epoch: 295	max: 0.99847/1.0	min: 0.001530015	loss: 34680.63671875	train_loss: 34648.021128975444	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_296
Epoch: 296	max: 0.9983169/1.0	min: 0.0016831919	loss: 34680.30859375	train_loss: 34647.842501141924	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_297
Epoch: 297	max: 0.9983266/1.0	min: 0.0016734176	loss: 34680.1640625	train_loss: 34647.68994110383	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_298
Epoch: 298	max: 0.99862146/1.0	min: 0.0013785369	loss: 34680.390625	train_loss: 34647.46458730104	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_299
Epoch: 299	max: 0.9983631/1.0	min: 0.0016369451	loss: 34679.7421875	train_loss: 34647.33861279496	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_300
Epoch: 300	max: 0.9983094/1.0	min: 0.001690656	loss: 34679.5390625	train_loss: 34647.140493388455	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_301
Epoch: 301	max: 0.9985493/1.0	min: 0.0014507157	loss: 34679.60546875	train_loss: 34646.995626819335	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_302
Epoch: 302	max: 0.99829715/1.0	min: 0.0017028545	loss: 34679.08984375	train_loss: 34646.78722864796	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_303
Epoch: 303	max: 0.9985448/1.0	min: 0.0014551627	loss: 34679.19140625	train_loss: 34646.652867292985	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_304
Epoch: 304	max: 0.9985922/1.0	min: 0.0014077391	loss: 34679.203125	train_loss: 34646.512704384986	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_305
Epoch: 305	max: 0.99836236/1.0	min: 0.0016375778	loss: 34678.5703125	train_loss: 34646.36520123018	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_306
Epoch: 306	max: 0.99852186/1.0	min: 0.0014781653	loss: 34678.57421875	train_loss: 34646.17375433544	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_307
Epoch: 307	max: 0.9985165/1.0	min: 0.0014834588	loss: 34678.375	train_loss: 34646.000416124734	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_308
Epoch: 308	max: 0.9985436/1.0	min: 0.0014563604	loss: 34678.23046875	train_loss: 34645.91298396275	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_309
Epoch: 309	max: 0.99843365/1.0	min: 0.0015663474	loss: 34677.83984375	train_loss: 34645.75706057228	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_310
Epoch: 310	max: 0.9985164/1.0	min: 0.001483564	loss: 34677.73828125	train_loss: 34645.56340047457	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_311
Epoch: 311	max: 0.99864405/1.0	min: 0.0013558979	loss: 34677.765625	train_loss: 34645.39707251409	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_312
Epoch: 312	max: 0.9981456/1.0	min: 0.0018544906	loss: 34677.34375	train_loss: 34645.26838013285	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_313
Epoch: 313	max: 0.99862874/1.0	min: 0.001371294	loss: 34677.42578125	train_loss: 34645.152084397836	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_314
Epoch: 314	max: 0.9986964/1.0	min: 0.0013035925	loss: 34677.44140625	train_loss: 34644.994869085225	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_315
Epoch: 315	max: 0.99845684/1.0	min: 0.001543129	loss: 34676.85546875	train_loss: 34644.91598828657	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_316
Epoch: 316	max: 0.99838495/1.0	min: 0.0016150685	loss: 34676.65625	train_loss: 34644.66566070931	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_317
Epoch: 317	max: 0.99828905/1.0	min: 0.0017109897	loss: 34676.49609375	train_loss: 34644.54973271244	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_318
Epoch: 318	max: 0.99850607/1.0	min: 0.0014939087	loss: 34676.38671875	train_loss: 34644.38634133454	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_319
Epoch: 319	max: 0.9986085/1.0	min: 0.0013915283	loss: 34676.27734375	train_loss: 34644.2331406579	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_320
Epoch: 320	max: 0.99863726/1.0	min: 0.001362779	loss: 34676.203125	train_loss: 34644.089987458196	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_321
Epoch: 321	max: 0.9984641/1.0	min: 0.0015358932	loss: 34675.86328125	train_loss: 34643.957731404065	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_322
Epoch: 322	max: 0.998425/1.0	min: 0.0015749645	loss: 34675.68359375	train_loss: 34643.80687989672	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_323
Epoch: 323	max: 0.99824893/1.0	min: 0.0017510541	loss: 34675.61328125	train_loss: 34643.86308721975	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_324
Epoch: 324	max: 0.99863464/1.0	min: 0.0013653081	loss: 34675.4609375	train_loss: 34643.62225744766	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_325
Epoch: 325	max: 0.99880755/1.0	min: 0.0011924242	loss: 34675.69921875	train_loss: 34643.422194351544	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_326
Epoch: 326	max: 0.99871194/1.0	min: 0.0012880751	loss: 34675.23828125	train_loss: 34643.307916821504	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_327
Epoch: 327	max: 0.99862516/1.0	min: 0.0013748049	loss: 34674.984375	train_loss: 34643.10988499474	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_328
Epoch: 328	max: 0.99866736/1.0	min: 0.001332612	loss: 34674.921875	train_loss: 34642.97847328673	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_329
Epoch: 329	max: 0.99873036/1.0	min: 0.0012696643	loss: 34674.7890625	train_loss: 34642.85888823083	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_330
Epoch: 330	max: 0.99841106/1.0	min: 0.0015888981	loss: 34674.48046875	train_loss: 34642.731179065246	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_331
Epoch: 331	max: 0.99849594/1.0	min: 0.0015040532	loss: 34674.30859375	train_loss: 34642.655797585314	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_332
Epoch: 332	max: 0.9988714/1.0	min: 0.0011286072	loss: 34674.5703125	train_loss: 34642.51167084727	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_333
Epoch: 333	max: 0.99877316/1.0	min: 0.001226823	loss: 34674.12109375	train_loss: 34642.39057080701	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_334
Epoch: 334	max: 0.99869365/1.0	min: 0.0013063822	loss: 34673.890625	train_loss: 34642.194477831195	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_335
Epoch: 335	max: 0.99871624/1.0	min: 0.0012837283	loss: 34673.76171875	train_loss: 34642.06413256379	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_336
Epoch: 336	max: 0.99899/1.0	min: 0.0010100439	loss: 34674.26171875	train_loss: 34641.954762402456	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_337
Epoch: 337	max: 0.9986572/1.0	min: 0.0013427339	loss: 34673.44921875	train_loss: 34641.88260056671	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_338
Epoch: 338	max: 0.99860257/1.0	min: 0.0013974246	loss: 34673.26953125	train_loss: 34641.69824376007	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_339
Epoch: 339	max: 0.99871266/1.0	min: 0.0012873968	loss: 34673.19921875	train_loss: 34641.58391639183	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_340
Epoch: 340	max: 0.99883133/1.0	min: 0.0011687118	loss: 34673.1953125	train_loss: 34641.51498871625	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_341
Epoch: 341	max: 0.99853444/1.0	min: 0.0014655481	loss: 34672.875	train_loss: 34641.36867974266	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_342
Epoch: 342	max: 0.9986268/1.0	min: 0.0013731465	loss: 34672.69921875	train_loss: 34641.272944924436	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_343
Epoch: 343	max: 0.998862/1.0	min: 0.00113803	loss: 34672.7109375	train_loss: 34641.10750485802	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_344
Epoch: 344	max: 0.99873644/1.0	min: 0.0012636129	loss: 34672.50390625	train_loss: 34640.952621295524	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_345
Epoch: 345	max: 0.99884427/1.0	min: 0.0011557423	loss: 34672.44140625	train_loss: 34640.81524884259	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_346
Epoch: 346	max: 0.99868554/1.0	min: 0.0013144366	loss: 34672.19921875	train_loss: 34640.69962229422	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_347
Epoch: 347	max: 0.9988207/1.0	min: 0.0011792987	loss: 34672.19140625	train_loss: 34640.595309016164	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_348
Epoch: 348	max: 0.99885845/1.0	min: 0.0011415145	loss: 34672.0234375	train_loss: 34640.473577530815	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_349
Epoch: 349	max: 0.9988513/1.0	min: 0.0011487084	loss: 34671.9140625	train_loss: 34640.34065083844	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_350
Epoch: 350	max: 0.9989641/1.0	min: 0.0010359422	loss: 34671.8515625	train_loss: 34640.23773351372	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_351
Epoch: 351	max: 0.998697/1.0	min: 0.0013030897	loss: 34671.5078125	train_loss: 34640.1137689869	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_352
Epoch: 352	max: 0.99889475/1.0	min: 0.0011052459	loss: 34671.51171875	train_loss: 34639.99521166233	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_353
Epoch: 353	max: 0.9989794/1.0	min: 0.0010205845	loss: 34671.48046875	train_loss: 34639.87658466106	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_354
Epoch: 354	max: 0.998865/1.0	min: 0.0011350726	loss: 34671.18359375	train_loss: 34639.8068489293	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_355
Epoch: 355	max: 0.9989686/1.0	min: 0.0010314123	loss: 34671.17578125	train_loss: 34639.683315527065	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_356
Epoch: 356	max: 0.9987815/1.0	min: 0.0012185298	loss: 34670.88671875	train_loss: 34639.60040751192	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_357
Epoch: 357	max: 0.9985739/1.0	min: 0.0014260521	loss: 34670.828125	train_loss: 34639.58079352084	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_358
Epoch: 358	max: 0.99866855/1.0	min: 0.0013315058	loss: 34670.63671875	train_loss: 34639.378673510466	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_359
Epoch: 359	max: 0.9991917/1.0	min: 0.0008083243	loss: 34671.17578125	train_loss: 34639.21840210036	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_360
Epoch: 360	max: 0.9989579/1.0	min: 0.0010420901	loss: 34670.52734375	train_loss: 34639.34484305323	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_361
Epoch: 361	max: 0.99888295/1.0	min: 0.0011170087	loss: 34670.31640625	train_loss: 34639.12008827651	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_362
Epoch: 362	max: 0.99906605/1.0	min: 0.0009339859	loss: 34670.328125	train_loss: 34638.87789109919	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_363
Epoch: 363	max: 0.99895537/1.0	min: 0.0010445755	loss: 34670.08984375	train_loss: 34638.77701085021	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_364
Epoch: 364	max: 0.998804/1.0	min: 0.0011959927	loss: 34669.93359375	train_loss: 34638.67826106311	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_365
Epoch: 365	max: 0.998771/1.0	min: 0.0012289878	loss: 34669.78515625	train_loss: 34638.581128839964	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_366
Epoch: 366	max: 0.9990388/1.0	min: 0.0009612463	loss: 34669.78515625	train_loss: 34638.48068939288	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_367
Epoch: 367	max: 0.999094/1.0	min: 0.0009060455	loss: 34669.875	train_loss: 34638.44115270423	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_368
Epoch: 368	max: 0.99903846/1.0	min: 0.00096154993	loss: 34669.56640625	train_loss: 34638.25112208519	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_369
Epoch: 369	max: 0.9988954/1.0	min: 0.0011045565	loss: 34669.390625	train_loss: 34638.11138788245	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_370
Epoch: 370	max: 0.9990609/1.0	min: 0.00093910156	loss: 34669.36328125	train_loss: 34638.00467462916	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_371
Epoch: 371	max: 0.9990355/1.0	min: 0.00096456596	loss: 34669.2265625	train_loss: 34637.90444034126	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_372
Epoch: 372	max: 0.9990746/1.0	min: 0.00092542195	loss: 34669.09375	train_loss: 34637.86946457327	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_373
Epoch: 373	max: 0.9987803/1.0	min: 0.0012196329	loss: 34668.93359375	train_loss: 34637.70004374148	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_374
Epoch: 374	max: 0.99864477/1.0	min: 0.0013552442	loss: 34668.94140625	train_loss: 34637.6859884027	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_375
Epoch: 375	max: 0.99875844/1.0	min: 0.0012416058	loss: 34668.6796875	train_loss: 34637.650208449464	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_376
Epoch: 376	max: 0.99891376/1.0	min: 0.0010862708	loss: 34668.56640625	train_loss: 34637.48898914592	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_377
Epoch: 377	max: 0.9989976/1.0	min: 0.0010023906	loss: 34668.50390625	train_loss: 34637.34104664081	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_378
Epoch: 378	max: 0.9989796/1.0	min: 0.0010203643	loss: 34668.34765625	train_loss: 34637.26142552722	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_379
Epoch: 379	max: 0.9990085/1.0	min: 0.0009915446	loss: 34668.2734375	train_loss: 34637.140947738604	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_380
Epoch: 380	max: 0.99909866/1.0	min: 0.00090140983	loss: 34668.2109375	train_loss: 34637.008974746066	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_381
Epoch: 381	max: 0.9990308/1.0	min: 0.00096914003	loss: 34668.0625	train_loss: 34636.893783193205	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_382
Epoch: 382	max: 0.99904853/1.0	min: 0.00095147983	loss: 34667.953125	train_loss: 34636.829457083026	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_383
Epoch: 383	max: 0.99909925/1.0	min: 0.00090081565	loss: 34667.88671875	train_loss: 34636.69915729902	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_384
Epoch: 384	max: 0.99925345/1.0	min: 0.000746557	loss: 34668.0859375	train_loss: 34636.614682525855	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_385
Epoch: 385	max: 0.9992386/1.0	min: 0.00076141575	loss: 34667.86328125	train_loss: 34636.537924447235	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_386
Epoch: 386	max: 0.99910235/1.0	min: 0.0008976895	loss: 34667.6015625	train_loss: 34636.44280365493	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_387
Epoch: 387	max: 0.99912554/1.0	min: 0.0008745015	loss: 34667.453125	train_loss: 34636.30920487273	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_388
Epoch: 388	max: 0.9993063/1.0	min: 0.000693697	loss: 34667.58984375	train_loss: 34636.22738555602	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_389
Epoch: 389	max: 0.9993581/1.0	min: 0.0006418496	loss: 34667.7421875	train_loss: 34636.20736898845	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_390
Epoch: 390	max: 0.9993243/1.0	min: 0.0006756477	loss: 34667.40234375	train_loss: 34636.13017059179	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_391
Epoch: 391	max: 0.9990753/1.0	min: 0.00092466874	loss: 34667.0	train_loss: 34635.99692551561	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_392
Epoch: 392	max: 0.99914885/1.0	min: 0.00085120305	loss: 34666.94921875	train_loss: 34635.8414022823	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_393
Epoch: 393	max: 0.99943/1.0	min: 0.0005699986	loss: 34667.4453125	train_loss: 34635.76034892543	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_394
Epoch: 394	max: 0.9992747/1.0	min: 0.00072538335	loss: 34666.91796875	train_loss: 34635.74220104825	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_395
Epoch: 395	max: 0.9992137/1.0	min: 0.0007863082	loss: 34666.68359375	train_loss: 34635.54750015484	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_396
Epoch: 396	max: 0.99925/1.0	min: 0.00074996013	loss: 34666.640625	train_loss: 34635.478239095595	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_397
Epoch: 397	max: 0.99920195/1.0	min: 0.0007981202	loss: 34666.453125	train_loss: 34635.38559569708	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_398
Epoch: 398	max: 0.9990652/1.0	min: 0.00093485083	loss: 34666.33984375	train_loss: 34635.28498447758	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_399
Epoch: 399	max: 0.9991756/1.0	min: 0.0008244024	loss: 34666.21875	train_loss: 34635.226356373096	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_400
Epoch: 400	max: 0.99916553/1.0	min: 0.0008344674	loss: 34666.15625	train_loss: 34635.0965385196	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_401
Epoch: 401	max: 0.9992304/1.0	min: 0.000769569	loss: 34666.078125	train_loss: 34634.987402065526	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_402
Epoch: 402	max: 0.9988305/1.0	min: 0.0011695197	loss: 34666.25390625	train_loss: 34634.92569947665	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_403
Epoch: 403	max: 0.9990108/1.0	min: 0.0009891961	loss: 34665.98046875	train_loss: 34634.94606781478	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_404
Epoch: 404	max: 0.99917173/1.0	min: 0.0008283119	loss: 34665.7890625	train_loss: 34634.758978133126	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_405
Epoch: 405	max: 0.99923635/1.0	min: 0.00076363893	loss: 34665.6640625	train_loss: 34634.606527932614	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_406
Epoch: 406	max: 0.9992649/1.0	min: 0.0007350444	loss: 34665.58984375	train_loss: 34634.5339475528	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_407
Epoch: 407	max: 0.9991955/1.0	min: 0.0008045205	loss: 34665.47265625	train_loss: 34634.446261361176	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_408
Epoch: 408	max: 0.9993643/1.0	min: 0.0006356869	loss: 34665.546875	train_loss: 34634.34039051855	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_409
Epoch: 409	max: 0.9992046/1.0	min: 0.0007954543	loss: 34665.26953125	train_loss: 34634.25033289979	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_410
Epoch: 410	max: 0.9990926/1.0	min: 0.0009074212	loss: 34665.30078125	train_loss: 34634.20393499164	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_411
Epoch: 411	max: 0.99937266/1.0	min: 0.0006273315	loss: 34665.19921875	train_loss: 34634.117028308094	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_412
Epoch: 412	max: 0.99942327/1.0	min: 0.0005767519	loss: 34665.13671875	train_loss: 34633.97984988542	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_413
Epoch: 413	max: 0.9992267/1.0	min: 0.00077334594	loss: 34664.9609375	train_loss: 34633.92511932135	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_414
Epoch: 414	max: 0.9993012/1.0	min: 0.00069873757	loss: 34664.875	train_loss: 34633.82588711988	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_415
Epoch: 415	max: 0.9994203/1.0	min: 0.0005797413	loss: 34664.87109375	train_loss: 34633.714792944076	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_416
Epoch: 416	max: 0.9992963/1.0	min: 0.000703728	loss: 34664.69921875	train_loss: 34633.61639976619	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_417
Epoch: 417	max: 0.99930596/1.0	min: 0.00069404417	loss: 34664.58984375	train_loss: 34633.542029566146	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_418
Epoch: 418	max: 0.99927324/1.0	min: 0.00072672917	loss: 34664.48828125	train_loss: 34633.44149092655	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_419
Epoch: 419	max: 0.9992654/1.0	min: 0.0007346296	loss: 34664.421875	train_loss: 34633.347351414435	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_420
Epoch: 420	max: 0.9994149/1.0	min: 0.0005850711	loss: 34664.3984375	train_loss: 34633.263549698844	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_421
Epoch: 421	max: 0.9993881/1.0	min: 0.00061187363	loss: 34664.26171875	train_loss: 34633.158355300846	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_422
Epoch: 422	max: 0.9995147/1.0	min: 0.00048530384	loss: 34664.34375	train_loss: 34633.1059351968	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_423
Epoch: 423	max: 0.9994319/1.0	min: 0.0005680657	loss: 34664.14453125	train_loss: 34633.00477333782	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_424
Epoch: 424	max: 0.99957913/1.0	min: 0.00042088664	loss: 34664.3984375	train_loss: 34632.912664611205	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_425
Epoch: 425	max: 0.99937254/1.0	min: 0.00062747835	loss: 34663.921875	train_loss: 34632.84025939087	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_426
Epoch: 426	max: 0.9991565/1.0	min: 0.0008435856	loss: 34663.9609375	train_loss: 34632.725099289295	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_427
Epoch: 427	max: 0.99942774/1.0	min: 0.0005721794	loss: 34663.73046875	train_loss: 34632.71368682646	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_428
Epoch: 428	max: 0.99946076/1.0	min: 0.00053929223	loss: 34663.671875	train_loss: 34632.57954901756	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_429
Epoch: 429	max: 0.9994273/1.0	min: 0.0005727589	loss: 34663.5859375	train_loss: 34632.50294190511	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_430
Epoch: 430	max: 0.9994843/1.0	min: 0.0005156799	loss: 34663.5	train_loss: 34632.35600100257	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_431
Epoch: 431	max: 0.9995235/1.0	min: 0.00047653905	loss: 34663.44140625	train_loss: 34632.30512249551	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_432
Epoch: 432	max: 0.9994942/1.0	min: 0.0005058005	loss: 34663.31640625	train_loss: 34632.212460710085	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_433
Epoch: 433	max: 0.9994031/1.0	min: 0.0005968536	loss: 34663.26953125	train_loss: 34632.13755245107	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_434
Epoch: 434	max: 0.99941874/1.0	min: 0.00058127556	loss: 34663.12890625	train_loss: 34632.07015475969	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_435
Epoch: 435	max: 0.9994629/1.0	min: 0.0005371156	loss: 34663.078125	train_loss: 34631.95735447247	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_436
Epoch: 436	max: 0.99961746/1.0	min: 0.00038256025	loss: 34663.25	train_loss: 34631.83106738898	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_437
Epoch: 437	max: 0.9995615/1.0	min: 0.00043851245	loss: 34663.00390625	train_loss: 34631.78766557894	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_438
Epoch: 438	max: 0.9995365/1.0	min: 0.00046350248	loss: 34662.90625	train_loss: 34631.69147253964	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_439
Epoch: 439	max: 0.999503/1.0	min: 0.0004969638	loss: 34662.74609375	train_loss: 34631.58444332187	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_440
Epoch: 440	max: 0.9995208/1.0	min: 0.00047927714	loss: 34662.71484375	train_loss: 34631.54486163369	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_441
Epoch: 441	max: 0.99963653/1.0	min: 0.000363414	loss: 34662.8984375	train_loss: 34631.48778335191	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_442
Epoch: 442	max: 0.99961686/1.0	min: 0.0003830775	loss: 34662.73828125	train_loss: 34631.37514564366	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_443
Epoch: 443	max: 0.99960977/1.0	min: 0.00039027206	loss: 34662.6015625	train_loss: 34631.3086663299	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_444
Epoch: 444	max: 0.9996983/1.0	min: 0.00030171144	loss: 34662.86328125	train_loss: 34631.22304431051	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_445
Epoch: 445	max: 0.99958724/1.0	min: 0.00041280006	loss: 34662.40625	train_loss: 34631.32681856187	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_446
Epoch: 446	max: 0.9995542/1.0	min: 0.0004457656	loss: 34662.1953125	train_loss: 34631.04286520268	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_447
Epoch: 447	max: 0.9994579/1.0	min: 0.00054205133	loss: 34662.12109375	train_loss: 34630.929202666295	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_448
Epoch: 448	max: 0.9995436/1.0	min: 0.0004563533	loss: 34662.0234375	train_loss: 34630.84382209603	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_449
Epoch: 449	max: 0.9994448/1.0	min: 0.00055516424	loss: 34661.97265625	train_loss: 34630.78039839589	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_450
Epoch: 450	max: 0.99954396/1.0	min: 0.00045600478	loss: 34661.87890625	train_loss: 34630.71461246206	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_451
Epoch: 451	max: 0.9996269/1.0	min: 0.00037308197	loss: 34661.90625	train_loss: 34630.621797291125	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_452
Epoch: 452	max: 0.99942255/1.0	min: 0.00057742815	loss: 34661.83984375	train_loss: 34630.53125338706	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_453
Epoch: 453	max: 0.9994293/1.0	min: 0.0005706705	loss: 34661.73046875	train_loss: 34630.479242149755	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_454
Epoch: 454	max: 0.99944276/1.0	min: 0.0005572137	loss: 34661.69140625	train_loss: 34630.41835632664	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_455
Epoch: 455	max: 0.99942374/1.0	min: 0.0005762536	loss: 34661.6015625	train_loss: 34630.39363464635	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_456
Epoch: 456	max: 0.99952364/1.0	min: 0.00047640144	loss: 34661.48046875	train_loss: 34630.24880146398	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_457
Epoch: 457	max: 0.99963236/1.0	min: 0.0003675776	loss: 34661.47265625	train_loss: 34630.119426347854	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_458
Epoch: 458	max: 0.9996481/1.0	min: 0.00035190547	loss: 34661.34375	train_loss: 34630.06276854561	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_459
Epoch: 459	max: 0.9995189/1.0	min: 0.00048112933	loss: 34661.2578125	train_loss: 34629.97704684984	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_460
Epoch: 460	max: 0.99957865/1.0	min: 0.00042139672	loss: 34661.14453125	train_loss: 34629.92849718971	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_461
Epoch: 461	max: 0.9996141/1.0	min: 0.00038583679	loss: 34661.015625	train_loss: 34629.847220286756	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_462
Epoch: 462	max: 0.9995683/1.0	min: 0.00043170742	loss: 34660.96484375	train_loss: 34629.73306662641	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_463
Epoch: 463	max: 0.99970967/1.0	min: 0.00029029808	loss: 34661.06640625	train_loss: 34629.66675908507	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_464
Epoch: 464	max: 0.9997311/1.0	min: 0.00026883374	loss: 34660.984375	train_loss: 34629.607612760126	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_465
Epoch: 465	max: 0.99968076/1.0	min: 0.00031925106	loss: 34660.81640625	train_loss: 34629.55925713025	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_466
Epoch: 466	max: 0.9996666/1.0	min: 0.00033338487	loss: 34660.671875	train_loss: 34629.458651233275	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_467
Epoch: 467	max: 0.99957067/1.0	min: 0.00042930583	loss: 34660.57421875	train_loss: 34629.36473720271	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_468
Epoch: 468	max: 0.9996406/1.0	min: 0.00035937413	loss: 34660.62890625	train_loss: 34629.27275766831	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_469
Epoch: 469	max: 0.9995623/1.0	min: 0.0004376357	loss: 34660.44921875	train_loss: 34629.213189412236	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_470
Epoch: 470	max: 0.99972194/1.0	min: 0.00027798457	loss: 34660.5859375	train_loss: 34629.1307662308	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_471
Epoch: 471	max: 0.9995492/1.0	min: 0.00045075233	loss: 34660.375	train_loss: 34629.141226445405	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_472
Epoch: 472	max: 0.99958235/1.0	min: 0.0004177002	loss: 34660.234375	train_loss: 34629.017011759875	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_473
Epoch: 473	max: 0.9995974/1.0	min: 0.00040265062	loss: 34660.21875	train_loss: 34628.925927377524	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_474
Epoch: 474	max: 0.9995915/1.0	min: 0.00040844045	loss: 34660.15234375	train_loss: 34628.85932467794	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_475
Epoch: 475	max: 0.9995285/1.0	min: 0.00047150574	loss: 34660.09375	train_loss: 34628.77002769649	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_476
Epoch: 476	max: 0.99949825/1.0	min: 0.00050171965	loss: 34660.03125	train_loss: 34628.738046575	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_477
Epoch: 477	max: 0.99959534/1.0	min: 0.0004046263	loss: 34659.86328125	train_loss: 34628.6916864084	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_478
Epoch: 478	max: 0.9997775/1.0	min: 0.00022247975	loss: 34659.96484375	train_loss: 34628.54081506255	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_479
Epoch: 479	max: 0.99971575/1.0	min: 0.0002841842	loss: 34659.76171875	train_loss: 34628.52483345333	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_480
Epoch: 480	max: 0.9996966/1.0	min: 0.00030338904	loss: 34659.68359375	train_loss: 34628.431097485445	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_481
Epoch: 481	max: 0.99954236/1.0	min: 0.0004576969	loss: 34659.625	train_loss: 34628.35880645748	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_482
Epoch: 482	max: 0.9995314/1.0	min: 0.00046859935	loss: 34659.56640625	train_loss: 34628.292671656294	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_483
Epoch: 483	max: 0.9995672/1.0	min: 0.00043276593	loss: 34659.4453125	train_loss: 34628.23162712514	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_484
Epoch: 484	max: 0.9995316/1.0	min: 0.00046835575	loss: 34659.52734375	train_loss: 34628.1376985786	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_485
Epoch: 485	max: 0.9996481/1.0	min: 0.0003518897	loss: 34659.26171875	train_loss: 34628.23686981296	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_486
Epoch: 486	max: 0.9997274/1.0	min: 0.00027255111	loss: 34659.19921875	train_loss: 34628.04793563421	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_487
Epoch: 487	max: 0.9996897/1.0	min: 0.00031034707	loss: 34659.12109375	train_loss: 34627.949575843086	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_488
Epoch: 488	max: 0.9996493/1.0	min: 0.0003507232	loss: 34659.03515625	train_loss: 34627.92016646925	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_489
Epoch: 489	max: 0.9997073/1.0	min: 0.0002927361	loss: 34658.98828125	train_loss: 34627.76553742026	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_490
Epoch: 490	max: 0.9996364/1.0	min: 0.00036362093	loss: 34658.94140625	train_loss: 34627.682807951656	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_491
Epoch: 491	max: 0.9995685/1.0	min: 0.000431412	loss: 34658.9453125	train_loss: 34627.654184860025	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_492
Epoch: 492	max: 0.999754/1.0	min: 0.00024598552	loss: 34658.8828125	train_loss: 34627.601388792114	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_493
Epoch: 493	max: 0.9996898/1.0	min: 0.00031022102	loss: 34658.71484375	train_loss: 34627.48425500124	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_494
Epoch: 494	max: 0.9996513/1.0	min: 0.00034870813	loss: 34658.71875	train_loss: 34627.446407972566	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_495
Epoch: 495	max: 0.9995784/1.0	min: 0.0004215379	loss: 34658.80859375	train_loss: 34627.390248068405	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_496
Epoch: 496	max: 0.99972624/1.0	min: 0.00027375872	loss: 34658.51953125	train_loss: 34627.344051448505	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_497
Epoch: 497	max: 0.9995845/1.0	min: 0.00041549574	loss: 34658.65625	train_loss: 34627.22112916899	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_498
Epoch: 498	max: 0.99970585/1.0	min: 0.00029406982	loss: 34658.44140625	train_loss: 34627.22867263951	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_499
Epoch: 499	max: 0.99971944/1.0	min: 0.00028058983	loss: 34658.328125	train_loss: 34627.06813461926	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_500
Epoch: 500	max: 0.9996706/1.0	min: 0.00032936834	loss: 34658.28515625	train_loss: 34627.00370302629	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_501
Epoch: 501	max: 0.99958783/1.0	min: 0.00041222182	loss: 34658.34765625	train_loss: 34626.977980227304	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_502
Epoch: 502	max: 0.9996383/1.0	min: 0.00036168832	loss: 34658.19140625	train_loss: 34626.92978814412	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_503
Epoch: 503	max: 0.9998049/1.0	min: 0.00019504898	loss: 34658.18359375	train_loss: 34626.87941285767	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_504
Epoch: 504	max: 0.99969685/1.0	min: 0.0003031488	loss: 34658.01953125	train_loss: 34626.76451743079	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_505
Epoch: 505	max: 0.99973685/1.0	min: 0.0002631462	loss: 34657.93359375	train_loss: 34626.67789477657	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_506
Epoch: 506	max: 0.9997421/1.0	min: 0.00025790362	loss: 34657.9453125	train_loss: 34626.614103822154	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_507
Epoch: 507	max: 0.9996929/1.0	min: 0.00030716273	loss: 34657.8671875	train_loss: 34626.538532182894	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_508
Epoch: 508	max: 0.9997813/1.0	min: 0.00021869324	loss: 34657.76171875	train_loss: 34626.483913391865	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_509
Epoch: 509	max: 0.9997055/1.0	min: 0.0002944553	loss: 34657.7109375	train_loss: 34626.439373045185	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_510
Epoch: 510	max: 0.999691/1.0	min: 0.00030900462	loss: 34657.703125	train_loss: 34626.35017235306	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_511
Epoch: 511	max: 0.99973315/1.0	min: 0.00026684807	loss: 34657.6015625	train_loss: 34626.273021375266	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_512
Epoch: 512	max: 0.99972457/1.0	min: 0.00027541615	loss: 34657.51171875	train_loss: 34626.21595325468	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_513
Epoch: 513	max: 0.99974686/1.0	min: 0.00025312766	loss: 34657.43359375	train_loss: 34626.16553974282	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_514
Epoch: 514	max: 0.9997867/1.0	min: 0.00021334374	loss: 34657.37109375	train_loss: 34626.0758909908	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_515
Epoch: 515	max: 0.9997787/1.0	min: 0.00022127181	loss: 34657.296875	train_loss: 34625.99504182537	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_516
Epoch: 516	max: 0.9997508/1.0	min: 0.00024925297	loss: 34657.24609375	train_loss: 34625.95275290707	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_517
Epoch: 517	max: 0.9998035/1.0	min: 0.00019657776	loss: 34657.21875	train_loss: 34625.88523570079	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_518
Epoch: 518	max: 0.9998282/1.0	min: 0.00017177238	loss: 34657.17578125	train_loss: 34625.86507639276	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_519
Epoch: 519	max: 0.99975985/1.0	min: 0.0002401464	loss: 34657.01171875	train_loss: 34625.776718111294	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_520
Epoch: 520	max: 0.99983156/1.0	min: 0.00016839757	loss: 34657.015625	train_loss: 34625.71439036758	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_521
Epoch: 521	max: 0.9997329/1.0	min: 0.00026708347	loss: 34656.88671875	train_loss: 34625.63476731853	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_522
Epoch: 522	max: 0.99974877/1.0	min: 0.00025128477	loss: 34656.78125	train_loss: 34625.54946610228	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_523
Epoch: 523	max: 0.9997814/1.0	min: 0.0002185815	loss: 34656.73828125	train_loss: 34625.485844984825	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_524
Epoch: 524	max: 0.9998561/1.0	min: 0.00014381732	loss: 34656.765625	train_loss: 34625.44653764864	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_525
Epoch: 525	max: 0.99975497/1.0	min: 0.0002449798	loss: 34656.6796875	train_loss: 34625.38273459758	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_526
Epoch: 526	max: 0.9997315/1.0	min: 0.00026855533	loss: 34656.61328125	train_loss: 34625.29535275765	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_527
Epoch: 527	max: 0.99971074/1.0	min: 0.0002892808	loss: 34656.578125	train_loss: 34625.22504267698	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_528
Epoch: 528	max: 0.99973613/1.0	min: 0.00026382474	loss: 34656.4140625	train_loss: 34625.179993303296	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_529
Epoch: 529	max: 0.99975234/1.0	min: 0.00024769013	loss: 34656.359375	train_loss: 34625.1435301313	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_530
Epoch: 530	max: 0.9998374/1.0	min: 0.0001625272	loss: 34656.26171875	train_loss: 34625.02426297535	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_531
Epoch: 531	max: 0.9998203/1.0	min: 0.00017975339	loss: 34656.2109375	train_loss: 34624.96332634631	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_532
Epoch: 532	max: 0.9998203/1.0	min: 0.00017979008	loss: 34656.18359375	train_loss: 34624.916094737084	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_533
Epoch: 533	max: 0.9998858/1.0	min: 0.00011420403	loss: 34656.19140625	train_loss: 34624.849111718846	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_534
Epoch: 534	max: 0.9997569/1.0	min: 0.00024307078	loss: 34656.0	train_loss: 34624.779772273316	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_535
Epoch: 535	max: 0.99980026/1.0	min: 0.00019980477	loss: 34655.875	train_loss: 34624.71228313127	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_536
Epoch: 536	max: 0.9998017/1.0	min: 0.00019838085	loss: 34655.85546875	train_loss: 34624.63632972176	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_537
Epoch: 537	max: 0.9997421/1.0	min: 0.00025788002	loss: 34655.890625	train_loss: 34624.57744081351	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_538
Epoch: 538	max: 0.99970144/1.0	min: 0.0002985633	loss: 34655.87109375	train_loss: 34624.53427513006	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_539
Epoch: 539	max: 0.9997303/1.0	min: 0.00026974705	loss: 34655.75390625	train_loss: 34624.49700535349	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_540
Epoch: 540	max: 0.9998448/1.0	min: 0.00015521528	loss: 34655.72265625	train_loss: 34624.41368169748	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_541
Epoch: 541	max: 0.9998449/1.0	min: 0.00015512622	loss: 34655.703125	train_loss: 34624.36955699167	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_542
Epoch: 542	max: 0.99983656/1.0	min: 0.00016336761	loss: 34655.484375	train_loss: 34624.30266639183	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_543
Epoch: 543	max: 0.9997427/1.0	min: 0.00025725822	loss: 34655.61328125	train_loss: 34624.3679979755	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_544
Epoch: 544	max: 0.9995888/1.0	min: 0.0004112149	loss: 34656.0546875	train_loss: 34624.25893313359	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_545
Epoch: 545	max: 0.99978036/1.0	min: 0.00021962728	loss: 34655.3984375	train_loss: 34624.21126410953	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_546
Epoch: 546	max: 0.99978215/1.0	min: 0.00021784124	loss: 34655.30078125	train_loss: 34624.05337815868	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_547
Epoch: 547	max: 0.99972695/1.0	min: 0.00027299504	loss: 34655.35546875	train_loss: 34623.95647673959	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_548
Epoch: 548	max: 0.9997788/1.0	min: 0.00022125558	loss: 34655.203125	train_loss: 34623.959933961974	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_549
Epoch: 549	max: 0.99987364/1.0	min: 0.00012637586	loss: 34655.0859375	train_loss: 34623.92581124969	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_550
Epoch: 550	max: 0.9998566/1.0	min: 0.00014334908	loss: 34654.9765625	train_loss: 34623.7793658259	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_551
Epoch: 551	max: 0.99974865/1.0	min: 0.00025129385	loss: 34654.95703125	train_loss: 34623.73408032562	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_552
Epoch: 552	max: 0.99974686/1.0	min: 0.00025310303	loss: 34654.984375	train_loss: 34623.705140301776	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_553
Epoch: 553	max: 0.99982065/1.0	min: 0.00017937056	loss: 34654.87109375	train_loss: 34623.64786460269	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_554
Epoch: 554	max: 0.99976426/1.0	min: 0.00023573112	loss: 34654.859375	train_loss: 34623.55085818469	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_555
Epoch: 555	max: 0.99984825/1.0	min: 0.00015175132	loss: 34654.6953125	train_loss: 34623.55062883222	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_556
Epoch: 556	max: 0.99987566/1.0	min: 0.00012428306	loss: 34654.7578125	train_loss: 34623.439338690696	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_557
Epoch: 557	max: 0.9998585/1.0	min: 0.00014150025	loss: 34654.62890625	train_loss: 34623.38626343212	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_558
Epoch: 558	max: 0.9998896/1.0	min: 0.00011033379	loss: 34654.5546875	train_loss: 34623.32603760219	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_559
Epoch: 559	max: 0.99986327/1.0	min: 0.0001366969	loss: 34654.4921875	train_loss: 34623.31838042317	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_560
Epoch: 560	max: 0.9998611/1.0	min: 0.00013888741	loss: 34654.48046875	train_loss: 34623.20888639214	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_561
Epoch: 561	max: 0.99978524/1.0	min: 0.00021479945	loss: 34654.48828125	train_loss: 34623.136021983	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_562
Epoch: 562	max: 0.9998436/1.0	min: 0.00015632287	loss: 34654.32421875	train_loss: 34623.09158518364	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_563
Epoch: 563	max: 0.9997918/1.0	min: 0.0002082519	loss: 34654.296875	train_loss: 34623.01730449879	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_564
Epoch: 564	max: 0.9998764/1.0	min: 0.00012359688	loss: 34654.26171875	train_loss: 34622.98073439242	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_565
Epoch: 565	max: 0.99989223/1.0	min: 0.00010776752	loss: 34654.2109375	train_loss: 34622.942834138485	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_566
Epoch: 566	max: 0.99979323/1.0	min: 0.00020673269	loss: 34654.18359375	train_loss: 34622.86424075622	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_567
Epoch: 567	max: 0.99983096/1.0	min: 0.00016904285	loss: 34654.0234375	train_loss: 34622.85441053512	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_568
Epoch: 568	max: 0.9998815/1.0	min: 0.00011853577	loss: 34654.078125	train_loss: 34622.75407221603	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_569
Epoch: 569	max: 0.99978393/1.0	min: 0.0002161212	loss: 34654.11328125	train_loss: 34622.70715802289	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_570
Epoch: 570	max: 0.999846/1.0	min: 0.00015401846	loss: 34653.9140625	train_loss: 34622.670010664406	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_571
Epoch: 571	max: 0.9999012/1.0	min: 9.8805394e-05	loss: 34653.8515625	train_loss: 34622.59725609284	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_572
Epoch: 572	max: 0.9999113/1.0	min: 8.8635476e-05	loss: 34653.89453125	train_loss: 34622.55469524186	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_573
Epoch: 573	max: 0.9998783/1.0	min: 0.000121735946	loss: 34653.71875	train_loss: 34622.48729609888	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_574
Epoch: 574	max: 0.99982977/1.0	min: 0.00017022554	loss: 34653.6484375	train_loss: 34622.42517593367	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_575
Epoch: 575	max: 0.9998288/1.0	min: 0.00017110935	loss: 34653.5859375	train_loss: 34622.35775162966	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_576
Epoch: 576	max: 0.99983156/1.0	min: 0.00016843386	loss: 34653.5859375	train_loss: 34622.33718151942	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_577
Epoch: 577	max: 0.9998336/1.0	min: 0.00016640348	loss: 34653.46484375	train_loss: 34622.26804142667	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_578
Epoch: 578	max: 0.99994814/1.0	min: 5.1817136e-05	loss: 34653.80859375	train_loss: 34622.198338597795	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_579
Epoch: 579	max: 0.99984276/1.0	min: 0.00015724332	loss: 34653.3515625	train_loss: 34622.39090031974	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_580
Epoch: 580	max: 0.99983895/1.0	min: 0.00016105657	loss: 34653.3046875	train_loss: 34622.16533651911	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_581
Epoch: 581	max: 0.9998547/1.0	min: 0.00014533265	loss: 34653.2421875	train_loss: 34622.041652150685	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_582
Epoch: 582	max: 0.9998938/1.0	min: 0.00010616198	loss: 34653.19921875	train_loss: 34621.97353156355	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_583
Epoch: 583	max: 0.9998944/1.0	min: 0.000105584004	loss: 34653.12890625	train_loss: 34621.91793729871	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_584
Epoch: 584	max: 0.99990857/1.0	min: 9.1430586e-05	loss: 34653.109375	train_loss: 34621.87603934411	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_585
Epoch: 585	max: 0.9998412/1.0	min: 0.00015881707	loss: 34653.11328125	train_loss: 34621.8078471448	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_586
Epoch: 586	max: 0.9999099/1.0	min: 9.014782e-05	loss: 34653.015625	train_loss: 34621.77261928264	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_587
Epoch: 587	max: 0.99986374/1.0	min: 0.00013619025	loss: 34652.9140625	train_loss: 34621.70190856094	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_588
Epoch: 588	max: 0.99987006/1.0	min: 0.00012988038	loss: 34652.91015625	train_loss: 34621.64872830345	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_589
Epoch: 589	max: 0.99992776/1.0	min: 7.223547e-05	loss: 34652.8984375	train_loss: 34621.619231833734	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_590
Epoch: 590	max: 0.9999207/1.0	min: 7.922245e-05	loss: 34652.8046875	train_loss: 34621.55820375402	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_591
Epoch: 591	max: 0.999821/1.0	min: 0.00017905408	loss: 34652.84375	train_loss: 34621.51597241577	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_592
Epoch: 592	max: 0.9998903/1.0	min: 0.00010968824	loss: 34652.65625	train_loss: 34621.46074492134	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_593
Epoch: 593	max: 0.9999435/1.0	min: 5.649276e-05	loss: 34652.953125	train_loss: 34621.39641929503	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_594
Epoch: 594	max: 0.9998647/1.0	min: 0.00013532063	loss: 34652.64453125	train_loss: 34621.364789944106	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_595
Epoch: 595	max: 0.99989486/1.0	min: 0.00010517673	loss: 34652.484375	train_loss: 34621.295001954815	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_596
Epoch: 596	max: 0.9998449/1.0	min: 0.000155031	loss: 34652.5078125	train_loss: 34621.22664378949	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_597
Epoch: 597	max: 0.9998605/1.0	min: 0.00013949793	loss: 34652.4140625	train_loss: 34621.19578717252	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_598
Epoch: 598	max: 0.9998847/1.0	min: 0.00011524614	loss: 34652.38671875	train_loss: 34621.13732261473	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_599
Epoch: 599	max: 0.99986804/1.0	min: 0.00013199994	loss: 34652.359375	train_loss: 34621.10258974746	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_600
Epoch: 600	max: 0.99992335/1.0	min: 7.6589604e-05	loss: 34652.4140625	train_loss: 34621.034602707325	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_601
Epoch: 601	max: 0.9999182/1.0	min: 8.181214e-05	loss: 34652.35546875	train_loss: 34620.98722400285	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_602
Epoch: 602	max: 0.9999082/1.0	min: 9.180933e-05	loss: 34652.265625	train_loss: 34621.002485135636	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_603
Epoch: 603	max: 0.99988747/1.0	min: 0.000112503156	loss: 34652.13671875	train_loss: 34620.92429868466	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_604
Epoch: 604	max: 0.99991584/1.0	min: 8.415213e-05	loss: 34652.14453125	train_loss: 34620.82530164205	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_605
Epoch: 605	max: 0.99988544/1.0	min: 0.000114566596	loss: 34652.0859375	train_loss: 34620.76279535179	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_606
Epoch: 606	max: 0.9998491/1.0	min: 0.00015091583	loss: 34652.0859375	train_loss: 34620.702971130624	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_607
Epoch: 607	max: 0.9999058/1.0	min: 9.415936e-05	loss: 34651.9375	train_loss: 34620.68696145717	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_608
Epoch: 608	max: 0.9998698/1.0	min: 0.00013016284	loss: 34651.86328125	train_loss: 34620.589780847426	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_609
Epoch: 609	max: 0.99989915/1.0	min: 0.00010078154	loss: 34651.734375	train_loss: 34620.633203947575	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_610
Epoch: 610	max: 0.9998888/1.0	min: 0.000111239904	loss: 34651.76171875	train_loss: 34620.518465777124	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_611
Epoch: 611	max: 0.9999248/1.0	min: 7.522762e-05	loss: 34651.75390625	train_loss: 34620.44036980908	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_612
Epoch: 612	max: 0.9999478/1.0	min: 5.21938e-05	loss: 34651.9296875	train_loss: 34620.39524301684	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_613
Epoch: 613	max: 0.9998908/1.0	min: 0.000109224085	loss: 34651.63671875	train_loss: 34620.48832576567	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_614
Epoch: 614	max: 0.9997402/1.0	min: 0.00025978487	loss: 34652.01171875	train_loss: 34620.3753043517	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_615
Epoch: 615	max: 0.9999105/1.0	min: 8.9514186e-05	loss: 34651.5234375	train_loss: 34620.37067327047	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_616
Epoch: 616	max: 0.9999163/1.0	min: 8.364211e-05	loss: 34651.4296875	train_loss: 34620.18665710548	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_617
Epoch: 617	max: 0.99992466/1.0	min: 7.5312026e-05	loss: 34651.3359375	train_loss: 34620.12044924052	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_618
Epoch: 618	max: 0.99991965/1.0	min: 8.03553e-05	loss: 34651.3046875	train_loss: 34620.067728655704	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_619
Epoch: 619	max: 0.9999182/1.0	min: 8.180216e-05	loss: 34651.23828125	train_loss: 34620.02822583767	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_620
Epoch: 620	max: 0.99991477/1.0	min: 8.523718e-05	loss: 34651.13671875	train_loss: 34619.97203206289	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_621
Epoch: 621	max: 0.99988437/1.0	min: 0.000115646195	loss: 34651.2265625	train_loss: 34619.92585334603	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_622
Epoch: 622	max: 0.9999368/1.0	min: 6.316639e-05	loss: 34651.01953125	train_loss: 34619.92057969079	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_623
Epoch: 623	max: 0.9999273/1.0	min: 7.27287e-05	loss: 34651.05859375	train_loss: 34619.805244429735	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_624
Epoch: 624	max: 0.9999087/1.0	min: 9.127569e-05	loss: 34651.03515625	train_loss: 34619.744542959554	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_625
Epoch: 625	max: 0.99992466/1.0	min: 7.527533e-05	loss: 34650.8671875	train_loss: 34619.70867978137	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_626
Epoch: 626	max: 0.9999584/1.0	min: 4.1655214e-05	loss: 34650.88671875	train_loss: 34619.657531277095	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_627
Epoch: 627	max: 0.99994624/1.0	min: 5.3704156e-05	loss: 34650.859375	train_loss: 34619.594521282364	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_628
Epoch: 628	max: 0.9999316/1.0	min: 6.840669e-05	loss: 34650.71875	train_loss: 34619.55911245432	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_629
Epoch: 629	max: 0.99992776/1.0	min: 7.219648e-05	loss: 34650.625	train_loss: 34619.48694481218	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_630
Epoch: 630	max: 0.9998995/1.0	min: 0.00010052384	loss: 34650.64453125	train_loss: 34619.40151198439	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_631
Epoch: 631	max: 0.99992967/1.0	min: 7.0279195e-05	loss: 34650.484375	train_loss: 34619.36657589341	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_632
Epoch: 632	max: 0.99992716/1.0	min: 7.284378e-05	loss: 34650.44140625	train_loss: 34619.29519259801	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_633
Epoch: 633	max: 0.99995494/1.0	min: 4.503592e-05	loss: 34650.4296875	train_loss: 34619.22790329261	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_634
Epoch: 634	max: 0.9999323/1.0	min: 6.765363e-05	loss: 34650.34765625	train_loss: 34619.200814056116	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_635
Epoch: 635	max: 0.99991333/1.0	min: 8.668742e-05	loss: 34650.31640625	train_loss: 34619.11352269912	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_636
Epoch: 636	max: 0.99990654/1.0	min: 9.340217e-05	loss: 34650.26953125	train_loss: 34619.06556142001	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_637
Epoch: 637	max: 0.9999386/1.0	min: 6.1377126e-05	loss: 34650.1953125	train_loss: 34618.99545698238	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_638
Epoch: 638	max: 0.999951/1.0	min: 4.9029033e-05	loss: 34650.1640625	train_loss: 34618.93486776911	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_639
Epoch: 639	max: 0.999912/1.0	min: 8.802213e-05	loss: 34650.09375	train_loss: 34618.89478334417	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_640
Epoch: 640	max: 0.99993384/1.0	min: 6.619441e-05	loss: 34650.0390625	train_loss: 34618.88384216679	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_641
Epoch: 641	max: 0.99992764/1.0	min: 7.231914e-05	loss: 34649.8671875	train_loss: 34618.73958623653	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_642
Epoch: 642	max: 0.99994516/1.0	min: 5.4844117e-05	loss: 34649.796875	train_loss: 34618.69975003484	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_643
Epoch: 643	max: 0.9999374/1.0	min: 6.256887e-05	loss: 34649.81640625	train_loss: 34618.63414264756	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_644
Epoch: 644	max: 0.9999244/1.0	min: 7.557678e-05	loss: 34649.76171875	train_loss: 34618.59908365462	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_645
Epoch: 645	max: 0.9999397/1.0	min: 6.030732e-05	loss: 34649.67578125	train_loss: 34618.52043607937	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_646
Epoch: 646	max: 0.99993503/1.0	min: 6.493311e-05	loss: 34649.53515625	train_loss: 34618.43328746284	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_647
Epoch: 647	max: 0.99996185/1.0	min: 3.8189763e-05	loss: 34649.46484375	train_loss: 34618.38676907206	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_648
Epoch: 648	max: 0.99996376/1.0	min: 3.6276986e-05	loss: 34649.453125	train_loss: 34618.34514837266	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_649
Epoch: 649	max: 0.99995005/1.0	min: 4.9888396e-05	loss: 34649.31640625	train_loss: 34618.30086882974	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_650
Epoch: 650	max: 0.9999473/1.0	min: 5.2660154e-05	loss: 34649.26171875	train_loss: 34618.19495927784	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_651
Epoch: 651	max: 0.9999447/1.0	min: 5.5326556e-05	loss: 34649.21484375	train_loss: 34618.117728946025	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_652
Epoch: 652	max: 0.9999354/1.0	min: 6.4597254e-05	loss: 34649.14453125	train_loss: 34618.079095151275	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_653
Epoch: 653	max: 0.9999492/1.0	min: 5.0772374e-05	loss: 34649.03125	train_loss: 34617.9975085741	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_654
Epoch: 654	max: 0.99993324/1.0	min: 6.670768e-05	loss: 34649.046875	train_loss: 34617.93760306345	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_655
Epoch: 655	max: 0.99993527/1.0	min: 6.474589e-05	loss: 34648.88671875	train_loss: 34617.862347872535	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_656
Epoch: 656	max: 0.9999151/1.0	min: 8.490281e-05	loss: 34648.9765625	train_loss: 34617.81079485631	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_657
Epoch: 657	max: 0.99995315/1.0	min: 4.68191e-05	loss: 34648.7265625	train_loss: 34617.767528044875	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_658
Epoch: 658	max: 0.9999492/1.0	min: 5.0815343e-05	loss: 34648.76953125	train_loss: 34617.670067276726	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_659
Epoch: 659	max: 0.99993587/1.0	min: 6.418989e-05	loss: 34648.6484375	train_loss: 34617.62010085702	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_660
Epoch: 660	max: 0.99993277/1.0	min: 6.725918e-05	loss: 34648.625	train_loss: 34617.6205561749	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_661
Epoch: 661	max: 0.9999738/1.0	min: 2.6202608e-05	loss: 34648.7890625	train_loss: 34617.52674617552	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_662
Epoch: 662	max: 0.99993944/1.0	min: 6.05038e-05	loss: 34648.51953125	train_loss: 34617.53574511489	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_663
Epoch: 663	max: 0.9999603/1.0	min: 3.9740327e-05	loss: 34648.68359375	train_loss: 34617.44888004382	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_664
Epoch: 664	max: 0.99995935/1.0	min: 4.0593914e-05	loss: 34648.33984375	train_loss: 34617.38944630249	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_665
Epoch: 665	max: 0.9999391/1.0	min: 6.0890223e-05	loss: 34648.28515625	train_loss: 34617.272550573674	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_666
Epoch: 666	max: 0.999894/1.0	min: 0.00010592374	loss: 34648.5078125	train_loss: 34617.243363294314	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_667
Epoch: 667	max: 0.999954/1.0	min: 4.59982e-05	loss: 34648.15234375	train_loss: 34617.157198861176	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_668
Epoch: 668	max: 0.9999682/1.0	min: 3.1871536e-05	loss: 34648.22265625	train_loss: 34617.08809070358	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_669
Epoch: 669	max: 0.9999461/1.0	min: 5.388689e-05	loss: 34647.984375	train_loss: 34617.070764914686	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_670
Epoch: 670	max: 0.99996495/1.0	min: 3.5066332e-05	loss: 34647.8515625	train_loss: 34616.9762639547	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_671
Epoch: 671	max: 0.9999726/1.0	min: 2.7403086e-05	loss: 34648.07421875	train_loss: 34617.082453664996	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_672
Epoch: 672	max: 0.99994004/1.0	min: 5.9977654e-05	loss: 34647.89453125	train_loss: 34616.94799456909	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_673
Epoch: 673	max: 0.9999347/1.0	min: 6.536851e-05	loss: 34647.78515625	train_loss: 34616.82755839294	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_674
Epoch: 674	max: 0.9999455/1.0	min: 5.4489366e-05	loss: 34647.78125	train_loss: 34616.7835052993	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_675
Epoch: 675	max: 0.9998987/1.0	min: 0.00010137112	loss: 34647.8359375	train_loss: 34616.73198808915	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_676
Epoch: 676	max: 0.9999144/1.0	min: 8.553911e-05	loss: 34647.76171875	train_loss: 34616.67616785891	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_677
Epoch: 677	max: 0.99992645/1.0	min: 7.359998e-05	loss: 34647.63671875	train_loss: 34616.68572421188	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_678
Epoch: 678	max: 0.9999598/1.0	min: 4.0198098e-05	loss: 34647.44140625	train_loss: 34616.58758167658	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_679
Epoch: 679	max: 0.99993896/1.0	min: 6.1089784e-05	loss: 34647.49609375	train_loss: 34616.50855039561	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_680
Epoch: 680	max: 0.9999372/1.0	min: 6.2801526e-05	loss: 34647.35546875	train_loss: 34616.45546304038	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_681
Epoch: 681	max: 0.9999393/1.0	min: 6.0688548e-05	loss: 34647.32421875	train_loss: 34616.39324174718	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_682
Epoch: 682	max: 0.99996567/1.0	min: 3.433329e-05	loss: 34647.37890625	train_loss: 34616.38913566054	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_683
Epoch: 683	max: 0.99993825/1.0	min: 6.178851e-05	loss: 34647.17578125	train_loss: 34616.33806796188	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_684
Epoch: 684	max: 0.99993825/1.0	min: 6.1728955e-05	loss: 34647.19140625	train_loss: 34616.26534193841	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_685
Epoch: 685	max: 0.9999517/1.0	min: 4.8255595e-05	loss: 34647.09375	train_loss: 34616.20615158166	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_686
Epoch: 686	max: 0.9999329/1.0	min: 6.70806e-05	loss: 34647.1484375	train_loss: 34616.13343910644	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_687
Epoch: 687	max: 0.99992585/1.0	min: 7.413235e-05	loss: 34647.08984375	train_loss: 34616.14884249582	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_688
Epoch: 688	max: 0.99991333/1.0	min: 8.670478e-05	loss: 34646.98828125	train_loss: 34616.10386183111	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_689
Epoch: 689	max: 0.9999355/1.0	min: 6.454418e-05	loss: 34646.88671875	train_loss: 34616.02296185975	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_690
Epoch: 690	max: 0.9999486/1.0	min: 5.1378134e-05	loss: 34646.90625	train_loss: 34615.9418954385	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_691
Epoch: 691	max: 0.99996924/1.0	min: 3.0737057e-05	loss: 34646.890625	train_loss: 34615.90799675616	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_692
Epoch: 692	max: 0.99995196/1.0	min: 4.8042864e-05	loss: 34646.68359375	train_loss: 34615.84213582311	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_693
Epoch: 693	max: 0.9999614/1.0	min: 3.8612063e-05	loss: 34646.74609375	train_loss: 34615.77863760761	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_694
Epoch: 694	max: 0.99991786/1.0	min: 8.212433e-05	loss: 34646.76171875	train_loss: 34615.753202708875	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_695
Epoch: 695	max: 0.9998822/1.0	min: 0.00011775964	loss: 34647.046875	train_loss: 34615.80514185015	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_696
Epoch: 696	max: 0.9999336/1.0	min: 6.6417226e-05	loss: 34646.58203125	train_loss: 34615.71646179781	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_697
Epoch: 697	max: 0.99993515/1.0	min: 6.48288e-05	loss: 34646.56640625	train_loss: 34615.59192534142	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_698
Epoch: 698	max: 0.9999343/1.0	min: 6.56525e-05	loss: 34646.46484375	train_loss: 34615.56595867398	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_699
Epoch: 699	max: 0.99993265/1.0	min: 6.7379486e-05	loss: 34646.375	train_loss: 34615.55900213288	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_700
Epoch: 700	max: 0.99988616/1.0	min: 0.00011382112	loss: 34646.73828125	train_loss: 34615.496579551436	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_701
Epoch: 701	max: 0.99992096/1.0	min: 7.906178e-05	loss: 34646.37890625	train_loss: 34615.53025371996	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_702
Epoch: 702	max: 0.99994254/1.0	min: 5.7467714e-05	loss: 34646.23046875	train_loss: 34615.375563703856	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_703
Epoch: 703	max: 0.9999411/1.0	min: 5.888573e-05	loss: 34646.33984375	train_loss: 34615.302311234205	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_704
Epoch: 704	max: 0.9999399/1.0	min: 6.0028753e-05	loss: 34646.15625	train_loss: 34615.31664769912	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_705
Epoch: 705	max: 0.99996233/1.0	min: 3.7623307e-05	loss: 34646.11328125	train_loss: 34615.2363757858	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_706
Epoch: 706	max: 0.999944/1.0	min: 5.608428e-05	loss: 34646.02734375	train_loss: 34615.18493744581	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_707
Epoch: 707	max: 0.9999269/1.0	min: 7.30455e-05	loss: 34646.05859375	train_loss: 34615.11033886102	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_708
Epoch: 708	max: 0.99994147/1.0	min: 5.849211e-05	loss: 34645.90625	train_loss: 34615.136876974175	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_709
Epoch: 709	max: 0.99995136/1.0	min: 4.8618094e-05	loss: 34645.94921875	train_loss: 34615.05366992986	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_710
Epoch: 710	max: 0.99995005/1.0	min: 5.0004048e-05	loss: 34645.9765625	train_loss: 34615.10944903149	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_711
Epoch: 711	max: 0.9999056/1.0	min: 9.438418e-05	loss: 34646.125	train_loss: 34614.94454702403	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_712
Epoch: 712	max: 0.9999509/1.0	min: 4.9153226e-05	loss: 34645.859375	train_loss: 34614.967956459805	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_713
Epoch: 713	max: 0.99994624/1.0	min: 5.3708864e-05	loss: 34645.73046875	train_loss: 34614.88200928248	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_714
Epoch: 714	max: 0.99994445/1.0	min: 5.554303e-05	loss: 34645.71484375	train_loss: 34614.81172242738	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_715
Epoch: 715	max: 0.99993634/1.0	min: 6.3702304e-05	loss: 34645.76171875	train_loss: 34614.75439059984	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_716
Epoch: 716	max: 0.99994683/1.0	min: 5.3117663e-05	loss: 34645.6015625	train_loss: 34614.72015611452	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_717
Epoch: 717	max: 0.99995863/1.0	min: 4.13045e-05	loss: 34645.5546875	train_loss: 34614.68840434551	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_718
Epoch: 718	max: 0.99994147/1.0	min: 5.8526537e-05	loss: 34645.61328125	train_loss: 34614.62215873901	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_719
Epoch: 719	max: 0.9999374/1.0	min: 6.261405e-05	loss: 34645.55859375	train_loss: 34614.59067019308	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_720
Epoch: 720	max: 0.99995327/1.0	min: 4.675775e-05	loss: 34645.40234375	train_loss: 34614.56078614672	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_721
Epoch: 721	max: 0.99994624/1.0	min: 5.3733253e-05	loss: 34645.44140625	train_loss: 34614.509979735696	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_722
Epoch: 722	max: 0.9999651/1.0	min: 3.4873206e-05	loss: 34645.4375	train_loss: 34614.47324172783	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_723
Epoch: 723	max: 0.9999275/1.0	min: 7.245706e-05	loss: 34645.47265625	train_loss: 34614.44473331243	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_724
Epoch: 724	max: 0.9999174/1.0	min: 8.260296e-05	loss: 34645.5859375	train_loss: 34614.44031997089	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_725
Epoch: 725	max: 0.99996257/1.0	min: 3.7419286e-05	loss: 34645.28515625	train_loss: 34614.37015408228	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_726
Epoch: 726	max: 0.9999635/1.0	min: 3.650847e-05	loss: 34645.171875	train_loss: 34614.301200277936	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_727
Epoch: 727	max: 0.999944/1.0	min: 5.6029003e-05	loss: 34645.21875	train_loss: 34614.257315569645	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_728
Epoch: 728	max: 0.99994683/1.0	min: 5.3165957e-05	loss: 34645.18359375	train_loss: 34614.230731489224	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_729
Epoch: 729	max: 0.99995244/1.0	min: 4.7618894e-05	loss: 34645.1328125	train_loss: 34614.237192067696	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_730
Epoch: 730	max: 0.99996734/1.0	min: 3.270336e-05	loss: 34645.05078125	train_loss: 34614.25016112737	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_731
Epoch: 731	max: 0.9999659/1.0	min: 3.4148277e-05	loss: 34645.203125	train_loss: 34614.12893770129	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_732
Epoch: 732	max: 0.99996364/1.0	min: 3.640771e-05	loss: 34645.14453125	train_loss: 34614.12011198594	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_733
Epoch: 733	max: 0.9999752/1.0	min: 2.474385e-05	loss: 34645.0703125	train_loss: 34613.99563407733	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_734
Epoch: 734	max: 0.99997115/1.0	min: 2.886433e-05	loss: 34645.10546875	train_loss: 34613.95648399759	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_735
Epoch: 735	max: 0.99996996/1.0	min: 3.0088977e-05	loss: 34644.9140625	train_loss: 34613.96538664762	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_736
Epoch: 736	max: 0.99994123/1.0	min: 5.8799877e-05	loss: 34645.03125	train_loss: 34613.88901759724	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_737
Epoch: 737	max: 0.9999546/1.0	min: 4.545484e-05	loss: 34644.88671875	train_loss: 34613.9293391165	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_738
Epoch: 738	max: 0.99995387/1.0	min: 4.6140547e-05	loss: 34644.84375	train_loss: 34613.826798239505	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_739
Epoch: 739	max: 0.9999683/1.0	min: 3.1722586e-05	loss: 34644.7890625	train_loss: 34613.777118752325	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_740
Epoch: 740	max: 0.9999435/1.0	min: 5.6447094e-05	loss: 34644.87109375	train_loss: 34613.72664282175	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_741
Epoch: 741	max: 0.99996424/1.0	min: 3.5760928e-05	loss: 34644.67578125	train_loss: 34613.692323176016	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_742
Epoch: 742	max: 0.99996376/1.0	min: 3.61819e-05	loss: 34644.6953125	train_loss: 34613.627432878115	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_743
Epoch: 743	max: 0.99992275/1.0	min: 7.725241e-05	loss: 34644.890625	train_loss: 34613.61247464542	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_744
Epoch: 744	max: 0.99996376/1.0	min: 3.6241436e-05	loss: 34644.73828125	train_loss: 34613.627549489815	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_745
Epoch: 745	max: 0.9999745/1.0	min: 2.5483556e-05	loss: 34644.73828125	train_loss: 34613.67754494147	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_746
Epoch: 746	max: 0.9999676/1.0	min: 3.2459113e-05	loss: 34644.55078125	train_loss: 34613.53010710857	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_747
Epoch: 747	max: 0.9999677/1.0	min: 3.2301195e-05	loss: 34644.62109375	train_loss: 34613.46669792441	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_748
Epoch: 748	max: 0.99996114/1.0	min: 3.890873e-05	loss: 34644.546875	train_loss: 34613.39319190899	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_749
Epoch: 749	max: 0.9999399/1.0	min: 6.00709e-05	loss: 34644.64453125	train_loss: 34613.36033111916	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_750
Epoch: 750	max: 0.9999728/1.0	min: 2.717636e-05	loss: 34644.38671875	train_loss: 34613.34013503732	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_751
Epoch: 751	max: 0.9999521/1.0	min: 4.7911828e-05	loss: 34644.49609375	train_loss: 34613.28381690899	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_752
Epoch: 752	max: 0.9999441/1.0	min: 5.5866058e-05	loss: 34644.5	train_loss: 34613.325165675706	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_753
Epoch: 753	max: 0.99996865/1.0	min: 3.1347638e-05	loss: 34644.49609375	train_loss: 34613.23113213025	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_754
Epoch: 754	max: 0.99997663/1.0	min: 2.3409708e-05	loss: 34644.3828125	train_loss: 34613.19444541218	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_755
Epoch: 755	max: 0.9999665/1.0	min: 3.348813e-05	loss: 34644.25390625	train_loss: 34613.17068081878	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_756
Epoch: 756	max: 0.9999759/1.0	min: 2.4078234e-05	loss: 34644.34765625	train_loss: 34613.10136121175	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_757
Epoch: 757	max: 0.9999862/1.0	min: 1.3866329e-05	loss: 34644.76171875	train_loss: 34613.133161851234	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_758
Epoch: 758	max: 0.9999819/1.0	min: 1.814106e-05	loss: 34644.80859375	train_loss: 34613.27246976805	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_759
Epoch: 759	max: 0.9999745/1.0	min: 2.550485e-05	loss: 34644.4609375	train_loss: 34613.0679633307	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_760
Epoch: 760	max: 0.9999616/1.0	min: 3.8379938e-05	loss: 34644.1171875	train_loss: 34612.962263292764	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_761
Epoch: 761	max: 0.9999672/1.0	min: 3.2770262e-05	loss: 34644.15625	train_loss: 34612.91153671962	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_762
Epoch: 762	max: 0.9999528/1.0	min: 4.7214333e-05	loss: 34644.18359375	train_loss: 34612.868761999875	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_763
Epoch: 763	max: 0.9999442/1.0	min: 5.5761102e-05	loss: 34644.1953125	train_loss: 34612.87620289081	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_764
Epoch: 764	max: 0.9999511/1.0	min: 4.8889757e-05	loss: 34644.08203125	train_loss: 34612.82467987427	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_765
Epoch: 765	max: 0.99998415/1.0	min: 1.58414e-05	loss: 34644.19140625	train_loss: 34612.780470975784	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_766
Epoch: 766	max: 0.99997604/1.0	min: 2.3940123e-05	loss: 34644.11328125	train_loss: 34612.74601246051	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_767
Epoch: 767	max: 0.9999516/1.0	min: 4.8381567e-05	loss: 34644.07421875	train_loss: 34612.694236865944	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_768
Epoch: 768	max: 0.9999722/1.0	min: 2.7759088e-05	loss: 34644.06640625	train_loss: 34612.681962637806	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_769
Epoch: 769	max: 0.9999641/1.0	min: 3.5934565e-05	loss: 34644.0234375	train_loss: 34612.680340235194	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_770
Epoch: 770	max: 0.9999714/1.0	min: 2.8630428e-05	loss: 34643.80859375	train_loss: 34612.60242668463	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_771
Epoch: 771	max: 0.999962/1.0	min: 3.8059457e-05	loss: 34643.921875	train_loss: 34612.59745060696	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_772
Epoch: 772	max: 0.9999666/1.0	min: 3.3430217e-05	loss: 34643.87890625	train_loss: 34612.50801765917	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_773
Epoch: 773	max: 0.999941/1.0	min: 5.8963888e-05	loss: 34643.96875	train_loss: 34612.48057665211	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_774
Epoch: 774	max: 0.99993753/1.0	min: 6.2488616e-05	loss: 34644.015625	train_loss: 34612.55442330918	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_775
Epoch: 775	max: 0.9999691/1.0	min: 3.0908188e-05	loss: 34643.76171875	train_loss: 34612.45209001069	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_776
Epoch: 776	max: 0.9999484/1.0	min: 5.167335e-05	loss: 34643.921875	train_loss: 34612.36630541233	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_777
Epoch: 777	max: 0.99997866/1.0	min: 2.1313015e-05	loss: 34643.62109375	train_loss: 34612.362558838104	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_778
Epoch: 778	max: 0.999964/1.0	min: 3.5975874e-05	loss: 34643.7109375	train_loss: 34612.32521261071	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_779
Epoch: 779	max: 0.9999565/1.0	min: 4.3480366e-05	loss: 34643.73046875	train_loss: 34612.276155859035	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_780
Epoch: 780	max: 0.9999691/1.0	min: 3.0902e-05	loss: 34643.62109375	train_loss: 34612.2682059411	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_781
Epoch: 781	max: 0.99997973/1.0	min: 2.0250049e-05	loss: 34643.8203125	train_loss: 34612.24219427412	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_782
Epoch: 782	max: 0.99998343/1.0	min: 1.6541484e-05	loss: 34643.89453125	train_loss: 34612.247818248325	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_783
Epoch: 783	max: 0.999987/1.0	min: 1.2988064e-05	loss: 34643.55078125	train_loss: 34612.21495020051	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_784
Epoch: 784	max: 0.99996305/1.0	min: 3.6929716e-05	loss: 34643.55078125	train_loss: 34612.214397625576	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_785
Epoch: 785	max: 0.99994767/1.0	min: 5.2371746e-05	loss: 34643.61328125	train_loss: 34612.127430458786	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_786
Epoch: 786	max: 0.9999715/1.0	min: 2.852561e-05	loss: 34643.4296875	train_loss: 34612.08228189257	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_787
Epoch: 787	max: 0.99997747/1.0	min: 2.2554994e-05	loss: 34643.34765625	train_loss: 34612.01401275858	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_788
Epoch: 788	max: 0.9999802/1.0	min: 1.9836923e-05	loss: 34643.42578125	train_loss: 34612.00156385482	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_789
Epoch: 789	max: 0.9999659/1.0	min: 3.4059194e-05	loss: 34643.62890625	train_loss: 34611.96657066766	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_790
Epoch: 790	max: 0.9999722/1.0	min: 2.772271e-05	loss: 34643.35546875	train_loss: 34611.95253661898	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_791
Epoch: 791	max: 0.9999745/1.0	min: 2.554614e-05	loss: 34643.359375	train_loss: 34611.859569997985	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_792
Epoch: 792	max: 0.9999515/1.0	min: 4.8563837e-05	loss: 34643.4609375	train_loss: 34611.85584664933	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_793
Epoch: 793	max: 0.9999738/1.0	min: 2.6283897e-05	loss: 34643.2734375	train_loss: 34611.820906203546	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_794
Epoch: 794	max: 0.99996924/1.0	min: 3.076301e-05	loss: 34643.3203125	train_loss: 34611.78455432073	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_795
Epoch: 795	max: 0.9999745/1.0	min: 2.5483894e-05	loss: 34643.3203125	train_loss: 34611.753876734176	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_796
Epoch: 796	max: 0.9999721/1.0	min: 2.7921255e-05	loss: 34643.23046875	train_loss: 34611.70798833689	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_797
Epoch: 797	max: 0.99997044/1.0	min: 2.9538438e-05	loss: 34643.1484375	train_loss: 34611.77406410644	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_798
Epoch: 798	max: 0.9999672/1.0	min: 3.273278e-05	loss: 34643.21875	train_loss: 34611.65623064536	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_799
Epoch: 799	max: 0.9999454/1.0	min: 5.4540153e-05	loss: 34643.36328125	train_loss: 34611.63278491964	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_800
Epoch: 800	max: 0.9999831/1.0	min: 1.69777e-05	loss: 34643.390625	train_loss: 34611.5832641405	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_801
Epoch: 801	max: 0.9999757/1.0	min: 2.4286175e-05	loss: 34643.1015625	train_loss: 34611.58273575886	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_802
Epoch: 802	max: 0.9999565/1.0	min: 4.3476797e-05	loss: 34643.265625	train_loss: 34611.52588199089	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_803
Epoch: 803	max: 0.9999746/1.0	min: 2.5394958e-05	loss: 34643.1796875	train_loss: 34611.501624338074	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_804
Epoch: 804	max: 0.99997675/1.0	min: 2.3283468e-05	loss: 34643.078125	train_loss: 34611.45746043912	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_805
Epoch: 805	max: 0.999966/1.0	min: 3.3925186e-05	loss: 34643.19921875	train_loss: 34611.442229789885	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_806
Epoch: 806	max: 0.9999833/1.0	min: 1.667906e-05	loss: 34643.2265625	train_loss: 34611.39863346572	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_807
Epoch: 807	max: 0.9999832/1.0	min: 1.6804262e-05	loss: 34643.296875	train_loss: 34611.3755332203	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_808
Epoch: 808	max: 0.9999769/1.0	min: 2.3117793e-05	loss: 34643.140625	train_loss: 34611.37103181516	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_809
Epoch: 809	max: 0.9999708/1.0	min: 2.9225626e-05	loss: 34643.0546875	train_loss: 34611.27848325437	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_810
Epoch: 810	max: 0.9999608/1.0	min: 3.9212086e-05	loss: 34643.0859375	train_loss: 34611.24744760699	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_811
Epoch: 811	max: 0.9999739/1.0	min: 2.6080452e-05	loss: 34642.9453125	train_loss: 34611.25692605754	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_812
Epoch: 812	max: 0.9999691/1.0	min: 3.0851937e-05	loss: 34643.0234375	train_loss: 34611.221468359035	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_813
Epoch: 813	max: 0.99996793/1.0	min: 3.20425e-05	loss: 34642.9921875	train_loss: 34611.19262655998	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_814
Epoch: 814	max: 0.9999771/1.0	min: 2.2869483e-05	loss: 34642.83984375	train_loss: 34611.135347473835	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_815
Epoch: 815	max: 0.9999733/1.0	min: 2.6674204e-05	loss: 34642.87890625	train_loss: 34611.09638561795	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_816
Epoch: 816	max: 0.9999753/1.0	min: 2.4681374e-05	loss: 34642.88671875	train_loss: 34611.06839832621	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_817
Epoch: 817	max: 0.99997294/1.0	min: 2.7029653e-05	loss: 34642.9453125	train_loss: 34611.05069608959	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_818
Epoch: 818	max: 0.9999738/1.0	min: 2.627748e-05	loss: 34642.796875	train_loss: 34611.04542824074	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_819
Epoch: 819	max: 0.9999784/1.0	min: 2.1518164e-05	loss: 34642.74609375	train_loss: 34610.971580615944	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_820
Epoch: 820	max: 0.9999511/1.0	min: 4.8837424e-05	loss: 34642.9296875	train_loss: 34610.95651254568	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_821
Epoch: 821	max: 0.99997735/1.0	min: 2.2704873e-05	loss: 34642.6640625	train_loss: 34610.99740018813	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_822
Epoch: 822	max: 0.9999856/1.0	min: 1.4368561e-05	loss: 34642.95703125	train_loss: 34610.978385706985	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_823
Epoch: 823	max: 0.99998367/1.0	min: 1.6295227e-05	loss: 34642.73828125	train_loss: 34610.925398512016	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_824
Epoch: 824	max: 0.99998784/1.0	min: 1.2208035e-05	loss: 34643.234375	train_loss: 34610.83041175059	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_825
Epoch: 825	max: 0.9999758/1.0	min: 2.4149178e-05	loss: 34642.87109375	train_loss: 34610.965546323394	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_826
Epoch: 826	max: 0.9999689/1.0	min: 3.1094176e-05	loss: 34642.640625	train_loss: 34610.814691912856	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_827
Epoch: 827	max: 0.99998593/1.0	min: 1.4007169e-05	loss: 34642.8671875	train_loss: 34610.74263701149	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_828
Epoch: 828	max: 0.9999763/1.0	min: 2.3666138e-05	loss: 34642.75	train_loss: 34610.79116731698	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_829
Epoch: 829	max: 0.9999666/1.0	min: 3.3411317e-05	loss: 34642.7109375	train_loss: 34610.70315983835	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_830
Epoch: 830	max: 0.9999728/1.0	min: 2.7224247e-05	loss: 34642.64453125	train_loss: 34610.76114585269	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_831
Epoch: 831	max: 0.99996626/1.0	min: 3.36863e-05	loss: 34642.68359375	train_loss: 34610.67853444738	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_832
Epoch: 832	max: 0.9999517/1.0	min: 4.823981e-05	loss: 34642.68359375	train_loss: 34610.70091034544	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_833
Epoch: 833	max: 0.99996746/1.0	min: 3.2527874e-05	loss: 34642.5234375	train_loss: 34610.631063808374	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_834
Epoch: 834	max: 0.9999691/1.0	min: 3.089198e-05	loss: 34642.4765625	train_loss: 34610.53887524387	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_835
Epoch: 835	max: 0.9999758/1.0	min: 2.4189903e-05	loss: 34642.4453125	train_loss: 34610.50173417565	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_836
Epoch: 836	max: 0.99998/1.0	min: 1.9979656e-05	loss: 34642.5703125	train_loss: 34610.48581014648	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_837
Epoch: 837	max: 0.9999763/1.0	min: 2.3686232e-05	loss: 34642.43359375	train_loss: 34610.45102695714	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_838
Epoch: 838	max: 0.99997854/1.0	min: 2.1466822e-05	loss: 34642.34765625	train_loss: 34610.43105926003	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_839
Epoch: 839	max: 0.99997437/1.0	min: 2.55931e-05	loss: 34642.43359375	train_loss: 34610.437473871236	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_840
Epoch: 840	max: 0.9999713/1.0	min: 2.8721272e-05	loss: 34642.4140625	train_loss: 34610.40549662068	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_841
Epoch: 841	max: 0.999977/1.0	min: 2.3037137e-05	loss: 34642.3515625	train_loss: 34610.33573863108	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_842
Epoch: 842	max: 0.99998474/1.0	min: 1.5221552e-05	loss: 34642.3984375	train_loss: 34610.30753408352	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_843
Epoch: 843	max: 0.99997866/1.0	min: 2.1341308e-05	loss: 34642.37109375	train_loss: 34610.38691471572	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_844
Epoch: 844	max: 0.9999857/1.0	min: 1.4308164e-05	loss: 34642.36328125	train_loss: 34610.28572817958	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_845
Epoch: 845	max: 0.9999683/1.0	min: 3.1760424e-05	loss: 34642.31640625	train_loss: 34610.258495234884	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_846
Epoch: 846	max: 0.99996984/1.0	min: 3.0186982e-05	loss: 34642.265625	train_loss: 34610.21223280921	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_847
Epoch: 847	max: 0.99998546/1.0	min: 1.4600275e-05	loss: 34642.2109375	train_loss: 34610.189102080236	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_848
Epoch: 848	max: 0.99998224/1.0	min: 1.774437e-05	loss: 34642.34765625	train_loss: 34610.146052040756	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_849
Epoch: 849	max: 0.9999877/1.0	min: 1.2283967e-05	loss: 34642.625	train_loss: 34610.21942886396	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_850
Epoch: 850	max: 0.99997616/1.0	min: 2.3826036e-05	loss: 34642.1875	train_loss: 34610.209650900375	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_851
Epoch: 851	max: 0.9999753/1.0	min: 2.4687048e-05	loss: 34642.078125	train_loss: 34610.07014605011	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_852
Epoch: 852	max: 0.99997616/1.0	min: 2.3783357e-05	loss: 34642.16015625	train_loss: 34610.051735917565	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_853
Epoch: 853	max: 0.999979/1.0	min: 2.0992264e-05	loss: 34642.0859375	train_loss: 34610.06053163322	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_854
Epoch: 854	max: 0.9999727/1.0	min: 2.7250635e-05	loss: 34642.0703125	train_loss: 34610.06313676762	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_855
Epoch: 855	max: 0.99996984/1.0	min: 3.013877e-05	loss: 34642.1484375	train_loss: 34609.96941386411	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_856
Epoch: 856	max: 0.9999671/1.0	min: 3.29186e-05	loss: 34642.1015625	train_loss: 34609.96166862149	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_857
Epoch: 857	max: 0.9999713/1.0	min: 2.8712071e-05	loss: 34642.078125	train_loss: 34609.93186489688	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_858
Epoch: 858	max: 0.99997985/1.0	min: 2.0177225e-05	loss: 34642.109375	train_loss: 34609.88826712111	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_859
Epoch: 859	max: 0.99998224/1.0	min: 1.7742796e-05	loss: 34642.046875	train_loss: 34609.8750967732	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_860
Epoch: 860	max: 0.9999722/1.0	min: 2.775869e-05	loss: 34642.1171875	train_loss: 34609.8284037068	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_861
Epoch: 861	max: 0.99998367/1.0	min: 1.6378832e-05	loss: 34641.90625	train_loss: 34609.83693813483	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_862
Epoch: 862	max: 0.99999106/1.0	min: 8.948857e-06	loss: 34642.34375	train_loss: 34609.863617052986	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_863
Epoch: 863	max: 0.9999763/1.0	min: 2.3671215e-05	loss: 34641.9765625	train_loss: 34609.771922031774	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_864
Epoch: 864	max: 0.9999764/1.0	min: 2.3569062e-05	loss: 34641.875	train_loss: 34609.78496851	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_865
Epoch: 865	max: 0.99997604/1.0	min: 2.3927752e-05	loss: 34642.05859375	train_loss: 34609.76121698099	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_866
Epoch: 866	max: 0.9999865/1.0	min: 1.3457102e-05	loss: 34641.84375	train_loss: 34609.66416701505	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_867
Epoch: 867	max: 0.99997926/1.0	min: 2.0720929e-05	loss: 34641.875	train_loss: 34609.6891494991	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_868
Epoch: 868	max: 0.999984/1.0	min: 1.6024158e-05	loss: 34641.96484375	train_loss: 34609.61805845875	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_869
Epoch: 869	max: 0.99998033/1.0	min: 1.9636956e-05	loss: 34641.96875	train_loss: 34609.64032984176	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_870
Epoch: 870	max: 0.99998534/1.0	min: 1.4603475e-05	loss: 34641.8203125	train_loss: 34609.561247754864	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_871
Epoch: 871	max: 0.99997604/1.0	min: 2.395387e-05	loss: 34641.82421875	train_loss: 34609.54579210795	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_872
Epoch: 872	max: 0.9999733/1.0	min: 2.6663343e-05	loss: 34641.80078125	train_loss: 34609.52021543649	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_873
Epoch: 873	max: 0.9999752/1.0	min: 2.4790475e-05	loss: 34641.796875	train_loss: 34609.510154411306	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_874
Epoch: 874	max: 0.9999851/1.0	min: 1.4899412e-05	loss: 34641.73828125	train_loss: 34609.48929398148	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_875
Epoch: 875	max: 0.9999721/1.0	min: 2.7838696e-05	loss: 34641.85546875	train_loss: 34609.48194308962	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_876
Epoch: 876	max: 0.99996865/1.0	min: 3.1344945e-05	loss: 34642.18359375	train_loss: 34609.460275087484	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_877
Epoch: 877	max: 0.9999722/1.0	min: 2.776396e-05	loss: 34641.703125	train_loss: 34609.55944245092	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_878
Epoch: 878	max: 0.99997807/1.0	min: 2.1988693e-05	loss: 34641.68359375	train_loss: 34609.3940449647	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_879
Epoch: 879	max: 0.9999778/1.0	min: 2.2113474e-05	loss: 34641.6328125	train_loss: 34609.33865198811	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_880
Epoch: 880	max: 0.99997616/1.0	min: 2.3869317e-05	loss: 34641.734375	train_loss: 34609.31473158987	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_881
Epoch: 881	max: 0.99998796/1.0	min: 1.2026703e-05	loss: 34641.65625	train_loss: 34609.3031091292	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_882
Epoch: 882	max: 0.9999857/1.0	min: 1.4251335e-05	loss: 34641.6484375	train_loss: 34609.329103377	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_883
Epoch: 883	max: 0.9999654/1.0	min: 3.4598797e-05	loss: 34641.69140625	train_loss: 34609.24631632835	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_884
Epoch: 884	max: 0.9999713/1.0	min: 2.8670616e-05	loss: 34641.609375	train_loss: 34609.417013114704	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_885
Epoch: 885	max: 0.9999621/1.0	min: 3.7933758e-05	loss: 34641.8125	train_loss: 34609.29774886195	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_886
Epoch: 886	max: 0.99998045/1.0	min: 1.9543695e-05	loss: 34641.57421875	train_loss: 34609.29955271429	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_887
Epoch: 887	max: 0.9999782/1.0	min: 2.1850019e-05	loss: 34641.484375	train_loss: 34609.13758148303	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_888
Epoch: 888	max: 0.99999046/1.0	min: 9.493445e-06	loss: 34641.5078125	train_loss: 34609.11948779884	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_889
Epoch: 889	max: 0.99998796/1.0	min: 1.2086066e-05	loss: 34641.62109375	train_loss: 34609.13456748189	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_890
Epoch: 890	max: 0.999985/1.0	min: 1.5035871e-05	loss: 34641.765625	train_loss: 34609.151136988265	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_891
Epoch: 891	max: 0.999985/1.0	min: 1.4978252e-05	loss: 34641.5625	train_loss: 34609.06766139833	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_892
Epoch: 892	max: 0.999985/1.0	min: 1.499483e-05	loss: 34641.49609375	train_loss: 34609.02214896491	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_893
Epoch: 893	max: 0.9999664/1.0	min: 3.3624965e-05	loss: 34641.55078125	train_loss: 34609.01053521383	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_894
Epoch: 894	max: 0.9999776/1.0	min: 2.2389675e-05	loss: 34641.37890625	train_loss: 34608.972757861855	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_895
Epoch: 895	max: 0.9999796/1.0	min: 2.0440153e-05	loss: 34641.4296875	train_loss: 34608.984435483246	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_896
Epoch: 896	max: 0.9999877/1.0	min: 1.22535475e-05	loss: 34641.71484375	train_loss: 34608.947346672554	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_897
Epoch: 897	max: 0.9999814/1.0	min: 1.8612938e-05	loss: 34641.34375	train_loss: 34608.92961104918	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_898
Epoch: 898	max: 0.9999831/1.0	min: 1.6944781e-05	loss: 34641.5390625	train_loss: 34608.866466055835	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_899
Epoch: 899	max: 0.99998546/1.0	min: 1.4537086e-05	loss: 34641.33984375	train_loss: 34608.926198342466	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_900
Epoch: 900	max: 0.99998116/1.0	min: 1.8794284e-05	loss: 34641.4296875	train_loss: 34608.82041459572	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_901
Epoch: 901	max: 0.9999871/1.0	min: 1.2825565e-05	loss: 34641.57421875	train_loss: 34608.810395666886	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_902
Epoch: 902	max: 0.99998176/1.0	min: 1.8214734e-05	loss: 34641.359375	train_loss: 34608.817263176636	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_903
Epoch: 903	max: 0.99997854/1.0	min: 2.146981e-05	loss: 34641.328125	train_loss: 34608.773790238294	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_904
Epoch: 904	max: 0.99998736/1.0	min: 1.2635701e-05	loss: 34641.37890625	train_loss: 34608.722738991084	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_905
Epoch: 905	max: 0.999985/1.0	min: 1.5044047e-05	loss: 34641.5625	train_loss: 34608.76262309551	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_906
Epoch: 906	max: 0.9999901/1.0	min: 9.931219e-06	loss: 34641.5859375	train_loss: 34608.72599153815	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_907
Epoch: 907	max: 0.99998605/1.0	min: 1.3908788e-05	loss: 34641.1875	train_loss: 34608.76632079927	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_908
Epoch: 908	max: 0.999982/1.0	min: 1.7969633e-05	loss: 34641.1953125	train_loss: 34608.667025211354	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_909
Epoch: 909	max: 0.9999784/1.0	min: 2.1543623e-05	loss: 34641.0859375	train_loss: 34608.71637857287	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_910
Epoch: 910	max: 0.99997735/1.0	min: 2.2678754e-05	loss: 34641.1640625	train_loss: 34608.61649170073	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_911
Epoch: 911	max: 0.9999831/1.0	min: 1.6908736e-05	loss: 34641.10546875	train_loss: 34608.58929504599	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_912
Epoch: 912	max: 0.99998546/1.0	min: 1.4560186e-05	loss: 34641.078125	train_loss: 34608.54330600458	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_913
Epoch: 913	max: 0.99998677/1.0	min: 1.3203921e-05	loss: 34641.12890625	train_loss: 34608.59419564056	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_914
Epoch: 914	max: 0.99998975/1.0	min: 1.0199184e-05	loss: 34641.19140625	train_loss: 34608.61139610817	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_915
Epoch: 915	max: 0.9999821/1.0	min: 1.792498e-05	loss: 34641.06640625	train_loss: 34608.52915873127	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_916
Epoch: 916	max: 0.9999746/1.0	min: 2.5370944e-05	loss: 34641.14453125	train_loss: 34608.48515208875	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_917
Epoch: 917	max: 0.9999716/1.0	min: 2.8356473e-05	loss: 34641.08203125	train_loss: 34608.48541144092	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_918
Epoch: 918	max: 0.9999832/1.0	min: 1.6853115e-05	loss: 34641.05078125	train_loss: 34608.46523374598	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_919
Epoch: 919	max: 0.99998724/1.0	min: 1.2803495e-05	loss: 34641.2890625	train_loss: 34608.45267113372	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_920
Epoch: 920	max: 0.9999734/1.0	min: 2.6614975e-05	loss: 34641.0234375	train_loss: 34608.39021661712	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_921
Epoch: 921	max: 0.9999913/1.0	min: 8.669744e-06	loss: 34641.453125	train_loss: 34608.372941150286	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_922
Epoch: 922	max: 0.9999907/1.0	min: 9.253441e-06	loss: 34641.21484375	train_loss: 34608.42219628701	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_923
Epoch: 923	max: 0.99998593/1.0	min: 1.4028599e-05	loss: 34640.984375	train_loss: 34608.44722135126	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_924
Epoch: 924	max: 0.99998593/1.0	min: 1.4114943e-05	loss: 34640.953125	train_loss: 34608.31966024867	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_925
Epoch: 925	max: 0.9999701/1.0	min: 2.991827e-05	loss: 34641.078125	train_loss: 34608.27960292023	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_926
Epoch: 926	max: 0.99997616/1.0	min: 2.3846427e-05	loss: 34640.94140625	train_loss: 34608.38424184008	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_927
Epoch: 927	max: 0.9999844/1.0	min: 1.5587093e-05	loss: 34640.9453125	train_loss: 34608.24173024666	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_928
Epoch: 928	max: 0.9999887/1.0	min: 1.1307082e-05	loss: 34641.015625	train_loss: 34608.20753688994	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_929
Epoch: 929	max: 0.9999896/1.0	min: 1.031983e-05	loss: 34641.1015625	train_loss: 34608.20903300353	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_930
Epoch: 930	max: 0.9999807/1.0	min: 1.9284276e-05	loss: 34640.91796875	train_loss: 34608.21145039793	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_931
Epoch: 931	max: 0.9999771/1.0	min: 2.282878e-05	loss: 34640.8125	train_loss: 34608.153550511735	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_932
Epoch: 932	max: 0.99997854/1.0	min: 2.1409738e-05	loss: 34640.8046875	train_loss: 34608.14739428496	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_933
Epoch: 933	max: 0.99998546/1.0	min: 1.453782e-05	loss: 34640.79296875	train_loss: 34608.12334662997	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_934
Epoch: 934	max: 0.99997854/1.0	min: 2.1401675e-05	loss: 34640.94921875	train_loss: 34608.08213237799	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_935
Epoch: 935	max: 0.999985/1.0	min: 1.50421965e-05	loss: 34640.86328125	train_loss: 34608.06796768549	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_936
Epoch: 936	max: 0.99998724/1.0	min: 1.2796368e-05	loss: 34640.84375	train_loss: 34608.05295816301	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_937
Epoch: 937	max: 0.9999846/1.0	min: 1.5336313e-05	loss: 34640.84765625	train_loss: 34608.03052613651	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_938
Epoch: 938	max: 0.99998415/1.0	min: 1.5864563e-05	loss: 34640.74609375	train_loss: 34608.03165064102	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_939
Epoch: 939	max: 0.9999826/1.0	min: 1.7396358e-05	loss: 34640.8046875	train_loss: 34608.012658901585	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_940
Epoch: 940	max: 0.9999865/1.0	min: 1.3503693e-05	loss: 34640.78125	train_loss: 34607.96049185944	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_941
Epoch: 941	max: 0.9999857/1.0	min: 1.43001835e-05	loss: 34640.6484375	train_loss: 34607.971408359655	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_942
Epoch: 942	max: 0.99999034/1.0	min: 9.706042e-06	loss: 34640.8828125	train_loss: 34607.923800302706	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_943
Epoch: 943	max: 0.9999887/1.0	min: 1.1294299e-05	loss: 34640.69140625	train_loss: 34607.95576739208	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_944
Epoch: 944	max: 0.99998677/1.0	min: 1.32324985e-05	loss: 34640.62890625	train_loss: 34607.88649617165	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_945
Epoch: 945	max: 0.99998/1.0	min: 1.9974168e-05	loss: 34640.6796875	train_loss: 34607.888652762296	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_946
Epoch: 946	max: 0.9999807/1.0	min: 1.9328945e-05	loss: 34640.640625	train_loss: 34607.90019586895	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_947
Epoch: 947	max: 0.99998164/1.0	min: 1.8414104e-05	loss: 34640.66015625	train_loss: 34607.83980068593	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_948
Epoch: 948	max: 0.99998844/1.0	min: 1.1505904e-05	loss: 34640.51953125	train_loss: 34607.79506776059	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_949
Epoch: 949	max: 0.9999846/1.0	min: 1.5422702e-05	loss: 34640.55078125	train_loss: 34607.80757763146	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_950
Epoch: 950	max: 0.9999839/1.0	min: 1.609857e-05	loss: 34640.546875	train_loss: 34607.75946393456	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_951
Epoch: 951	max: 0.99998975/1.0	min: 1.0266078e-05	loss: 34640.64453125	train_loss: 34607.743239908494	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_952
Epoch: 952	max: 0.9999795/1.0	min: 2.0555211e-05	loss: 34640.5234375	train_loss: 34607.747087126845	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_953
Epoch: 953	max: 0.9999795/1.0	min: 2.046461e-05	loss: 34640.51171875	train_loss: 34607.71781904187	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_954
Epoch: 954	max: 0.9999875/1.0	min: 1.2528825e-05	loss: 34640.578125	train_loss: 34607.68027926808	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_955
Epoch: 955	max: 0.99999034/1.0	min: 9.607237e-06	loss: 34640.64453125	train_loss: 34607.65536597687	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_956
Epoch: 956	max: 0.9999902/1.0	min: 9.764104e-06	loss: 34640.6640625	train_loss: 34607.66969566766	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_957
Epoch: 957	max: 0.99998844/1.0	min: 1.1613521e-05	loss: 34640.37109375	train_loss: 34607.628432545214	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_958
Epoch: 958	max: 0.9999752/1.0	min: 2.47805e-05	loss: 34640.4921875	train_loss: 34607.61091417766	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_959
Epoch: 959	max: 0.9999896/1.0	min: 1.0405481e-05	loss: 34640.30859375	train_loss: 34607.60197039902	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_960
Epoch: 960	max: 0.9999908/1.0	min: 9.226408e-06	loss: 34640.41015625	train_loss: 34607.59938994178	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_961
Epoch: 961	max: 0.99998534/1.0	min: 1.462883e-05	loss: 34640.39453125	train_loss: 34607.57289827976	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_962
Epoch: 962	max: 0.9999821/1.0	min: 1.793098e-05	loss: 34640.390625	train_loss: 34607.524586681684	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_963
Epoch: 963	max: 0.9999888/1.0	min: 1.1149102e-05	loss: 34640.37109375	train_loss: 34607.50204239827	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_964
Epoch: 964	max: 0.99999213/1.0	min: 7.8455505e-06	loss: 34640.453125	train_loss: 34607.469163705406	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_965
Epoch: 965	max: 0.9999827/1.0	min: 1.7277185e-05	loss: 34640.359375	train_loss: 34607.49628100613	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_966
Epoch: 966	max: 0.99998295/1.0	min: 1.6989181e-05	loss: 34640.37890625	train_loss: 34607.433011175366	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_967
Epoch: 967	max: 0.99998844/1.0	min: 1.152775e-05	loss: 34640.1953125	train_loss: 34607.44846101588	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_968
Epoch: 968	max: 0.9999851/1.0	min: 1.4955772e-05	loss: 34640.31640625	train_loss: 34607.41693908321	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_969
Epoch: 969	max: 0.9999796/1.0	min: 2.038199e-05	loss: 34640.328125	train_loss: 34607.37675836895	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_970
Epoch: 970	max: 0.9999902/1.0	min: 9.734946e-06	loss: 34640.2578125	train_loss: 34607.37139181144	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_971
Epoch: 971	max: 0.99998343/1.0	min: 1.6513115e-05	loss: 34640.28125	train_loss: 34607.348168664066	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_972
Epoch: 972	max: 0.99998593/1.0	min: 1.4016684e-05	loss: 34640.16015625	train_loss: 34607.33717571302	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_973
Epoch: 973	max: 0.9999908/1.0	min: 9.142829e-06	loss: 34640.69921875	train_loss: 34607.34653803574	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_974
Epoch: 974	max: 0.9999896/1.0	min: 1.0338891e-05	loss: 34640.203125	train_loss: 34607.3469551282	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_975
Epoch: 975	max: 0.9999846/1.0	min: 1.5357535e-05	loss: 34640.2265625	train_loss: 34607.25446850226	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_976
Epoch: 976	max: 0.9999906/1.0	min: 9.417573e-06	loss: 34640.34765625	train_loss: 34607.3017339821	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_977
Epoch: 977	max: 0.9999865/1.0	min: 1.3507543e-05	loss: 34640.2578125	train_loss: 34607.30873939366	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_978
Epoch: 978	max: 0.99999225/1.0	min: 7.729797e-06	loss: 34640.265625	train_loss: 34607.18927965905	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_979
Epoch: 979	max: 0.9999931/1.0	min: 6.9352723e-06	loss: 34640.38671875	train_loss: 34607.19391074028	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_980
Epoch: 980	max: 0.9999782/1.0	min: 2.1795326e-05	loss: 34640.47265625	train_loss: 34607.182917789236	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_981
Epoch: 981	max: 0.9999882/1.0	min: 1.1854643e-05	loss: 34640.05078125	train_loss: 34607.14962684256	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_982
Epoch: 982	max: 0.99998987/1.0	min: 1.0133739e-05	loss: 34640.125	train_loss: 34607.13716197123	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_983
Epoch: 983	max: 0.99998677/1.0	min: 1.3224312e-05	loss: 34640.22265625	train_loss: 34607.11797523381	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_984
Epoch: 984	max: 0.9999734/1.0	min: 2.661693e-05	loss: 34640.3984375	train_loss: 34607.13737825932	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_985
Epoch: 985	max: 0.999966/1.0	min: 3.4005e-05	loss: 34640.34765625	train_loss: 34607.0864692687	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_986
Epoch: 986	max: 0.9999895/1.0	min: 1.0477134e-05	loss: 34640.1484375	train_loss: 34607.053762832125	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_987
Epoch: 987	max: 0.99999285/1.0	min: 7.119846e-06	loss: 34640.1484375	train_loss: 34607.01272906215	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_988
Epoch: 988	max: 0.99999046/1.0	min: 9.539331e-06	loss: 34640.01171875	train_loss: 34606.96475181547	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_989
Epoch: 989	max: 0.99999285/1.0	min: 7.1991713e-06	loss: 34640.16796875	train_loss: 34606.9567752849	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_990
Epoch: 990	max: 0.999984/1.0	min: 1.5926335e-05	loss: 34639.98828125	train_loss: 34606.93684291001	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_991
Epoch: 991	max: 0.9999914/1.0	min: 8.617796e-06	loss: 34639.94921875	train_loss: 34606.93543195683	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_992
Epoch: 992	max: 0.99998736/1.0	min: 1.2579167e-05	loss: 34640.10546875	train_loss: 34606.89499866453	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_993
Epoch: 993	max: 0.99998677/1.0	min: 1.3224816e-05	loss: 34640.01953125	train_loss: 34606.872653733895	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_994
Epoch: 994	max: 0.999992/1.0	min: 7.974589e-06	loss: 34640.10546875	train_loss: 34606.87377727069	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_995
Epoch: 995	max: 0.999992/1.0	min: 7.97795e-06	loss: 34640.30078125	train_loss: 34606.88388861792	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_996
Epoch: 996	max: 0.9999895/1.0	min: 1.0534443e-05	loss: 34639.99609375	train_loss: 34606.81871671002	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_997
Epoch: 997	max: 0.9999901/1.0	min: 9.941606e-06	loss: 34640.12109375	train_loss: 34606.78937798061	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_998
Epoch: 998	max: 0.99999166/1.0	min: 8.2985225e-06	loss: 34639.89453125	train_loss: 34606.83656410644	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_999
Epoch: 999	max: 0.99998856/1.0	min: 1.1425023e-05	loss: 34639.87890625	train_loss: 34606.75822572154	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1000
Epoch: 1000	max: 0.999979/1.0	min: 2.0937003e-05	loss: 34640.05078125	train_loss: 34606.74224749938	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1001
Epoch: 1001	max: 0.99998915/1.0	min: 1.0887223e-05	loss: 34639.8828125	train_loss: 34606.79709225582	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1002
Epoch: 1002	max: 0.9999906/1.0	min: 9.399288e-06	loss: 34639.9609375	train_loss: 34606.72262286325	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1003
Epoch: 1003	max: 0.9999852/1.0	min: 1.4724258e-05	loss: 34639.87890625	train_loss: 34606.69826940496	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1004
Epoch: 1004	max: 0.99999094/1.0	min: 9.104007e-06	loss: 34639.765625	train_loss: 34606.64870749721	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1005
Epoch: 1005	max: 0.99998796/1.0	min: 1.205718e-05	loss: 34639.765625	train_loss: 34606.63257250248	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1006
Epoch: 1006	max: 0.9999908/1.0	min: 9.129046e-06	loss: 34639.74609375	train_loss: 34606.61545913074	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1007
Epoch: 1007	max: 0.9999769/1.0	min: 2.3069078e-05	loss: 34639.81640625	train_loss: 34606.64132660566	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1008
Epoch: 1008	max: 0.99999356/1.0	min: 6.455442e-06	loss: 34639.79296875	train_loss: 34606.622157287406	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1009
Epoch: 1009	max: 0.9999888/1.0	min: 1.1199144e-05	loss: 34639.69140625	train_loss: 34606.569356864704	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1010
Epoch: 1010	max: 0.9999856/1.0	min: 1.4429778e-05	loss: 34639.74609375	train_loss: 34606.61008483138	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1011
Epoch: 1011	max: 0.9999914/1.0	min: 8.578445e-06	loss: 34639.67578125	train_loss: 34606.558293269234	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1012
Epoch: 1012	max: 0.99999356/1.0	min: 6.4779642e-06	loss: 34639.796875	train_loss: 34606.54552307847	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1013
Epoch: 1013	max: 0.9999826/1.0	min: 1.7453223e-05	loss: 34639.734375	train_loss: 34606.50201675337	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1014
Epoch: 1014	max: 0.99998283/1.0	min: 1.7114508e-05	loss: 34639.8359375	train_loss: 34606.500756766385	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1015
Epoch: 1015	max: 0.9999869/1.0	min: 1.3070059e-05	loss: 34639.6640625	train_loss: 34606.460592503565	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1016
Epoch: 1016	max: 0.99997914/1.0	min: 2.0815598e-05	loss: 34639.7109375	train_loss: 34606.51362324647	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1017
Epoch: 1017	max: 0.9999926/1.0	min: 7.3742945e-06	loss: 34639.69921875	train_loss: 34606.520444788956	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1018
Epoch: 1018	max: 0.99999475/1.0	min: 5.2739924e-06	loss: 34640.16796875	train_loss: 34606.45570981203	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1019
Epoch: 1019	max: 0.99999344/1.0	min: 6.574495e-06	loss: 34639.6484375	train_loss: 34606.43011523752	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1020
Epoch: 1020	max: 0.9999924/1.0	min: 7.59031e-06	loss: 34639.51953125	train_loss: 34606.42367546529	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1021
Epoch: 1021	max: 0.99999285/1.0	min: 7.1746e-06	loss: 34639.5546875	train_loss: 34606.41399572649	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1022
Epoch: 1022	max: 0.9999918/1.0	min: 8.1835515e-06	loss: 34639.69921875	train_loss: 34606.342971943515	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1023
Epoch: 1023	max: 0.99998605/1.0	min: 1.3977747e-05	loss: 34639.58984375	train_loss: 34606.336365721385	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1024
Epoch: 1024	max: 0.9999869/1.0	min: 1.30595545e-05	loss: 34639.50390625	train_loss: 34606.36288060898	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1025
Epoch: 1025	max: 0.9999865/1.0	min: 1.3452021e-05	loss: 34639.625	train_loss: 34606.4113194638	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1026
Epoch: 1026	max: 0.9999862/1.0	min: 1.3785002e-05	loss: 34639.53515625	train_loss: 34606.30138995339	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1027
Epoch: 1027	max: 0.99999106/1.0	min: 8.911265e-06	loss: 34639.67578125	train_loss: 34606.27052994937	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1028
Epoch: 1028	max: 0.9999932/1.0	min: 6.790245e-06	loss: 34639.80078125	train_loss: 34606.292561818715	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1029
Epoch: 1029	max: 0.99999046/1.0	min: 9.538203e-06	loss: 34639.453125	train_loss: 34606.236161433175	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1030
Epoch: 1030	max: 0.9999883/1.0	min: 1.171526e-05	loss: 34639.484375	train_loss: 34606.2255115431	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1031
Epoch: 1031	max: 0.99999034/1.0	min: 9.656877e-06	loss: 34639.484375	train_loss: 34606.19359090487	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1032
Epoch: 1032	max: 0.99999595/1.0	min: 4.107175e-06	loss: 34640.03125	train_loss: 34606.27241896213	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1033
Epoch: 1033	max: 0.9999951/1.0	min: 4.930684e-06	loss: 34639.4375	train_loss: 34606.25911119627	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1034
Epoch: 1034	max: 0.9999865/1.0	min: 1.3477343e-05	loss: 34639.44921875	train_loss: 34606.16374943872	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1035
Epoch: 1035	max: 0.9999844/1.0	min: 1.5611224e-05	loss: 34639.4453125	train_loss: 34606.20033406107	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1036
Epoch: 1036	max: 0.9999757/1.0	min: 2.4319528e-05	loss: 34639.57421875	train_loss: 34606.14543172457	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1037
Epoch: 1037	max: 0.9999895/1.0	min: 1.0500082e-05	loss: 34639.38671875	train_loss: 34606.1809915188	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1038
Epoch: 1038	max: 0.9999851/1.0	min: 1.4850385e-05	loss: 34639.41796875	train_loss: 34606.13437393549	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1039
Epoch: 1039	max: 0.9999871/1.0	min: 1.2858473e-05	loss: 34639.4765625	train_loss: 34606.10227958937	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1040
Epoch: 1040	max: 0.9999877/1.0	min: 1.2270502e-05	loss: 34639.44921875	train_loss: 34606.03053629769	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1041
Epoch: 1041	max: 0.99998164/1.0	min: 1.8361603e-05	loss: 34639.5546875	train_loss: 34606.036281722256	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1042
Epoch: 1042	max: 0.99999154/1.0	min: 8.447077e-06	loss: 34639.47265625	train_loss: 34606.068429293635	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1043
Epoch: 1043	max: 0.9999788/1.0	min: 2.1170546e-05	loss: 34639.58984375	train_loss: 34605.986913360895	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1044
Epoch: 1044	max: 0.9999902/1.0	min: 9.792499e-06	loss: 34639.3359375	train_loss: 34605.98465612613	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1045
Epoch: 1045	max: 0.99999094/1.0	min: 9.071638e-06	loss: 34639.30078125	train_loss: 34605.95237307228	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1046
Epoch: 1046	max: 0.9999869/1.0	min: 1.3157313e-05	loss: 34639.484375	train_loss: 34605.95699931485	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1047
Epoch: 1047	max: 0.9999949/1.0	min: 5.1498173e-06	loss: 34639.4140625	train_loss: 34605.94297784668	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1048
Epoch: 1048	max: 0.9999914/1.0	min: 8.529556e-06	loss: 34639.36328125	train_loss: 34605.96239925911	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1049
Epoch: 1049	max: 0.99998605/1.0	min: 1.3906639e-05	loss: 34639.40625	train_loss: 34605.90815352874	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1050
Epoch: 1050	max: 0.9999869/1.0	min: 1.3088619e-05	loss: 34639.23828125	train_loss: 34605.92725413802	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1051
Epoch: 1051	max: 0.99998486/1.0	min: 1.5137851e-05	loss: 34639.36328125	train_loss: 34605.907025637156	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1052
Epoch: 1052	max: 0.9999933/1.0	min: 6.713031e-06	loss: 34639.359375	train_loss: 34605.854698435374	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1053
Epoch: 1053	max: 0.99999225/1.0	min: 7.7466675e-06	loss: 34639.24609375	train_loss: 34605.83849086074	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1054
Epoch: 1054	max: 0.9999924/1.0	min: 7.660186e-06	loss: 34639.14453125	train_loss: 34605.814618849094	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1055
Epoch: 1055	max: 0.9999887/1.0	min: 1.136078e-05	loss: 34639.2578125	train_loss: 34605.825643251424	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1056
Epoch: 1056	max: 0.9999914/1.0	min: 8.578281e-06	loss: 34639.25390625	train_loss: 34605.779064861264	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1057
Epoch: 1057	max: 0.9999877/1.0	min: 1.229285e-05	loss: 34639.23046875	train_loss: 34605.79309503902	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1058
Epoch: 1058	max: 0.99999356/1.0	min: 6.4466262e-06	loss: 34639.171875	train_loss: 34605.841265832096	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1059
Epoch: 1059	max: 0.99998987/1.0	min: 1.0164384e-05	loss: 34639.26171875	train_loss: 34605.84912913802	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1060
Epoch: 1060	max: 0.9999906/1.0	min: 9.446123e-06	loss: 34639.21875	train_loss: 34605.758188463864	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1061
Epoch: 1061	max: 0.99998724/1.0	min: 1.2810898e-05	loss: 34639.12109375	train_loss: 34605.739607042764	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1062
Epoch: 1062	max: 0.9999858/1.0	min: 1.4174226e-05	loss: 34639.109375	train_loss: 34605.72609363387	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1063
Epoch: 1063	max: 0.99998474/1.0	min: 1.5205303e-05	loss: 34639.19140625	train_loss: 34605.71721324167	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1064
Epoch: 1064	max: 0.9999924/1.0	min: 7.67026e-06	loss: 34639.01171875	train_loss: 34605.721486262075	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1065
Epoch: 1065	max: 0.9999871/1.0	min: 1.2883945e-05	loss: 34639.125	train_loss: 34605.68222876409	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1066
Epoch: 1066	max: 0.9999944/1.0	min: 5.5928176e-06	loss: 34639.19921875	train_loss: 34605.6364598817	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1067
Epoch: 1067	max: 0.99998856/1.0	min: 1.1395677e-05	loss: 34639.12890625	train_loss: 34605.67053662672	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1068
Epoch: 1068	max: 0.9999896/1.0	min: 1.0360961e-05	loss: 34639.265625	train_loss: 34605.621910515765	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1069
Epoch: 1069	max: 0.99999523/1.0	min: 4.7193716e-06	loss: 34639.13671875	train_loss: 34605.60357635018	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1070
Epoch: 1070	max: 0.9999819/1.0	min: 1.8095825e-05	loss: 34639.14453125	train_loss: 34605.64460431376	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1071
Epoch: 1071	max: 0.999987/1.0	min: 1.304503e-05	loss: 34638.9296875	train_loss: 34605.6960320087	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1072
Epoch: 1072	max: 0.9999894/1.0	min: 1.0581202e-05	loss: 34638.984375	train_loss: 34605.60732292441	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1073
Epoch: 1073	max: 0.9999888/1.0	min: 1.1157738e-05	loss: 34639.05078125	train_loss: 34605.524913291214	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1074
Epoch: 1074	max: 0.999977/1.0	min: 2.3013661e-05	loss: 34639.19921875	train_loss: 34605.512477935714	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1075
Epoch: 1075	max: 0.9999939/1.0	min: 6.034974e-06	loss: 34638.94921875	train_loss: 34605.529756789605	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1076
Epoch: 1076	max: 0.9999888/1.0	min: 1.1201013e-05	loss: 34638.9609375	train_loss: 34605.50658541589	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1077
Epoch: 1077	max: 0.99998474/1.0	min: 1.5220826e-05	loss: 34639.0703125	train_loss: 34605.49224217686	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1078
Epoch: 1078	max: 0.99999344/1.0	min: 6.598137e-06	loss: 34638.8203125	train_loss: 34605.50164611204	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1079
Epoch: 1079	max: 0.9999925/1.0	min: 7.55656e-06	loss: 34638.95703125	train_loss: 34605.44992954911	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1080
Epoch: 1080	max: 0.99999344/1.0	min: 6.613017e-06	loss: 34639.171875	train_loss: 34605.43542082791	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1081
Epoch: 1081	max: 0.99998975/1.0	min: 1.0218568e-05	loss: 34639.01953125	train_loss: 34605.4351522823	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1082
Epoch: 1082	max: 0.9999956/1.0	min: 4.3801933e-06	loss: 34638.76953125	train_loss: 34605.4242682011	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1083
Epoch: 1083	max: 0.9999918/1.0	min: 8.183934e-06	loss: 34638.9375	train_loss: 34605.39621752292	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1084
Epoch: 1084	max: 0.9999938/1.0	min: 6.155998e-06	loss: 34639.03125	train_loss: 34605.41196590874	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1085
Epoch: 1085	max: 0.9999944/1.0	min: 5.54585e-06	loss: 34638.984375	train_loss: 34605.38517812074	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1086
Epoch: 1086	max: 0.9999894/1.0	min: 1.0638613e-05	loss: 34638.82421875	train_loss: 34605.39453028227	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1087
Epoch: 1087	max: 0.99998605/1.0	min: 1.394018e-05	loss: 34638.84765625	train_loss: 34605.35714679719	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1088
Epoch: 1088	max: 0.99997365/1.0	min: 2.6366944e-05	loss: 34639.25	train_loss: 34605.34883881844	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1089
Epoch: 1089	max: 0.9999801/1.0	min: 1.9932326e-05	loss: 34639.015625	train_loss: 34605.5765466292	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1090
Epoch: 1090	max: 0.9999925/1.0	min: 7.5516605e-06	loss: 34638.7421875	train_loss: 34605.3169878569	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1091
Epoch: 1091	max: 0.99998677/1.0	min: 1.3212589e-05	loss: 34638.8828125	train_loss: 34605.30002545135	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1092
Epoch: 1092	max: 0.9999919/1.0	min: 8.065857e-06	loss: 34638.94921875	train_loss: 34605.35406795801	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1093
Epoch: 1093	max: 0.99998176/1.0	min: 1.8280167e-05	loss: 34638.9609375	train_loss: 34605.39613139477	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1094
Epoch: 1094	max: 0.99998605/1.0	min: 1.399195e-05	loss: 34638.87890625	train_loss: 34605.273429274275	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1095
Epoch: 1095	max: 0.999984/1.0	min: 1.5996202e-05	loss: 34638.91015625	train_loss: 34605.25498672272	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1096
Epoch: 1096	max: 0.9999901/1.0	min: 9.83496e-06	loss: 34638.75	train_loss: 34605.230446008296	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1097
Epoch: 1097	max: 0.99999356/1.0	min: 6.432888e-06	loss: 34638.8125	train_loss: 34605.21332537858	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1098
Epoch: 1098	max: 0.99999094/1.0	min: 9.09572e-06	loss: 34638.80078125	train_loss: 34605.22274818453	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1099
Epoch: 1099	max: 0.99998915/1.0	min: 1.0896925e-05	loss: 34638.6015625	train_loss: 34605.195159598356	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1100
Epoch: 1100	max: 0.9999931/1.0	min: 6.8785193e-06	loss: 34638.828125	train_loss: 34605.14837169423	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1101
Epoch: 1101	max: 0.9999918/1.0	min: 8.210075e-06	loss: 34638.671875	train_loss: 34605.13545392435	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1102
Epoch: 1102	max: 0.9999914/1.0	min: 8.560612e-06	loss: 34639.15625	train_loss: 34605.13882695405	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1103
Epoch: 1103	max: 0.9999918/1.0	min: 8.173108e-06	loss: 34638.75390625	train_loss: 34605.14721912548	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1104
Epoch: 1104	max: 0.99998915/1.0	min: 1.0797337e-05	loss: 34638.76953125	train_loss: 34605.12671578874	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1105
Epoch: 1105	max: 0.9999949/1.0	min: 5.0846197e-06	loss: 34638.953125	train_loss: 34605.09336000402	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1106
Epoch: 1106	max: 0.999995/1.0	min: 5.008531e-06	loss: 34638.75	train_loss: 34605.10913113155	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1107
Epoch: 1107	max: 0.99999297/1.0	min: 7.0768747e-06	loss: 34639.0625	train_loss: 34605.100527026814	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1108
Epoch: 1108	max: 0.9999938/1.0	min: 6.1868564e-06	loss: 34638.68359375	train_loss: 34605.07535583503	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1109
Epoch: 1109	max: 0.9999908/1.0	min: 9.138977e-06	loss: 34638.65625	train_loss: 34605.04051748498	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1110
Epoch: 1110	max: 0.9999856/1.0	min: 1.4459755e-05	loss: 34638.68359375	train_loss: 34605.074281652574	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1111
Epoch: 1111	max: 0.9999883/1.0	min: 1.16552155e-05	loss: 34638.62890625	train_loss: 34605.09476998947	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1112
Epoch: 1112	max: 0.9999932/1.0	min: 6.8505146e-06	loss: 34638.58984375	train_loss: 34605.03372642605	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1113
Epoch: 1113	max: 0.9999902/1.0	min: 9.774212e-06	loss: 34638.6484375	train_loss: 34604.99764502431	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1114
Epoch: 1114	max: 0.99999046/1.0	min: 9.484812e-06	loss: 34638.56640625	train_loss: 34604.961411204786	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1115
Epoch: 1115	max: 0.9999924/1.0	min: 7.655797e-06	loss: 34638.49609375	train_loss: 34604.96998530983	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1116
Epoch: 1116	max: 0.9999919/1.0	min: 8.125934e-06	loss: 34638.953125	train_loss: 34605.007429762016	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1117
Epoch: 1117	max: 0.99999404/1.0	min: 5.963539e-06	loss: 34638.55859375	train_loss: 34604.994878278674	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1118
Epoch: 1118	max: 0.9999852/1.0	min: 1.4782874e-05	loss: 34638.4609375	train_loss: 34604.9298254018	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1119
Epoch: 1119	max: 0.99998236/1.0	min: 1.7598444e-05	loss: 34638.65625	train_loss: 34604.9594515476	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1120
Epoch: 1120	max: 0.99999297/1.0	min: 6.9743173e-06	loss: 34638.5390625	train_loss: 34604.935494859405	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1121
Epoch: 1121	max: 0.99999046/1.0	min: 9.577854e-06	loss: 34638.51171875	train_loss: 34604.887687933544	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1122
Epoch: 1122	max: 0.99999034/1.0	min: 9.684841e-06	loss: 34638.421875	train_loss: 34604.874740647836	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1123
Epoch: 1123	max: 0.99999046/1.0	min: 9.595444e-06	loss: 34638.734375	train_loss: 34604.84976106698	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1124
Epoch: 1124	max: 0.9999945/1.0	min: 5.499041e-06	loss: 34638.59375	train_loss: 34604.847708991394	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1125
Epoch: 1125	max: 0.99999225/1.0	min: 7.764167e-06	loss: 34638.48046875	train_loss: 34604.83225915088	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1126
Epoch: 1126	max: 0.99998057/1.0	min: 1.9400559e-05	loss: 34638.61328125	train_loss: 34604.862457710115	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1127
Epoch: 1127	max: 0.9999943/1.0	min: 5.69908e-06	loss: 34638.35546875	train_loss: 34604.805668780195	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1128
Epoch: 1128	max: 0.99999034/1.0	min: 9.64482e-06	loss: 34638.57421875	train_loss: 34604.790091682924	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1129
Epoch: 1129	max: 0.9999943/1.0	min: 5.7453235e-06	loss: 34638.41796875	train_loss: 34604.79263826954	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1130
Epoch: 1130	max: 0.9999865/1.0	min: 1.34424545e-05	loss: 34638.48828125	train_loss: 34604.774368941995	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1131
Epoch: 1131	max: 0.9999906/1.0	min: 9.446916e-06	loss: 34638.4765625	train_loss: 34604.78029000991	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1132
Epoch: 1132	max: 0.9999964/1.0	min: 3.6089255e-06	loss: 34638.74609375	train_loss: 34604.74653116484	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1133
Epoch: 1133	max: 0.9999931/1.0	min: 6.9733137e-06	loss: 34638.40625	train_loss: 34604.73943768968	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1134
Epoch: 1134	max: 0.99999285/1.0	min: 7.1358477e-06	loss: 34638.42578125	train_loss: 34604.714230207945	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1135
Epoch: 1135	max: 0.9999901/1.0	min: 9.936515e-06	loss: 34638.42578125	train_loss: 34604.68928788477	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1136
Epoch: 1136	max: 0.9999912/1.0	min: 8.876288e-06	loss: 34638.48828125	train_loss: 34604.68693048975	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1137
Epoch: 1137	max: 0.9999958/1.0	min: 4.1610615e-06	loss: 34638.31640625	train_loss: 34604.679988948505	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1138
Epoch: 1138	max: 0.99998975/1.0	min: 1.0299843e-05	loss: 34638.421875	train_loss: 34604.656397095256	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1139
Epoch: 1139	max: 0.9999937/1.0	min: 6.3003e-06	loss: 34638.34375	train_loss: 34604.640951125664	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1140
Epoch: 1140	max: 0.99999535/1.0	min: 4.6917776e-06	loss: 34638.3359375	train_loss: 34604.63824147622	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1141
Epoch: 1141	max: 0.9999939/1.0	min: 6.077529e-06	loss: 34638.28515625	train_loss: 34604.632967337115	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1142
Epoch: 1142	max: 0.9999912/1.0	min: 8.858132e-06	loss: 34638.484375	train_loss: 34604.655054367184	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1143
Epoch: 1143	max: 0.99998975/1.0	min: 1.02532695e-05	loss: 34638.37890625	train_loss: 34604.58246769711	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1144
Epoch: 1144	max: 0.99998677/1.0	min: 1.3241361e-05	loss: 34638.34375	train_loss: 34604.67141097253	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1145
Epoch: 1145	max: 0.99998677/1.0	min: 1.319053e-05	loss: 34638.421875	train_loss: 34604.56698592143	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1146
Epoch: 1146	max: 0.9999902/1.0	min: 9.737963e-06	loss: 34638.5	train_loss: 34604.5744747151	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1147
Epoch: 1147	max: 0.9999819/1.0	min: 1.809346e-05	loss: 34638.390625	train_loss: 34604.63563053543	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1148
Epoch: 1148	max: 0.999987/1.0	min: 1.2944117e-05	loss: 34638.2734375	train_loss: 34604.557342472595	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1149
Epoch: 1149	max: 0.9999927/1.0	min: 7.2395706e-06	loss: 34638.19140625	train_loss: 34604.507339762946	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1150
Epoch: 1150	max: 0.9999713/1.0	min: 2.8737546e-05	loss: 34638.55078125	train_loss: 34604.576625015485	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1151
Epoch: 1151	max: 0.9999908/1.0	min: 9.122779e-06	loss: 34638.28125	train_loss: 34604.59635658599	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1152
Epoch: 1152	max: 0.99999404/1.0	min: 5.964398e-06	loss: 34638.11328125	train_loss: 34604.46065492227	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1153
Epoch: 1153	max: 0.9999932/1.0	min: 6.8531804e-06	loss: 34638.62109375	train_loss: 34604.48634433451	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1154
Epoch: 1154	max: 0.99999535/1.0	min: 4.6293358e-06	loss: 34638.2265625	train_loss: 34604.55543700839	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1155
Epoch: 1155	max: 0.99999094/1.0	min: 9.081731e-06	loss: 34638.265625	train_loss: 34604.44122770346	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1156
Epoch: 1156	max: 0.99999154/1.0	min: 8.4564335e-06	loss: 34638.15625	train_loss: 34604.431028776475	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1157
Epoch: 1157	max: 0.99998116/1.0	min: 1.8831206e-05	loss: 34638.37109375	train_loss: 34604.45009599901	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1158
Epoch: 1158	max: 0.9999919/1.0	min: 8.143069e-06	loss: 34638.25390625	train_loss: 34604.44750538059	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1159
Epoch: 1159	max: 0.9999918/1.0	min: 8.186822e-06	loss: 34638.12890625	train_loss: 34604.40307051669	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1160
Epoch: 1160	max: 0.99998343/1.0	min: 1.6570142e-05	loss: 34638.35546875	train_loss: 34604.40925771089	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1161
Epoch: 1161	max: 0.99999523/1.0	min: 4.7529575e-06	loss: 34638.31640625	train_loss: 34604.403229708594	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1162
Epoch: 1162	max: 0.99999213/1.0	min: 7.907295e-06	loss: 34638.21875	train_loss: 34604.381315902545	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1163
Epoch: 1163	max: 0.9999938/1.0	min: 6.2040317e-06	loss: 34638.0546875	train_loss: 34604.345844171934	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1164
Epoch: 1164	max: 0.999995/1.0	min: 5.029141e-06	loss: 34638.17578125	train_loss: 34604.31666947309	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1165
Epoch: 1165	max: 0.9999932/1.0	min: 6.78917e-06	loss: 34638.12890625	train_loss: 34604.3207291086	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1166
Epoch: 1166	max: 0.99999464/1.0	min: 5.389405e-06	loss: 34638.2109375	train_loss: 34604.299359167904	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1167
Epoch: 1167	max: 0.9999958/1.0	min: 4.1275302e-06	loss: 34638.26171875	train_loss: 34604.30299784002	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1168
Epoch: 1168	max: 0.99999356/1.0	min: 6.456612e-06	loss: 34638.0234375	train_loss: 34604.29840111328	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1169
Epoch: 1169	max: 0.9999877/1.0	min: 1.2276871e-05	loss: 34638.37109375	train_loss: 34604.28448561176	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1170
Epoch: 1170	max: 0.99999464/1.0	min: 5.384689e-06	loss: 34638.0390625	train_loss: 34604.28061323238	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1171
Epoch: 1171	max: 0.9999944/1.0	min: 5.655981e-06	loss: 34638.30078125	train_loss: 34604.23950736637	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1172
Epoch: 1172	max: 0.9999901/1.0	min: 9.921942e-06	loss: 34638.1015625	train_loss: 34604.31659979639	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1173
Epoch: 1173	max: 0.99999404/1.0	min: 5.948158e-06	loss: 34638.05859375	train_loss: 34604.24147089449	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1174
Epoch: 1174	max: 0.9999931/1.0	min: 6.857494e-06	loss: 34638.21484375	train_loss: 34604.25425269804	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1175
Epoch: 1175	max: 0.9999925/1.0	min: 7.468153e-06	loss: 34638.00390625	train_loss: 34604.21258167658	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1176
Epoch: 1176	max: 0.9999876/1.0	min: 1.2377323e-05	loss: 34638.0703125	train_loss: 34604.20016712731	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1177
Epoch: 1177	max: 0.99998856/1.0	min: 1.1459529e-05	loss: 34638.12890625	train_loss: 34604.24135960532	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1178
Epoch: 1178	max: 0.99999046/1.0	min: 9.58383e-06	loss: 34637.9453125	train_loss: 34604.14474511876	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1179
Epoch: 1179	max: 0.99999475/1.0	min: 5.28119e-06	loss: 34638.1015625	train_loss: 34604.15246907129	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1180
Epoch: 1180	max: 0.9999932/1.0	min: 6.787092e-06	loss: 34638.03125	train_loss: 34604.150200707605	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1181
Epoch: 1181	max: 0.9999938/1.0	min: 6.2422105e-06	loss: 34637.86328125	train_loss: 34604.13371007138	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1182
Epoch: 1182	max: 0.9999858/1.0	min: 1.4151656e-05	loss: 34638.28515625	train_loss: 34604.18416713118	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1183
Epoch: 1183	max: 0.99999297/1.0	min: 6.9766725e-06	loss: 34637.87109375	train_loss: 34604.08904924207	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1184
Epoch: 1184	max: 0.9999876/1.0	min: 1.2416209e-05	loss: 34638.28125	train_loss: 34604.07859386613	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1185
Epoch: 1185	max: 0.9999968/1.0	min: 3.2699909e-06	loss: 34637.9765625	train_loss: 34604.08655200979	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1186
Epoch: 1186	max: 0.9999906/1.0	min: 9.409234e-06	loss: 34637.875	train_loss: 34604.04363213025	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1187
Epoch: 1187	max: 0.9999951/1.0	min: 4.8343936e-06	loss: 34637.88671875	train_loss: 34604.04132021863	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1188
Epoch: 1188	max: 0.99999535/1.0	min: 4.616515e-06	loss: 34637.890625	train_loss: 34604.07976191858	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1189
Epoch: 1189	max: 0.99999404/1.0	min: 5.927998e-06	loss: 34638.3203125	train_loss: 34604.19220366112	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1190
Epoch: 1190	max: 0.99999714/1.0	min: 2.8941915e-06	loss: 34637.87109375	train_loss: 34604.16602699585	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1191
Epoch: 1191	max: 0.999995/1.0	min: 4.97219e-06	loss: 34637.7890625	train_loss: 34604.045441788985	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1192
Epoch: 1192	max: 0.9999933/1.0	min: 6.6364046e-06	loss: 34637.8203125	train_loss: 34604.01496210362	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1193
Epoch: 1193	max: 0.99999547/1.0	min: 4.562183e-06	loss: 34637.90234375	train_loss: 34603.98044842763	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1194
Epoch: 1194	max: 0.99999535/1.0	min: 4.670969e-06	loss: 34637.953125	train_loss: 34604.02498006472	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1195
Epoch: 1195	max: 0.99999356/1.0	min: 6.4327282e-06	loss: 34637.76171875	train_loss: 34603.938461441685	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1196
Epoch: 1196	max: 0.99999225/1.0	min: 7.7658115e-06	loss: 34637.77734375	train_loss: 34603.913723309954	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1197
Epoch: 1197	max: 0.9999912/1.0	min: 8.766696e-06	loss: 34637.859375	train_loss: 34603.896034621575	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1198
Epoch: 1198	max: 0.99999213/1.0	min: 7.832811e-06	loss: 34637.875	train_loss: 34603.906000809024	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1199
Epoch: 1199	max: 0.9999924/1.0	min: 7.5861126e-06	loss: 34637.6953125	train_loss: 34603.95436321302	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1200
Epoch: 1200	max: 0.9999832/1.0	min: 1.6820923e-05	loss: 34637.875	train_loss: 34603.91753230289	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1201
Epoch: 1201	max: 0.9999889/1.0	min: 1.112357e-05	loss: 34637.68359375	train_loss: 34603.85799791744	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1202
Epoch: 1202	max: 0.9999937/1.0	min: 6.351749e-06	loss: 34637.640625	train_loss: 34603.89771073331	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1203
Epoch: 1203	max: 0.99999344/1.0	min: 6.6139123e-06	loss: 34637.796875	train_loss: 34603.87827432104	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1204
Epoch: 1204	max: 0.999995/1.0	min: 4.998887e-06	loss: 34637.671875	train_loss: 34603.82309666481	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1205
Epoch: 1205	max: 0.9999902/1.0	min: 9.800534e-06	loss: 34637.7265625	train_loss: 34603.80090028103	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1206
Epoch: 1206	max: 0.99999714/1.0	min: 2.8359427e-06	loss: 34637.80078125	train_loss: 34603.79518582389	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1207
Epoch: 1207	max: 0.9999933/1.0	min: 6.618379e-06	loss: 34637.7109375	train_loss: 34603.7981519223	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1208
Epoch: 1208	max: 0.9999938/1.0	min: 6.1668807e-06	loss: 34637.7421875	train_loss: 34603.77442119952	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1209
Epoch: 1209	max: 0.9999944/1.0	min: 5.545559e-06	loss: 34637.8359375	train_loss: 34603.78958701072	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1210
Epoch: 1210	max: 0.99999464/1.0	min: 5.316309e-06	loss: 34637.80078125	train_loss: 34603.80003851573	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1211
Epoch: 1211	max: 0.9999924/1.0	min: 7.5852518e-06	loss: 34637.671875	train_loss: 34603.756222516415	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1212
Epoch: 1212	max: 0.9999858/1.0	min: 1.4163646e-05	loss: 34637.6796875	train_loss: 34603.72750894184	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1213
Epoch: 1213	max: 0.999995/1.0	min: 5.032231e-06	loss: 34637.640625	train_loss: 34603.7229364084	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1214
Epoch: 1214	max: 0.99998975/1.0	min: 1.0284001e-05	loss: 34637.61328125	train_loss: 34603.688503538026	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1215
Epoch: 1215	max: 0.9999975/1.0	min: 2.5524212e-06	loss: 34637.67578125	train_loss: 34603.68274214589	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1216
Epoch: 1216	max: 0.9999951/1.0	min: 4.926947e-06	loss: 34637.859375	train_loss: 34603.758820392824	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1217
Epoch: 1217	max: 0.99999344/1.0	min: 6.58196e-06	loss: 34637.74609375	train_loss: 34603.72713539731	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1218
Epoch: 1218	max: 0.99999535/1.0	min: 4.631637e-06	loss: 34637.5703125	train_loss: 34603.662044778896	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1219
Epoch: 1219	max: 0.99998534/1.0	min: 1.4663303e-05	loss: 34637.703125	train_loss: 34603.6329276601	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1220
Epoch: 1220	max: 0.9999945/1.0	min: 5.426875e-06	loss: 34637.62109375	train_loss: 34603.648329114025	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1221
Epoch: 1221	max: 0.99999416/1.0	min: 5.845429e-06	loss: 34637.72265625	train_loss: 34603.63186509042	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1222
Epoch: 1222	max: 0.9999902/1.0	min: 9.774837e-06	loss: 34637.60546875	train_loss: 34603.64389012758	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1223
Epoch: 1223	max: 0.9999893/1.0	min: 1.0733807e-05	loss: 34637.640625	train_loss: 34603.60094073223	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1224
Epoch: 1224	max: 0.9999913/1.0	min: 8.712962e-06	loss: 34637.61328125	train_loss: 34603.586044918244	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1225
Epoch: 1225	max: 0.99998987/1.0	min: 1.0125663e-05	loss: 34637.5546875	train_loss: 34603.55755343816	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1226
Epoch: 1226	max: 0.9999877/1.0	min: 1.22861e-05	loss: 34637.734375	train_loss: 34603.609916446025	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1227
Epoch: 1227	max: 0.9999944/1.0	min: 5.572208e-06	loss: 34637.46484375	train_loss: 34603.58825666961	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1228
Epoch: 1228	max: 0.9999933/1.0	min: 6.691338e-06	loss: 34637.9140625	train_loss: 34603.640495807784	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1229
Epoch: 1229	max: 0.99999356/1.0	min: 6.3793577e-06	loss: 34637.4453125	train_loss: 34603.59412209293	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1230
Epoch: 1230	max: 0.9999901/1.0	min: 9.912409e-06	loss: 34637.55859375	train_loss: 34603.52610408538	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1231
Epoch: 1231	max: 0.9999925/1.0	min: 7.5121834e-06	loss: 34637.44921875	train_loss: 34603.63368103942	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1232
Epoch: 1232	max: 0.9999949/1.0	min: 5.1531924e-06	loss: 34637.5859375	train_loss: 34603.485440472876	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1233
Epoch: 1233	max: 0.99997807/1.0	min: 2.1888807e-05	loss: 34637.67578125	train_loss: 34603.45335580407	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1234
Epoch: 1234	max: 0.99999475/1.0	min: 5.296806e-06	loss: 34637.4140625	train_loss: 34603.53690300616	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1235
Epoch: 1235	max: 0.9999932/1.0	min: 6.7866454e-06	loss: 34637.34375	train_loss: 34603.42826396631	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1236
Epoch: 1236	max: 0.99999046/1.0	min: 9.574138e-06	loss: 34637.4296875	train_loss: 34603.434882768954	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1237
Epoch: 1237	max: 0.99999714/1.0	min: 2.8940149e-06	loss: 34637.48046875	train_loss: 34603.50029467438	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1238
Epoch: 1238	max: 0.99999297/1.0	min: 6.9750686e-06	loss: 34637.36328125	train_loss: 34603.41829681113	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1239
Epoch: 1239	max: 0.9999875/1.0	min: 1.2528778e-05	loss: 34637.48046875	train_loss: 34603.410177056234	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1240
Epoch: 1240	max: 0.99999523/1.0	min: 4.8080856e-06	loss: 34637.3359375	train_loss: 34603.3846995773	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1241
Epoch: 1241	max: 0.9999858/1.0	min: 1.4135606e-05	loss: 34637.39453125	train_loss: 34603.35877645779	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1242
Epoch: 1242	max: 0.999992/1.0	min: 7.983484e-06	loss: 34637.359375	train_loss: 34603.347073675366	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1243
Epoch: 1243	max: 0.99998355/1.0	min: 1.6420336e-05	loss: 34637.5625	train_loss: 34603.39180031045	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1244
Epoch: 1244	max: 0.9999932/1.0	min: 6.745889e-06	loss: 34637.265625	train_loss: 34603.40176456243	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1245
Epoch: 1245	max: 0.9999907/1.0	min: 9.261688e-06	loss: 34637.3984375	train_loss: 34603.397105416974	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1246
Epoch: 1246	max: 0.99998724/1.0	min: 1.28060365e-05	loss: 34637.41796875	train_loss: 34603.311084208166	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1247
Epoch: 1247	max: 0.9999913/1.0	min: 8.700706e-06	loss: 34637.35546875	train_loss: 34603.2943438971	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1248
Epoch: 1248	max: 0.9999896/1.0	min: 1.0406514e-05	loss: 34637.359375	train_loss: 34603.28159644804	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1249
Epoch: 1249	max: 0.9999846/1.0	min: 1.532523e-05	loss: 34637.38671875	train_loss: 34603.26673014988	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1250
Epoch: 1250	max: 0.9999963/1.0	min: 3.7501268e-06	loss: 34637.30859375	train_loss: 34603.268783193205	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1251
Epoch: 1251	max: 0.9999944/1.0	min: 5.634989e-06	loss: 34637.2734375	train_loss: 34603.249751776755	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1252
Epoch: 1252	max: 0.9999864/1.0	min: 1.3578708e-05	loss: 34637.40625	train_loss: 34603.21686969683	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1253
Epoch: 1253	max: 0.99998856/1.0	min: 1.1434431e-05	loss: 34637.38671875	train_loss: 34603.26074424393	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1254
Epoch: 1254	max: 0.99998975/1.0	min: 1.0218382e-05	loss: 34637.40625	train_loss: 34603.303736219495	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1255
Epoch: 1255	max: 0.99998903/1.0	min: 1.09332e-05	loss: 34637.39453125	train_loss: 34603.29992480723	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1256
Epoch: 1256	max: 0.9999933/1.0	min: 6.732881e-06	loss: 34637.2890625	train_loss: 34603.25928877509	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1257
Epoch: 1257	max: 0.9999939/1.0	min: 6.0300035e-06	loss: 34637.40625	train_loss: 34603.17150968119	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1258
Epoch: 1258	max: 0.9999951/1.0	min: 4.851987e-06	loss: 34637.31640625	train_loss: 34603.1424380458	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1259
Epoch: 1259	max: 0.999995/1.0	min: 4.9715354e-06	loss: 34637.23828125	train_loss: 34603.20646948161	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1260
Epoch: 1260	max: 0.9999943/1.0	min: 5.7588672e-06	loss: 34637.2890625	train_loss: 34603.13767874009	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1261
Epoch: 1261	max: 0.99999607/1.0	min: 3.9487136e-06	loss: 34637.19921875	train_loss: 34603.126763207605	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1262
Epoch: 1262	max: 0.999995/1.0	min: 5.06146e-06	loss: 34637.37890625	train_loss: 34603.09831575932	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1263
Epoch: 1263	max: 0.99999523/1.0	min: 4.8167453e-06	loss: 34637.140625	train_loss: 34603.11546396941	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1264
Epoch: 1264	max: 0.9999933/1.0	min: 6.6693588e-06	loss: 34637.140625	train_loss: 34603.08290075715	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1265
Epoch: 1265	max: 0.9999863/1.0	min: 1.3728825e-05	loss: 34637.2265625	train_loss: 34603.11928409126	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1266
Epoch: 1266	max: 0.9999844/1.0	min: 1.5639924e-05	loss: 34637.375	train_loss: 34603.13508231528	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1267
Epoch: 1267	max: 0.99999154/1.0	min: 8.479409e-06	loss: 34637.203125	train_loss: 34603.16748004537	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1268
Epoch: 1268	max: 0.9999956/1.0	min: 4.36112e-06	loss: 34637.26171875	train_loss: 34603.03928217515	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1269
Epoch: 1269	max: 0.9999962/1.0	min: 3.8621633e-06	loss: 34637.265625	train_loss: 34603.0379931562	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1270
Epoch: 1270	max: 0.9999963/1.0	min: 3.7509208e-06	loss: 34637.1953125	train_loss: 34603.023479112475	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1271
Epoch: 1271	max: 0.999995/1.0	min: 4.9801533e-06	loss: 34637.17578125	train_loss: 34602.99837372646	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1272
Epoch: 1272	max: 0.99998593/1.0	min: 1.40224065e-05	loss: 34637.26171875	train_loss: 34602.99726180246	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1273
Epoch: 1273	max: 0.99999225/1.0	min: 7.717533e-06	loss: 34637.140625	train_loss: 34602.98272211383	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1274
Epoch: 1274	max: 0.99997914/1.0	min: 2.0858583e-05	loss: 34637.4609375	train_loss: 34602.97993359424	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1275
Epoch: 1275	max: 0.9999951/1.0	min: 4.8787274e-06	loss: 34637.01171875	train_loss: 34602.987468839034	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1276
Epoch: 1276	max: 0.99999297/1.0	min: 7.088032e-06	loss: 34637.078125	train_loss: 34602.943677033014	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1277
Epoch: 1277	max: 0.99999225/1.0	min: 7.7181585e-06	loss: 34637.19921875	train_loss: 34602.928458480426	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1278
Epoch: 1278	max: 0.999992/1.0	min: 8.045431e-06	loss: 34637.05078125	train_loss: 34602.92191612861	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1279
Epoch: 1279	max: 0.99999213/1.0	min: 7.816186e-06	loss: 34637.0390625	train_loss: 34602.896241232345	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1280
Epoch: 1280	max: 0.9999925/1.0	min: 7.534454e-06	loss: 34637.0390625	train_loss: 34602.908581750125	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1281
Epoch: 1281	max: 0.99999404/1.0	min: 6.010369e-06	loss: 34637.06640625	train_loss: 34602.91552329137	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1282
Epoch: 1282	max: 0.9999913/1.0	min: 8.689992e-06	loss: 34637.3359375	train_loss: 34602.873026794565	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1283
Epoch: 1283	max: 0.99999845/1.0	min: 1.556422e-06	loss: 34637.54296875	train_loss: 34602.944465734545	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1284
Epoch: 1284	max: 0.99999607/1.0	min: 3.983295e-06	loss: 34637.0703125	train_loss: 34602.95163082187	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1285
Epoch: 1285	max: 0.9999894/1.0	min: 1.0606722e-05	loss: 34637.1640625	train_loss: 34602.86745652948	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1286
Epoch: 1286	max: 0.9999919/1.0	min: 8.080971e-06	loss: 34637.015625	train_loss: 34602.84668851805	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1287
Epoch: 1287	max: 0.99999154/1.0	min: 8.47966e-06	loss: 34637.01171875	train_loss: 34602.8093587421	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1288
Epoch: 1288	max: 0.99999475/1.0	min: 5.206041e-06	loss: 34636.92578125	train_loss: 34602.85536181562	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1289
Epoch: 1289	max: 0.99999094/1.0	min: 9.00493e-06	loss: 34636.94921875	train_loss: 34602.79219504831	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1290
Epoch: 1290	max: 0.9999906/1.0	min: 9.456263e-06	loss: 34636.9296875	train_loss: 34602.832752694165	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1291
Epoch: 1291	max: 0.9999908/1.0	min: 9.225537e-06	loss: 34636.984375	train_loss: 34602.803052033014	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1292
Epoch: 1292	max: 0.9999912/1.0	min: 8.770484e-06	loss: 34636.98828125	train_loss: 34602.790474904774	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1293
Epoch: 1293	max: 0.9999882/1.0	min: 1.1824045e-05	loss: 34636.90625	train_loss: 34602.77604505373	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1294
Epoch: 1294	max: 0.999987/1.0	min: 1.2940464e-05	loss: 34636.92578125	train_loss: 34602.77562699353	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1295
Epoch: 1295	max: 0.9999865/1.0	min: 1.3430998e-05	loss: 34637.0234375	train_loss: 34602.7432113604	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1296
Epoch: 1296	max: 0.99999046/1.0	min: 9.587028e-06	loss: 34636.85546875	train_loss: 34602.849069622505	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1297
Epoch: 1297	max: 0.9999913/1.0	min: 8.7469125e-06	loss: 34636.90625	train_loss: 34602.696601518954	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1298
Epoch: 1298	max: 0.9999882/1.0	min: 1.1819422e-05	loss: 34636.79296875	train_loss: 34602.709147679765	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1299
Epoch: 1299	max: 0.9999863/1.0	min: 1.3659348e-05	loss: 34636.9140625	train_loss: 34602.672357414376	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1300
Epoch: 1300	max: 0.99999356/1.0	min: 6.4821484e-06	loss: 34636.8515625	train_loss: 34602.651737949804	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1301
Epoch: 1301	max: 0.9999958/1.0	min: 4.155248e-06	loss: 34637.15234375	train_loss: 34602.64538575731	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1302
Epoch: 1302	max: 0.9999945/1.0	min: 5.4287593e-06	loss: 34636.92578125	train_loss: 34602.715110844016	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1303
Epoch: 1303	max: 0.9999944/1.0	min: 5.58142e-06	loss: 34636.9375	train_loss: 34602.63697229577	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1304
Epoch: 1304	max: 0.9999957/1.0	min: 4.299063e-06	loss: 34637.109375	train_loss: 34602.68729484083	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1305
Epoch: 1305	max: 0.99999356/1.0	min: 6.4610595e-06	loss: 34637.015625	train_loss: 34602.68428954927	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1306
Epoch: 1306	max: 0.9999883/1.0	min: 1.163019e-05	loss: 34636.8515625	train_loss: 34602.59130308977	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1307
Epoch: 1307	max: 0.9999944/1.0	min: 5.6532954e-06	loss: 34636.7734375	train_loss: 34602.597863344636	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1308
Epoch: 1308	max: 0.99999154/1.0	min: 8.5153015e-06	loss: 34636.88671875	train_loss: 34602.55689102564	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1309
Epoch: 1309	max: 0.9999839/1.0	min: 1.609378e-05	loss: 34636.99609375	train_loss: 34602.56588706181	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1310
Epoch: 1310	max: 0.9999831/1.0	min: 1.692687e-05	loss: 34637.03515625	train_loss: 34602.602006205096	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1311
Epoch: 1311	max: 0.9999919/1.0	min: 8.124686e-06	loss: 34636.88671875	train_loss: 34602.56473933172	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1312
Epoch: 1312	max: 0.99999046/1.0	min: 9.540287e-06	loss: 34636.76953125	train_loss: 34602.58312236777	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1313
Epoch: 1313	max: 0.9999913/1.0	min: 8.72244e-06	loss: 34636.76171875	train_loss: 34602.528761477304	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1314
Epoch: 1314	max: 0.9999927/1.0	min: 7.3166634e-06	loss: 34636.61328125	train_loss: 34602.52163267992	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1315
Epoch: 1315	max: 0.9999876/1.0	min: 1.2439366e-05	loss: 34636.73828125	train_loss: 34602.52775455221	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1316
Epoch: 1316	max: 0.9999894/1.0	min: 1.0552511e-05	loss: 34636.79296875	train_loss: 34602.51765868868	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1317
Epoch: 1317	max: 0.9999957/1.0	min: 4.3013147e-06	loss: 34636.828125	train_loss: 34602.49536988651	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1318
Epoch: 1318	max: 0.9999943/1.0	min: 5.6665194e-06	loss: 34636.72265625	train_loss: 34602.4938810309	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1319
Epoch: 1319	max: 0.9999925/1.0	min: 7.536603e-06	loss: 34636.734375	train_loss: 34602.4683077465	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1320
Epoch: 1320	max: 0.99998677/1.0	min: 1.319657e-05	loss: 34636.828125	train_loss: 34602.48369855537	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1321
Epoch: 1321	max: 0.99999547/1.0	min: 4.5700212e-06	loss: 34636.66796875	train_loss: 34602.42971072557	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1322
Epoch: 1322	max: 0.9999908/1.0	min: 9.172995e-06	loss: 34636.70703125	train_loss: 34602.47204561114	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1323
Epoch: 1323	max: 0.9999869/1.0	min: 1.3159634e-05	loss: 34636.7109375	train_loss: 34602.405076625015	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1324
Epoch: 1324	max: 0.99999404/1.0	min: 5.9646877e-06	loss: 34636.625	train_loss: 34602.3853223128	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1325
Epoch: 1325	max: 0.9999838/1.0	min: 1.6200585e-05	loss: 34636.69921875	train_loss: 34602.39296400811	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1326
Epoch: 1326	max: 0.9999864/1.0	min: 1.3576712e-05	loss: 34636.64453125	train_loss: 34602.40036086724	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1327
Epoch: 1327	max: 0.9999865/1.0	min: 1.3464316e-05	loss: 34636.80078125	train_loss: 34602.35264200499	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1328
Epoch: 1328	max: 0.9999949/1.0	min: 5.1806733e-06	loss: 34636.53515625	train_loss: 34602.34831333999	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1329
Epoch: 1329	max: 0.99999714/1.0	min: 2.8944978e-06	loss: 34636.81640625	train_loss: 34602.3435182282	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1330
Epoch: 1330	max: 0.99999654/1.0	min: 3.4400243e-06	loss: 34636.86328125	train_loss: 34602.39166192478	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1331
Epoch: 1331	max: 0.9999962/1.0	min: 3.7782163e-06	loss: 34636.7265625	train_loss: 34602.369916987955	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1332
Epoch: 1332	max: 0.9999906/1.0	min: 9.417492e-06	loss: 34636.6953125	train_loss: 34602.32761984393	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1333
Epoch: 1333	max: 0.99997246/1.0	min: 2.7585998e-05	loss: 34637.1015625	train_loss: 34602.351918625354	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1334
Epoch: 1334	max: 0.99998367/1.0	min: 1.6276032e-05	loss: 34636.71875	train_loss: 34602.374547585314	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1335
Epoch: 1335	max: 0.9999924/1.0	min: 7.6197193e-06	loss: 34636.60546875	train_loss: 34602.3391498862	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1336
Epoch: 1336	max: 0.9999957/1.0	min: 4.252886e-06	loss: 34636.65625	train_loss: 34602.263275346835	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1337
Epoch: 1337	max: 0.99999225/1.0	min: 7.7183795e-06	loss: 34636.74609375	train_loss: 34602.30102995711	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1338
Epoch: 1338	max: 0.9999881/1.0	min: 1.1927195e-05	loss: 34636.62109375	train_loss: 34602.247090513905	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1339
Epoch: 1339	max: 0.999995/1.0	min: 5.0430353e-06	loss: 34636.6953125	train_loss: 34602.210381537996	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1340
Epoch: 1340	max: 0.9999902/1.0	min: 9.799011e-06	loss: 34636.65625	train_loss: 34602.2719259027	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1341
Epoch: 1341	max: 0.99999607/1.0	min: 3.9873885e-06	loss: 34636.546875	train_loss: 34602.22408317075	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1342
Epoch: 1342	max: 0.9999927/1.0	min: 7.3055216e-06	loss: 34636.5546875	train_loss: 34602.18385068283	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1343
Epoch: 1343	max: 0.9999957/1.0	min: 4.3472014e-06	loss: 34636.47265625	train_loss: 34602.202876776755	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1344
Epoch: 1344	max: 0.9999918/1.0	min: 8.2093475e-06	loss: 34636.48046875	train_loss: 34602.19948971494	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1345
Epoch: 1345	max: 0.99999547/1.0	min: 4.47933e-06	loss: 34636.55078125	train_loss: 34602.26107327279	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1346
Epoch: 1346	max: 0.9999963/1.0	min: 3.6946492e-06	loss: 34636.75390625	train_loss: 34602.209937349035	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1347
Epoch: 1347	max: 0.9999969/1.0	min: 3.092802e-06	loss: 34636.51171875	train_loss: 34602.194963148766	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1348
Epoch: 1348	max: 0.9999863/1.0	min: 1.3649568e-05	loss: 34636.58984375	train_loss: 34602.163305733615	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1349
Epoch: 1349	max: 0.9999809/1.0	min: 1.9034107e-05	loss: 34636.66015625	train_loss: 34602.12740142683	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1350
Epoch: 1350	max: 0.9999906/1.0	min: 9.406587e-06	loss: 34636.40625	train_loss: 34602.116081866254	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1351
Epoch: 1351	max: 0.9999882/1.0	min: 1.1815388e-05	loss: 34636.5078125	train_loss: 34602.09557272312	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1352
Epoch: 1352	max: 0.99999475/1.0	min: 5.2616742e-06	loss: 34636.3203125	train_loss: 34602.0810301313	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1353
Epoch: 1353	max: 0.9999908/1.0	min: 9.174342e-06	loss: 34636.546875	train_loss: 34602.10262555354	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1354
Epoch: 1354	max: 0.99999464/1.0	min: 5.3668223e-06	loss: 34636.34765625	train_loss: 34602.079463857146	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1355
Epoch: 1355	max: 0.99999225/1.0	min: 7.712699e-06	loss: 34636.46875	train_loss: 34602.08413993791	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1356
Epoch: 1356	max: 0.99999297/1.0	min: 7.0042256e-06	loss: 34636.30078125	train_loss: 34602.07984804673	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1357
Epoch: 1357	max: 0.9999943/1.0	min: 5.755046e-06	loss: 34636.38671875	train_loss: 34602.0408513525	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1358
Epoch: 1358	max: 0.9999815/1.0	min: 1.851179e-05	loss: 34636.59765625	train_loss: 34602.05499378716	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1359
Epoch: 1359	max: 0.99999595/1.0	min: 4.0883547e-06	loss: 34636.30078125	train_loss: 34602.0305488782	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1360
Epoch: 1360	max: 0.9999924/1.0	min: 7.686193e-06	loss: 34636.47265625	train_loss: 34601.994379412856	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1361
Epoch: 1361	max: 0.99999464/1.0	min: 5.305961e-06	loss: 34636.47265625	train_loss: 34601.98567659947	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1362
Epoch: 1362	max: 0.9999969/1.0	min: 3.103859e-06	loss: 34636.44140625	train_loss: 34601.995241178156	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1363
Epoch: 1363	max: 0.9999937/1.0	min: 6.3346415e-06	loss: 34636.390625	train_loss: 34602.014919039546	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1364
Epoch: 1364	max: 0.99999714/1.0	min: 2.920565e-06	loss: 34636.171875	train_loss: 34601.980043915675	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1365
Epoch: 1365	max: 0.9999908/1.0	min: 9.237414e-06	loss: 34636.48828125	train_loss: 34601.93695032826	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1366
Epoch: 1366	max: 0.9999937/1.0	min: 6.2958316e-06	loss: 34636.30859375	train_loss: 34601.92526690047	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1367
Epoch: 1367	max: 0.9999895/1.0	min: 1.044519e-05	loss: 34636.328125	train_loss: 34601.9001808691	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1368
Epoch: 1368	max: 0.99999547/1.0	min: 4.551814e-06	loss: 34636.28125	train_loss: 34601.904711306204	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1369
Epoch: 1369	max: 0.9999918/1.0	min: 8.253015e-06	loss: 34636.30078125	train_loss: 34601.92773945559	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1370
Epoch: 1370	max: 0.99998844/1.0	min: 1.1593692e-05	loss: 34636.30078125	train_loss: 34601.90712821674	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1371
Epoch: 1371	max: 0.99997985/1.0	min: 2.0129251e-05	loss: 34636.46484375	train_loss: 34601.86667992459	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1372
Epoch: 1372	max: 0.9999907/1.0	min: 9.290988e-06	loss: 34636.37109375	train_loss: 34601.87743481358	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1373
Epoch: 1373	max: 0.9999932/1.0	min: 6.819422e-06	loss: 34636.1484375	train_loss: 34601.89551640112	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1374
Epoch: 1374	max: 0.9999845/1.0	min: 1.54559e-05	loss: 34636.640625	train_loss: 34601.942794945346	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1375
Epoch: 1375	max: 0.999997/1.0	min: 2.9531461e-06	loss: 34636.328125	train_loss: 34601.87380194785	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1376
Epoch: 1376	max: 0.9999939/1.0	min: 6.0774482e-06	loss: 34636.31640625	train_loss: 34601.81514819847	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1377
Epoch: 1377	max: 0.9999958/1.0	min: 4.1426892e-06	loss: 34636.296875	train_loss: 34601.78781073873	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1378
Epoch: 1378	max: 0.9999919/1.0	min: 8.125578e-06	loss: 34636.23828125	train_loss: 34601.795109373066	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1379
Epoch: 1379	max: 0.9999912/1.0	min: 8.831266e-06	loss: 34636.12890625	train_loss: 34601.767451594045	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1380
Epoch: 1380	max: 0.9999907/1.0	min: 9.339058e-06	loss: 34636.3046875	train_loss: 34601.7506043486	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1381
Epoch: 1381	max: 0.9999918/1.0	min: 8.188868e-06	loss: 34636.125	train_loss: 34601.766660473186	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1382
Epoch: 1382	max: 0.99998903/1.0	min: 1.0935651e-05	loss: 34636.2109375	train_loss: 34601.76455759166	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1383
Epoch: 1383	max: 0.999992/1.0	min: 8.034191e-06	loss: 34636.1640625	train_loss: 34601.73569934117	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1384
Epoch: 1384	max: 0.99999154/1.0	min: 8.509082e-06	loss: 34636.19140625	train_loss: 34601.71107636953	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1385
Epoch: 1385	max: 0.9999956/1.0	min: 4.3836117e-06	loss: 34636.1640625	train_loss: 34601.71744404574	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1386
Epoch: 1386	max: 0.9999975/1.0	min: 2.5520367e-06	loss: 34636.13671875	train_loss: 34601.72084901059	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1387
Epoch: 1387	max: 0.9999937/1.0	min: 6.305446e-06	loss: 34636.4140625	train_loss: 34601.69498782593	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1388
Epoch: 1388	max: 0.9999919/1.0	min: 8.114148e-06	loss: 34636.14453125	train_loss: 34601.68223844141	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1389
Epoch: 1389	max: 0.9999901/1.0	min: 9.939444e-06	loss: 34636.265625	train_loss: 34601.688906598385	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1390
Epoch: 1390	max: 0.9999919/1.0	min: 8.127251e-06	loss: 34636.1484375	train_loss: 34601.678100903475	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1391
Epoch: 1391	max: 0.9999931/1.0	min: 6.9350076e-06	loss: 34636.20703125	train_loss: 34601.64857007928	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1392
Epoch: 1392	max: 0.9999944/1.0	min: 5.630821e-06	loss: 34636.21875	train_loss: 34601.6365793966	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1393
Epoch: 1393	max: 0.99998295/1.0	min: 1.704356e-05	loss: 34636.4296875	train_loss: 34601.618875224514	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1394
Epoch: 1394	max: 0.99999654/1.0	min: 3.4960433e-06	loss: 34636.04296875	train_loss: 34601.77264105661	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1395
Epoch: 1395	max: 0.9999714/1.0	min: 2.8643317e-05	loss: 34636.26953125	train_loss: 34601.61560816146	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1396
Epoch: 1396	max: 0.99999464/1.0	min: 5.3557173e-06	loss: 34635.94921875	train_loss: 34601.66104704726	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1397
Epoch: 1397	max: 0.99999344/1.0	min: 6.574783e-06	loss: 34636.0234375	train_loss: 34601.57758403784	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1398
Epoch: 1398	max: 0.99999464/1.0	min: 5.313339e-06	loss: 34635.87109375	train_loss: 34601.560192443176	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1399
Epoch: 1399	max: 0.99998605/1.0	min: 1.3903244e-05	loss: 34635.98828125	train_loss: 34601.58691781246	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1400
Epoch: 1400	max: 0.9999906/1.0	min: 9.474227e-06	loss: 34636.03125	train_loss: 34601.59673980785	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1401
Epoch: 1401	max: 0.9999858/1.0	min: 1.4227464e-05	loss: 34636.1015625	train_loss: 34601.55555410396	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1402
Epoch: 1402	max: 0.99998975/1.0	min: 1.0249291e-05	loss: 34636.07421875	train_loss: 34601.530869681344	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1403
Epoch: 1403	max: 0.9999938/1.0	min: 6.214306e-06	loss: 34635.9140625	train_loss: 34601.49945468305	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1404
Epoch: 1404	max: 0.9999944/1.0	min: 5.647384e-06	loss: 34636.04296875	train_loss: 34601.49658439009	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1405
Epoch: 1405	max: 0.9999939/1.0	min: 6.059201e-06	loss: 34636.0	train_loss: 34601.495045696305	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1406
Epoch: 1406	max: 0.9999976/1.0	min: 2.4022231e-06	loss: 34636.40234375	train_loss: 34601.47094771925	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1407
Epoch: 1407	max: 0.99999464/1.0	min: 5.3205495e-06	loss: 34636.10546875	train_loss: 34601.56855993745	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1408
Epoch: 1408	max: 0.99999344/1.0	min: 6.563168e-06	loss: 34635.859375	train_loss: 34601.4540520872	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1409
Epoch: 1409	max: 0.9999895/1.0	min: 1.0446346e-05	loss: 34635.98828125	train_loss: 34601.422134352164	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1410
Epoch: 1410	max: 0.99998534/1.0	min: 1.4669374e-05	loss: 34636.01953125	train_loss: 34601.42563367088	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1411
Epoch: 1411	max: 0.9999901/1.0	min: 9.93086e-06	loss: 34635.92578125	train_loss: 34601.43137425678	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1412
Epoch: 1412	max: 0.999985/1.0	min: 1.4966144e-05	loss: 34636.03125	train_loss: 34601.430163624114	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1413
Epoch: 1413	max: 0.9999939/1.0	min: 6.1333208e-06	loss: 34635.88671875	train_loss: 34601.42328353385	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1414
Epoch: 1414	max: 0.9999912/1.0	min: 8.809413e-06	loss: 34636.03125	train_loss: 34601.39501656757	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1415
Epoch: 1415	max: 0.99998903/1.0	min: 1.0930333e-05	loss: 34635.92578125	train_loss: 34601.373865334295	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1416
Epoch: 1416	max: 0.9999918/1.0	min: 8.1752905e-06	loss: 34635.80078125	train_loss: 34601.35052557522	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1417
Epoch: 1417	max: 0.99999297/1.0	min: 7.087931e-06	loss: 34635.83984375	train_loss: 34601.34814301917	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1418
Epoch: 1418	max: 0.99999857/1.0	min: 1.4078493e-06	loss: 34636.2109375	train_loss: 34601.31670818237	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1419
Epoch: 1419	max: 0.99999857/1.0	min: 1.3736072e-06	loss: 34636.0234375	train_loss: 34601.45498256147	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1420
Epoch: 1420	max: 0.9999912/1.0	min: 8.85152e-06	loss: 34635.93359375	train_loss: 34601.34016213381	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1421
Epoch: 1421	max: 0.9999902/1.0	min: 9.791136e-06	loss: 34636.0078125	train_loss: 34601.29553904605	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1422
Epoch: 1422	max: 0.99998057/1.0	min: 1.9395231e-05	loss: 34636.08984375	train_loss: 34601.38277524232	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1423
Epoch: 1423	max: 0.99997985/1.0	min: 2.0127754e-05	loss: 34635.93359375	train_loss: 34601.4162965092	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1424
Epoch: 1424	max: 0.9999924/1.0	min: 7.6156293e-06	loss: 34635.828125	train_loss: 34601.32366036867	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1425
Epoch: 1425	max: 0.99998975/1.0	min: 1.0220448e-05	loss: 34635.921875	train_loss: 34601.262152293915	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1426
Epoch: 1426	max: 0.99999774/1.0	min: 2.2983024e-06	loss: 34635.91015625	train_loss: 34601.35494230382	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1427
Epoch: 1427	max: 0.9999912/1.0	min: 8.836068e-06	loss: 34635.8046875	train_loss: 34601.24036816394	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1428
Epoch: 1428	max: 0.9999943/1.0	min: 5.7197867e-06	loss: 34635.89453125	train_loss: 34601.223840753904	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1429
Epoch: 1429	max: 0.9999968/1.0	min: 3.1904788e-06	loss: 34635.8046875	train_loss: 34601.22575831475	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1430
Epoch: 1430	max: 0.99998546/1.0	min: 1.4568785e-05	loss: 34636.05859375	train_loss: 34601.19441541249	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1431
Epoch: 1431	max: 0.9999901/1.0	min: 9.894161e-06	loss: 34635.796875	train_loss: 34601.18967546141	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1432
Epoch: 1432	max: 0.9999938/1.0	min: 6.2452054e-06	loss: 34635.71875	train_loss: 34601.18611856265	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1433
Epoch: 1433	max: 0.9999939/1.0	min: 6.027565e-06	loss: 34635.83203125	train_loss: 34601.15926109795	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1434
Epoch: 1434	max: 0.99999547/1.0	min: 4.4776643e-06	loss: 34635.74609375	train_loss: 34601.161054305245	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1435
Epoch: 1435	max: 0.9999875/1.0	min: 1.2550518e-05	loss: 34635.8515625	train_loss: 34601.141704021116	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1436
Epoch: 1436	max: 0.9999975/1.0	min: 2.4767833e-06	loss: 34635.8515625	train_loss: 34601.13947726991	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1437
Epoch: 1437	max: 0.9999951/1.0	min: 4.9178498e-06	loss: 34635.81640625	train_loss: 34601.12923963366	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1438
Epoch: 1438	max: 0.99999475/1.0	min: 5.2224905e-06	loss: 34635.6484375	train_loss: 34601.128458190105	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1439
Epoch: 1439	max: 0.99999607/1.0	min: 3.885148e-06	loss: 34635.76953125	train_loss: 34601.09336774588	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1440
Epoch: 1440	max: 0.9999846/1.0	min: 1.5362823e-05	loss: 34635.90625	train_loss: 34601.1221901903	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1441
Epoch: 1441	max: 0.99999046/1.0	min: 9.541369e-06	loss: 34635.921875	train_loss: 34601.05998147761	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1442
Epoch: 1442	max: 0.9999956/1.0	min: 4.4469657e-06	loss: 34635.61328125	train_loss: 34601.118394261735	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1443
Epoch: 1443	max: 0.9999901/1.0	min: 9.951272e-06	loss: 34635.6953125	train_loss: 34601.07351327341	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1444
Epoch: 1444	max: 0.99999547/1.0	min: 4.482958e-06	loss: 34635.75390625	train_loss: 34601.053525253934	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1445
Epoch: 1445	max: 0.999997/1.0	min: 3.0007818e-06	loss: 34635.5859375	train_loss: 34601.03615011071	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1446
Epoch: 1446	max: 0.99999094/1.0	min: 9.039062e-06	loss: 34635.6484375	train_loss: 34601.02095526756	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1447
Epoch: 1447	max: 0.9999968/1.0	min: 3.1739755e-06	loss: 34635.7734375	train_loss: 34601.01989802041	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1448
Epoch: 1448	max: 0.9999907/1.0	min: 9.279998e-06	loss: 34635.70703125	train_loss: 34601.000842410656	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1449
Epoch: 1449	max: 0.9999918/1.0	min: 8.2200795e-06	loss: 34635.71484375	train_loss: 34601.007210086864	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1450
Epoch: 1450	max: 0.99999666/1.0	min: 3.3904923e-06	loss: 34635.703125	train_loss: 34600.98382097346	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1451
Epoch: 1451	max: 0.99999475/1.0	min: 5.261935e-06	loss: 34635.71484375	train_loss: 34600.966306960705	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1452
Epoch: 1452	max: 0.9999969/1.0	min: 3.0726399e-06	loss: 34635.625	train_loss: 34601.00986602719	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1453
Epoch: 1453	max: 0.99999464/1.0	min: 5.3570557e-06	loss: 34635.55859375	train_loss: 34600.93708532686	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1454
Epoch: 1454	max: 0.99999774/1.0	min: 2.2465533e-06	loss: 34635.703125	train_loss: 34600.92750478059	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1455
Epoch: 1455	max: 0.99997985/1.0	min: 2.0097448e-05	loss: 34635.92578125	train_loss: 34600.93882482503	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1456
Epoch: 1456	max: 0.99998474/1.0	min: 1.5209566e-05	loss: 34635.7734375	train_loss: 34600.97478235709	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1457
Epoch: 1457	max: 0.99999046/1.0	min: 9.478627e-06	loss: 34635.65625	train_loss: 34600.95896623003	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1458
Epoch: 1458	max: 0.9999974/1.0	min: 2.5707966e-06	loss: 34635.53515625	train_loss: 34600.90853916992	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1459
Epoch: 1459	max: 0.9999889/1.0	min: 1.1085563e-05	loss: 34635.703125	train_loss: 34600.91211300399	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1460
Epoch: 1460	max: 0.9999974/1.0	min: 2.6756004e-06	loss: 34635.37890625	train_loss: 34600.969370316176	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1461
Epoch: 1461	max: 0.9999832/1.0	min: 1.6851749e-05	loss: 34635.74609375	train_loss: 34600.85715937771	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1462
Epoch: 1462	max: 0.99999714/1.0	min: 2.8914988e-06	loss: 34635.375	train_loss: 34600.88193428326	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1463
Epoch: 1463	max: 0.99999/1.0	min: 9.981038e-06	loss: 34635.75390625	train_loss: 34600.889579365634	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1464
Epoch: 1464	max: 0.9999944/1.0	min: 5.6288877e-06	loss: 34635.37109375	train_loss: 34600.8564442238	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1465
Epoch: 1465	max: 0.9999826/1.0	min: 1.7445085e-05	loss: 34635.6953125	train_loss: 34600.89754718661	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1466
Epoch: 1466	max: 0.99999547/1.0	min: 4.5369493e-06	loss: 34635.734375	train_loss: 34600.79833579137	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1467
Epoch: 1467	max: 0.99999607/1.0	min: 3.9233014e-06	loss: 34635.46875	train_loss: 34600.806135226994	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1468
Epoch: 1468	max: 0.999984/1.0	min: 1.5936224e-05	loss: 34635.61328125	train_loss: 34600.78891104995	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1469
Epoch: 1469	max: 0.9999963/1.0	min: 3.6400445e-06	loss: 34635.37890625	train_loss: 34600.76331018518	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1470
Epoch: 1470	max: 0.9999914/1.0	min: 8.5675465e-06	loss: 34635.57421875	train_loss: 34600.75935167766	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1471
Epoch: 1471	max: 0.9999949/1.0	min: 5.149994e-06	loss: 34635.58984375	train_loss: 34600.76677127849	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1472
Epoch: 1472	max: 0.999995/1.0	min: 5.018304e-06	loss: 34635.4453125	train_loss: 34600.788037188	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1473
Epoch: 1473	max: 0.9999962/1.0	min: 3.7617317e-06	loss: 34635.50390625	train_loss: 34600.72067143178	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1474
Epoch: 1474	max: 0.99999154/1.0	min: 8.421554e-06	loss: 34635.3984375	train_loss: 34600.717606624705	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1475
Epoch: 1475	max: 0.99999464/1.0	min: 5.3316226e-06	loss: 34635.453125	train_loss: 34600.69843150006	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1476
Epoch: 1476	max: 0.9999888/1.0	min: 1.12355165e-05	loss: 34635.4921875	train_loss: 34600.746996160036	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1477
Epoch: 1477	max: 0.9999926/1.0	min: 7.4090044e-06	loss: 34635.36328125	train_loss: 34600.69658071271	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1478
Epoch: 1478	max: 0.99998915/1.0	min: 1.0850861e-05	loss: 34635.359375	train_loss: 34600.66170655658	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1479
Epoch: 1479	max: 0.9999794/1.0	min: 2.0601974e-05	loss: 34635.5546875	train_loss: 34600.74371506488	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1480
Epoch: 1480	max: 0.999995/1.0	min: 4.983227e-06	loss: 34635.3203125	train_loss: 34600.66931292968	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1481
Epoch: 1481	max: 0.99998844/1.0	min: 1.1512621e-05	loss: 34635.3671875	train_loss: 34600.63168944708	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1482
Epoch: 1482	max: 0.99998593/1.0	min: 1.401405e-05	loss: 34635.4921875	train_loss: 34600.625936764525	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1483
Epoch: 1483	max: 0.9999932/1.0	min: 6.7924084e-06	loss: 34635.328125	train_loss: 34600.609168873096	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1484
Epoch: 1484	max: 0.9999907/1.0	min: 9.244128e-06	loss: 34635.31640625	train_loss: 34600.60561197433	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1485
Epoch: 1485	max: 0.9999931/1.0	min: 6.882312e-06	loss: 34635.28515625	train_loss: 34600.656332741084	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1486
Epoch: 1486	max: 0.99999166/1.0	min: 8.400235e-06	loss: 34635.31640625	train_loss: 34600.67009485709	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1487
Epoch: 1487	max: 0.9999869/1.0	min: 1.3162107e-05	loss: 34635.46484375	train_loss: 34600.5580576265	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1488
Epoch: 1488	max: 0.9999943/1.0	min: 5.668271e-06	loss: 34635.42578125	train_loss: 34600.559101809275	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1489
Epoch: 1489	max: 0.99999714/1.0	min: 2.8236984e-06	loss: 34635.22265625	train_loss: 34600.61539477657	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1490
Epoch: 1490	max: 0.99998486/1.0	min: 1.5087551e-05	loss: 34635.4765625	train_loss: 34600.55168753097	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1491
Epoch: 1491	max: 0.9999924/1.0	min: 7.662364e-06	loss: 34635.25390625	train_loss: 34600.52206719157	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1492
Epoch: 1492	max: 0.999997/1.0	min: 2.9892083e-06	loss: 34635.23046875	train_loss: 34600.50714476496	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1493
Epoch: 1493	max: 0.9999944/1.0	min: 5.560572e-06	loss: 34635.15625	train_loss: 34600.50999086461	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1494
Epoch: 1494	max: 0.9999906/1.0	min: 9.440972e-06	loss: 34635.265625	train_loss: 34600.486879006414	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1495
Epoch: 1495	max: 0.99999464/1.0	min: 5.3532663e-06	loss: 34635.140625	train_loss: 34600.4739815589	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1496
Epoch: 1496	max: 0.9999839/1.0	min: 1.6073333e-05	loss: 34635.296875	train_loss: 34600.470501110955	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1497
Epoch: 1497	max: 0.9999968/1.0	min: 3.2161824e-06	loss: 34635.1484375	train_loss: 34600.59355548588	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1498
Epoch: 1498	max: 0.99999547/1.0	min: 4.55803e-06	loss: 34635.2890625	train_loss: 34600.50781588706	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1499
Epoch: 1499	max: 0.9999933/1.0	min: 6.619925e-06	loss: 34635.2578125	train_loss: 34600.44016997244	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1500
Epoch: 1500	max: 0.9999889/1.0	min: 1.1070931e-05	loss: 34635.34375	train_loss: 34600.42579576598	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1501
Epoch: 1501	max: 0.99998736/1.0	min: 1.2639714e-05	loss: 34635.17578125	train_loss: 34600.43243779419	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1502
Epoch: 1502	max: 0.99999475/1.0	min: 5.2084642e-06	loss: 34635.08984375	train_loss: 34600.38947630218	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1503
Epoch: 1503	max: 0.9999882/1.0	min: 1.1848042e-05	loss: 34635.2265625	train_loss: 34600.406159517064	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1504
Epoch: 1504	max: 0.9999933/1.0	min: 6.7289784e-06	loss: 34635.14453125	train_loss: 34600.38882453471	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1505
Epoch: 1505	max: 0.99999654/1.0	min: 3.4567533e-06	loss: 34635.1953125	train_loss: 34600.386021983	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1506
Epoch: 1506	max: 0.99999547/1.0	min: 4.5470542e-06	loss: 34635.01171875	train_loss: 34600.388759696674	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1507
Epoch: 1507	max: 0.999997/1.0	min: 3.018701e-06	loss: 34635.18359375	train_loss: 34600.337768448844	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1508
Epoch: 1508	max: 0.99999213/1.0	min: 7.879315e-06	loss: 34635.21875	train_loss: 34600.343280650006	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1509
Epoch: 1509	max: 0.9999931/1.0	min: 6.911008e-06	loss: 34635.296875	train_loss: 34600.30934809705	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1510
Epoch: 1510	max: 0.9999895/1.0	min: 1.04939945e-05	loss: 34635.13671875	train_loss: 34600.35806469095	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1511
Epoch: 1511	max: 0.9999932/1.0	min: 6.824757e-06	loss: 34635.05078125	train_loss: 34600.34132341215	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1512
Epoch: 1512	max: 0.9999938/1.0	min: 6.218248e-06	loss: 34635.03515625	train_loss: 34600.28831928186	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1513
Epoch: 1513	max: 0.99999404/1.0	min: 5.9496215e-06	loss: 34635.10546875	train_loss: 34600.29565178682	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1514
Epoch: 1514	max: 0.9999975/1.0	min: 2.4449484e-06	loss: 34634.99609375	train_loss: 34600.328238708506	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1515
Epoch: 1515	max: 0.9999769/1.0	min: 2.3149121e-05	loss: 34635.1953125	train_loss: 34600.303304127185	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1516
Epoch: 1516	max: 0.9999958/1.0	min: 4.220152e-06	loss: 34635.03125	train_loss: 34600.253988991084	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1517
Epoch: 1517	max: 0.99999046/1.0	min: 9.55902e-06	loss: 34634.9453125	train_loss: 34600.238311733556	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1518
Epoch: 1518	max: 0.99998796/1.0	min: 1.2083092e-05	loss: 34635.1484375	train_loss: 34600.28705252075	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1519
Epoch: 1519	max: 0.99999833/1.0	min: 1.6683883e-06	loss: 34635.01171875	train_loss: 34600.20788091865	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1520
Epoch: 1520	max: 0.9999931/1.0	min: 6.914911e-06	loss: 34635.0390625	train_loss: 34600.20203726929	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1521
Epoch: 1521	max: 0.99999356/1.0	min: 6.3992766e-06	loss: 34635.0234375	train_loss: 34600.18356713737	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1522
Epoch: 1522	max: 0.999995/1.0	min: 4.992422e-06	loss: 34634.9609375	train_loss: 34600.168151651334	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1523
Epoch: 1523	max: 0.9999852/1.0	min: 1.4808624e-05	loss: 34634.8984375	train_loss: 34600.160171249845	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1524
Epoch: 1524	max: 0.9999918/1.0	min: 8.228543e-06	loss: 34634.984375	train_loss: 34600.173338210705	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1525
Epoch: 1525	max: 0.99998784/1.0	min: 1.20998e-05	loss: 34635.1640625	train_loss: 34600.15109344033	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1526
Epoch: 1526	max: 0.9999919/1.0	min: 8.136898e-06	loss: 34634.89453125	train_loss: 34600.139218401615	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1527
Epoch: 1527	max: 0.9999913/1.0	min: 8.700565e-06	loss: 34634.9453125	train_loss: 34600.09764657268	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1528
Epoch: 1528	max: 0.99999475/1.0	min: 5.2548744e-06	loss: 34634.8359375	train_loss: 34600.13099074461	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1529
Epoch: 1529	max: 0.99998546/1.0	min: 1.4502979e-05	loss: 34634.86328125	train_loss: 34600.08384816673	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1530
Epoch: 1530	max: 0.99998176/1.0	min: 1.8199284e-05	loss: 34634.87890625	train_loss: 34600.068193650906	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1531
Epoch: 1531	max: 0.9999887/1.0	min: 1.1312906e-05	loss: 34634.92578125	train_loss: 34600.090932932304	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1532
Epoch: 1532	max: 0.9999932/1.0	min: 6.786917e-06	loss: 34634.84375	train_loss: 34600.159656900316	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1533
Epoch: 1533	max: 0.99998355/1.0	min: 1.6391643e-05	loss: 34635.05078125	train_loss: 34600.07613534312	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1534
Epoch: 1534	max: 0.99999547/1.0	min: 4.4775147e-06	loss: 34634.78125	train_loss: 34600.092280982906	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1535
Epoch: 1535	max: 0.9999857/1.0	min: 1.4267763e-05	loss: 34634.921875	train_loss: 34600.07216764214	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1536
