Epoch: 0	max: 0.61266327/1.0	min: 0.38733673	loss: 36164.80859375	train_loss: 36480.61149046203	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1
Epoch: 1	max: 0.6902327/1.0	min: 0.30976725	loss: 35734.09375	train_loss: 35997.485570632816	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_2
Epoch: 2	max: 0.7533219/1.0	min: 0.24667819	loss: 35426.12890625	train_loss: 35647.622049385296	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_3
Epoch: 3	max: 0.80264246/1.0	min: 0.19735752	loss: 35209.46875	train_loss: 35403.95050196256	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_4
Epoch: 4	max: 0.8398414/1.0	min: 0.16015854	loss: 35059.07421875	train_loss: 35236.90268584324	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_5
Epoch: 5	max: 0.867503/1.0	min: 0.13249703	loss: 34955.328125	train_loss: 35124.671560003255	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_6
Epoch: 6	max: 0.88814926/1.0	min: 0.111850776	loss: 34883.99609375	train_loss: 35050.29557533599	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_7
Epoch: 7	max: 0.9033579/1.0	min: 0.096642084	loss: 34835.26171875	train_loss: 35001.74214298433	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_8
Epoch: 8	max: 0.91462284/1.0	min: 0.08537719	loss: 34801.79296875	train_loss: 34970.04251488372	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_9
Epoch: 9	max: 0.9231545/1.0	min: 0.07684554	loss: 34778.28125	train_loss: 34949.471396263005	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_10
Epoch: 10	max: 0.9298117/1.0	min: 0.07018831	loss: 34761.24609375	train_loss: 34935.73492128468	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_11
Epoch: 11	max: 0.93516386/1.0	min: 0.064836085	loss: 34748.71484375	train_loss: 34926.55960212669	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_12
Epoch: 12	max: 0.93943894/1.0	min: 0.060561065	loss: 34739.40234375	train_loss: 34920.176589306175	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_13
Epoch: 13	max: 0.9430268/1.0	min: 0.056973185	loss: 34732.078125	train_loss: 34915.79815772869	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_14
Epoch: 14	max: 0.9457829/1.0	min: 0.054217085	loss: 34726.71875	train_loss: 34912.75371754227	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_15
Epoch: 15	max: 0.94775075/1.0	min: 0.052249257	loss: 34722.9609375	train_loss: 34910.542671656294	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_16
Epoch: 16	max: 0.9491405/1.0	min: 0.050859526	loss: 34720.265625	train_loss: 34908.81953202419	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_17
Epoch: 17	max: 0.95018363/1.0	min: 0.049816325	loss: 34718.1640625	train_loss: 34907.34286888006	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_18
Epoch: 18	max: 0.95095307/1.0	min: 0.049046986	loss: 34716.49609375	train_loss: 34905.952101623465	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_19
Epoch: 19	max: 0.9513732/1.0	min: 0.048626743	loss: 34715.3359375	train_loss: 34904.543123587115	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_20
Epoch: 20	max: 0.9518321/1.0	min: 0.048167847	loss: 34714.08984375	train_loss: 34903.08259350226	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_21
Epoch: 21	max: 0.9519264/1.0	min: 0.048073523	loss: 34713.328125	train_loss: 34901.52081204323	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_22
Epoch: 22	max: 0.95211/1.0	min: 0.047889967	loss: 34712.390625	train_loss: 34899.81765268875	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_23
Epoch: 23	max: 0.9522074/1.0	min: 0.047792606	loss: 34711.51171875	train_loss: 34897.97682765855	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_24
Epoch: 24	max: 0.9524416/1.0	min: 0.04755841	loss: 34710.36328125	train_loss: 34895.95649706197	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_25
Epoch: 25	max: 0.952669/1.0	min: 0.047330953	loss: 34709.140625	train_loss: 34893.73029407438	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_26
Epoch: 26	max: 0.952843/1.0	min: 0.047156934	loss: 34707.88671875	train_loss: 34891.22089497786	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_27
Epoch: 27	max: 0.9528755/1.0	min: 0.04712451	loss: 34706.703125	train_loss: 34888.36399543618	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_28
Epoch: 28	max: 0.9530419/1.0	min: 0.0469581	loss: 34705.15234375	train_loss: 34885.06667044082	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_29
Epoch: 29	max: 0.95347565/1.0	min: 0.046524428	loss: 34702.99609375	train_loss: 34881.146141072095	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_30
Epoch: 30	max: 0.9536562/1.0	min: 0.046343755	loss: 34700.86328125	train_loss: 34876.43046265329	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_31
Epoch: 31	max: 0.9540058/1.0	min: 0.045994215	loss: 34698.015625	train_loss: 34870.50819475412	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_32
Epoch: 32	max: 0.9545203/1.0	min: 0.045479696	loss: 34694.125	train_loss: 34862.70075550833	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_33
Epoch: 33	max: 0.95488906/1.0	min: 0.045110904	loss: 34688.765625	train_loss: 34851.9968389036	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_34
Epoch: 34	max: 0.95525086/1.0	min: 0.044749122	loss: 34679.90234375	train_loss: 34835.433877779324	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_35
Epoch: 35	max: 0.9562889/1.0	min: 0.04371115	loss: 34663.9609375	train_loss: 34808.88014688235	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_36
Epoch: 36	max: 0.9616938/1.0	min: 0.038306233	loss: 34638.125	train_loss: 34773.3005252849	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_37
Epoch: 37	max: 0.9686716/1.0	min: 0.031328335	loss: 34610.12890625	train_loss: 34734.59883107658	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_38
Epoch: 38	max: 0.9747824/1.0	min: 0.025217569	loss: 34585.4765625	train_loss: 34698.525581510126	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_39
Epoch: 39	max: 0.9793075/1.0	min: 0.020692492	loss: 34566.12109375	train_loss: 34668.7102436362	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_40
Epoch: 40	max: 0.9828173/1.0	min: 0.017182682	loss: 34550.765625	train_loss: 34644.91479216989	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_41
Epoch: 41	max: 0.98568165/1.0	min: 0.01431835	loss: 34538.71875	train_loss: 34625.615408808684	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_42
Epoch: 42	max: 0.98783475/1.0	min: 0.012165253	loss: 34529.859375	train_loss: 34610.96978063452	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_43
Epoch: 43	max: 0.9892958/1.0	min: 0.010704266	loss: 34522.87890625	train_loss: 34600.652989711074	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_44
Epoch: 44	max: 0.990476/1.0	min: 0.009523997	loss: 34517.171875	train_loss: 34593.026754401246	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_45
Epoch: 45	max: 0.9913105/1.0	min: 0.008689506	loss: 34511.83984375	train_loss: 34586.73413645408	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_46
Epoch: 46	max: 0.9921193/1.0	min: 0.0078807175	loss: 34507.5390625	train_loss: 34581.301071569585	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_47
Epoch: 47	max: 0.99264866/1.0	min: 0.007351308	loss: 34502.44921875	train_loss: 34576.29306213613	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_48
Epoch: 48	max: 0.99310195/1.0	min: 0.006898028	loss: 34497.8671875	train_loss: 34571.72122400672	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_49
Epoch: 49	max: 0.9935254/1.0	min: 0.006474562	loss: 34493.9296875	train_loss: 34567.41736004661	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_50
Epoch: 50	max: 0.9938414/1.0	min: 0.006158602	loss: 34490.171875	train_loss: 34563.35459875898	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_51
Epoch: 51	max: 0.9940162/1.0	min: 0.005983863	loss: 34486.203125	train_loss: 34559.44420831785	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_52
Epoch: 52	max: 0.9941901/1.0	min: 0.00580992	loss: 34482.69140625	train_loss: 34555.623045665336	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_53
Epoch: 53	max: 0.9945058/1.0	min: 0.0054941103	loss: 34479.9453125	train_loss: 34551.819515572744	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_54
Epoch: 54	max: 0.9947162/1.0	min: 0.005283764	loss: 34477.0703125	train_loss: 34548.03114306562	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_55
Epoch: 55	max: 0.994806/1.0	min: 0.00519399	loss: 34473.58203125	train_loss: 34544.269043029235	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_56
Epoch: 56	max: 0.99499595/1.0	min: 0.0050040316	loss: 34470.67578125	train_loss: 34540.47913957017	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_57
Epoch: 57	max: 0.9950523/1.0	min: 0.0049477885	loss: 34467.17578125	train_loss: 34536.69422960795	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_58
Epoch: 58	max: 0.99510866/1.0	min: 0.004891316	loss: 34463.625	train_loss: 34532.908360623376	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_59
Epoch: 59	max: 0.99523664/1.0	min: 0.0047633103	loss: 34460.39453125	train_loss: 34529.10726389276	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_60
Epoch: 60	max: 0.99546355/1.0	min: 0.004536502	loss: 34457.76953125	train_loss: 34525.35775017806	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_61
Epoch: 61	max: 0.99561596/1.0	min: 0.004384097	loss: 34454.75390625	train_loss: 34521.54841659699	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_62
Epoch: 62	max: 0.99572104/1.0	min: 0.004278968	loss: 34451.46484375	train_loss: 34517.80025335222	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_63
Epoch: 63	max: 0.9958924/1.0	min: 0.0041076173	loss: 34448.80859375	train_loss: 34514.07245989719	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_64
Epoch: 64	max: 0.99596834/1.0	min: 0.0040317	loss: 34445.68359375	train_loss: 34510.480552458816	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_65
Epoch: 65	max: 0.99606425/1.0	min: 0.0039357534	loss: 34442.640625	train_loss: 34507.00841636473	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_66
Epoch: 66	max: 0.9961941/1.0	min: 0.003805922	loss: 34440.1015625	train_loss: 34503.67260612149	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_67
Epoch: 67	max: 0.9963033/1.0	min: 0.0036967255	loss: 34437.6953125	train_loss: 34500.45547900796	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_68
Epoch: 68	max: 0.9963775/1.0	min: 0.0036224735	loss: 34435.1640625	train_loss: 34497.3288203154	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_69
Epoch: 69	max: 0.9965668/1.0	min: 0.0034332203	loss: 34433.4609375	train_loss: 34494.33674362071	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_70
Epoch: 70	max: 0.99658597/1.0	min: 0.0034139906	loss: 34430.99609375	train_loss: 34491.52095381596	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_71
Epoch: 71	max: 0.9967789/1.0	min: 0.0032211137	loss: 34429.390625	train_loss: 34488.96495455531	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_72
Epoch: 72	max: 0.9968172/1.0	min: 0.0031828147	loss: 34427.28125	train_loss: 34486.64416447959	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_73
Epoch: 73	max: 0.9969222/1.0	min: 0.0030777215	loss: 34425.5546875	train_loss: 34484.41271057847	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_74
Epoch: 74	max: 0.99704176/1.0	min: 0.0029582107	loss: 34424.10546875	train_loss: 34482.362176583985	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_75
Epoch: 75	max: 0.9971027/1.0	min: 0.0028973373	loss: 34422.4765625	train_loss: 34480.38642552722	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_76
Epoch: 76	max: 0.99724615/1.0	min: 0.002753823	loss: 34421.35546875	train_loss: 34478.521994127805	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_77
Epoch: 77	max: 0.99727863/1.0	min: 0.0027214044	loss: 34419.9140625	train_loss: 34476.75175933668	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_78
Epoch: 78	max: 0.9973132/1.0	min: 0.0026868072	loss: 34418.515625	train_loss: 34475.06063614827	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_79
Epoch: 79	max: 0.9974579/1.0	min: 0.0025421095	loss: 34417.7109375	train_loss: 34473.3896011396	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_80
Epoch: 80	max: 0.9973508/1.0	min: 0.0026491482	loss: 34415.88671875	train_loss: 34471.81089646817	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_81
Epoch: 81	max: 0.99749184/1.0	min: 0.0025081567	loss: 34415.10546875	train_loss: 34470.24369183931	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_82
Epoch: 82	max: 0.99736613/1.0	min: 0.0026339	loss: 34413.4609375	train_loss: 34468.72773103633	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_83
Epoch: 83	max: 0.9974739/1.0	min: 0.002526037	loss: 34412.55078125	train_loss: 34467.24735422086	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_84
Epoch: 84	max: 0.99739885/1.0	min: 0.0026011579	loss: 34411.20703125	train_loss: 34465.78911185433	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_85
Epoch: 85	max: 0.9974293/1.0	min: 0.0025707153	loss: 34410.1875	train_loss: 34464.33537621547	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_86
Epoch: 86	max: 0.9975768/1.0	min: 0.0024232212	loss: 34409.55078125	train_loss: 34462.93882143797	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_87
Epoch: 87	max: 0.99744177/1.0	min: 0.002558212	loss: 34408.0390625	train_loss: 34461.55321122491	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_88
Epoch: 88	max: 0.9973246/1.0	min: 0.0026753559	loss: 34406.83984375	train_loss: 34460.18650517156	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_89
Epoch: 89	max: 0.9975074/1.0	min: 0.0024926006	loss: 34406.15625	train_loss: 34458.82040878933	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_90
Epoch: 90	max: 0.9973851/1.0	min: 0.002614915	loss: 34404.875	train_loss: 34457.49524262975	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_91
Epoch: 91	max: 0.99751115/1.0	min: 0.0024888406	loss: 34404.17578125	train_loss: 34456.18043362133	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_92
Epoch: 92	max: 0.99744403/1.0	min: 0.0025559545	loss: 34403.03125	train_loss: 34454.88430619426	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_93
Epoch: 93	max: 0.99746907/1.0	min: 0.0025309585	loss: 34402.18359375	train_loss: 34453.634674416266	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_94
Epoch: 94	max: 0.997412/1.0	min: 0.002587994	loss: 34401.10546875	train_loss: 34452.34587707482	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_95
Epoch: 95	max: 0.9973762/1.0	min: 0.002623837	loss: 34400.1015625	train_loss: 34451.11261399883	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_96
Epoch: 96	max: 0.99755824/1.0	min: 0.0024417078	loss: 34399.62109375	train_loss: 34449.90496146491	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_97
Epoch: 97	max: 0.99747807/1.0	min: 0.002521993	loss: 34398.38671875	train_loss: 34448.69991309767	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_98
Epoch: 98	max: 0.9975936/1.0	min: 0.002406414	loss: 34397.6796875	train_loss: 34447.56337628128	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_99
Epoch: 99	max: 0.99747294/1.0	min: 0.00252706	loss: 34396.41796875	train_loss: 34446.42460255249	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_100
Epoch: 100	max: 0.9977187/1.0	min: 0.0022813894	loss: 34396.1640625	train_loss: 34445.31340821643	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_101
Epoch: 101	max: 0.99762696/1.0	min: 0.002373029	loss: 34394.953125	train_loss: 34444.23787480258	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_102
Epoch: 102	max: 0.9977133/1.0	min: 0.00228664	loss: 34394.28515625	train_loss: 34443.187973704786	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_103
Epoch: 103	max: 0.99775034/1.0	min: 0.00224962	loss: 34393.546875	train_loss: 34442.19239333658	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_104
Epoch: 104	max: 0.99781644/1.0	min: 0.002183587	loss: 34392.8984375	train_loss: 34441.22945021213	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_105
Epoch: 105	max: 0.99784374/1.0	min: 0.002156247	loss: 34392.1640625	train_loss: 34440.309222775766	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_106
Epoch: 106	max: 0.9977233/1.0	min: 0.0022767272	loss: 34391.078125	train_loss: 34439.47695152824	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_107
Epoch: 107	max: 0.99786454/1.0	min: 0.0021354416	loss: 34390.6640625	train_loss: 34438.59394064319	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_108
Epoch: 108	max: 0.9978248/1.0	min: 0.0021752485	loss: 34389.828125	train_loss: 34437.780214526814	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_109
Epoch: 109	max: 0.99791914/1.0	min: 0.0020808915	loss: 34389.375	train_loss: 34436.99598294469	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_110
Epoch: 110	max: 0.99790907/1.0	min: 0.0020910108	loss: 34388.6171875	train_loss: 34436.26621338102	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_111
Epoch: 111	max: 0.99795556/1.0	min: 0.002044371	loss: 34388.05078125	train_loss: 34435.56009131519	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_112
Epoch: 112	max: 0.9979017/1.0	min: 0.0020982798	loss: 34387.3359375	train_loss: 34434.8791622151	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_113
Epoch: 113	max: 0.99810433/1.0	min: 0.0018956511	loss: 34387.13671875	train_loss: 34434.26623370339	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_114
Epoch: 114	max: 0.99809045/1.0	min: 0.0019094951	loss: 34386.515625	train_loss: 34433.61714395206	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_115
Epoch: 115	max: 0.99814177/1.0	min: 0.0018582173	loss: 34386.078125	train_loss: 34433.01382501858	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_116
Epoch: 116	max: 0.9981535/1.0	min: 0.001846465	loss: 34385.4609375	train_loss: 34432.45168404713	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_117
Epoch: 117	max: 0.998073/1.0	min: 0.0019269427	loss: 34384.7734375	train_loss: 34431.87280663555	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_118
Epoch: 118	max: 0.99823594/1.0	min: 0.0017640372	loss: 34384.68359375	train_loss: 34431.33629798015	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_119
Epoch: 119	max: 0.9981669/1.0	min: 0.0018330398	loss: 34383.87890625	train_loss: 34430.80665344745	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_120
Epoch: 120	max: 0.99818784/1.0	min: 0.0018121196	loss: 34383.4296875	train_loss: 34430.28305046529	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_121
Epoch: 121	max: 0.99822646/1.0	min: 0.0017735993	loss: 34383.0390625	train_loss: 34429.78143435294	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_122
Epoch: 122	max: 0.9983286/1.0	min: 0.0016714225	loss: 34382.74609375	train_loss: 34429.2903166806	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_123
Epoch: 123	max: 0.99831533/1.0	min: 0.0016847198	loss: 34382.24609375	train_loss: 34428.81349192525	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_124
Epoch: 124	max: 0.99829036/1.0	min: 0.0017096038	loss: 34381.703125	train_loss: 34428.350355738265	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_125
Epoch: 125	max: 0.9983479/1.0	min: 0.0016521022	loss: 34381.42578125	train_loss: 34427.89134208937	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_126
Epoch: 126	max: 0.99840575/1.0	min: 0.0015942194	loss: 34381.1015625	train_loss: 34427.43993142652	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_127
Epoch: 127	max: 0.9982735/1.0	min: 0.0017265083	loss: 34380.37890625	train_loss: 34427.04789789267	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_128
Epoch: 128	max: 0.9983741/1.0	min: 0.0016258205	loss: 34380.0859375	train_loss: 34426.59181260064	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_129
Epoch: 129	max: 0.9983144/1.0	min: 0.0016856213	loss: 34379.62890625	train_loss: 34426.17651624241	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_130
Epoch: 130	max: 0.9985214/1.0	min: 0.001478637	loss: 34379.5546875	train_loss: 34425.752418846	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_131
Epoch: 131	max: 0.9983241/1.0	min: 0.0016759336	loss: 34378.828125	train_loss: 34425.38263153413	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_132
Epoch: 132	max: 0.9983925/1.0	min: 0.0016074857	loss: 34378.51953125	train_loss: 34424.99007929595	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_133
Epoch: 133	max: 0.9984555/1.0	min: 0.0015444349	loss: 34378.265625	train_loss: 34424.59069680571	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_134
Epoch: 134	max: 0.9984421/1.0	min: 0.0015579292	loss: 34377.84375	train_loss: 34424.211822007	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_135
Epoch: 135	max: 0.9984653/1.0	min: 0.001534668	loss: 34377.515625	train_loss: 34423.85099782841	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_136
Epoch: 136	max: 0.99849737/1.0	min: 0.0015025908	loss: 34377.2421875	train_loss: 34423.50859249195	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_137
Epoch: 137	max: 0.99860245/1.0	min: 0.0013975124	loss: 34377.0859375	train_loss: 34423.14124144525	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_138
Epoch: 138	max: 0.9984511/1.0	min: 0.001548859	loss: 34376.5078125	train_loss: 34422.78917814397	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_139
Epoch: 139	max: 0.9985567/1.0	min: 0.0014433174	loss: 34376.30859375	train_loss: 34422.48806592964	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_140
Epoch: 140	max: 0.9986866/1.0	min: 0.0013134305	loss: 34376.24609375	train_loss: 34422.14472576412	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_141
Epoch: 141	max: 0.9986399/1.0	min: 0.0013601026	loss: 34375.80859375	train_loss: 34421.83515460486	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_142
Epoch: 142	max: 0.99864095/1.0	min: 0.001359081	loss: 34375.46875	train_loss: 34421.4946276361	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_143
Epoch: 143	max: 0.998555/1.0	min: 0.0014450082	loss: 34375.10546875	train_loss: 34421.19825827605	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_144
Epoch: 144	max: 0.99864095/1.0	min: 0.0013590052	loss: 34374.87109375	train_loss: 34420.90121440682	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_145
Epoch: 145	max: 0.9986228/1.0	min: 0.0013772806	loss: 34374.56640625	train_loss: 34420.597653346806	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_146
Epoch: 146	max: 0.9987484/1.0	min: 0.0012515867	loss: 34374.453125	train_loss: 34420.30107931144	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_147
Epoch: 147	max: 0.9986596/1.0	min: 0.0013403497	loss: 34374.03125	train_loss: 34420.059905026785	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_148
Epoch: 148	max: 0.99868816/1.0	min: 0.0013118665	loss: 34373.765625	train_loss: 34419.76410856404	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_149
Epoch: 149	max: 0.9987436/1.0	min: 0.0012564888	loss: 34373.55859375	train_loss: 34419.474718486774	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_150
Epoch: 150	max: 0.99877447/1.0	min: 0.0012254646	loss: 34373.3515625	train_loss: 34419.22080449492	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_151
Epoch: 151	max: 0.9987664/1.0	min: 0.0012335759	loss: 34373.06640625	train_loss: 34418.945665238294	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_152
Epoch: 152	max: 0.9988864/1.0	min: 0.0011136386	loss: 34373.0703125	train_loss: 34418.71412666063	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_153
Epoch: 153	max: 0.9987866/1.0	min: 0.0012133757	loss: 34372.57421875	train_loss: 34418.448234082745	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_154
Epoch: 154	max: 0.99876225/1.0	min: 0.0012377846	loss: 34372.3828125	train_loss: 34418.22656491933	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_155
Epoch: 155	max: 0.9988984/1.0	min: 0.0011015512	loss: 34372.30859375	train_loss: 34417.97024611359	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_156
Epoch: 156	max: 0.9987692/1.0	min: 0.0012307375	loss: 34371.9609375	train_loss: 34417.730184720676	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_157
Epoch: 157	max: 0.9989324/1.0	min: 0.0010675652	loss: 34371.9375	train_loss: 34417.50231481482	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_158
Epoch: 158	max: 0.99886596/1.0	min: 0.001134008	loss: 34371.56640625	train_loss: 34417.26763207606	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_159
Epoch: 159	max: 0.9989126/1.0	min: 0.0010874891	loss: 34371.4140625	train_loss: 34417.04730951165	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_160
Epoch: 160	max: 0.99896145/1.0	min: 0.0010385035	loss: 34371.2890625	train_loss: 34416.82443745742	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_161
Epoch: 161	max: 0.9988869/1.0	min: 0.0011131306	loss: 34370.94921875	train_loss: 34416.60903387449	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_162
Epoch: 162	max: 0.99894685/1.0	min: 0.0010531503	loss: 34370.80859375	train_loss: 34416.39433480042	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_163
Epoch: 163	max: 0.999019/1.0	min: 0.0009809551	loss: 34370.75390625	train_loss: 34416.18490696225	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_164
Epoch: 164	max: 0.99888533/1.0	min: 0.0011146192	loss: 34370.34375	train_loss: 34416.00622106482	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_165
Epoch: 165	max: 0.9989506/1.0	min: 0.0010493395	loss: 34370.171875	train_loss: 34415.77361217562	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_166
Epoch: 166	max: 0.9990244/1.0	min: 0.0009755986	loss: 34370.09375	train_loss: 34415.57768032717	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_167
Epoch: 167	max: 0.99895716/1.0	min: 0.0010428529	loss: 34369.83203125	train_loss: 34415.385917467946	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_168
Epoch: 168	max: 0.99906594/1.0	min: 0.000934131	loss: 34369.86328125	train_loss: 34415.20490465905	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_169
Epoch: 169	max: 0.99902236/1.0	min: 0.0009776261	loss: 34369.5390625	train_loss: 34415.01777965518	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_170
Epoch: 170	max: 0.9990075/1.0	min: 0.0009925356	loss: 34369.359375	train_loss: 34414.80805182011	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_171
Epoch: 171	max: 0.99906236/1.0	min: 0.00093771034	loss: 34369.19140625	train_loss: 34414.63104832466	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_172
Epoch: 172	max: 0.9990946/1.0	min: 0.0009054479	loss: 34369.1484375	train_loss: 34414.44643652066	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_173
Epoch: 173	max: 0.99906796/1.0	min: 0.0009320177	loss: 34368.92578125	train_loss: 34414.29442276725	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_174
Epoch: 174	max: 0.9990374/1.0	min: 0.0009626169	loss: 34368.6640625	train_loss: 34414.094283704166	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_175
Epoch: 175	max: 0.99909973/1.0	min: 0.0009003313	loss: 34368.5390625	train_loss: 34413.92111387882	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_176
Epoch: 176	max: 0.9990615/1.0	min: 0.0009385327	loss: 34368.34375	train_loss: 34413.737464484235	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_177
Epoch: 177	max: 0.99911815/1.0	min: 0.0008818048	loss: 34368.26953125	train_loss: 34413.575180191685	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_178
Epoch: 178	max: 0.9990331/1.0	min: 0.0009668671	loss: 34368.01953125	train_loss: 34413.40546129846	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_179
Epoch: 179	max: 0.99911183/1.0	min: 0.0008881315	loss: 34367.93359375	train_loss: 34413.23252324492	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_180
Epoch: 180	max: 0.99904853/1.0	min: 0.0009514762	loss: 34367.7109375	train_loss: 34413.07608695652	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_181
Epoch: 181	max: 0.9990926/1.0	min: 0.0009074515	loss: 34367.59375	train_loss: 34412.934395999786	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_182
Epoch: 182	max: 0.9991942/1.0	min: 0.00080584944	loss: 34367.578125	train_loss: 34412.769837053296	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_183
Epoch: 183	max: 0.9991418/1.0	min: 0.0008581741	loss: 34367.30859375	train_loss: 34412.59279388084	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_184
Epoch: 184	max: 0.9991456/1.0	min: 0.00085440953	loss: 34367.19921875	train_loss: 34412.43552002044	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_185
Epoch: 185	max: 0.99906117/1.0	min: 0.000938809	loss: 34367.00390625	train_loss: 34412.290961190076	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_186
Epoch: 186	max: 0.9991098/1.0	min: 0.0008901576	loss: 34366.8671875	train_loss: 34412.14070822495	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_187
Epoch: 187	max: 0.9991623/1.0	min: 0.00083767716	loss: 34366.73828125	train_loss: 34412.03095919655	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_188
Epoch: 188	max: 0.99916124/1.0	min: 0.00083879585	loss: 34366.59375	train_loss: 34411.83870279403	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_189
Epoch: 189	max: 0.99912816/1.0	min: 0.0008718145	loss: 34366.4609375	train_loss: 34411.69748941301	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_190
Epoch: 190	max: 0.9992293/1.0	min: 0.0007706735	loss: 34366.4375	train_loss: 34411.553962668775	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_191
Epoch: 191	max: 0.9992111/1.0	min: 0.0007888855	loss: 34366.234375	train_loss: 34411.3929272343	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_192
Epoch: 192	max: 0.9992353/1.0	min: 0.0007647841	loss: 34366.0859375	train_loss: 34411.25806507804	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_193
Epoch: 193	max: 0.9991068/1.0	min: 0.00089317834	loss: 34365.984375	train_loss: 34411.11192739301	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_194
Epoch: 194	max: 0.99924856/1.0	min: 0.0007514123	loss: 34365.921875	train_loss: 34411.0133682491	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_195
Epoch: 195	max: 0.9992848/1.0	min: 0.0007151997	loss: 34365.80078125	train_loss: 34410.8461446527	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_196
Epoch: 196	max: 0.9992835/1.0	min: 0.0007165731	loss: 34365.73828125	train_loss: 34410.704890626934	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_197
Epoch: 197	max: 0.99929607/1.0	min: 0.00070389797	loss: 34365.61328125	train_loss: 34410.58073836012	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_198
Epoch: 198	max: 0.99933547/1.0	min: 0.00066447194	loss: 34365.48828125	train_loss: 34410.43506905735	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_199
Epoch: 199	max: 0.9993255/1.0	min: 0.0006745327	loss: 34365.41015625	train_loss: 34410.33913391862	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_200
Epoch: 200	max: 0.99925894/1.0	min: 0.0007410675	loss: 34365.19921875	train_loss: 34410.19872133578	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_201
Epoch: 201	max: 0.99941456/1.0	min: 0.0005854596	loss: 34365.39453125	train_loss: 34410.03961797814	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_202
Epoch: 202	max: 0.9993444/1.0	min: 0.00065553567	loss: 34365.03125	train_loss: 34409.95094760312	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_203
Epoch: 203	max: 0.99928254/1.0	min: 0.00071742374	loss: 34364.86328125	train_loss: 34409.792055211044	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_204
Epoch: 204	max: 0.9993772/1.0	min: 0.00062287936	loss: 34364.890625	train_loss: 34409.69966874536	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_205
Epoch: 205	max: 0.99932766/1.0	min: 0.0006723237	loss: 34364.65234375	train_loss: 34409.558064400626	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_206
Epoch: 206	max: 0.9992404/1.0	min: 0.0007596351	loss: 34364.484375	train_loss: 34409.42802396879	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_207
Epoch: 207	max: 0.99931216/1.0	min: 0.0006878613	loss: 34364.46484375	train_loss: 34409.340969222256	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_208
Epoch: 208	max: 0.99930334/1.0	min: 0.0006966079	loss: 34364.25390625	train_loss: 34409.18340359067	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_209
Epoch: 209	max: 0.99922144/1.0	min: 0.0007785351	loss: 34364.1640625	train_loss: 34409.073557305215	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_210
Epoch: 210	max: 0.99933726/1.0	min: 0.00066272833	loss: 34364.07421875	train_loss: 34408.967874202586	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_211
Epoch: 211	max: 0.99941254/1.0	min: 0.0005874713	loss: 34364.08984375	train_loss: 34408.86484607256	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_212
Epoch: 212	max: 0.99940324/1.0	min: 0.00059676316	loss: 34363.9609375	train_loss: 34408.730603748605	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_213
Epoch: 213	max: 0.99940526/1.0	min: 0.0005947954	loss: 34363.8984375	train_loss: 34408.604319568316	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_214
Epoch: 214	max: 0.99931526/1.0	min: 0.0006846879	loss: 34363.6328125	train_loss: 34408.49648035891	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_215
Epoch: 215	max: 0.9993723/1.0	min: 0.0006277236	loss: 34363.5859375	train_loss: 34408.4192940589	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_216
Epoch: 216	max: 0.99933857/1.0	min: 0.0006613926	loss: 34363.48828125	train_loss: 34408.27331846897	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_217
Epoch: 217	max: 0.9993013/1.0	min: 0.000698686	loss: 34363.43359375	train_loss: 34408.200981957605	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_218
Epoch: 218	max: 0.99937266/1.0	min: 0.0006274191	loss: 34363.3359375	train_loss: 34408.0564308691	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_219
Epoch: 219	max: 0.99941707/1.0	min: 0.0005829511	loss: 34363.234375	train_loss: 34407.93930482008	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_220
Epoch: 220	max: 0.9994252/1.0	min: 0.0005748925	loss: 34363.23828125	train_loss: 34407.8512852448	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_221
Epoch: 221	max: 0.9993656/1.0	min: 0.00063436147	loss: 34363.02734375	train_loss: 34407.726898302986	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_222
Epoch: 222	max: 0.99943393/1.0	min: 0.00056605204	loss: 34363.01171875	train_loss: 34407.63782825468	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_223
Epoch: 223	max: 0.99939096/1.0	min: 0.0006090202	loss: 34362.83984375	train_loss: 34407.54732693082	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_224
Epoch: 224	max: 0.99944097/1.0	min: 0.0005590149	loss: 34362.796875	train_loss: 34407.47597847377	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_225
Epoch: 225	max: 0.9994111/1.0	min: 0.000588852	loss: 34362.625	train_loss: 34407.31387466323	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_226
Epoch: 226	max: 0.99940205/1.0	min: 0.00059798046	loss: 34362.57421875	train_loss: 34407.220744011676	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_227
Epoch: 227	max: 0.9994192/1.0	min: 0.0005808245	loss: 34362.5390625	train_loss: 34407.106540996996	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_228
Epoch: 228	max: 0.99942243/1.0	min: 0.00057760515	loss: 34362.41015625	train_loss: 34407.01077714682	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_229
Epoch: 229	max: 0.99946326/1.0	min: 0.00053672714	loss: 34362.41796875	train_loss: 34406.90728402158	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_230
Epoch: 230	max: 0.99956685/1.0	min: 0.00043314253	loss: 34362.51171875	train_loss: 34406.80658812554	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_231
Epoch: 231	max: 0.99943966/1.0	min: 0.0005603004	loss: 34362.1796875	train_loss: 34406.75155272591	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_232
Epoch: 232	max: 0.99947196/1.0	min: 0.0005280529	loss: 34362.21484375	train_loss: 34406.61289125402	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_233
Epoch: 233	max: 0.9994404/1.0	min: 0.00055962853	loss: 34361.9453125	train_loss: 34406.515924513034	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_234
Epoch: 234	max: 0.99946874/1.0	min: 0.0005312572	loss: 34361.98828125	train_loss: 34406.42158177722	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_235
Epoch: 235	max: 0.99941754/1.0	min: 0.0005824771	loss: 34361.82421875	train_loss: 34406.32989207853	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_236
Epoch: 236	max: 0.99944204/1.0	min: 0.0005579673	loss: 34361.77734375	train_loss: 34406.239687848385	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_237
Epoch: 237	max: 0.9995678/1.0	min: 0.00043215085	loss: 34361.87890625	train_loss: 34406.15483856296	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_238
Epoch: 238	max: 0.99945134/1.0	min: 0.0005487104	loss: 34361.60546875	train_loss: 34406.05647199771	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_239
Epoch: 239	max: 0.99944776/1.0	min: 0.0005522378	loss: 34361.53125	train_loss: 34405.967993233615	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_240
Epoch: 240	max: 0.999534/1.0	min: 0.00046601976	loss: 34361.55078125	train_loss: 34405.851528629384	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_241
Epoch: 241	max: 0.99946123/1.0	min: 0.00053876813	loss: 34361.40625	train_loss: 34405.766879664465	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_242
Epoch: 242	max: 0.99941444/1.0	min: 0.0005855346	loss: 34361.296875	train_loss: 34405.688006123804	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_243
Epoch: 243	max: 0.9994727/1.0	min: 0.0005273173	loss: 34361.24609375	train_loss: 34405.613238669794	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_244
Epoch: 244	max: 0.99947804/1.0	min: 0.00052193867	loss: 34361.09375	train_loss: 34405.501915625384	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_245
Epoch: 245	max: 0.9994641/1.0	min: 0.0005358663	loss: 34361.1640625	train_loss: 34405.420639206306	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_246
Epoch: 246	max: 0.9995441/1.0	min: 0.00045592504	loss: 34360.9765625	train_loss: 34405.31825897281	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_247
Epoch: 247	max: 0.9995289/1.0	min: 0.00047111826	loss: 34361.03515625	train_loss: 34405.225263319866	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_248
Epoch: 248	max: 0.9995407/1.0	min: 0.0004593022	loss: 34360.8515625	train_loss: 34405.14924071752	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_249
Epoch: 249	max: 0.9994898/1.0	min: 0.000510239	loss: 34360.828125	train_loss: 34405.1053264934	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_250
Epoch: 250	max: 0.9994917/1.0	min: 0.0005082401	loss: 34360.71875	train_loss: 34405.00487059489	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_251
Epoch: 251	max: 0.99952555/1.0	min: 0.00047447445	loss: 34360.63671875	train_loss: 34404.89949281169	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_252
Epoch: 252	max: 0.9995173/1.0	min: 0.00048271005	loss: 34360.58984375	train_loss: 34404.81719930633	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_253
Epoch: 253	max: 0.9996043/1.0	min: 0.00039568948	loss: 34360.6796875	train_loss: 34404.72065014167	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_254
Epoch: 254	max: 0.9995808/1.0	min: 0.0004191445	loss: 34360.515625	train_loss: 34404.69229559566	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_255
Epoch: 255	max: 0.99954563/1.0	min: 0.00045439432	loss: 34360.38671875	train_loss: 34404.5870537788	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_256
Epoch: 256	max: 0.99956197/1.0	min: 0.00043798645	loss: 34360.3203125	train_loss: 34404.485408537716	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_257
Epoch: 257	max: 0.999509/1.0	min: 0.000491076	loss: 34360.171875	train_loss: 34404.42470706754	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_258
Epoch: 258	max: 0.99953663/1.0	min: 0.0004633483	loss: 34360.24609375	train_loss: 34404.33957472052	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_259
Epoch: 259	max: 0.9995003/1.0	min: 0.0004997394	loss: 34360.09375	train_loss: 34404.231597609316	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_260
Epoch: 260	max: 0.9995167/1.0	min: 0.0004832381	loss: 34360.0859375	train_loss: 34404.17665946674	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_261
Epoch: 261	max: 0.99957377/1.0	min: 0.00042628366	loss: 34359.98046875	train_loss: 34404.07725646058	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_262
Epoch: 262	max: 0.99951255/1.0	min: 0.0004873895	loss: 34359.9375	train_loss: 34403.998533402235	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_263
Epoch: 263	max: 0.99953544/1.0	min: 0.00046463232	loss: 34359.7734375	train_loss: 34403.93402245525	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_264
Epoch: 264	max: 0.9995963/1.0	min: 0.00040367295	loss: 34359.8359375	train_loss: 34403.85120056825	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_265
Epoch: 265	max: 0.9995906/1.0	min: 0.000409384	loss: 34359.80078125	train_loss: 34403.76931254258	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_266
Epoch: 266	max: 0.9995579/1.0	min: 0.0004420372	loss: 34359.59375	train_loss: 34403.687406130004	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_267
Epoch: 267	max: 0.9995615/1.0	min: 0.00043852208	loss: 34359.6640625	train_loss: 34403.61728862799	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_268
Epoch: 268	max: 0.9995602/1.0	min: 0.0004398134	loss: 34359.546875	train_loss: 34403.54905820327	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_269
Epoch: 269	max: 0.99965477/1.0	min: 0.00034519986	loss: 34359.51171875	train_loss: 34403.47965440357	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_270
Epoch: 270	max: 0.9996755/1.0	min: 0.00032444386	loss: 34359.515625	train_loss: 34403.39701348244	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_271
Epoch: 271	max: 0.9996543/1.0	min: 0.00034575982	loss: 34359.41015625	train_loss: 34403.33581217871	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_272
Epoch: 272	max: 0.999608/1.0	min: 0.00039206835	loss: 34359.24609375	train_loss: 34403.251424501424	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_273
Epoch: 273	max: 0.99965036/1.0	min: 0.00034961302	loss: 34359.2890625	train_loss: 34403.1773126858	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_274
Epoch: 274	max: 0.99961495/1.0	min: 0.00038500477	loss: 34359.18359375	train_loss: 34403.12902479716	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_275
Epoch: 275	max: 0.99961495/1.0	min: 0.0003850297	loss: 34359.078125	train_loss: 34403.05455734005	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_276
Epoch: 276	max: 0.9996735/1.0	min: 0.00032651107	loss: 34359.1484375	train_loss: 34402.950605509875	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_277
Epoch: 277	max: 0.99962926/1.0	min: 0.00037075137	loss: 34359.02734375	train_loss: 34402.88955468847	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_278
Epoch: 278	max: 0.99959666/1.0	min: 0.0004033198	loss: 34358.9375	train_loss: 34402.81442627044	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_279
Epoch: 279	max: 0.9995708/1.0	min: 0.00042918307	loss: 34358.8984375	train_loss: 34402.75242126533	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_280
Epoch: 280	max: 0.9995969/1.0	min: 0.00040308308	loss: 34358.875	train_loss: 34402.684243098134	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_281
Epoch: 281	max: 0.9996238/1.0	min: 0.00037619847	loss: 34358.74609375	train_loss: 34402.61248141955	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_282
Epoch: 282	max: 0.99966836/1.0	min: 0.00033165433	loss: 34358.78125	train_loss: 34402.53039549269	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_283
Epoch: 283	max: 0.99966216/1.0	min: 0.0003377958	loss: 34358.64453125	train_loss: 34402.473266404995	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_284
Epoch: 284	max: 0.9996635/1.0	min: 0.00033649403	loss: 34358.5390625	train_loss: 34402.39642123049	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_285
Epoch: 285	max: 0.9995353/1.0	min: 0.00046466544	loss: 34358.59375	train_loss: 34402.335993628454	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_286
Epoch: 286	max: 0.99959415/1.0	min: 0.00040591147	loss: 34358.484375	train_loss: 34402.30689005791	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_287
Epoch: 287	max: 0.9996069/1.0	min: 0.00039306527	loss: 34358.36328125	train_loss: 34402.226745401334	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_288
Epoch: 288	max: 0.99955446/1.0	min: 0.00044557636	loss: 34358.45703125	train_loss: 34402.13984162099	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_289
Epoch: 289	max: 0.99964464/1.0	min: 0.00035535663	loss: 34358.2421875	train_loss: 34402.07383697975	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_290
Epoch: 290	max: 0.9996966/1.0	min: 0.00030346715	loss: 34358.46484375	train_loss: 34402.0022069127	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_291
Epoch: 291	max: 0.999686/1.0	min: 0.00031398144	loss: 34358.21484375	train_loss: 34401.95011825684	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_292
Epoch: 292	max: 0.9996238/1.0	min: 0.00037623182	loss: 34358.0234375	train_loss: 34401.87610514988	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_293
Epoch: 293	max: 0.99963737/1.0	min: 0.00036266664	loss: 34358.19921875	train_loss: 34401.817241886536	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_294
Epoch: 294	max: 0.999713/1.0	min: 0.00028691423	loss: 34358.03125	train_loss: 34401.738478667314	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_295
Epoch: 295	max: 0.9996691/1.0	min: 0.0003309746	loss: 34357.96484375	train_loss: 34401.68578034033	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_296
Epoch: 296	max: 0.999652/1.0	min: 0.00034796706	loss: 34358.00390625	train_loss: 34401.62002343847	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_297
Epoch: 297	max: 0.99963474/1.0	min: 0.00036526375	loss: 34357.890625	train_loss: 34401.55203059194	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_298
Epoch: 298	max: 0.9996344/1.0	min: 0.0003656496	loss: 34357.8046875	train_loss: 34401.499004203826	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_299
Epoch: 299	max: 0.99955064/1.0	min: 0.0004493437	loss: 34357.87890625	train_loss: 34401.434141970145	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_300
Epoch: 300	max: 0.9996344/1.0	min: 0.00036565415	loss: 34357.75390625	train_loss: 34401.4267809171	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_301
Epoch: 301	max: 0.9996942/1.0	min: 0.00030583842	loss: 34357.63671875	train_loss: 34401.3327778552	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_302
Epoch: 302	max: 0.99961996/1.0	min: 0.000379999	loss: 34357.6796875	train_loss: 34401.25189675461	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_303
Epoch: 303	max: 0.99965453/1.0	min: 0.00034542667	loss: 34357.609375	train_loss: 34401.19935229701	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_304
Epoch: 304	max: 0.9996766/1.0	min: 0.00032340872	loss: 34357.578125	train_loss: 34401.13664665397	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_305
Epoch: 305	max: 0.9996803/1.0	min: 0.0003197323	loss: 34357.39453125	train_loss: 34401.08272317834	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_306
Epoch: 306	max: 0.9996674/1.0	min: 0.0003325478	loss: 34357.3515625	train_loss: 34401.001032569984	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_307
Epoch: 307	max: 0.99964666/1.0	min: 0.0003533828	loss: 34357.44140625	train_loss: 34400.98309323904	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_308
Epoch: 308	max: 0.9996712/1.0	min: 0.0003287406	loss: 34357.2734375	train_loss: 34400.8924153041	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_309
Epoch: 309	max: 0.99972636/1.0	min: 0.0002736533	loss: 34357.265625	train_loss: 34400.83989407206	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_310
Epoch: 310	max: 0.9997348/1.0	min: 0.00026520123	loss: 34357.203125	train_loss: 34400.80652425523	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_311
Epoch: 311	max: 0.99973935/1.0	min: 0.00026062166	loss: 34357.32421875	train_loss: 34400.739145918495	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_312
Epoch: 312	max: 0.9997377/1.0	min: 0.00026235788	loss: 34357.09375	train_loss: 34400.66759568934	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_313
Epoch: 313	max: 0.99977225/1.0	min: 0.00022778993	loss: 34357.15625	train_loss: 34400.64591220349	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_314
Epoch: 314	max: 0.99973553/1.0	min: 0.00026445586	loss: 34357.01171875	train_loss: 34400.55801311083	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_315
Epoch: 315	max: 0.99967015/1.0	min: 0.00032990356	loss: 34357.02734375	train_loss: 34400.494830375945	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_316
Epoch: 316	max: 0.9997125/1.0	min: 0.00028750658	loss: 34356.921875	train_loss: 34400.459802834295	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_317
Epoch: 317	max: 0.99976677/1.0	min: 0.00023320498	loss: 34356.96875	train_loss: 34400.39262530193	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_318
Epoch: 318	max: 0.9997236/1.0	min: 0.00027635437	loss: 34356.89453125	train_loss: 34400.359428709125	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_319
Epoch: 319	max: 0.99973136/1.0	min: 0.000268596	loss: 34356.890625	train_loss: 34400.280753069645	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_320
Epoch: 320	max: 0.99972385/1.0	min: 0.00027608627	loss: 34356.77734375	train_loss: 34400.225966860984	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_321
Epoch: 321	max: 0.9997476/1.0	min: 0.00025243306	loss: 34356.6640625	train_loss: 34400.17516335315	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_322
Epoch: 322	max: 0.99974126/1.0	min: 0.00025879135	loss: 34356.5234375	train_loss: 34400.12772997182	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_323
Epoch: 323	max: 0.9996624/1.0	min: 0.0003375479	loss: 34356.7890625	train_loss: 34400.088772470735	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_324
Epoch: 324	max: 0.9997125/1.0	min: 0.0002874498	loss: 34356.66796875	train_loss: 34400.0372480026	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_325
Epoch: 325	max: 0.99972326/1.0	min: 0.00027671375	loss: 34356.49609375	train_loss: 34399.96593196457	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_326
Epoch: 326	max: 0.9997483/1.0	min: 0.00025167246	loss: 34356.50390625	train_loss: 34399.918178263964	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_327
Epoch: 327	max: 0.99962175/1.0	min: 0.00037826053	loss: 34356.66015625	train_loss: 34399.89538285411	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_328
Epoch: 328	max: 0.99961686/1.0	min: 0.00038307314	loss: 34356.625	train_loss: 34399.86504203828	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_329
Epoch: 329	max: 0.9996525/1.0	min: 0.00034747183	loss: 34356.55859375	train_loss: 34399.82613534312	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_330
Epoch: 330	max: 0.9997255/1.0	min: 0.00027443608	loss: 34356.375	train_loss: 34399.721806097485	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_331
Epoch: 331	max: 0.999728/1.0	min: 0.000272006	loss: 34356.20703125	train_loss: 34399.6723356404	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_332
Epoch: 332	max: 0.9997595/1.0	min: 0.00024054194	loss: 34356.1640625	train_loss: 34399.627624972905	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_333
Epoch: 333	max: 0.9997534/1.0	min: 0.00024661113	loss: 34356.203125	train_loss: 34399.576808400685	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_334
Epoch: 334	max: 0.9997906/1.0	min: 0.00020945448	loss: 34356.1640625	train_loss: 34399.5133029272	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_335
Epoch: 335	max: 0.9996984/1.0	min: 0.00030160733	loss: 34356.21484375	train_loss: 34399.48832092701	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_336
Epoch: 336	max: 0.99979585/1.0	min: 0.00020416733	loss: 34356.08984375	train_loss: 34399.42612140778	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_337
Epoch: 337	max: 0.9997726/1.0	min: 0.00022745549	loss: 34356.11328125	train_loss: 34399.38428538802	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_338
Epoch: 338	max: 0.99974495/1.0	min: 0.00025508937	loss: 34356.05859375	train_loss: 34399.340956157874	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_339
Epoch: 339	max: 0.99976355/1.0	min: 0.00023643882	loss: 34355.87890625	train_loss: 34399.2801990431	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_340
Epoch: 340	max: 0.99977857/1.0	min: 0.00022140179	loss: 34356.0859375	train_loss: 34399.216738085284	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_341
Epoch: 341	max: 0.9997826/1.0	min: 0.0002173433	loss: 34355.94140625	train_loss: 34399.216471475134	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_342
Epoch: 342	max: 0.99981254/1.0	min: 0.000187433	loss: 34355.8515625	train_loss: 34399.13257153475	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_343
Epoch: 343	max: 0.99976164/1.0	min: 0.000238421	loss: 34355.69140625	train_loss: 34399.09327145655	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_344
Epoch: 344	max: 0.9997969/1.0	min: 0.00020312946	loss: 34355.71484375	train_loss: 34399.0498469048	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_345
Epoch: 345	max: 0.9997894/1.0	min: 0.00021056057	loss: 34355.703125	train_loss: 34398.99717083565	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_346
Epoch: 346	max: 0.9997986/1.0	min: 0.00020137016	loss: 34355.71484375	train_loss: 34398.98962301034	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_347
Epoch: 347	max: 0.9997917/1.0	min: 0.00020837721	loss: 34355.6171875	train_loss: 34398.91030431299	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_348
Epoch: 348	max: 0.9998016/1.0	min: 0.00019842472	loss: 34355.5625	train_loss: 34398.872970182245	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_349
Epoch: 349	max: 0.99975973/1.0	min: 0.0002402497	loss: 34355.60546875	train_loss: 34398.80915019587	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_350
Epoch: 350	max: 0.99981564/1.0	min: 0.00018437394	loss: 34355.609375	train_loss: 34398.78277272622	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_351
Epoch: 351	max: 0.99976176/1.0	min: 0.00023818783	loss: 34355.4765625	train_loss: 34398.76221326103	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_352
Epoch: 352	max: 0.99971336/1.0	min: 0.0002866389	loss: 34355.59375	train_loss: 34398.75526252632	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_353
Epoch: 353	max: 0.99972004/1.0	min: 0.000279984	loss: 34355.5234375	train_loss: 34398.67951766304	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_354
Epoch: 354	max: 0.99981886/1.0	min: 0.00018113773	loss: 34355.28515625	train_loss: 34398.60741582668	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_355
Epoch: 355	max: 0.99976796/1.0	min: 0.00023201843	loss: 34355.25390625	train_loss: 34398.553462835225	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_356
Epoch: 356	max: 0.9997731/1.0	min: 0.00022688559	loss: 34355.41015625	train_loss: 34398.52708826877	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_357
Epoch: 357	max: 0.9998037/1.0	min: 0.00019630484	loss: 34355.34765625	train_loss: 34398.48590014555	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_358
Epoch: 358	max: 0.9997578/1.0	min: 0.00024222546	loss: 34355.26171875	train_loss: 34398.45251774821	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_359
Epoch: 359	max: 0.99982446/1.0	min: 0.00017550844	loss: 34355.125	train_loss: 34398.38553763316	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_360
Epoch: 360	max: 0.9998111/1.0	min: 0.00018886785	loss: 34355.1015625	train_loss: 34398.34944074771	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_361
Epoch: 361	max: 0.999759/1.0	min: 0.00024100658	loss: 34355.1484375	train_loss: 34398.34280259042	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_362
Epoch: 362	max: 0.9997625/1.0	min: 0.00023755779	loss: 34355.07421875	train_loss: 34398.292373110984	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_363
Epoch: 363	max: 0.9997931/1.0	min: 0.00020688551	loss: 34355.03125	train_loss: 34398.24263797922	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_364
Epoch: 364	max: 0.9997789/1.0	min: 0.00022109383	loss: 34355.0390625	train_loss: 34398.186137917284	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_365
Epoch: 365	max: 0.9998425/1.0	min: 0.00015750235	loss: 34355.05078125	train_loss: 34398.138647439766	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_366
Epoch: 366	max: 0.9998442/1.0	min: 0.00015581082	loss: 34354.99609375	train_loss: 34398.11993634259	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_367
Epoch: 367	max: 0.9998222/1.0	min: 0.00017788807	loss: 34354.96875	train_loss: 34398.0631043486	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_368
Epoch: 368	max: 0.9998429/1.0	min: 0.0001571489	loss: 34354.82421875	train_loss: 34398.0239750751	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_369
Epoch: 369	max: 0.9998431/1.0	min: 0.00015687567	loss: 34354.83984375	train_loss: 34397.9842356466	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_370
Epoch: 370	max: 0.9998696/1.0	min: 0.00013040059	loss: 34354.7890625	train_loss: 34397.948839399076	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_371
Epoch: 371	max: 0.99984145/1.0	min: 0.0001584779	loss: 34354.6953125	train_loss: 34397.92222918989	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_372
Epoch: 372	max: 0.99985623/1.0	min: 0.00014375949	loss: 34354.67578125	train_loss: 34397.85996338102	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_373
Epoch: 373	max: 0.999859/1.0	min: 0.00014097622	loss: 34354.78125	train_loss: 34397.82843031943	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_374
Epoch: 374	max: 0.9998585/1.0	min: 0.00014143022	loss: 34354.6484375	train_loss: 34397.81588851341	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_375
Epoch: 375	max: 0.9998504/1.0	min: 0.00014958116	loss: 34354.578125	train_loss: 34397.76703111452	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_376
Epoch: 376	max: 0.99982965/1.0	min: 0.00017026985	loss: 34354.57421875	train_loss: 34397.73716013254	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_377
Epoch: 377	max: 0.9998536/1.0	min: 0.0001464028	loss: 34354.62109375	train_loss: 34397.71057895532	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_378
Epoch: 378	max: 0.99986255/1.0	min: 0.00013743718	loss: 34354.63671875	train_loss: 34397.69020239146	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_379
Epoch: 379	max: 0.99986434/1.0	min: 0.00013558514	loss: 34354.6015625	train_loss: 34397.627912873155	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_380
Epoch: 380	max: 0.9998677/1.0	min: 0.00013234717	loss: 34354.3515625	train_loss: 34397.58110803372	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_381
Epoch: 381	max: 0.9998412/1.0	min: 0.0001587379	loss: 34354.44140625	train_loss: 34397.52827035334	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_382
Epoch: 382	max: 0.99982786/1.0	min: 0.0001720576	loss: 34354.5234375	train_loss: 34397.49424296265	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_383
Epoch: 383	max: 0.9998411/1.0	min: 0.00015889175	loss: 34354.375	train_loss: 34397.47102997646	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_384
Epoch: 384	max: 0.99987316/1.0	min: 0.00012677534	loss: 34354.23828125	train_loss: 34397.43746274232	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_385
Epoch: 385	max: 0.99987316/1.0	min: 0.00012681307	loss: 34354.25390625	train_loss: 34397.4127115462	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_386
Epoch: 386	max: 0.9998419/1.0	min: 0.00015809879	loss: 34354.16015625	train_loss: 34397.373634530224	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_387
Epoch: 387	max: 0.9998235/1.0	min: 0.00017649152	loss: 34354.24609375	train_loss: 34397.33785360925	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_388
Epoch: 388	max: 0.99984753/1.0	min: 0.00015244777	loss: 34354.3046875	train_loss: 34397.284453676606	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_389
Epoch: 389	max: 0.99982566/1.0	min: 0.00017438446	loss: 34354.18359375	train_loss: 34397.261455043044	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_390
Epoch: 390	max: 0.9998721/1.0	min: 0.00012786631	loss: 34354.08984375	train_loss: 34397.23489370432	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_391
Epoch: 391	max: 0.99985635/1.0	min: 0.00014366685	loss: 34354.19140625	train_loss: 34397.19517846913	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_392
Epoch: 392	max: 0.9997851/1.0	min: 0.00021492768	loss: 34354.1640625	train_loss: 34397.15365792998	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_393
Epoch: 393	max: 0.9998416/1.0	min: 0.00015840902	loss: 34354.12890625	train_loss: 34397.18707226248	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_394
Epoch: 394	max: 0.9998933/1.0	min: 0.0001067241	loss: 34353.94921875	train_loss: 34397.08822618605	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_395
Epoch: 395	max: 0.9998635/1.0	min: 0.00013642108	loss: 34353.95703125	train_loss: 34397.058247785826	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_396
Epoch: 396	max: 0.99987984/1.0	min: 0.00012011929	loss: 34353.9609375	train_loss: 34397.013409861574	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_397
Epoch: 397	max: 0.9998679/1.0	min: 0.00013206742	loss: 34353.86328125	train_loss: 34396.989926878174	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_398
Epoch: 398	max: 0.9998791/1.0	min: 0.00012080804	loss: 34353.90625	train_loss: 34396.946691518024	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_399
Epoch: 399	max: 0.99984217/1.0	min: 0.00015785475	loss: 34353.921875	train_loss: 34396.918570195405	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_400
Epoch: 400	max: 0.99987054/1.0	min: 0.00012941728	loss: 34353.83984375	train_loss: 34396.89887588257	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_401
Epoch: 401	max: 0.999845/1.0	min: 0.0001549902	loss: 34353.765625	train_loss: 34396.860667406014	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_402
Epoch: 402	max: 0.9998609/1.0	min: 0.00013910476	loss: 34353.83203125	train_loss: 34396.83603766026	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_403
Epoch: 403	max: 0.9998524/1.0	min: 0.0001475869	loss: 34353.796875	train_loss: 34396.79354842143	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_404
Epoch: 404	max: 0.9998363/1.0	min: 0.000163603	loss: 34353.75390625	train_loss: 34396.759361354976	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_405
Epoch: 405	max: 0.9998785/1.0	min: 0.000121506426	loss: 34353.73046875	train_loss: 34396.72738410442	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_406
Epoch: 406	max: 0.99985373/1.0	min: 0.00014621977	loss: 34353.703125	train_loss: 34396.69518185619	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_407
Epoch: 407	max: 0.99985445/1.0	min: 0.00014549044	loss: 34353.59375	train_loss: 34396.6700392125	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_408
Epoch: 408	max: 0.9998186/1.0	min: 0.00018138504	loss: 34353.75	train_loss: 34396.68191957373	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_409
Epoch: 409	max: 0.9998311/1.0	min: 0.00016891636	loss: 34353.66015625	train_loss: 34396.6158379978	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_410
Epoch: 410	max: 0.9997969/1.0	min: 0.00020313973	loss: 34353.68359375	train_loss: 34396.61108546621	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_411
Epoch: 411	max: 0.99985945/1.0	min: 0.0001404962	loss: 34353.61328125	train_loss: 34396.61943312198	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_412
Epoch: 412	max: 0.99982566/1.0	min: 0.00017437598	loss: 34353.62890625	train_loss: 34396.53584285582	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_413
Epoch: 413	max: 0.99986887/1.0	min: 0.00013106166	loss: 34353.5546875	train_loss: 34396.51391792085	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_414
Epoch: 414	max: 0.99989784/1.0	min: 0.00010209694	loss: 34353.359375	train_loss: 34396.455474653165	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_415
Epoch: 415	max: 0.9998846/1.0	min: 0.00011537523	loss: 34353.4609375	train_loss: 34396.427032527405	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_416
Epoch: 416	max: 0.9999081/1.0	min: 9.184803e-05	loss: 34353.4765625	train_loss: 34396.41838100381	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_417
Epoch: 417	max: 0.9999099/1.0	min: 9.014636e-05	loss: 34353.30078125	train_loss: 34396.41042286015	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_418
Epoch: 418	max: 0.99992/1.0	min: 8.003319e-05	loss: 34353.37109375	train_loss: 34396.342543238265	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_419
Epoch: 419	max: 0.99992/1.0	min: 7.9943784e-05	loss: 34353.33984375	train_loss: 34396.34956897219	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_420
Epoch: 420	max: 0.99990785/1.0	min: 9.217329e-05	loss: 34353.1484375	train_loss: 34396.29498211631	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_421
Epoch: 421	max: 0.9998951/1.0	min: 0.00010486157	loss: 34353.0546875	train_loss: 34396.25884361839	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_422
Epoch: 422	max: 0.9999082/1.0	min: 9.17247e-05	loss: 34353.1328125	train_loss: 34396.251014666945	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_423
Epoch: 423	max: 0.99989045/1.0	min: 0.00010952738	loss: 34353.20703125	train_loss: 34396.21867596851	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_424
Epoch: 424	max: 0.99989116/1.0	min: 0.00010887781	loss: 34353.1484375	train_loss: 34396.18137328905	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_425
Epoch: 425	max: 0.999897/1.0	min: 0.00010302566	loss: 34353.13671875	train_loss: 34396.142785945434	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_426
Epoch: 426	max: 0.9998907/1.0	min: 0.00010924971	loss: 34353.30078125	train_loss: 34396.11241609764	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_427
Epoch: 427	max: 0.99991226/1.0	min: 8.7745735e-05	loss: 34353.20703125	train_loss: 34396.09330048851	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_428
Epoch: 428	max: 0.9999082/1.0	min: 9.1781665e-05	loss: 34353.18359375	train_loss: 34396.07136297303	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_429
Epoch: 429	max: 0.9999012/1.0	min: 9.880313e-05	loss: 34353.05859375	train_loss: 34396.05993454261	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_430
Epoch: 430	max: 0.9998908/1.0	min: 0.000109128196	loss: 34353.09375	train_loss: 34396.01099585424	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_431
Epoch: 431	max: 0.9998807/1.0	min: 0.00011935148	loss: 34353.140625	train_loss: 34395.98445967655	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_432
Epoch: 432	max: 0.9998956/1.0	min: 0.00010436448	loss: 34353.015625	train_loss: 34395.979103280224	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_433
Epoch: 433	max: 0.99993134/1.0	min: 6.868554e-05	loss: 34353.046875	train_loss: 34395.97117949105	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_434
Epoch: 434	max: 0.99992096/1.0	min: 7.904867e-05	loss: 34352.97265625	train_loss: 34395.96078556609	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_435
Epoch: 435	max: 0.99986696/1.0	min: 0.00013299068	loss: 34352.94921875	train_loss: 34395.89235917565	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_436
Epoch: 436	max: 0.99992657/1.0	min: 7.3482996e-05	loss: 34352.8359375	train_loss: 34395.888271959775	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_437
Epoch: 437	max: 0.9998909/1.0	min: 0.00010901805	loss: 34353.0	train_loss: 34395.835640406294	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_438
Epoch: 438	max: 0.9998779/1.0	min: 0.00012209518	loss: 34352.93359375	train_loss: 34395.81318950901	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_439
Epoch: 439	max: 0.999863/1.0	min: 0.00013691449	loss: 34352.86328125	train_loss: 34395.81910283507	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_440
Epoch: 440	max: 0.9999155/1.0	min: 8.456796e-05	loss: 34352.7890625	train_loss: 34395.76056231032	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_441
Epoch: 441	max: 0.9998987/1.0	min: 0.00010131585	loss: 34352.8046875	train_loss: 34395.72525073935	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_442
Epoch: 442	max: 0.9999039/1.0	min: 9.6064665e-05	loss: 34352.65625	train_loss: 34395.70048067246	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_443
Epoch: 443	max: 0.9999093/1.0	min: 9.068315e-05	loss: 34352.71875	train_loss: 34395.68805112335	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_444
Epoch: 444	max: 0.9999095/1.0	min: 9.044341e-05	loss: 34352.69921875	train_loss: 34395.64821976031	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_445
Epoch: 445	max: 0.9999089/1.0	min: 9.102502e-05	loss: 34352.640625	train_loss: 34395.62595999009	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_446
Epoch: 446	max: 0.9999354/1.0	min: 6.460422e-05	loss: 34352.78515625	train_loss: 34395.605810359375	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_447
Epoch: 447	max: 0.9999168/1.0	min: 8.3206e-05	loss: 34352.67578125	train_loss: 34395.587039746686	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_448
Epoch: 448	max: 0.999915/1.0	min: 8.5032116e-05	loss: 34352.6015625	train_loss: 34395.56056937477	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_449
Epoch: 449	max: 0.99991596/1.0	min: 8.4050844e-05	loss: 34352.57421875	train_loss: 34395.54114409142	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_450
Epoch: 450	max: 0.9999205/1.0	min: 7.955253e-05	loss: 34352.59375	train_loss: 34395.51515032748	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_451
Epoch: 451	max: 0.9999118/1.0	min: 8.822624e-05	loss: 34352.6484375	train_loss: 34395.4807687469	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_452
Epoch: 452	max: 0.99992776/1.0	min: 7.2283976e-05	loss: 34352.55078125	train_loss: 34395.46290683451	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_453
Epoch: 453	max: 0.9999087/1.0	min: 9.125098e-05	loss: 34352.578125	train_loss: 34395.45699689552	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_454
Epoch: 454	max: 0.99989784/1.0	min: 0.00010220274	loss: 34352.609375	train_loss: 34395.417702623716	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_455
Epoch: 455	max: 0.9999193/1.0	min: 8.066108e-05	loss: 34352.375	train_loss: 34395.39640816611	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_456
Epoch: 456	max: 0.99990904/1.0	min: 9.089006e-05	loss: 34352.37109375	train_loss: 34395.37257776694	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_457
Epoch: 457	max: 0.9999281/1.0	min: 7.188905e-05	loss: 34352.34375	train_loss: 34395.36443817354	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_458
Epoch: 458	max: 0.9999262/1.0	min: 7.3749616e-05	loss: 34352.5	train_loss: 34395.31299451103	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_459
Epoch: 459	max: 0.99992347/1.0	min: 7.652763e-05	loss: 34352.375	train_loss: 34395.305567652205	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_460
Epoch: 460	max: 0.999918/1.0	min: 8.197027e-05	loss: 34352.33984375	train_loss: 34395.27701568887	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_461
Epoch: 461	max: 0.9999229/1.0	min: 7.7074925e-05	loss: 34352.359375	train_loss: 34395.25190885126	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_462
Epoch: 462	max: 0.99992657/1.0	min: 7.3484676e-05	loss: 34352.296875	train_loss: 34395.23222421575	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_463
Epoch: 463	max: 0.9999169/1.0	min: 8.313289e-05	loss: 34352.390625	train_loss: 34395.21936838071	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_464
Epoch: 464	max: 0.99994564/1.0	min: 5.432256e-05	loss: 34352.35546875	train_loss: 34395.18364842686	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_465
Epoch: 465	max: 0.99991274/1.0	min: 8.7280496e-05	loss: 34352.2109375	train_loss: 34395.19463170058	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_466
Epoch: 466	max: 0.9998981/1.0	min: 0.000101903	loss: 34352.32421875	train_loss: 34395.158216431315	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_467
Epoch: 467	max: 0.999918/1.0	min: 8.202634e-05	loss: 34352.15625	train_loss: 34395.119508121206	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_468
Epoch: 468	max: 0.99993074/1.0	min: 6.9304595e-05	loss: 34352.0390625	train_loss: 34395.091712440386	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_469
Epoch: 469	max: 0.999943/1.0	min: 5.693342e-05	loss: 34352.0859375	train_loss: 34395.07111668525	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_470
Epoch: 470	max: 0.9999486/1.0	min: 5.1331168e-05	loss: 34352.07421875	train_loss: 34395.06368498777	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_471
Epoch: 471	max: 0.99991834/1.0	min: 8.159639e-05	loss: 34352.0859375	train_loss: 34395.035625599994	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_472
Epoch: 472	max: 0.9998996/1.0	min: 0.00010042267	loss: 34352.19140625	train_loss: 34395.01648144277	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_473
Epoch: 473	max: 0.9999348/1.0	min: 6.519358e-05	loss: 34352.14453125	train_loss: 34395.0137166326	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_474
Epoch: 474	max: 0.9999238/1.0	min: 7.615765e-05	loss: 34351.99609375	train_loss: 34394.96594357736	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_475
Epoch: 475	max: 0.9999136/1.0	min: 8.6433516e-05	loss: 34352.0234375	train_loss: 34394.941834471385	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_476
Epoch: 476	max: 0.9999093/1.0	min: 9.0720176e-05	loss: 34352.00390625	train_loss: 34394.934924865294	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_477
Epoch: 477	max: 0.99992895/1.0	min: 7.101303e-05	loss: 34351.92578125	train_loss: 34394.904184860025	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_478
Epoch: 478	max: 0.99992573/1.0	min: 7.430703e-05	loss: 34351.84375	train_loss: 34394.88778470674	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_479
Epoch: 479	max: 0.9999343/1.0	min: 6.5704364e-05	loss: 34351.89453125	train_loss: 34394.86372592283	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_480
Epoch: 480	max: 0.99991953/1.0	min: 8.049864e-05	loss: 34351.84375	train_loss: 34394.835695083144	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_481
Epoch: 481	max: 0.999905/1.0	min: 9.505376e-05	loss: 34351.9296875	train_loss: 34394.831085292026	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_482
Epoch: 482	max: 0.99993646/1.0	min: 6.350553e-05	loss: 34351.90625	train_loss: 34394.795389531464	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_483
Epoch: 483	max: 0.99993384/1.0	min: 6.620084e-05	loss: 34351.83984375	train_loss: 34394.76804287827	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_484
Epoch: 484	max: 0.9999349/1.0	min: 6.51169e-05	loss: 34351.765625	train_loss: 34394.74384764415	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_485
Epoch: 485	max: 0.9999312/1.0	min: 6.882861e-05	loss: 34351.75390625	train_loss: 34394.721307231666	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_486
Epoch: 486	max: 0.99993277/1.0	min: 6.7178284e-05	loss: 34351.73046875	train_loss: 34394.71315554162	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_487
Epoch: 487	max: 0.99991465/1.0	min: 8.5395186e-05	loss: 34351.76171875	train_loss: 34394.68957143023	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_488
Epoch: 488	max: 0.9999317/1.0	min: 6.8290414e-05	loss: 34351.671875	train_loss: 34394.66317412208	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_489
Epoch: 489	max: 0.9999474/1.0	min: 5.2569892e-05	loss: 34351.67578125	train_loss: 34394.640993222005	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_490
Epoch: 490	max: 0.9999211/1.0	min: 7.8889316e-05	loss: 34351.625	train_loss: 34394.62624305169	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_491
Epoch: 491	max: 0.9999312/1.0	min: 6.880066e-05	loss: 34351.578125	train_loss: 34394.58840424873	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_492
Epoch: 492	max: 0.9999299/1.0	min: 7.004782e-05	loss: 34351.65625	train_loss: 34394.58159577062	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_493
Epoch: 493	max: 0.99995124/1.0	min: 4.8700364e-05	loss: 34351.63671875	train_loss: 34394.55972115772	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_494
Epoch: 494	max: 0.99994624/1.0	min: 5.379201e-05	loss: 34351.609375	train_loss: 34394.538104445375	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_495
Epoch: 495	max: 0.9999398/1.0	min: 6.0203143e-05	loss: 34351.59765625	train_loss: 34394.51525726186	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_496
Epoch: 496	max: 0.99994457/1.0	min: 5.5487395e-05	loss: 34351.48046875	train_loss: 34394.48964526818	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_497
Epoch: 497	max: 0.999949/1.0	min: 5.1024774e-05	loss: 34351.40625	train_loss: 34394.477871357456	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_498
Epoch: 498	max: 0.9999442/1.0	min: 5.584375e-05	loss: 34351.40625	train_loss: 34394.45396692679	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_499
Epoch: 499	max: 0.9999393/1.0	min: 6.069561e-05	loss: 34351.46875	train_loss: 34394.42892976588	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_500
Epoch: 500	max: 0.999923/1.0	min: 7.70094e-05	loss: 34351.48828125	train_loss: 34394.414020887525	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_501
Epoch: 501	max: 0.99993455/1.0	min: 6.539656e-05	loss: 34351.27734375	train_loss: 34394.39411270593	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_502
Epoch: 502	max: 0.99990606/1.0	min: 9.393605e-05	loss: 34351.3984375	train_loss: 34394.38066994147	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_503
Epoch: 503	max: 0.9999566/1.0	min: 4.3350155e-05	loss: 34351.28125	train_loss: 34394.39586768782	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_504
Epoch: 504	max: 0.9999559/1.0	min: 4.4109325e-05	loss: 34351.28515625	train_loss: 34394.33381139291	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_505
Epoch: 505	max: 0.99995375/1.0	min: 4.6261885e-05	loss: 34351.19921875	train_loss: 34394.31188936114	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_506
Epoch: 506	max: 0.99996245/1.0	min: 3.7510712e-05	loss: 34351.25390625	train_loss: 34394.288939598046	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_507
Epoch: 507	max: 0.99994314/1.0	min: 5.685486e-05	loss: 34351.26953125	train_loss: 34394.2913192509	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_508
Epoch: 508	max: 0.9999393/1.0	min: 6.0722126e-05	loss: 34351.203125	train_loss: 34394.2398852657	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_509
Epoch: 509	max: 0.9999386/1.0	min: 6.142702e-05	loss: 34351.34375	train_loss: 34394.21608728555	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_510
Epoch: 510	max: 0.999938/1.0	min: 6.195518e-05	loss: 34351.2109375	train_loss: 34394.20424708519	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_511
Epoch: 511	max: 0.9999397/1.0	min: 6.0283222e-05	loss: 34351.21484375	train_loss: 34394.18813967082	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_512
Epoch: 512	max: 0.99993026/1.0	min: 6.974609e-05	loss: 34351.1015625	train_loss: 34394.17152032624	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_513
Epoch: 513	max: 0.99993336/1.0	min: 6.667188e-05	loss: 34351.1640625	train_loss: 34394.148428306544	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_514
Epoch: 514	max: 0.9999379/1.0	min: 6.21382e-05	loss: 34351.15625	train_loss: 34394.139080499815	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_515
Epoch: 515	max: 0.9999411/1.0	min: 5.891977e-05	loss: 34351.12109375	train_loss: 34394.12102697649	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_516
Epoch: 516	max: 0.99994683/1.0	min: 5.314639e-05	loss: 34351.0390625	train_loss: 34394.07967917751	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_517
Epoch: 517	max: 0.9999578/1.0	min: 4.2225987e-05	loss: 34351.08984375	train_loss: 34394.07097104159	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_518
Epoch: 518	max: 0.99996066/1.0	min: 3.9321207e-05	loss: 34351.13671875	train_loss: 34394.04560436795	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_519
Epoch: 519	max: 0.99993896/1.0	min: 6.1014496e-05	loss: 34351.03125	train_loss: 34394.03505415428	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_520
Epoch: 520	max: 0.9999273/1.0	min: 7.274146e-05	loss: 34351.0859375	train_loss: 34394.02511796652	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_521
Epoch: 521	max: 0.99994636/1.0	min: 5.3627493e-05	loss: 34350.91015625	train_loss: 34393.98858898876	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_522
Epoch: 522	max: 0.9999553/1.0	min: 4.472626e-05	loss: 34350.95703125	train_loss: 34393.96146733324	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_523
Epoch: 523	max: 0.99996436/1.0	min: 3.567006e-05	loss: 34351.01953125	train_loss: 34393.95158340301	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_524
Epoch: 524	max: 0.9999666/1.0	min: 3.3322314e-05	loss: 34351.1015625	train_loss: 34393.93213634569	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_525
Epoch: 525	max: 0.9999474/1.0	min: 5.2513624e-05	loss: 34350.78125	train_loss: 34393.92537383485	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_526
Epoch: 526	max: 0.9999529/1.0	min: 4.709822e-05	loss: 34350.94921875	train_loss: 34393.904968722905	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_527
Epoch: 527	max: 0.99996305/1.0	min: 3.6907604e-05	loss: 34351.01171875	train_loss: 34393.881801220115	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_528
Epoch: 528	max: 0.9999598/1.0	min: 4.011618e-05	loss: 34350.9765625	train_loss: 34393.86022224932	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_529
Epoch: 529	max: 0.9999672/1.0	min: 3.2744334e-05	loss: 34350.953125	train_loss: 34393.84410757695	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_530
Epoch: 530	max: 0.99994516/1.0	min: 5.4796958e-05	loss: 34350.7890625	train_loss: 34393.82998449694	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_531
Epoch: 531	max: 0.9999372/1.0	min: 6.2855026e-05	loss: 34350.8515625	train_loss: 34393.836870877465	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_532
Epoch: 532	max: 0.9999603/1.0	min: 3.9684506e-05	loss: 34350.84375	train_loss: 34393.78052371718	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_533
Epoch: 533	max: 0.9999459/1.0	min: 5.413701e-05	loss: 34350.7265625	train_loss: 34393.75882281215	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_534
Epoch: 534	max: 0.99995303/1.0	min: 4.7002784e-05	loss: 34350.67578125	train_loss: 34393.73985284668	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_535
Epoch: 535	max: 0.9999391/1.0	min: 6.0854636e-05	loss: 34350.76953125	train_loss: 34393.71929725241	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_536
Epoch: 536	max: 0.9999521/1.0	min: 4.7948848e-05	loss: 34350.640625	train_loss: 34393.72660846727	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_537
Epoch: 537	max: 0.99996173/1.0	min: 3.821799e-05	loss: 34350.7734375	train_loss: 34393.6990111715	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_538
Epoch: 538	max: 0.9999602/1.0	min: 3.9843202e-05	loss: 34350.75390625	train_loss: 34393.66068705097	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_539
Epoch: 539	max: 0.9999409/1.0	min: 5.910057e-05	loss: 34350.6484375	train_loss: 34393.66263848244	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_540
Epoch: 540	max: 0.99995184/1.0	min: 4.8201833e-05	loss: 34350.6796875	train_loss: 34393.63139525656	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_541
Epoch: 541	max: 0.9999678/1.0	min: 3.223725e-05	loss: 34350.6015625	train_loss: 34393.602107333085	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_542
Epoch: 542	max: 0.99995124/1.0	min: 4.8809772e-05	loss: 34350.56640625	train_loss: 34393.589163434444	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_543
Epoch: 543	max: 0.99993086/1.0	min: 6.918707e-05	loss: 34350.62109375	train_loss: 34393.56807655534	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_544
Epoch: 544	max: 0.99995327/1.0	min: 4.674491e-05	loss: 34350.54296875	train_loss: 34393.5616895245	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_545
Epoch: 545	max: 0.99994314/1.0	min: 5.691193e-05	loss: 34350.55859375	train_loss: 34393.52883792813	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_546
Epoch: 546	max: 0.99996805/1.0	min: 3.1919713e-05	loss: 34350.73046875	train_loss: 34393.52497812926	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_547
Epoch: 547	max: 0.999972/1.0	min: 2.7983493e-05	loss: 34350.5234375	train_loss: 34393.50845217082	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_548
Epoch: 548	max: 0.99995506/1.0	min: 4.4899636e-05	loss: 34350.4765625	train_loss: 34393.47387317292	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_549
Epoch: 549	max: 0.9999242/1.0	min: 7.582171e-05	loss: 34350.546875	train_loss: 34393.46404730661	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_550
Epoch: 550	max: 0.99992836/1.0	min: 7.160354e-05	loss: 34350.55859375	train_loss: 34393.45595271275	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_551
Epoch: 551	max: 0.99992514/1.0	min: 7.48912e-05	loss: 34350.61328125	train_loss: 34393.44637748901	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_552
Epoch: 552	max: 0.99995863/1.0	min: 4.133122e-05	loss: 34350.40625	train_loss: 34393.41162768642	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_553
Epoch: 553	max: 0.9999654/1.0	min: 3.4528886e-05	loss: 34350.40625	train_loss: 34393.38290878933	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_554
Epoch: 554	max: 0.9999677/1.0	min: 3.2334083e-05	loss: 34350.4609375	train_loss: 34393.36634412161	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_555
Epoch: 555	max: 0.9999807/1.0	min: 1.9343477e-05	loss: 34350.7265625	train_loss: 34393.349877194814	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_556
Epoch: 556	max: 0.99996614/1.0	min: 3.3906297e-05	loss: 34350.37109375	train_loss: 34393.43902272622	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_557
Epoch: 557	max: 0.99996066/1.0	min: 3.929819e-05	loss: 34350.35546875	train_loss: 34393.30789166047	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_558
Epoch: 558	max: 0.9999548/1.0	min: 4.5134846e-05	loss: 34350.46875	train_loss: 34393.29283471913	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_559
Epoch: 559	max: 0.999961/1.0	min: 3.9033977e-05	loss: 34350.328125	train_loss: 34393.27559118745	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_560
Epoch: 560	max: 0.9999453/1.0	min: 5.4670913e-05	loss: 34350.3515625	train_loss: 34393.28489544624	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_561
Epoch: 561	max: 0.99995935/1.0	min: 4.060336e-05	loss: 34350.203125	train_loss: 34393.24617020082	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_562
Epoch: 562	max: 0.99996245/1.0	min: 3.756982e-05	loss: 34350.1484375	train_loss: 34393.227847164155	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_563
Epoch: 563	max: 0.99996436/1.0	min: 3.559319e-05	loss: 34350.1796875	train_loss: 34393.21693501873	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_564
Epoch: 564	max: 0.9999474/1.0	min: 5.261227e-05	loss: 34350.24609375	train_loss: 34393.20079179828	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_565
Epoch: 565	max: 0.99992955/1.0	min: 7.045225e-05	loss: 34350.21875	train_loss: 34393.196372650345	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_566
Epoch: 566	max: 0.999933/1.0	min: 6.69568e-05	loss: 34350.2734375	train_loss: 34393.26856835671	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_567
Epoch: 567	max: 0.9999486/1.0	min: 5.1416566e-05	loss: 34350.18359375	train_loss: 34393.16809407129	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_568
Epoch: 568	max: 0.99993813/1.0	min: 6.184728e-05	loss: 34350.3359375	train_loss: 34393.11758959262	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_569
Epoch: 569	max: 0.99995565/1.0	min: 4.4305016e-05	loss: 34349.99609375	train_loss: 34393.12098681562	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_570
Epoch: 570	max: 0.999956/1.0	min: 4.3929067e-05	loss: 34350.06640625	train_loss: 34393.13781712576	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_571
Epoch: 571	max: 0.99993944/1.0	min: 6.05109e-05	loss: 34350.11328125	train_loss: 34393.085511697944	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_572
Epoch: 572	max: 0.9999653/1.0	min: 3.47112e-05	loss: 34350.0546875	train_loss: 34393.05540604097	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_573
Epoch: 573	max: 0.99997425/1.0	min: 2.5763366e-05	loss: 34350.01171875	train_loss: 34393.02805212978	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_574
Epoch: 574	max: 0.9999528/1.0	min: 4.7188583e-05	loss: 34350.015625	train_loss: 34393.04894643023	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_575
Epoch: 575	max: 0.9999609/1.0	min: 3.9063052e-05	loss: 34349.8984375	train_loss: 34393.033087722964	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_576
Epoch: 576	max: 0.9999691/1.0	min: 3.091662e-05	loss: 34349.8671875	train_loss: 34393.00861523365	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_577
Epoch: 577	max: 0.9999734/1.0	min: 2.6535292e-05	loss: 34349.87109375	train_loss: 34392.957756081225	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_578
Epoch: 578	max: 0.99996793/1.0	min: 3.2010124e-05	loss: 34349.99609375	train_loss: 34392.942568496066	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_579
Epoch: 579	max: 0.999966/1.0	min: 3.3938843e-05	loss: 34349.97265625	train_loss: 34392.92193258005	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_580
Epoch: 580	max: 0.9999703/1.0	min: 2.971267e-05	loss: 34350.09375	train_loss: 34392.91350411867	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_581
Epoch: 581	max: 0.9999523/1.0	min: 4.7721314e-05	loss: 34349.9296875	train_loss: 34392.90681418772	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_582
Epoch: 582	max: 0.9999453/1.0	min: 5.4707783e-05	loss: 34349.92578125	train_loss: 34392.94446089589	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_583
Epoch: 583	max: 0.99995816/1.0	min: 4.1896794e-05	loss: 34349.859375	train_loss: 34392.85297054998	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_584
Epoch: 584	max: 0.9999703/1.0	min: 2.9682651e-05	loss: 34349.82421875	train_loss: 34392.84601739595	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_585
Epoch: 585	max: 0.99997914/1.0	min: 2.0870302e-05	loss: 34349.8203125	train_loss: 34392.82894950762	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_586
Epoch: 586	max: 0.9999628/1.0	min: 3.723241e-05	loss: 34349.87109375	train_loss: 34392.80665538291	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_587
Epoch: 587	max: 0.9999571/1.0	min: 4.2857304e-05	loss: 34349.86328125	train_loss: 34392.78761961167	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_588
Epoch: 588	max: 0.9999747/1.0	min: 2.5215413e-05	loss: 34349.9375	train_loss: 34392.766897083646	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_589
Epoch: 589	max: 0.99997735/1.0	min: 2.2610122e-05	loss: 34349.91015625	train_loss: 34392.78641575313	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_590
Epoch: 590	max: 0.99996424/1.0	min: 3.5754143e-05	loss: 34349.75390625	train_loss: 34392.75543575034	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_591
Epoch: 591	max: 0.99997115/1.0	min: 2.8792134e-05	loss: 34349.73046875	train_loss: 34392.737066746406	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_592
Epoch: 592	max: 0.99996245/1.0	min: 3.750463e-05	loss: 34349.69140625	train_loss: 34392.69915633129	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_593
Epoch: 593	max: 0.9999558/1.0	min: 4.4202385e-05	loss: 34349.75390625	train_loss: 34392.703310804536	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_594
Epoch: 594	max: 0.9999652/1.0	min: 3.4847715e-05	loss: 34349.640625	train_loss: 34392.66841439056	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_595
Epoch: 595	max: 0.99997234/1.0	min: 2.7695232e-05	loss: 34349.81640625	train_loss: 34392.66190687709	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_596
Epoch: 596	max: 0.99997413/1.0	min: 2.590634e-05	loss: 34349.7421875	train_loss: 34392.63718326134	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_597
Epoch: 597	max: 0.99996996/1.0	min: 2.9985451e-05	loss: 34349.7421875	train_loss: 34392.62238470442	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_598
Epoch: 598	max: 0.9999732/1.0	min: 2.6823174e-05	loss: 34349.6640625	train_loss: 34392.61485526601	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_599
Epoch: 599	max: 0.99998/1.0	min: 2.006627e-05	loss: 34349.6796875	train_loss: 34392.59311129692	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_600
Epoch: 600	max: 0.99998/1.0	min: 2.0070904e-05	loss: 34349.59375	train_loss: 34392.57439003856	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_601
Epoch: 601	max: 0.9999697/1.0	min: 3.0309055e-05	loss: 34349.671875	train_loss: 34392.54711015886	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_602
Epoch: 602	max: 0.9999838/1.0	min: 1.622865e-05	loss: 34349.78515625	train_loss: 34392.53251966431	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_603
Epoch: 603	max: 0.9999628/1.0	min: 3.7226444e-05	loss: 34349.5	train_loss: 34392.540371357456	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_604
Epoch: 604	max: 0.99996674/1.0	min: 3.3308625e-05	loss: 34349.6171875	train_loss: 34392.504332052056	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_605
Epoch: 605	max: 0.9999782/1.0	min: 2.1818429e-05	loss: 34349.7421875	train_loss: 34392.50372770346	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_606
Epoch: 606	max: 0.9999809/1.0	min: 1.9086388e-05	loss: 34349.5234375	train_loss: 34392.50283109981	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_607
Epoch: 607	max: 0.9999871/1.0	min: 1.2816811e-05	loss: 34349.48046875	train_loss: 34392.452915486036	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_608
Epoch: 608	max: 0.99997973/1.0	min: 2.0223417e-05	loss: 34349.47265625	train_loss: 34392.42857364053	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_609
Epoch: 609	max: 0.9999831/1.0	min: 1.6912381e-05	loss: 34349.41015625	train_loss: 34392.42021775904	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_610
Epoch: 610	max: 0.999987/1.0	min: 1.2958025e-05	loss: 34349.6640625	train_loss: 34392.391704988855	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_611
Epoch: 611	max: 0.9999844/1.0	min: 1.5560092e-05	loss: 34349.4140625	train_loss: 34392.44514846944	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_612
Epoch: 612	max: 0.9999856/1.0	min: 1.4396213e-05	loss: 34349.296875	train_loss: 34392.402296815	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_613
Epoch: 613	max: 0.9999788/1.0	min: 2.1248987e-05	loss: 34349.44140625	train_loss: 34392.34986219497	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_614
Epoch: 614	max: 0.9999783/1.0	min: 2.175166e-05	loss: 34349.35546875	train_loss: 34392.37751852239	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_615
Epoch: 615	max: 0.99997544/1.0	min: 2.4598547e-05	loss: 34349.4453125	train_loss: 34392.38225411867	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_616
Epoch: 616	max: 0.9999783/1.0	min: 2.1640197e-05	loss: 34349.5234375	train_loss: 34392.31100195095	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_617
Epoch: 617	max: 0.99998426/1.0	min: 1.5723912e-05	loss: 34349.36328125	train_loss: 34392.26983656943	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_618
Epoch: 618	max: 0.9999869/1.0	min: 1.3113619e-05	loss: 34349.40234375	train_loss: 34392.256713640374	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_619
Epoch: 619	max: 0.9999771/1.0	min: 2.2868959e-05	loss: 34349.39453125	train_loss: 34392.246034234486	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_620
Epoch: 620	max: 0.9999738/1.0	min: 2.625636e-05	loss: 34349.2421875	train_loss: 34392.222904473245	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_621
Epoch: 621	max: 0.9999814/1.0	min: 1.8586563e-05	loss: 34349.28125	train_loss: 34392.20327161139	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_622
Epoch: 622	max: 0.9999887/1.0	min: 1.1265622e-05	loss: 34349.3203125	train_loss: 34392.208490105906	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_623
Epoch: 623	max: 0.9999883/1.0	min: 1.17150585e-05	loss: 34349.2578125	train_loss: 34392.18715548743	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_624
Epoch: 624	max: 0.99998415/1.0	min: 1.5847627e-05	loss: 34349.12109375	train_loss: 34392.168741000096	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_625
Epoch: 625	max: 0.99998283/1.0	min: 1.7195558e-05	loss: 34349.26953125	train_loss: 34392.14369948439	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_626
Epoch: 626	max: 0.9999807/1.0	min: 1.9269091e-05	loss: 34349.140625	train_loss: 34392.1160712212	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_627
Epoch: 627	max: 0.9999778/1.0	min: 2.213487e-05	loss: 34349.1875	train_loss: 34392.10682792952	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_628
Epoch: 628	max: 0.9999808/1.0	min: 1.9143296e-05	loss: 34349.18359375	train_loss: 34392.13640520485	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_629
Epoch: 629	max: 0.9999802/1.0	min: 1.9757777e-05	loss: 34349.23828125	train_loss: 34392.080105947294	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_630
Epoch: 630	max: 0.99998915/1.0	min: 1.0857506e-05	loss: 34349.265625	train_loss: 34392.05272784281	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_631
Epoch: 631	max: 0.9999877/1.0	min: 1.2303007e-05	loss: 34349.234375	train_loss: 34392.05584829447	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_632
Epoch: 632	max: 0.99998534/1.0	min: 1.4658801e-05	loss: 34349.19921875	train_loss: 34392.07983546621	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_633
Epoch: 633	max: 0.9999789/1.0	min: 2.1122149e-05	loss: 34349.1328125	train_loss: 34392.01117101372	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_634
Epoch: 634	max: 0.9999758/1.0	min: 2.415459e-05	loss: 34349.19921875	train_loss: 34391.981587931994	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_635
Epoch: 635	max: 0.99997413/1.0	min: 2.5904512e-05	loss: 34349.03515625	train_loss: 34391.968974029944	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_636
Epoch: 636	max: 0.9999795/1.0	min: 2.0473706e-05	loss: 34349.17578125	train_loss: 34391.94263575344	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_637
Epoch: 637	max: 0.99998605/1.0	min: 1.4001468e-05	loss: 34349.140625	train_loss: 34391.93035475117	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_638
Epoch: 638	max: 0.99998593/1.0	min: 1.4110071e-05	loss: 34349.171875	train_loss: 34391.92442739301	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_639
Epoch: 639	max: 0.9999883/1.0	min: 1.1647482e-05	loss: 34348.984375	train_loss: 34391.90846368683	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_640
Epoch: 640	max: 0.99998474/1.0	min: 1.5216356e-05	loss: 34348.98828125	train_loss: 34391.881001389665	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_641
Epoch: 641	max: 0.9999839/1.0	min: 1.6053495e-05	loss: 34349.0390625	train_loss: 34391.86907554503	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_642
Epoch: 642	max: 0.9999796/1.0	min: 2.0385334e-05	loss: 34348.98046875	train_loss: 34391.86195690883	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_643
Epoch: 643	max: 0.99998724/1.0	min: 1.2765262e-05	loss: 34349.12109375	train_loss: 34391.81437933544	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_644
Epoch: 644	max: 0.9999865/1.0	min: 1.3509566e-05	loss: 34348.859375	train_loss: 34391.8230811811	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_645
Epoch: 645	max: 0.9999845/1.0	min: 1.546202e-05	loss: 34348.81640625	train_loss: 34391.78558398752	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_646
Epoch: 646	max: 0.9999876/1.0	min: 1.2347308e-05	loss: 34348.83203125	train_loss: 34391.81678173	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_647
Epoch: 647	max: 0.9999826/1.0	min: 1.7442357e-05	loss: 34348.94921875	train_loss: 34391.761433752945	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_648
Epoch: 648	max: 0.9999821/1.0	min: 1.7843795e-05	loss: 34348.91015625	train_loss: 34391.725510091506	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_649
Epoch: 649	max: 0.99997675/1.0	min: 2.3275366e-05	loss: 34348.82421875	train_loss: 34391.70481562771	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_650
Epoch: 650	max: 0.99998426/1.0	min: 1.5793206e-05	loss: 34348.828125	train_loss: 34391.71234167906	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_651
Epoch: 651	max: 0.99998355/1.0	min: 1.6497486e-05	loss: 34348.890625	train_loss: 34391.669468734515	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_652
Epoch: 652	max: 0.99998593/1.0	min: 1.4088825e-05	loss: 34348.9609375	train_loss: 34391.66111478849	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_653
Epoch: 653	max: 0.9999883/1.0	min: 1.1623049e-05	loss: 34348.90234375	train_loss: 34391.64693025749	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_654
Epoch: 654	max: 0.9999888/1.0	min: 1.1250548e-05	loss: 34348.93359375	train_loss: 34391.64660364796	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_655
Epoch: 655	max: 0.99998677/1.0	min: 1.3213268e-05	loss: 34348.90625	train_loss: 34391.60479666016	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_656
Epoch: 656	max: 0.99998486/1.0	min: 1.5147339e-05	loss: 34348.7890625	train_loss: 34391.57005411557	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_657
Epoch: 657	max: 0.9999807/1.0	min: 1.9338164e-05	loss: 34348.73828125	train_loss: 34391.570297500155	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_658
Epoch: 658	max: 0.9999888/1.0	min: 1.1222891e-05	loss: 34348.90625	train_loss: 34391.54136908909	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_659
Epoch: 659	max: 0.9999838/1.0	min: 1.6247715e-05	loss: 34348.828125	train_loss: 34391.53779864208	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_660
Epoch: 660	max: 0.9999888/1.0	min: 1.1249593e-05	loss: 34348.83203125	train_loss: 34391.509953123066	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_661
Epoch: 661	max: 0.99997866/1.0	min: 2.1392618e-05	loss: 34348.71875	train_loss: 34391.49532488697	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_662
Epoch: 662	max: 0.9999902/1.0	min: 9.754583e-06	loss: 34348.61328125	train_loss: 34391.48440983835	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_663
Epoch: 663	max: 0.9999852/1.0	min: 1.47724595e-05	loss: 34348.65625	train_loss: 34391.445827333395	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_664
Epoch: 664	max: 0.9999769/1.0	min: 2.3072313e-05	loss: 34348.875	train_loss: 34391.41729036991	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_665
Epoch: 665	max: 0.99997604/1.0	min: 2.3970964e-05	loss: 34348.8046875	train_loss: 34391.42426868497	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_666
Epoch: 666	max: 0.9999889/1.0	min: 1.105638e-05	loss: 34348.796875	train_loss: 34391.389835814596	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_667
Epoch: 667	max: 0.99998283/1.0	min: 1.7192442e-05	loss: 34348.7109375	train_loss: 34391.35837775223	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_668
Epoch: 668	max: 0.99998343/1.0	min: 1.6580116e-05	loss: 34348.66015625	train_loss: 34391.33589395206	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_669
Epoch: 669	max: 0.99999094/1.0	min: 9.090845e-06	loss: 34348.73828125	train_loss: 34391.33183044562	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_670
Epoch: 670	max: 0.99998784/1.0	min: 1.2205532e-05	loss: 34348.69921875	train_loss: 34391.29966303574	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_671
Epoch: 671	max: 0.99998784/1.0	min: 1.2122392e-05	loss: 34348.6875	train_loss: 34391.28274853292	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_672
Epoch: 672	max: 0.99998724/1.0	min: 1.2801127e-05	loss: 34348.609375	train_loss: 34391.2790900223	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_673
Epoch: 673	max: 0.99998903/1.0	min: 1.0933304e-05	loss: 34348.71484375	train_loss: 34391.246564067726	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_674
Epoch: 674	max: 0.99998677/1.0	min: 1.3256447e-05	loss: 34348.5390625	train_loss: 34391.21949128267	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_675
Epoch: 675	max: 0.9999857/1.0	min: 1.4280422e-05	loss: 34348.48828125	train_loss: 34391.202207106246	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_676
Epoch: 676	max: 0.9999888/1.0	min: 1.1264204e-05	loss: 34348.578125	train_loss: 34391.18767854654	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_677
Epoch: 677	max: 0.9999876/1.0	min: 1.2386795e-05	loss: 34348.49609375	train_loss: 34391.146354456985	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_678
Epoch: 678	max: 0.9999882/1.0	min: 1.1835597e-05	loss: 34348.58203125	train_loss: 34391.1537130907	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_679
Epoch: 679	max: 0.99999046/1.0	min: 9.544699e-06	loss: 34348.484375	train_loss: 34391.10805356203	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_680
Epoch: 680	max: 0.9999833/1.0	min: 1.6682765e-05	loss: 34348.43359375	train_loss: 34391.08427154946	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_681
Epoch: 681	max: 0.999987/1.0	min: 1.29415e-05	loss: 34348.45703125	train_loss: 34391.09322355382	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_682
Epoch: 682	max: 0.99999356/1.0	min: 6.403593e-06	loss: 34348.56640625	train_loss: 34391.10501439985	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_683
Epoch: 683	max: 0.9999932/1.0	min: 6.792136e-06	loss: 34348.64453125	train_loss: 34391.031671447265	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_684
Epoch: 684	max: 0.9999951/1.0	min: 4.8614124e-06	loss: 34348.8359375	train_loss: 34391.09921671776	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_685
Epoch: 685	max: 0.9999856/1.0	min: 1.4399288e-05	loss: 34348.484375	train_loss: 34391.100754443825	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_686
Epoch: 686	max: 0.99998724/1.0	min: 1.27891935e-05	loss: 34348.4140625	train_loss: 34390.956381901866	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_687
Epoch: 687	max: 0.9999715/1.0	min: 2.8482933e-05	loss: 34348.5546875	train_loss: 34390.93326907593	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_688
Epoch: 688	max: 0.9999877/1.0	min: 1.2245673e-05	loss: 34348.53125	train_loss: 34390.92893557228	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_689
Epoch: 689	max: 0.99999225/1.0	min: 7.780489e-06	loss: 34348.4296875	train_loss: 34390.905814036756	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_690
Epoch: 690	max: 0.99998736/1.0	min: 1.2581435e-05	loss: 34348.2109375	train_loss: 34390.89351706692	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_691
Epoch: 691	max: 0.9999752/1.0	min: 2.4750907e-05	loss: 34348.296875	train_loss: 34390.87674917549	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_692
Epoch: 692	max: 0.9999896/1.0	min: 1.0385832e-05	loss: 34348.33203125	train_loss: 34390.874907097736	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_693
Epoch: 693	max: 0.99999356/1.0	min: 6.390184e-06	loss: 34348.421875	train_loss: 34390.833271398486	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_694
Epoch: 694	max: 0.9999925/1.0	min: 7.458629e-06	loss: 34348.4375	train_loss: 34390.79901949399	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_695
Epoch: 695	max: 0.99998903/1.0	min: 1.0939343e-05	loss: 34348.1640625	train_loss: 34390.78263385668	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_696
Epoch: 696	max: 0.9999925/1.0	min: 7.523547e-06	loss: 34348.36328125	train_loss: 34390.75393431423	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_697
Epoch: 697	max: 0.99998903/1.0	min: 1.0968762e-05	loss: 34348.3984375	train_loss: 34390.72331575932	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_698
Epoch: 698	max: 0.99997914/1.0	min: 2.0882626e-05	loss: 34348.2890625	train_loss: 34390.6998942269	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_699
Epoch: 699	max: 0.99998474/1.0	min: 1.5257203e-05	loss: 34348.28125	train_loss: 34390.69129302536	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_700
Epoch: 700	max: 0.99997723/1.0	min: 2.2824906e-05	loss: 34348.30078125	train_loss: 34390.6825471479	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_701
Epoch: 701	max: 0.9999893/1.0	min: 1.0732241e-05	loss: 34348.3828125	train_loss: 34390.652370846496	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_702
Epoch: 702	max: 0.9999913/1.0	min: 8.708344e-06	loss: 34348.24609375	train_loss: 34390.63333652685	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_703
Epoch: 703	max: 0.99999416/1.0	min: 5.8605115e-06	loss: 34348.23828125	train_loss: 34390.60541552474	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_704
Epoch: 704	max: 0.99998736/1.0	min: 1.2576444e-05	loss: 34348.10546875	train_loss: 34390.59360000155	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_705
Epoch: 705	max: 0.9999788/1.0	min: 2.1258555e-05	loss: 34348.3046875	train_loss: 34390.55291413121	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_706
Epoch: 706	max: 0.9999871/1.0	min: 1.287957e-05	loss: 34348.17578125	train_loss: 34390.535194475415	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_707
Epoch: 707	max: 0.9999875/1.0	min: 1.2471793e-05	loss: 34348.171875	train_loss: 34390.5168336972	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_708
Epoch: 708	max: 0.99999464/1.0	min: 5.332223e-06	loss: 34348.26171875	train_loss: 34390.490541871826	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_709
Epoch: 709	max: 0.99999297/1.0	min: 7.081343e-06	loss: 34348.02734375	train_loss: 34390.5282040637	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_710
Epoch: 710	max: 0.99999106/1.0	min: 8.9441555e-06	loss: 34348.2265625	train_loss: 34390.48057665211	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_711
Epoch: 711	max: 0.9999852/1.0	min: 1.48399395e-05	loss: 34348.19921875	train_loss: 34390.465283100304	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_712
Epoch: 712	max: 0.99999416/1.0	min: 5.857483e-06	loss: 34348.2265625	train_loss: 34390.402505361235	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_713
Epoch: 713	max: 0.9999932/1.0	min: 6.828494e-06	loss: 34348.3984375	train_loss: 34390.38232379537	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_714
Epoch: 714	max: 0.9999924/1.0	min: 7.6233614e-06	loss: 34348.12890625	train_loss: 34390.3867840719	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_715
Epoch: 715	max: 0.99998736/1.0	min: 1.269439e-05	loss: 34348.12890625	train_loss: 34390.364232530505	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_716
Epoch: 716	max: 0.99998987/1.0	min: 1.0115741e-05	loss: 34348.140625	train_loss: 34390.31522997182	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_717
Epoch: 717	max: 0.9999939/1.0	min: 6.1175133e-06	loss: 34348.140625	train_loss: 34390.30047254351	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_718
Epoch: 718	max: 0.9999864/1.0	min: 1.361373e-05	loss: 34347.98046875	train_loss: 34390.27227041528	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_719
Epoch: 719	max: 0.9999914/1.0	min: 8.56191e-06	loss: 34348.08203125	train_loss: 34390.24864517528	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_720
Epoch: 720	max: 0.9999943/1.0	min: 5.704953e-06	loss: 34348.2890625	train_loss: 34390.26811400656	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_721
Epoch: 721	max: 0.99998724/1.0	min: 1.2795782e-05	loss: 34347.9765625	train_loss: 34390.20700221804	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_722
Epoch: 722	max: 0.9999838/1.0	min: 1.6214495e-05	loss: 34347.8359375	train_loss: 34390.22111707234	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_723
Epoch: 723	max: 0.99997616/1.0	min: 2.3888811e-05	loss: 34347.9296875	train_loss: 34390.187075165675	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_724
Epoch: 724	max: 0.99999094/1.0	min: 9.058714e-06	loss: 34347.98828125	train_loss: 34390.13417264725	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_725
Epoch: 725	max: 0.9999944/1.0	min: 5.5578525e-06	loss: 34347.875	train_loss: 34390.10890613387	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_726
Epoch: 726	max: 0.99998915/1.0	min: 1.0809783e-05	loss: 34347.9765625	train_loss: 34390.09252291589	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_727
Epoch: 727	max: 0.9999825/1.0	min: 1.7523736e-05	loss: 34347.8828125	train_loss: 34390.07904870014	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_728
Epoch: 728	max: 0.9999882/1.0	min: 1.18096195e-05	loss: 34347.984375	train_loss: 34390.056846026106	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_729
Epoch: 729	max: 0.99998915/1.0	min: 1.082975e-05	loss: 34347.98046875	train_loss: 34390.02540199585	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_730
Epoch: 730	max: 0.99998987/1.0	min: 1.0156254e-05	loss: 34347.99609375	train_loss: 34390.01746514229	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_731
Epoch: 731	max: 0.9999858/1.0	min: 1.4137223e-05	loss: 34347.77734375	train_loss: 34389.977509425706	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_732
Epoch: 732	max: 0.99999285/1.0	min: 7.134283e-06	loss: 34347.890625	train_loss: 34389.97357898241	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_733
Epoch: 733	max: 0.99999356/1.0	min: 6.4025057e-06	loss: 34347.7265625	train_loss: 34389.946300554315	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_734
Epoch: 734	max: 0.9999939/1.0	min: 6.055302e-06	loss: 34347.9609375	train_loss: 34389.91556393611	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_735
Epoch: 735	max: 0.9999932/1.0	min: 6.809154e-06	loss: 34347.86328125	train_loss: 34389.91235880791	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_736
Epoch: 736	max: 0.9999882/1.0	min: 1.17573645e-05	loss: 34347.8515625	train_loss: 34389.86501155472	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_737
Epoch: 737	max: 0.99998605/1.0	min: 1.3968486e-05	loss: 34347.66796875	train_loss: 34389.84588336507	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_738
Epoch: 738	max: 0.9999907/1.0	min: 9.254633e-06	loss: 34347.6796875	train_loss: 34389.828125	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_739
Epoch: 739	max: 0.9999889/1.0	min: 1.1105763e-05	loss: 34347.6796875	train_loss: 34389.84188759987	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_740
Epoch: 740	max: 0.999985/1.0	min: 1.5000809e-05	loss: 34347.76171875	train_loss: 34389.786081885606	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_741
Epoch: 741	max: 0.999984/1.0	min: 1.593814e-05	loss: 34347.87890625	train_loss: 34389.74547924021	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_742
Epoch: 742	max: 0.9999862/1.0	min: 1.3831777e-05	loss: 34347.6796875	train_loss: 34389.734258872166	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_743
Epoch: 743	max: 0.99999356/1.0	min: 6.4707033e-06	loss: 34347.70703125	train_loss: 34389.71207603664	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_744
Epoch: 744	max: 0.99998724/1.0	min: 1.2722967e-05	loss: 34347.58984375	train_loss: 34389.68123490338	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_745
Epoch: 745	max: 0.9999864/1.0	min: 1.36454455e-05	loss: 34347.55078125	train_loss: 34389.68489438174	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_746
Epoch: 746	max: 0.9999887/1.0	min: 1.1337813e-05	loss: 34347.62890625	train_loss: 34389.6613422055	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_747
Epoch: 747	max: 0.99999/1.0	min: 9.967141e-06	loss: 34347.80078125	train_loss: 34389.61386334077	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_748
Epoch: 748	max: 0.99999344/1.0	min: 6.5435815e-06	loss: 34347.63671875	train_loss: 34389.589062306455	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_749
Epoch: 749	max: 0.9999857/1.0	min: 1.4345943e-05	loss: 34347.61328125	train_loss: 34389.572581347544	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_750
Epoch: 750	max: 0.99998605/1.0	min: 1.3975268e-05	loss: 34347.65625	train_loss: 34389.543578904995	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_751
Epoch: 751	max: 0.9999893/1.0	min: 1.0717575e-05	loss: 34347.828125	train_loss: 34389.523341694534	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_752
Epoch: 752	max: 0.9999919/1.0	min: 8.070051e-06	loss: 34347.5703125	train_loss: 34389.498090181005	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_753
Epoch: 753	max: 0.9999856/1.0	min: 1.44732185e-05	loss: 34347.5	train_loss: 34389.471207555274	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_754
Epoch: 754	max: 0.9999896/1.0	min: 1.0316917e-05	loss: 34347.68359375	train_loss: 34389.47115529775	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_755
Epoch: 755	max: 0.99998736/1.0	min: 1.2626703e-05	loss: 34347.58984375	train_loss: 34389.453501931595	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_756
Epoch: 756	max: 0.9999949/1.0	min: 5.159659e-06	loss: 34347.63671875	train_loss: 34389.430897648796	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_757
Epoch: 757	max: 0.99999106/1.0	min: 8.974754e-06	loss: 34347.57421875	train_loss: 34389.39589623591	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_758
Epoch: 758	max: 0.99999356/1.0	min: 6.433734e-06	loss: 34347.484375	train_loss: 34389.3587904899	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_759
Epoch: 759	max: 0.99999416/1.0	min: 5.891775e-06	loss: 34347.6640625	train_loss: 34389.34371129072	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_760
Epoch: 760	max: 0.99999225/1.0	min: 7.737188e-06	loss: 34347.61328125	train_loss: 34389.343316456085	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_761
Epoch: 761	max: 0.9999908/1.0	min: 9.19398e-06	loss: 34347.4296875	train_loss: 34389.312943705096	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_762
Epoch: 762	max: 0.9999908/1.0	min: 9.224666e-06	loss: 34347.37890625	train_loss: 34389.30367331692	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_763
Epoch: 763	max: 0.9999865/1.0	min: 1.34165575e-05	loss: 34347.40625	train_loss: 34389.2484172744	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_764
Epoch: 764	max: 0.99997985/1.0	min: 2.018498e-05	loss: 34347.48828125	train_loss: 34389.24701309535	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_765
Epoch: 765	max: 0.99998534/1.0	min: 1.467714e-05	loss: 34347.390625	train_loss: 34389.24628681252	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_766
Epoch: 766	max: 0.9999918/1.0	min: 8.222534e-06	loss: 34347.50390625	train_loss: 34389.22380494782	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_767
Epoch: 767	max: 0.99998975/1.0	min: 1.0205264e-05	loss: 34347.47265625	train_loss: 34389.1678322998	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_768
Epoch: 768	max: 0.99999404/1.0	min: 5.9974514e-06	loss: 34347.52734375	train_loss: 34389.14130676715	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_769
Epoch: 769	max: 0.9999912/1.0	min: 8.79563e-06	loss: 34347.51171875	train_loss: 34389.131816703826	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_770
Epoch: 770	max: 0.9999931/1.0	min: 6.92732e-06	loss: 34347.3125	train_loss: 34389.095027890035	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_771
Epoch: 771	max: 0.9999907/1.0	min: 9.329773e-06	loss: 34347.42578125	train_loss: 34389.089997619376	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_772
Epoch: 772	max: 0.9999925/1.0	min: 7.5506236e-06	loss: 34347.47265625	train_loss: 34389.063293540195	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_773
Epoch: 773	max: 0.9999944/1.0	min: 5.5496907e-06	loss: 34347.703125	train_loss: 34389.07822806345	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_774
Epoch: 774	max: 0.9999949/1.0	min: 5.177848e-06	loss: 34347.7109375	train_loss: 34389.07518503035	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_775
Epoch: 775	max: 0.99998665/1.0	min: 1.3405138e-05	loss: 34347.484375	train_loss: 34389.003606736966	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_776
Epoch: 776	max: 0.9999865/1.0	min: 1.3493122e-05	loss: 34347.4765625	train_loss: 34388.97670765979	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_777
Epoch: 777	max: 0.99999344/1.0	min: 6.5502313e-06	loss: 34347.53515625	train_loss: 34388.946082814626	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_778
Epoch: 778	max: 0.9999908/1.0	min: 9.146195e-06	loss: 34347.38671875	train_loss: 34388.95783737071	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_779
Epoch: 779	max: 0.99998844/1.0	min: 1.1613267e-05	loss: 34347.546875	train_loss: 34388.89779589372	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_780
Epoch: 780	max: 0.9999908/1.0	min: 9.21742e-06	loss: 34347.55859375	train_loss: 34388.89069370897	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_781
Epoch: 781	max: 0.9999871/1.0	min: 1.2815784e-05	loss: 34347.28515625	train_loss: 34388.876811110335	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_782
Epoch: 782	max: 0.99998486/1.0	min: 1.5141142e-05	loss: 34347.171875	train_loss: 34388.85377618683	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_783
Epoch: 783	max: 0.9999844/1.0	min: 1.5578087e-05	loss: 34347.109375	train_loss: 34388.843537098976	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_784
Epoch: 784	max: 0.9999869/1.0	min: 1.3138242e-05	loss: 34347.32421875	train_loss: 34388.79632774759	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_785
Epoch: 785	max: 0.99999106/1.0	min: 8.9395935e-06	loss: 34347.30859375	train_loss: 34388.76980753747	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_786
Epoch: 786	max: 0.9999889/1.0	min: 1.1082307e-05	loss: 34347.05078125	train_loss: 34388.754168989224	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_787
Epoch: 787	max: 0.9999907/1.0	min: 9.288649e-06	loss: 34347.03125	train_loss: 34388.76390001781	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_788
Epoch: 788	max: 0.99999154/1.0	min: 8.4703815e-06	loss: 34347.203125	train_loss: 34388.70918832451	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_789
Epoch: 789	max: 0.9999894/1.0	min: 1.06209945e-05	loss: 34347.125	train_loss: 34388.69492589109	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_790
Epoch: 790	max: 0.9999858/1.0	min: 1.4233001e-05	loss: 34347.078125	train_loss: 34388.66531329354	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_791
Epoch: 791	max: 0.99999106/1.0	min: 8.891021e-06	loss: 34347.234375	train_loss: 34388.671866774275	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_792
Epoch: 792	max: 0.9999894/1.0	min: 1.0660978e-05	loss: 34347.21875	train_loss: 34388.64824976	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_793
Epoch: 793	max: 0.9999918/1.0	min: 8.2325305e-06	loss: 34347.35546875	train_loss: 34388.610923854976	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_794
Epoch: 794	max: 0.99999404/1.0	min: 6.014245e-06	loss: 34347.21875	train_loss: 34388.63413200251	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_795
Epoch: 795	max: 0.99999106/1.0	min: 8.913849e-06	loss: 34347.2109375	train_loss: 34388.5768935611	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_796
Epoch: 796	max: 0.9999907/1.0	min: 9.302887e-06	loss: 34347.2109375	train_loss: 34388.53903782283	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_797
Epoch: 797	max: 0.9999901/1.0	min: 9.880689e-06	loss: 34347.171875	train_loss: 34388.513673084664	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_798
Epoch: 798	max: 0.99999154/1.0	min: 8.50918e-06	loss: 34347.01953125	train_loss: 34388.49294523412	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_799
Epoch: 799	max: 0.99999404/1.0	min: 5.9120994e-06	loss: 34347.03515625	train_loss: 34388.48843028072	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_800
Epoch: 800	max: 0.9999939/1.0	min: 6.07757e-06	loss: 34347.01171875	train_loss: 34388.48048665304	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_801
Epoch: 801	max: 0.9999833/1.0	min: 1.6677437e-05	loss: 34347.140625	train_loss: 34388.43020475272	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_802
Epoch: 802	max: 0.99998736/1.0	min: 1.2604169e-05	loss: 34347.0390625	train_loss: 34388.40855029884	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_803
Epoch: 803	max: 0.9999937/1.0	min: 6.3214375e-06	loss: 34347.1640625	train_loss: 34388.382683307784	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_804
Epoch: 804	max: 0.99999523/1.0	min: 4.7537283e-06	loss: 34346.9609375	train_loss: 34388.37364614301	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_805
Epoch: 805	max: 0.9999931/1.0	min: 6.867036e-06	loss: 34346.91796875	train_loss: 34388.364788976374	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_806
Epoch: 806	max: 0.99998593/1.0	min: 1.403157e-05	loss: 34346.87109375	train_loss: 34388.33812554193	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_807
Epoch: 807	max: 0.9999933/1.0	min: 6.676015e-06	loss: 34346.953125	train_loss: 34388.319729925366	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_808
Epoch: 808	max: 0.99998486/1.0	min: 1.5143367e-05	loss: 34346.84765625	train_loss: 34388.28265708225	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_809
Epoch: 809	max: 0.9999932/1.0	min: 6.7438436e-06	loss: 34347.1015625	train_loss: 34388.28293482132	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_810
Epoch: 810	max: 0.99998486/1.0	min: 1.5091465e-05	loss: 34346.87890625	train_loss: 34388.244645055274	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_811
Epoch: 811	max: 0.9999937/1.0	min: 6.3006364e-06	loss: 34346.96484375	train_loss: 34388.22356059551	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_812
Epoch: 812	max: 0.9999919/1.0	min: 8.074762e-06	loss: 34346.8515625	train_loss: 34388.24860743373	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_813
Epoch: 813	max: 0.99999225/1.0	min: 7.705436e-06	loss: 34347.05859375	train_loss: 34388.22020353338	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_814
Epoch: 814	max: 0.9999939/1.0	min: 6.0807065e-06	loss: 34347.0859375	train_loss: 34388.2275365222	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_815
Epoch: 815	max: 0.9999926/1.0	min: 7.3788738e-06	loss: 34347.0	train_loss: 34388.15716837762	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_816
Epoch: 816	max: 0.9999888/1.0	min: 1.1223587e-05	loss: 34346.80078125	train_loss: 34388.1821276361	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_817
Epoch: 817	max: 0.9999918/1.0	min: 8.281557e-06	loss: 34346.90625	train_loss: 34388.09678771058	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_818
Epoch: 818	max: 0.99998605/1.0	min: 1.3968672e-05	loss: 34346.83984375	train_loss: 34388.078920959524	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_819
Epoch: 819	max: 0.9999926/1.0	min: 7.3577157e-06	loss: 34346.703125	train_loss: 34388.0814738364	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_820
Epoch: 820	max: 0.99999213/1.0	min: 7.8440535e-06	loss: 34346.69921875	train_loss: 34388.046042750524	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_821
Epoch: 821	max: 0.99999285/1.0	min: 7.1503446e-06	loss: 34346.80078125	train_loss: 34388.043209231386	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_822
Epoch: 822	max: 0.9999881/1.0	min: 1.186731e-05	loss: 34346.71484375	train_loss: 34388.00243191038	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_823
Epoch: 823	max: 0.99998975/1.0	min: 1.0227888e-05	loss: 34346.734375	train_loss: 34387.981247774216	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_824
Epoch: 824	max: 0.99999034/1.0	min: 9.712478e-06	loss: 34346.6484375	train_loss: 34387.97189851588	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_825
Epoch: 825	max: 0.9999858/1.0	min: 1.4239354e-05	loss: 34346.6484375	train_loss: 34388.04867304595	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_826
Epoch: 826	max: 0.99998844/1.0	min: 1.1538406e-05	loss: 34346.859375	train_loss: 34387.966968889355	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_827
Epoch: 827	max: 0.99998856/1.0	min: 1.1404612e-05	loss: 34346.80859375	train_loss: 34387.907050314316	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_828
Epoch: 828	max: 0.99999094/1.0	min: 9.013918e-06	loss: 34346.875	train_loss: 34387.88284830608	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_829
Epoch: 829	max: 0.9999882/1.0	min: 1.1783059e-05	loss: 34346.69921875	train_loss: 34387.869724893164	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_830
Epoch: 830	max: 0.9999863/1.0	min: 1.3702469e-05	loss: 34346.765625	train_loss: 34387.87685369054	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_831
Epoch: 831	max: 0.9999907/1.0	min: 9.353461e-06	loss: 34346.85546875	train_loss: 34387.83572072804	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_832
Epoch: 832	max: 0.99999213/1.0	min: 7.83329e-06	loss: 34346.78125	train_loss: 34387.82344795151	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_833
Epoch: 833	max: 0.9999852/1.0	min: 1.4787161e-05	loss: 34346.55859375	train_loss: 34387.825900668126	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_834
Epoch: 834	max: 0.9999907/1.0	min: 9.354209e-06	loss: 34346.609375	train_loss: 34387.80257832822	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_835
Epoch: 835	max: 0.99999464/1.0	min: 5.370289e-06	loss: 34346.71484375	train_loss: 34387.76583161077	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_836
Epoch: 836	max: 0.999992/1.0	min: 7.938136e-06	loss: 34346.62890625	train_loss: 34387.744761666974	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_837
Epoch: 837	max: 0.9999888/1.0	min: 1.1200853e-05	loss: 34346.55078125	train_loss: 34387.72414752493	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_838
Epoch: 838	max: 0.9999871/1.0	min: 1.2919724e-05	loss: 34346.6015625	train_loss: 34387.74681664576	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_839
Epoch: 839	max: 0.9999956/1.0	min: 4.3729397e-06	loss: 34346.53125	train_loss: 34387.715394389474	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_840
Epoch: 840	max: 0.9999907/1.0	min: 9.346853e-06	loss: 34346.63671875	train_loss: 34387.701421791775	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_841
Epoch: 841	max: 0.9999918/1.0	min: 8.274767e-06	loss: 34346.6484375	train_loss: 34387.66397685572	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_842
Epoch: 842	max: 0.9999924/1.0	min: 7.571375e-06	loss: 34346.76171875	train_loss: 34387.6347179642	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_843
Epoch: 843	max: 0.9999932/1.0	min: 6.8414e-06	loss: 34346.56640625	train_loss: 34387.62061278722	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_844
Epoch: 844	max: 0.99999154/1.0	min: 8.505814e-06	loss: 34346.57421875	train_loss: 34387.62030504846	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_845
Epoch: 845	max: 0.99999344/1.0	min: 6.600768e-06	loss: 34346.5	train_loss: 34387.57576179859	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_846
Epoch: 846	max: 0.99999166/1.0	min: 8.388162e-06	loss: 34346.74609375	train_loss: 34387.5612414646	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_847
Epoch: 847	max: 0.9999919/1.0	min: 8.163496e-06	loss: 34346.70703125	train_loss: 34387.54027748746	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_848
Epoch: 848	max: 0.99998903/1.0	min: 1.102102e-05	loss: 34346.578125	train_loss: 34387.533982875015	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_849
Epoch: 849	max: 0.9999919/1.0	min: 8.05518e-06	loss: 34346.57421875	train_loss: 34387.50490398164	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_850
Epoch: 850	max: 0.9999858/1.0	min: 1.4188928e-05	loss: 34346.609375	train_loss: 34387.498946623775	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_851
Epoch: 851	max: 0.999995/1.0	min: 4.983056e-06	loss: 34346.57421875	train_loss: 34387.46793468583	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_852
Epoch: 852	max: 0.99999166/1.0	min: 8.306931e-06	loss: 34346.7109375	train_loss: 34387.461962812	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_853
Epoch: 853	max: 0.99998844/1.0	min: 1.1537614e-05	loss: 34346.62890625	train_loss: 34387.45174694971	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_854
Epoch: 854	max: 0.9999949/1.0	min: 5.156914e-06	loss: 34346.734375	train_loss: 34387.417211983615	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_855
Epoch: 855	max: 0.9999957/1.0	min: 4.3166547e-06	loss: 34346.6015625	train_loss: 34387.44567636721	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_856
Epoch: 856	max: 0.9999939/1.0	min: 6.0979532e-06	loss: 34346.62109375	train_loss: 34387.38433280689	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_857
Epoch: 857	max: 0.9999914/1.0	min: 8.600694e-06	loss: 34346.55859375	train_loss: 34387.34574159235	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_858
Epoch: 858	max: 0.9999931/1.0	min: 6.923892e-06	loss: 34346.92578125	train_loss: 34387.34361113047	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_859
Epoch: 859	max: 0.9999895/1.0	min: 1.0520118e-05	loss: 34346.55859375	train_loss: 34387.32868338133	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_860
Epoch: 860	max: 0.9999894/1.0	min: 1.06283205e-05	loss: 34346.58203125	train_loss: 34387.29353826025	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_861
Epoch: 861	max: 0.99999094/1.0	min: 9.01023e-06	loss: 34346.453125	train_loss: 34387.26366485895	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_862
Epoch: 862	max: 0.99999166/1.0	min: 8.38219e-06	loss: 34346.45703125	train_loss: 34387.22630411557	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_863
Epoch: 863	max: 0.9999931/1.0	min: 6.884268e-06	loss: 34346.31640625	train_loss: 34387.20416192478	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_864
Epoch: 864	max: 0.99999285/1.0	min: 7.179001e-06	loss: 34346.56640625	train_loss: 34387.194195737335	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_865
Epoch: 865	max: 0.99999/1.0	min: 9.974064e-06	loss: 34346.32421875	train_loss: 34387.22191787053	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_866
Epoch: 866	max: 0.9999894/1.0	min: 1.05974805e-05	loss: 34346.37109375	train_loss: 34387.19055900068	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_867
Epoch: 867	max: 0.9999864/1.0	min: 1.362742e-05	loss: 34346.375	train_loss: 34387.15808288431	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_868
Epoch: 868	max: 0.9999908/1.0	min: 9.131232e-06	loss: 34346.36328125	train_loss: 34387.07887789545	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_869
Epoch: 869	max: 0.99998546/1.0	min: 1.4488049e-05	loss: 34346.35546875	train_loss: 34387.05885455376	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_870
Epoch: 870	max: 0.9999933/1.0	min: 6.705795e-06	loss: 34346.515625	train_loss: 34387.01528629382	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_871
Epoch: 871	max: 0.9999957/1.0	min: 4.331616e-06	loss: 34346.40625	train_loss: 34386.980465846806	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_872
Epoch: 872	max: 0.9999925/1.0	min: 7.5359917e-06	loss: 34346.36328125	train_loss: 34386.961374430975	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_873
Epoch: 873	max: 0.99999404/1.0	min: 5.9044696e-06	loss: 34346.31640625	train_loss: 34386.89693461229	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_874
Epoch: 874	max: 0.99999356/1.0	min: 6.421071e-06	loss: 34346.3515625	train_loss: 34386.86693782516	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_875
Epoch: 875	max: 0.9999906/1.0	min: 9.450638e-06	loss: 34346.51953125	train_loss: 34386.841140510805	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_876
Epoch: 876	max: 0.99999297/1.0	min: 7.048222e-06	loss: 34346.57421875	train_loss: 34386.82143942385	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_877
Epoch: 877	max: 0.9999956/1.0	min: 4.3925e-06	loss: 34346.42578125	train_loss: 34386.76972915118	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_878
Epoch: 878	max: 0.9999949/1.0	min: 5.0826607e-06	loss: 34346.43359375	train_loss: 34386.74003042549	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_879
Epoch: 879	max: 0.99999475/1.0	min: 5.1868324e-06	loss: 34346.3359375	train_loss: 34386.73373436145	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_880
Epoch: 880	max: 0.9999951/1.0	min: 4.9028968e-06	loss: 34346.5390625	train_loss: 34386.69004707048	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_881
Epoch: 881	max: 0.9999957/1.0	min: 4.291792e-06	loss: 34346.328125	train_loss: 34386.708156722256	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_882
Epoch: 882	max: 0.99999607/1.0	min: 3.9760953e-06	loss: 34346.1875	train_loss: 34386.659384967636	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_883
Epoch: 883	max: 0.9999944/1.0	min: 5.575243e-06	loss: 34346.359375	train_loss: 34386.62608385978	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_884
Epoch: 884	max: 0.9999951/1.0	min: 4.868957e-06	loss: 34346.21875	train_loss: 34386.58650604252	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_885
Epoch: 885	max: 0.99998784/1.0	min: 1.2159396e-05	loss: 34346.171875	train_loss: 34386.55869923278	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_886
Epoch: 886	max: 0.99999166/1.0	min: 8.39917e-06	loss: 34346.203125	train_loss: 34386.58414235724	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_887
Epoch: 887	max: 0.999995/1.0	min: 4.969241e-06	loss: 34346.19921875	train_loss: 34386.51639773396	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_888
Epoch: 888	max: 0.9999938/1.0	min: 6.1924525e-06	loss: 34346.16796875	train_loss: 34386.48942075437	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_889
Epoch: 889	max: 0.99999607/1.0	min: 3.9886772e-06	loss: 34346.48828125	train_loss: 34386.46869967794	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_890
Epoch: 890	max: 0.9999964/1.0	min: 3.5794035e-06	loss: 34346.15625	train_loss: 34386.45850752509	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_891
Epoch: 891	max: 0.9999925/1.0	min: 7.507922e-06	loss: 34346.28125	train_loss: 34386.437119681344	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_892
Epoch: 892	max: 0.99999285/1.0	min: 7.1463155e-06	loss: 34346.23828125	train_loss: 34386.405765166295	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_893
Epoch: 893	max: 0.99999344/1.0	min: 6.6091334e-06	loss: 34346.171875	train_loss: 34386.387766803695	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_894
Epoch: 894	max: 0.99999225/1.0	min: 7.737682e-06	loss: 34346.2890625	train_loss: 34386.366525087484	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_895
Epoch: 895	max: 0.9999938/1.0	min: 6.17621e-06	loss: 34346.5	train_loss: 34386.36676073021	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_896
Epoch: 896	max: 0.999997/1.0	min: 2.9603732e-06	loss: 34346.6328125	train_loss: 34386.36973021569	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_897
Epoch: 897	max: 0.99999714/1.0	min: 2.8463392e-06	loss: 34346.32421875	train_loss: 34386.34121938096	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_898
Epoch: 898	max: 0.9999938/1.0	min: 6.1631886e-06	loss: 34346.26171875	train_loss: 34386.2938261605	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_899
Epoch: 899	max: 0.99999106/1.0	min: 8.952545e-06	loss: 34346.09375	train_loss: 34386.25843765484	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_900
Epoch: 900	max: 0.99999356/1.0	min: 6.4561686e-06	loss: 34346.0625	train_loss: 34386.24066719311	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_901
Epoch: 901	max: 0.99999535/1.0	min: 4.669949e-06	loss: 34346.171875	train_loss: 34386.22411897684	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_902
Epoch: 902	max: 0.9999956/1.0	min: 4.3997698e-06	loss: 34346.26171875	train_loss: 34386.21146297845	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_903
Epoch: 903	max: 0.9999927/1.0	min: 7.262862e-06	loss: 34346.15625	train_loss: 34386.18819773474	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_904
Epoch: 904	max: 0.9999906/1.0	min: 9.403492e-06	loss: 34346.11328125	train_loss: 34386.18202215332	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_905
Epoch: 905	max: 0.99999106/1.0	min: 8.997301e-06	loss: 34346.1640625	train_loss: 34386.145358176946	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_906
Epoch: 906	max: 0.99999607/1.0	min: 3.9456118e-06	loss: 34346.05859375	train_loss: 34386.127826261145	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_907
Epoch: 907	max: 0.9999945/1.0	min: 5.4574857e-06	loss: 34346.1484375	train_loss: 34386.136434720676	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_908
Epoch: 908	max: 0.99998987/1.0	min: 1.0120952e-05	loss: 34346.00390625	train_loss: 34386.12580757231	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_909
Epoch: 909	max: 0.9999906/1.0	min: 9.386263e-06	loss: 34346.140625	train_loss: 34386.07958433977	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_910
Epoch: 910	max: 0.9999937/1.0	min: 6.262166e-06	loss: 34346.453125	train_loss: 34386.05493040072	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_911
Epoch: 911	max: 0.9999944/1.0	min: 5.5935375e-06	loss: 34346.0546875	train_loss: 34386.05279606791	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_912
Epoch: 912	max: 0.99999213/1.0	min: 7.839537e-06	loss: 34346.0546875	train_loss: 34386.013666310544	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_913
Epoch: 913	max: 0.99999166/1.0	min: 8.3269515e-06	loss: 34345.984375	train_loss: 34386.00753040614	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_914
Epoch: 914	max: 0.99999166/1.0	min: 8.311749e-06	loss: 34345.984375	train_loss: 34386.00811927103	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_915
Epoch: 915	max: 0.99999714/1.0	min: 2.818689e-06	loss: 34346.19140625	train_loss: 34385.97393801096	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_916
Epoch: 916	max: 0.9999932/1.0	min: 6.839704e-06	loss: 34345.984375	train_loss: 34385.98479499567	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_917
Epoch: 917	max: 0.99999297/1.0	min: 7.062069e-06	loss: 34346.1015625	train_loss: 34385.93136699879	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_918
Epoch: 918	max: 0.999998/1.0	min: 2.0156654e-06	loss: 34346.4296875	train_loss: 34385.9139899201	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_919
Epoch: 919	max: 0.9999957/1.0	min: 4.2481593e-06	loss: 34345.98828125	train_loss: 34385.9598212212	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_920
Epoch: 920	max: 0.9999937/1.0	min: 6.3460093e-06	loss: 34345.88671875	train_loss: 34385.897734926606	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_921
Epoch: 921	max: 0.99999654/1.0	min: 3.509643e-06	loss: 34345.75	train_loss: 34385.8943706065	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_922
Epoch: 922	max: 0.99999666/1.0	min: 3.3831443e-06	loss: 34345.921875	train_loss: 34385.8887195358	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_923
Epoch: 923	max: 0.99999595/1.0	min: 4.0330046e-06	loss: 34345.80859375	train_loss: 34385.84910688019	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_924
Epoch: 924	max: 0.9999974/1.0	min: 2.5973127e-06	loss: 34346.03125	train_loss: 34385.81726124117	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_925
Epoch: 925	max: 0.9999945/1.0	min: 5.527612e-06	loss: 34345.859375	train_loss: 34385.80226042828	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_926
Epoch: 926	max: 0.9999943/1.0	min: 5.717823e-06	loss: 34345.91796875	train_loss: 34385.80661957683	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_927
Epoch: 927	max: 0.9999945/1.0	min: 5.5235964e-06	loss: 34345.96875	train_loss: 34385.78764090177	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_928
Epoch: 928	max: 0.9999937/1.0	min: 6.3599928e-06	loss: 34345.75	train_loss: 34385.77053333643	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_929
Epoch: 929	max: 0.9999962/1.0	min: 3.7580387e-06	loss: 34345.7734375	train_loss: 34385.75146127524	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_930
Epoch: 930	max: 0.99999666/1.0	min: 3.354023e-06	loss: 34345.87109375	train_loss: 34385.73916236994	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_931
Epoch: 931	max: 0.99999833/1.0	min: 1.6734826e-06	loss: 34346.203125	train_loss: 34385.72882360569	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_932
Epoch: 932	max: 0.9999962/1.0	min: 3.7913546e-06	loss: 34345.87890625	train_loss: 34385.71210361699	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_933
Epoch: 933	max: 0.999997/1.0	min: 3.0163037e-06	loss: 34345.73828125	train_loss: 34385.70715753902	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_934
Epoch: 934	max: 0.99999595/1.0	min: 4.006385e-06	loss: 34345.7421875	train_loss: 34385.674215943574	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_935
Epoch: 935	max: 0.99999595/1.0	min: 3.9996926e-06	loss: 34346.0859375	train_loss: 34385.657599018334	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_936
Epoch: 936	max: 0.9999968/1.0	min: 3.258019e-06	loss: 34346.0234375	train_loss: 34385.64757041218	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_937
Epoch: 937	max: 0.99999666/1.0	min: 3.3379183e-06	loss: 34346.1796875	train_loss: 34385.63885646987	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_938
Epoch: 938	max: 0.99999523/1.0	min: 4.7209014e-06	loss: 34346.0390625	train_loss: 34385.64950587607	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_939
Epoch: 939	max: 0.99999535/1.0	min: 4.622568e-06	loss: 34345.91796875	train_loss: 34385.589948748915	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_940
Epoch: 940	max: 0.9999968/1.0	min: 3.2104062e-06	loss: 34345.94140625	train_loss: 34385.57788742181	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_941
Epoch: 941	max: 0.99999726/1.0	min: 2.699526e-06	loss: 34345.890625	train_loss: 34385.583418009875	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_942
Epoch: 942	max: 0.9999962/1.0	min: 3.8303906e-06	loss: 34345.7265625	train_loss: 34385.55030367428	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_943
Epoch: 943	max: 0.99999785/1.0	min: 2.100967e-06	loss: 34345.828125	train_loss: 34385.5359014036	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_944
Epoch: 944	max: 0.9999969/1.0	min: 3.147396e-06	loss: 34345.7265625	train_loss: 34385.542462626196	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_945
Epoch: 945	max: 0.9999964/1.0	min: 3.6091526e-06	loss: 34345.66796875	train_loss: 34385.54779144215	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_946
Epoch: 946	max: 0.99999356/1.0	min: 6.4796145e-06	loss: 34345.69140625	train_loss: 34385.50287997027	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_947
Epoch: 947	max: 0.9999958/1.0	min: 4.113454e-06	loss: 34345.84765625	train_loss: 34385.54123989688	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_948
Epoch: 948	max: 0.9999963/1.0	min: 3.7358768e-06	loss: 34345.85546875	train_loss: 34385.46982418246	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_949
Epoch: 949	max: 0.99999726/1.0	min: 2.7232738e-06	loss: 34345.859375	train_loss: 34385.4646119782	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_950
Epoch: 950	max: 0.99999726/1.0	min: 2.7018416e-06	loss: 34345.953125	train_loss: 34385.46761678589	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_951
Epoch: 951	max: 0.9999976/1.0	min: 2.3833786e-06	loss: 34345.80078125	train_loss: 34385.43527953905	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_952
Epoch: 952	max: 0.9999974/1.0	min: 2.5996544e-06	loss: 34345.703125	train_loss: 34385.41497023257	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_953
Epoch: 953	max: 0.99999785/1.0	min: 2.1944368e-06	loss: 34345.93359375	train_loss: 34385.39622090998	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_954
Epoch: 954	max: 0.99999845/1.0	min: 1.593131e-06	loss: 34345.9375	train_loss: 34385.49484876285	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_955
Epoch: 955	max: 0.99999774/1.0	min: 2.2294275e-06	loss: 34345.42578125	train_loss: 34385.51581370773	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_956
Epoch: 956	max: 0.99999833/1.0	min: 1.6398068e-06	loss: 34345.5	train_loss: 34385.400452801776	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_957
Epoch: 957	max: 0.999995/1.0	min: 5.0110775e-06	loss: 34345.59375	train_loss: 34385.37852883454	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_958
Epoch: 958	max: 0.99999464/1.0	min: 5.3183985e-06	loss: 34345.57421875	train_loss: 34385.355986970455	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_959
Epoch: 959	max: 0.9999963/1.0	min: 3.748332e-06	loss: 34345.6796875	train_loss: 34385.34623320017	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_960
Epoch: 960	max: 0.99999857/1.0	min: 1.3735483e-06	loss: 34345.9609375	train_loss: 34385.37540112489	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_961
Epoch: 961	max: 0.99999726/1.0	min: 2.7261062e-06	loss: 34345.7734375	train_loss: 34385.327805648456	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_962
Epoch: 962	max: 0.9999968/1.0	min: 3.174496e-06	loss: 34345.859375	train_loss: 34385.30553716865	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_963
Epoch: 963	max: 0.99999475/1.0	min: 5.2083e-06	loss: 34345.62890625	train_loss: 34385.30362299486	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_964
Epoch: 964	max: 0.9999926/1.0	min: 7.4246004e-06	loss: 34345.81640625	train_loss: 34385.27834099777	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_965
Epoch: 965	max: 0.999998/1.0	min: 2.0529428e-06	loss: 34345.6796875	train_loss: 34385.27487700127	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_966
Epoch: 966	max: 0.999997/1.0	min: 2.9920404e-06	loss: 34345.60546875	train_loss: 34385.252176429145	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_967
Epoch: 967	max: 0.9999976/1.0	min: 2.4172225e-06	loss: 34345.734375	train_loss: 34385.233983552425	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_968
Epoch: 968	max: 0.9999974/1.0	min: 2.6642313e-06	loss: 34345.65625	train_loss: 34385.227780390655	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_969
Epoch: 969	max: 0.9999968/1.0	min: 3.1662146e-06	loss: 34345.64453125	train_loss: 34385.2068933482	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_970
Epoch: 970	max: 0.9999951/1.0	min: 4.947047e-06	loss: 34345.75	train_loss: 34385.198105374395	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_971
Epoch: 971	max: 0.99999535/1.0	min: 4.5902707e-06	loss: 34345.5	train_loss: 34385.20096018364	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_972
Epoch: 972	max: 0.9999975/1.0	min: 2.5372963e-06	loss: 34345.8828125	train_loss: 34385.21497681314	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_973
Epoch: 973	max: 0.9999958/1.0	min: 4.1142034e-06	loss: 34345.59375	train_loss: 34385.18148119116	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_974
Epoch: 974	max: 0.99999774/1.0	min: 2.2664588e-06	loss: 34345.7890625	train_loss: 34385.1735046606	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_975
Epoch: 975	max: 0.9999975/1.0	min: 2.5194772e-06	loss: 34345.71875	train_loss: 34385.162557192954	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_976
Epoch: 976	max: 0.9999976/1.0	min: 2.337699e-06	loss: 34345.78515625	train_loss: 34385.139598236405	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_977
Epoch: 977	max: 0.99999785/1.0	min: 2.1273997e-06	loss: 34345.625	train_loss: 34385.135033444814	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_978
Epoch: 978	max: 0.99999714/1.0	min: 2.8266218e-06	loss: 34345.546875	train_loss: 34385.11040660225	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_979
Epoch: 979	max: 0.9999987/1.0	min: 1.3450997e-06	loss: 34345.7109375	train_loss: 34385.100780088724	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_980
Epoch: 980	max: 0.999995/1.0	min: 4.9984437e-06	loss: 34345.578125	train_loss: 34385.10577213397	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_981
Epoch: 981	max: 0.9999964/1.0	min: 3.523389e-06	loss: 34345.51953125	train_loss: 34385.09051342051	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_982
Epoch: 982	max: 0.99999666/1.0	min: 3.367218e-06	loss: 34345.546875	train_loss: 34385.061466462284	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_983
Epoch: 983	max: 0.99999714/1.0	min: 2.8682775e-06	loss: 34345.62890625	train_loss: 34385.06813800632	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_984
Epoch: 984	max: 0.99999845/1.0	min: 1.4932891e-06	loss: 34345.53515625	train_loss: 34385.13928033646	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_985
Epoch: 985	max: 0.9999989/1.0	min: 1.0621709e-06	loss: 34345.65625	train_loss: 34385.03963926824	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_986
Epoch: 986	max: 0.99999774/1.0	min: 2.2567338e-06	loss: 34345.35546875	train_loss: 34385.027283266754	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_987
Epoch: 987	max: 0.9999964/1.0	min: 3.5397638e-06	loss: 34345.42578125	train_loss: 34385.01086908135	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_988
Epoch: 988	max: 0.9999975/1.0	min: 2.4891226e-06	loss: 34345.69921875	train_loss: 34385.00780282268	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_989
Epoch: 989	max: 0.999998/1.0	min: 1.9851423e-06	loss: 34345.5234375	train_loss: 34384.98985526601	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_990
Epoch: 990	max: 0.9999975/1.0	min: 2.5020217e-06	loss: 34345.51953125	train_loss: 34385.02229025378	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_991
Epoch: 991	max: 0.9999982/1.0	min: 1.827556e-06	loss: 34345.6796875	train_loss: 34384.986170626624	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_992
Epoch: 992	max: 0.9999968/1.0	min: 3.273598e-06	loss: 34345.3046875	train_loss: 34384.9825648574	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_993
Epoch: 993	max: 0.99999714/1.0	min: 2.870119e-06	loss: 34345.3984375	train_loss: 34384.97453655317	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_994
Epoch: 994	max: 0.9999989/1.0	min: 1.122759e-06	loss: 34345.55859375	train_loss: 34384.94347332544	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_995
Epoch: 995	max: 0.9999939/1.0	min: 6.0912816e-06	loss: 34345.48046875	train_loss: 34384.92367788462	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_996
Epoch: 996	max: 0.9999949/1.0	min: 5.1107645e-06	loss: 34345.37890625	train_loss: 34384.92807235538	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_997
Epoch: 997	max: 0.9999963/1.0	min: 3.6995928e-06	loss: 34345.25390625	train_loss: 34384.930166527316	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_998
Epoch: 998	max: 0.9999969/1.0	min: 3.1007996e-06	loss: 34345.4609375	train_loss: 34384.920994847795	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_999
Epoch: 999	max: 0.99999475/1.0	min: 5.2328605e-06	loss: 34345.34375	train_loss: 34384.89861556268	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1000
Epoch: 1000	max: 0.99999785/1.0	min: 2.158609e-06	loss: 34345.28125	train_loss: 34384.908915133776	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1001
Epoch: 1001	max: 0.9999988/1.0	min: 1.2022812e-06	loss: 34345.390625	train_loss: 34384.89795073083	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1002
Epoch: 1002	max: 0.99999857/1.0	min: 1.3767653e-06	loss: 34345.49609375	train_loss: 34384.873278888736	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1003
Epoch: 1003	max: 0.9999964/1.0	min: 3.5287555e-06	loss: 34345.265625	train_loss: 34384.8661365431	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1004
Epoch: 1004	max: 0.9999957/1.0	min: 4.3315704e-06	loss: 34345.484375	train_loss: 34384.851664111855	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1005
Epoch: 1005	max: 0.9999969/1.0	min: 3.060019e-06	loss: 34345.30078125	train_loss: 34384.83151496501	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1006
Epoch: 1006	max: 0.99999547/1.0	min: 4.52839e-06	loss: 34345.265625	train_loss: 34384.829719338384	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1007
Epoch: 1007	max: 0.9999963/1.0	min: 3.7066698e-06	loss: 34345.32421875	train_loss: 34384.84486531107	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1008
Epoch: 1008	max: 0.99999774/1.0	min: 2.2414747e-06	loss: 34345.37890625	train_loss: 34384.80163914437	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1009
Epoch: 1009	max: 0.999998/1.0	min: 2.0662737e-06	loss: 34345.44921875	train_loss: 34384.79501695466	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1010
Epoch: 1010	max: 0.99999714/1.0	min: 2.9170217e-06	loss: 34345.51953125	train_loss: 34384.793860998856	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1011
Epoch: 1011	max: 0.99999774/1.0	min: 2.3145928e-06	loss: 34345.5703125	train_loss: 34384.78446432166	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1012
Epoch: 1012	max: 0.999998/1.0	min: 1.979886e-06	loss: 34345.45703125	train_loss: 34384.77065768999	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1013
Epoch: 1013	max: 0.9999958/1.0	min: 4.1815406e-06	loss: 34345.12890625	train_loss: 34384.74597375124	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1014
Epoch: 1014	max: 0.99999714/1.0	min: 2.8597094e-06	loss: 34345.28515625	train_loss: 34384.79648452016	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1015
Epoch: 1015	max: 0.999998/1.0	min: 2.008462e-06	loss: 34345.19140625	train_loss: 34384.76320712173	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1016
Epoch: 1016	max: 0.99999785/1.0	min: 2.1408814e-06	loss: 34345.19921875	train_loss: 34384.7366288477	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1017
Epoch: 1017	max: 0.99999475/1.0	min: 5.228715e-06	loss: 34345.4140625	train_loss: 34384.714083596555	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1018
Epoch: 1018	max: 0.99999714/1.0	min: 2.834888e-06	loss: 34345.2890625	train_loss: 34384.72458832683	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1019
Epoch: 1019	max: 0.9999958/1.0	min: 4.175563e-06	loss: 34345.30859375	train_loss: 34384.702940163195	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1020
Epoch: 1020	max: 0.99999726/1.0	min: 2.7854917e-06	loss: 34345.26953125	train_loss: 34384.691161413815	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1021
Epoch: 1021	max: 0.9999951/1.0	min: 4.9225187e-06	loss: 34345.390625	train_loss: 34384.70880510266	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1022
Epoch: 1022	max: 0.9999981/1.0	min: 1.955268e-06	loss: 34345.2890625	train_loss: 34384.67086468785	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1023
Epoch: 1023	max: 0.99999774/1.0	min: 2.2809324e-06	loss: 34345.421875	train_loss: 34384.65874529682	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1024
Epoch: 1024	max: 0.99999845/1.0	min: 1.554049e-06	loss: 34345.5078125	train_loss: 34384.65308019401	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1025
Epoch: 1025	max: 0.99999845/1.0	min: 1.6003916e-06	loss: 34345.65625	train_loss: 34384.70355418912	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1026
Epoch: 1026	max: 0.9999968/1.0	min: 3.2382407e-06	loss: 34345.53125	train_loss: 34384.65298680788	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1027
Epoch: 1027	max: 0.9999963/1.0	min: 3.6370777e-06	loss: 34345.16015625	train_loss: 34384.674856582125	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1028
Epoch: 1028	max: 0.99999666/1.0	min: 3.3946048e-06	loss: 34345.21484375	train_loss: 34384.649173460144	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1029
Epoch: 1029	max: 0.99999785/1.0	min: 2.0957561e-06	loss: 34345.0859375	train_loss: 34384.63709761706	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1030
Epoch: 1030	max: 0.9999988/1.0	min: 1.150482e-06	loss: 34345.12109375	train_loss: 34384.60895210114	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1031
Epoch: 1031	max: 0.99999833/1.0	min: 1.6620995e-06	loss: 34345.2734375	train_loss: 34384.58608556299	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1032
Epoch: 1032	max: 0.9999918/1.0	min: 8.21078e-06	loss: 34345.18359375	train_loss: 34384.64180998777	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1033
Epoch: 1033	max: 0.9999988/1.0	min: 1.163593e-06	loss: 34345.265625	train_loss: 34384.59505305107	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1034
Epoch: 1034	max: 0.999998/1.0	min: 2.0064977e-06	loss: 34345.20703125	train_loss: 34384.56211677815	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1035
Epoch: 1035	max: 0.9999981/1.0	min: 1.8881041e-06	loss: 34345.17578125	train_loss: 34384.55776391985	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1036
Epoch: 1036	max: 0.99999857/1.0	min: 1.4359932e-06	loss: 34345.140625	train_loss: 34384.58563943856	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1037
Epoch: 1037	max: 0.99999785/1.0	min: 2.1813312e-06	loss: 34345.0859375	train_loss: 34384.54060748405	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1038
Epoch: 1038	max: 0.9999988/1.0	min: 1.1440302e-06	loss: 34345.38671875	train_loss: 34384.53644236576	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1039
Epoch: 1039	max: 0.99999774/1.0	min: 2.2654906e-06	loss: 34345.09765625	train_loss: 34384.52168445358	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1040
Epoch: 1040	max: 0.9999974/1.0	min: 2.586412e-06	loss: 34345.3046875	train_loss: 34384.54424373684	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1041
Epoch: 1041	max: 0.99999917/1.0	min: 8.117654e-07	loss: 34345.1953125	train_loss: 34384.52494329091	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1042
Epoch: 1042	max: 0.9999988/1.0	min: 1.1508037e-06	loss: 34345.10546875	train_loss: 34384.50146950096	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1043
Epoch: 1043	max: 0.9999949/1.0	min: 5.1621396e-06	loss: 34345.10546875	train_loss: 34384.495925364645	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1044
Epoch: 1044	max: 0.9999988/1.0	min: 1.2500698e-06	loss: 34344.984375	train_loss: 34384.48444564443	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1045
Epoch: 1045	max: 0.99999833/1.0	min: 1.6920309e-06	loss: 34344.9921875	train_loss: 34384.46982708565	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1046
Epoch: 1046	max: 0.99999475/1.0	min: 5.202696e-06	loss: 34345.11328125	train_loss: 34384.49029751951	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1047
Epoch: 1047	max: 0.99999726/1.0	min: 2.7537149e-06	loss: 34345.1796875	train_loss: 34384.48136486978	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1048
Epoch: 1048	max: 0.9999987/1.0	min: 1.3441726e-06	loss: 34345.12890625	train_loss: 34384.472839151334	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1049
Epoch: 1049	max: 0.9999976/1.0	min: 2.3466112e-06	loss: 34345.3515625	train_loss: 34384.428773961044	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1050
Epoch: 1050	max: 0.9999951/1.0	min: 4.931794e-06	loss: 34345.109375	train_loss: 34384.468537098976	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1051
Epoch: 1051	max: 0.9999964/1.0	min: 3.5442465e-06	loss: 34344.90234375	train_loss: 34384.44556217484	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1052
Epoch: 1052	max: 0.99999726/1.0	min: 2.7138058e-06	loss: 34345.10546875	train_loss: 34384.44904552598	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1053
Epoch: 1053	max: 0.99999714/1.0	min: 2.8175846e-06	loss: 34345.50390625	train_loss: 34384.441415443456	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1054
Epoch: 1054	max: 0.99999833/1.0	min: 1.6649757e-06	loss: 34345.203125	train_loss: 34384.422991762665	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1055
Epoch: 1055	max: 0.9999988/1.0	min: 1.2020726e-06	loss: 34345.09375	train_loss: 34384.38390119844	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1056
Epoch: 1056	max: 0.9999993/1.0	min: 7.095087e-07	loss: 34345.31640625	train_loss: 34384.38741745247	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1057
Epoch: 1057	max: 0.999998/1.0	min: 1.9984539e-06	loss: 34345.01171875	train_loss: 34384.39812734191	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1058
Epoch: 1058	max: 0.99999845/1.0	min: 1.5185764e-06	loss: 34345.1953125	train_loss: 34384.35312296776	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1059
Epoch: 1059	max: 0.999998/1.0	min: 2.0856235e-06	loss: 34345.11328125	train_loss: 34384.350784443515	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1060
Epoch: 1060	max: 0.9999987/1.0	min: 1.2566343e-06	loss: 34345.0234375	train_loss: 34384.34211114595	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1061
Epoch: 1061	max: 0.9999982/1.0	min: 1.7445731e-06	loss: 34344.90625	train_loss: 34384.33271495262	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1062
Epoch: 1062	max: 0.9999993/1.0	min: 7.080689e-07	loss: 34345.1015625	train_loss: 34384.33007401214	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1063
Epoch: 1063	max: 0.9999989/1.0	min: 1.0907848e-06	loss: 34345.30078125	train_loss: 34384.348405274526	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1064
Epoch: 1064	max: 0.9999963/1.0	min: 3.6907757e-06	loss: 34344.875	train_loss: 34384.336722330605	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1065
Epoch: 1065	max: 0.999998/1.0	min: 2.0740958e-06	loss: 34345.015625	train_loss: 34384.418247940666	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1066
Epoch: 1066	max: 0.99999857/1.0	min: 1.457785e-06	loss: 34345.171875	train_loss: 34384.302873486464	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1067
Epoch: 1067	max: 0.999997/1.0	min: 2.9710643e-06	loss: 34344.92578125	train_loss: 34384.30055141366	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1068
Epoch: 1068	max: 0.99999845/1.0	min: 1.5451968e-06	loss: 34344.9140625	train_loss: 34384.27437958705	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1069
Epoch: 1069	max: 0.9999976/1.0	min: 2.4267829e-06	loss: 34345.046875	train_loss: 34384.27455813359	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1070
Epoch: 1070	max: 0.9999987/1.0	min: 1.3384382e-06	loss: 34345.1015625	train_loss: 34384.258922488545	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1071
Epoch: 1071	max: 0.99999726/1.0	min: 2.7447823e-06	loss: 34344.859375	train_loss: 34384.266696279265	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1072
Epoch: 1072	max: 0.99999845/1.0	min: 1.5258029e-06	loss: 34344.99609375	train_loss: 34384.25969425477	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1073
Epoch: 1073	max: 0.99999547/1.0	min: 4.5009465e-06	loss: 34344.984375	train_loss: 34384.2392155952	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1074
Epoch: 1074	max: 0.9999982/1.0	min: 1.8074223e-06	loss: 34344.8671875	train_loss: 34384.2722970279	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1075
Epoch: 1075	max: 0.99999845/1.0	min: 1.602218e-06	loss: 34344.99609375	train_loss: 34384.22870989719	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1076
Epoch: 1076	max: 0.99999917/1.0	min: 8.4643864e-07	loss: 34344.91015625	train_loss: 34384.22706088195	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1077
Epoch: 1077	max: 0.99999785/1.0	min: 2.1978046e-06	loss: 34344.91015625	train_loss: 34384.20994992955	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1078
Epoch: 1078	max: 0.99999857/1.0	min: 1.4819778e-06	loss: 34344.890625	train_loss: 34384.20815188359	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1079
Epoch: 1079	max: 0.9999989/1.0	min: 1.0819939e-06	loss: 34344.75390625	train_loss: 34384.199839066176	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1080
Epoch: 1080	max: 0.9999989/1.0	min: 1.0921318e-06	loss: 34344.82421875	train_loss: 34384.17854799563	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1081
Epoch: 1081	max: 0.9999968/1.0	min: 3.2709454e-06	loss: 34344.890625	train_loss: 34384.178395093986	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1082
Epoch: 1082	max: 0.9999989/1.0	min: 1.0679065e-06	loss: 34344.94140625	train_loss: 34384.17556980057	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1083
Epoch: 1083	max: 0.9999988/1.0	min: 1.1969535e-06	loss: 34344.98828125	train_loss: 34384.165642322405	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1084
Epoch: 1084	max: 0.999998/1.0	min: 2.032234e-06	loss: 34345.19921875	train_loss: 34384.154080344975	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1085
Epoch: 1085	max: 0.99999857/1.0	min: 1.4589393e-06	loss: 34345.0234375	train_loss: 34384.173400629414	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1086
Epoch: 1086	max: 0.99999917/1.0	min: 8.708772e-07	loss: 34345.046875	train_loss: 34384.16888422442	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1087
Epoch: 1087	max: 0.9999987/1.0	min: 1.3479839e-06	loss: 34345.0546875	train_loss: 34384.13073768271	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1088
Epoch: 1088	max: 0.99999917/1.0	min: 7.933474e-07	loss: 34344.96875	train_loss: 34384.16927712359	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1089
Epoch: 1089	max: 0.99999785/1.0	min: 2.1273631e-06	loss: 34344.71875	train_loss: 34384.114565914155	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1090
Epoch: 1090	max: 0.9999995/1.0	min: 4.5572943e-07	loss: 34344.921875	train_loss: 34384.11825926313	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1091
Epoch: 1091	max: 0.99999833/1.0	min: 1.615804e-06	loss: 34344.890625	train_loss: 34384.10157217732	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1092
Epoch: 1092	max: 0.9999976/1.0	min: 2.4118597e-06	loss: 34344.90625	train_loss: 34384.10402199074	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1093
Epoch: 1093	max: 0.9999987/1.0	min: 1.3466323e-06	loss: 34344.9765625	train_loss: 34384.08343059039	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1094
Epoch: 1094	max: 0.99999833/1.0	min: 1.672082e-06	loss: 34344.85546875	train_loss: 34384.092904202276	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1095
Epoch: 1095	max: 0.99999785/1.0	min: 2.1541073e-06	loss: 34344.7109375	train_loss: 34384.067215273906	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1096
Epoch: 1096	max: 0.99999845/1.0	min: 1.5320786e-06	loss: 34345.03515625	train_loss: 34384.08270914623	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1097
Epoch: 1097	max: 0.9999943/1.0	min: 5.7756424e-06	loss: 34344.94921875	train_loss: 34384.06480658909	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1098
Epoch: 1098	max: 0.9999988/1.0	min: 1.1711825e-06	loss: 34344.8671875	train_loss: 34384.04716628732	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1099
Epoch: 1099	max: 0.9999963/1.0	min: 3.700217e-06	loss: 34344.78125	train_loss: 34384.03937556128	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1100
Epoch: 1100	max: 0.99999666/1.0	min: 3.3476733e-06	loss: 34344.98828125	train_loss: 34384.03774202976	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1101
Epoch: 1101	max: 0.999998/1.0	min: 2.0851662e-06	loss: 34344.984375	train_loss: 34384.03528979701	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1102
Epoch: 1102	max: 0.99999833/1.0	min: 1.6170434e-06	loss: 34344.69140625	train_loss: 34383.99778534544	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1103
Epoch: 1103	max: 0.9999987/1.0	min: 1.2618148e-06	loss: 34344.98828125	train_loss: 34384.00355302784	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1104
Epoch: 1104	max: 0.99999785/1.0	min: 2.1301323e-06	loss: 34344.890625	train_loss: 34384.01101037022	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1105
Epoch: 1105	max: 0.99999654/1.0	min: 3.4963068e-06	loss: 34344.703125	train_loss: 34384.00791895051	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1106
Epoch: 1106	max: 0.99999845/1.0	min: 1.5323388e-06	loss: 34344.6640625	train_loss: 34383.97977875712	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1107
Epoch: 1107	max: 0.9999988/1.0	min: 1.2338965e-06	loss: 34344.58984375	train_loss: 34383.9605891165	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1108
Epoch: 1108	max: 0.9999989/1.0	min: 1.1198877e-06	loss: 34344.71875	train_loss: 34383.96064766428	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1109
Epoch: 1109	max: 0.9999982/1.0	min: 1.8057322e-06	loss: 34344.80078125	train_loss: 34383.96855935681	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1110
Epoch: 1110	max: 0.99999905/1.0	min: 9.537433e-07	loss: 34344.93359375	train_loss: 34383.92708720426	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1111
Epoch: 1111	max: 0.9999988/1.0	min: 1.1847314e-06	loss: 34344.796875	train_loss: 34383.91640586291	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1112
Epoch: 1112	max: 0.9999981/1.0	min: 1.8761069e-06	loss: 34345.1796875	train_loss: 34383.921330166915	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1113
Epoch: 1113	max: 0.99999917/1.0	min: 7.8543604e-07	loss: 34344.89453125	train_loss: 34383.9577991453	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1114
Epoch: 1114	max: 0.999998/1.0	min: 2.0134885e-06	loss: 34344.8203125	train_loss: 34383.94343316456	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1115
Epoch: 1115	max: 0.99999785/1.0	min: 2.0945452e-06	loss: 34344.68359375	train_loss: 34383.8614454625	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1116
Epoch: 1116	max: 0.9999975/1.0	min: 2.454691e-06	loss: 34344.6640625	train_loss: 34383.90374550972	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1117
Epoch: 1117	max: 0.9999976/1.0	min: 2.3507685e-06	loss: 34344.87890625	train_loss: 34383.849020752044	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1118
Epoch: 1118	max: 0.99999774/1.0	min: 2.287631e-06	loss: 34344.71484375	train_loss: 34383.82361924006	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1119
Epoch: 1119	max: 0.9999963/1.0	min: 3.6960344e-06	loss: 34344.828125	train_loss: 34383.8196171846	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1120
Epoch: 1120	max: 0.9999982/1.0	min: 1.7980269e-06	loss: 34344.98046875	train_loss: 34383.82272118481	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1121
Epoch: 1121	max: 0.99999905/1.0	min: 9.1237905e-07	loss: 34344.94921875	train_loss: 34383.8731187291	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1122
Epoch: 1122	max: 0.99999726/1.0	min: 2.6978737e-06	loss: 34344.75390625	train_loss: 34383.81350160256	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1123
Epoch: 1123	max: 0.9999981/1.0	min: 1.9604943e-06	loss: 34344.875	train_loss: 34383.785415602164	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1124
Epoch: 1124	max: 0.999998/1.0	min: 1.98762e-06	loss: 34344.92578125	train_loss: 34383.829046280815	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1125
Epoch: 1125	max: 0.99999547/1.0	min: 4.5746433e-06	loss: 34344.65234375	train_loss: 34383.81988621408	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1126
Epoch: 1126	max: 0.99999726/1.0	min: 2.7326655e-06	loss: 34344.546875	train_loss: 34383.809961639105	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1127
Epoch: 1127	max: 0.99999917/1.0	min: 8.520366e-07	loss: 34344.86328125	train_loss: 34383.76868642001	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1128
Epoch: 1128	max: 0.99999917/1.0	min: 8.381905e-07	loss: 34344.57421875	train_loss: 34383.761571654744	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1129
Epoch: 1129	max: 0.9999962/1.0	min: 3.8085648e-06	loss: 34344.578125	train_loss: 34383.74194653475	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1130
Epoch: 1130	max: 0.999995/1.0	min: 5.0466e-06	loss: 34344.74609375	train_loss: 34383.77160461569	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1131
Epoch: 1131	max: 0.9999968/1.0	min: 3.2156734e-06	loss: 34344.67578125	train_loss: 34383.732001153534	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1132
Epoch: 1132	max: 0.99999833/1.0	min: 1.6850034e-06	loss: 34344.6484375	train_loss: 34383.7277711972	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1133
Epoch: 1133	max: 0.9999989/1.0	min: 1.1125841e-06	loss: 34344.52734375	train_loss: 34383.71141410798	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1134
Epoch: 1134	max: 0.99999726/1.0	min: 2.7577148e-06	loss: 34344.6015625	train_loss: 34383.70064179983	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1135
Epoch: 1135	max: 0.9999988/1.0	min: 1.135033e-06	loss: 34344.5703125	train_loss: 34383.69985745308	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1136
Epoch: 1136	max: 0.99999833/1.0	min: 1.6893575e-06	loss: 34344.63671875	train_loss: 34383.71194055416	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1137
Epoch: 1137	max: 0.99999857/1.0	min: 1.3861377e-06	loss: 34344.73828125	train_loss: 34383.688834502354	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1138
Epoch: 1138	max: 0.9999993/1.0	min: 7.434538e-07	loss: 34344.73828125	train_loss: 34383.68796838226	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1139
Epoch: 1139	max: 0.99999833/1.0	min: 1.6105209e-06	loss: 34344.69140625	train_loss: 34383.669641958535	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1140
Epoch: 1140	max: 0.9999962/1.0	min: 3.8080452e-06	loss: 34344.66015625	train_loss: 34383.66506797349	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1141
Epoch: 1141	max: 0.9999975/1.0	min: 2.4722453e-06	loss: 34344.6171875	train_loss: 34383.654100183485	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1142
Epoch: 1142	max: 0.9999976/1.0	min: 2.4329117e-06	loss: 34344.51171875	train_loss: 34383.67412981544	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1143
Epoch: 1143	max: 0.99999845/1.0	min: 1.6067656e-06	loss: 34344.375	train_loss: 34383.6606894703	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1144
Epoch: 1144	max: 0.9999993/1.0	min: 7.178482e-07	loss: 34344.6484375	train_loss: 34383.63210750728	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1145
Epoch: 1145	max: 0.9999982/1.0	min: 1.8392304e-06	loss: 34344.51953125	train_loss: 34383.62690933513	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1146
Epoch: 1146	max: 0.9999989/1.0	min: 1.0200672e-06	loss: 34344.69140625	train_loss: 34383.61176723337	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1147
Epoch: 1147	max: 0.9999982/1.0	min: 1.7774419e-06	loss: 34344.48046875	train_loss: 34383.60943064459	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1148
Epoch: 1148	max: 0.9999968/1.0	min: 3.2363264e-06	loss: 34344.50390625	train_loss: 34383.617032662885	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1149
Epoch: 1149	max: 0.9999976/1.0	min: 2.3265966e-06	loss: 34344.96484375	train_loss: 34383.611021595905	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1150
Epoch: 1150	max: 0.9999982/1.0	min: 1.7404967e-06	loss: 34344.49609375	train_loss: 34383.599694777346	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1151
Epoch: 1151	max: 0.9999987/1.0	min: 1.3257622e-06	loss: 34344.76171875	train_loss: 34383.5767087243	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1152
Epoch: 1152	max: 0.9999995/1.0	min: 5.2968795e-07	loss: 34344.6875	train_loss: 34383.58130303171	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1153
Epoch: 1153	max: 0.9999994/1.0	min: 5.87673e-07	loss: 34344.484375	train_loss: 34383.58759474096	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1154
Epoch: 1154	max: 0.9999993/1.0	min: 7.7021065e-07	loss: 34344.53515625	train_loss: 34383.56002841261	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1155
Epoch: 1155	max: 0.9999982/1.0	min: 1.8284032e-06	loss: 34344.3984375	train_loss: 34383.55212301034	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1156
Epoch: 1156	max: 0.9999981/1.0	min: 1.9164222e-06	loss: 34344.50390625	train_loss: 34383.56500207094	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1157
Epoch: 1157	max: 0.9999974/1.0	min: 2.6187372e-06	loss: 34344.51953125	train_loss: 34383.535036735106	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1158
Epoch: 1158	max: 0.9999968/1.0	min: 3.2317278e-06	loss: 34344.5234375	train_loss: 34383.52604844079	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1159
Epoch: 1159	max: 0.99999774/1.0	min: 2.2653956e-06	loss: 34344.4453125	train_loss: 34383.515741127834	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1160
Epoch: 1160	max: 0.99999666/1.0	min: 3.3614906e-06	loss: 34344.36328125	train_loss: 34383.5139300175	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1161
Epoch: 1161	max: 0.9999993/1.0	min: 7.409121e-07	loss: 34344.4140625	train_loss: 34383.54309503902	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1162
Epoch: 1162	max: 0.9999976/1.0	min: 2.3823106e-06	loss: 34344.296875	train_loss: 34383.5059994542	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1163
Epoch: 1163	max: 0.99999905/1.0	min: 9.997939e-07	loss: 34344.33984375	train_loss: 34383.49582859145	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1164
Epoch: 1164	max: 0.999998/1.0	min: 2.0606574e-06	loss: 34344.33203125	train_loss: 34383.48153083581	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1165
Epoch: 1165	max: 0.9999988/1.0	min: 1.1550753e-06	loss: 34344.3046875	train_loss: 34383.48641739827	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1166
Epoch: 1166	max: 0.99999905/1.0	min: 9.602497e-07	loss: 34344.62109375	train_loss: 34383.47344930633	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1167
Epoch: 1167	max: 0.999998/1.0	min: 2.0320983e-06	loss: 34344.30859375	train_loss: 34383.466362605286	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1168
Epoch: 1168	max: 0.99999845/1.0	min: 1.5148099e-06	loss: 34344.35546875	train_loss: 34383.45334564288	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1169
Epoch: 1169	max: 0.99999774/1.0	min: 2.231942e-06	loss: 34344.40625	train_loss: 34383.44687054843	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1170
Epoch: 1170	max: 0.9999994/1.0	min: 6.225887e-07	loss: 34344.17578125	train_loss: 34383.44776231342	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1171
Epoch: 1171	max: 0.99999774/1.0	min: 2.2832787e-06	loss: 34344.296875	train_loss: 34383.46048314985	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1172
Epoch: 1172	max: 0.9999974/1.0	min: 2.5734753e-06	loss: 34344.359375	train_loss: 34383.45857042766	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1173
Epoch: 1173	max: 0.99999857/1.0	min: 1.3988956e-06	loss: 34344.3515625	train_loss: 34383.41767988201	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1174
Epoch: 1174	max: 0.99999845/1.0	min: 1.5401006e-06	loss: 34344.31640625	train_loss: 34383.39617252338	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1175
Epoch: 1175	max: 0.9999982/1.0	min: 1.7585896e-06	loss: 34344.50390625	train_loss: 34383.40354325375	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1176
Epoch: 1176	max: 0.9999989/1.0	min: 1.0715322e-06	loss: 34344.515625	train_loss: 34383.385755372845	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1177
Epoch: 1177	max: 0.99999917/1.0	min: 8.5805607e-07	loss: 34344.484375	train_loss: 34383.386317141245	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1178
Epoch: 1178	max: 0.9999993/1.0	min: 7.6753133e-07	loss: 34344.63671875	train_loss: 34383.420435982596	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1179
Epoch: 1179	max: 0.9999987/1.0	min: 1.3080768e-06	loss: 34344.453125	train_loss: 34383.379424470455	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1180
Epoch: 1180	max: 0.9999943/1.0	min: 5.741314e-06	loss: 34344.453125	train_loss: 34383.36072885699	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1181
Epoch: 1181	max: 0.9999968/1.0	min: 3.2160046e-06	loss: 34344.5859375	train_loss: 34383.35457214635	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1182
Epoch: 1182	max: 0.9999987/1.0	min: 1.2866896e-06	loss: 34344.33203125	train_loss: 34383.350317996716	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1183
Epoch: 1183	max: 0.9999988/1.0	min: 1.2368429e-06	loss: 34344.39453125	train_loss: 34383.34483627911	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1184
Epoch: 1184	max: 0.9999989/1.0	min: 1.1129639e-06	loss: 34344.5859375	train_loss: 34383.36207642373	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1185
Epoch: 1185	max: 0.99999845/1.0	min: 1.5700257e-06	loss: 34344.3515625	train_loss: 34383.328523221695	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1186
Epoch: 1186	max: 0.99999785/1.0	min: 2.1532448e-06	loss: 34344.28515625	train_loss: 34383.31687027747	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1187
Epoch: 1187	max: 0.999998/1.0	min: 2.0163498e-06	loss: 34344.19921875	train_loss: 34383.31898380404	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1188
Epoch: 1188	max: 0.9999963/1.0	min: 3.6874578e-06	loss: 34344.2109375	train_loss: 34383.32597179642	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1189
Epoch: 1189	max: 0.999997/1.0	min: 2.9512175e-06	loss: 34344.2109375	train_loss: 34383.35641277251	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1190
Epoch: 1190	max: 0.9999975/1.0	min: 2.4573144e-06	loss: 34344.4140625	train_loss: 34383.34000390964	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1191
Epoch: 1191	max: 0.9999981/1.0	min: 1.8915084e-06	loss: 34344.21875	train_loss: 34383.284692706395	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1192
Epoch: 1192	max: 0.9999987/1.0	min: 1.2965575e-06	loss: 34344.078125	train_loss: 34383.28482964047	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1193
Epoch: 1193	max: 0.9999995/1.0	min: 5.252973e-07	loss: 34344.078125	train_loss: 34383.276526984235	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1194
Epoch: 1194	max: 0.9999951/1.0	min: 4.862822e-06	loss: 34344.25390625	train_loss: 34383.29378261256	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1195
Epoch: 1195	max: 0.9999987/1.0	min: 1.261099e-06	loss: 34344.125	train_loss: 34383.27657972563	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1196
Epoch: 1196	max: 0.99999917/1.0	min: 8.654426e-07	loss: 34344.2578125	train_loss: 34383.25533220302	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1197
Epoch: 1197	max: 0.9999988/1.0	min: 1.156324e-06	loss: 34344.21484375	train_loss: 34383.24989790428	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1198
Epoch: 1198	max: 0.9999988/1.0	min: 1.2394099e-06	loss: 34344.30078125	train_loss: 34383.23945317339	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1199
Epoch: 1199	max: 0.99999845/1.0	min: 1.5545321e-06	loss: 34344.0703125	train_loss: 34383.23645223662	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1200
Epoch: 1200	max: 0.9999927/1.0	min: 7.2290977e-06	loss: 34344.24609375	train_loss: 34383.23491934922	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1201
Epoch: 1201	max: 0.9999962/1.0	min: 3.8090443e-06	loss: 34344.296875	train_loss: 34383.247311640655	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1202
Epoch: 1202	max: 0.9999962/1.0	min: 3.8665494e-06	loss: 34344.328125	train_loss: 34383.227543780195	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1203
Epoch: 1203	max: 0.99999833/1.0	min: 1.6240103e-06	loss: 34344.48828125	train_loss: 34383.2071280232	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1204
Epoch: 1204	max: 0.9999976/1.0	min: 2.3425553e-06	loss: 34344.25390625	train_loss: 34383.21902144881	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1205
Epoch: 1205	max: 0.999998/1.0	min: 1.9734125e-06	loss: 34344.234375	train_loss: 34383.18641130156	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1206
Epoch: 1206	max: 0.99999905/1.0	min: 1.0126003e-06	loss: 34344.26171875	train_loss: 34383.18822870216	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1207
Epoch: 1207	max: 0.9999989/1.0	min: 1.0982335e-06	loss: 34344.265625	train_loss: 34383.190266261765	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1208
Epoch: 1208	max: 0.99999845/1.0	min: 1.6013687e-06	loss: 34344.125	train_loss: 34383.17554705887	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1209
Epoch: 1209	max: 0.99999917/1.0	min: 8.5643904e-07	loss: 34344.2734375	train_loss: 34383.158851747336	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1210
Epoch: 1210	max: 0.9999982/1.0	min: 1.7845347e-06	loss: 34344.03125	train_loss: 34383.153282933854	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1211
Epoch: 1211	max: 0.99999833/1.0	min: 1.7015295e-06	loss: 34344.140625	train_loss: 34383.15285471247	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1212
Epoch: 1212	max: 0.9999989/1.0	min: 1.0597263e-06	loss: 34344.0234375	train_loss: 34383.141038705406	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1213
Epoch: 1213	max: 0.9999988/1.0	min: 1.2265637e-06	loss: 34343.98046875	train_loss: 34383.14416206026	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1214
Epoch: 1214	max: 0.99999905/1.0	min: 9.716736e-07	loss: 34343.99609375	train_loss: 34383.13516602409	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1215
Epoch: 1215	max: 0.9999982/1.0	min: 1.8250392e-06	loss: 34344.1171875	train_loss: 34383.129819788956	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1216
Epoch: 1216	max: 0.9999989/1.0	min: 1.1205896e-06	loss: 34344.15625	train_loss: 34383.11573783754	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1217
Epoch: 1217	max: 0.9999969/1.0	min: 3.12092e-06	loss: 34344.078125	train_loss: 34383.10652309396	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1218
Epoch: 1218	max: 0.9999988/1.0	min: 1.2302118e-06	loss: 34344.28515625	train_loss: 34383.095983041465	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1219
Epoch: 1219	max: 0.999998/1.0	min: 2.0648158e-06	loss: 34344.08203125	train_loss: 34383.09427112365	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1220
Epoch: 1220	max: 0.9999987/1.0	min: 1.3214806e-06	loss: 34344.1328125	train_loss: 34383.112221099655	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1221
Epoch: 1221	max: 0.9999995/1.0	min: 4.4800683e-07	loss: 34344.3359375	train_loss: 34383.10559890995	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1222
Epoch: 1222	max: 0.9999988/1.0	min: 1.1422161e-06	loss: 34344.12890625	train_loss: 34383.104702790166	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1223
Epoch: 1223	max: 0.99999726/1.0	min: 2.6855625e-06	loss: 34344.11328125	train_loss: 34383.072686346466	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1224
Epoch: 1224	max: 0.99999857/1.0	min: 1.4455578e-06	loss: 34344.12890625	train_loss: 34383.05264800492	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1225
Epoch: 1225	max: 0.9999969/1.0	min: 3.0712076e-06	loss: 34344.07421875	train_loss: 34383.04870449725	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1226
Epoch: 1226	max: 0.9999987/1.0	min: 1.2682498e-06	loss: 34344.05078125	train_loss: 34383.05987889803	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1227
Epoch: 1227	max: 0.99999785/1.0	min: 2.1535159e-06	loss: 34344.00390625	train_loss: 34383.04612307228	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1228
Epoch: 1228	max: 0.99999845/1.0	min: 1.5027393e-06	loss: 34344.05078125	train_loss: 34383.045387112135	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1229
Epoch: 1229	max: 0.99999964/1.0	min: 3.8698954e-07	loss: 34344.03515625	train_loss: 34383.028924540136	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1230
Epoch: 1230	max: 0.99999905/1.0	min: 9.2312325e-07	loss: 34344.18359375	train_loss: 34383.044656474514	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1231
Epoch: 1231	max: 0.9999975/1.0	min: 2.4630133e-06	loss: 34344.11328125	train_loss: 34383.04525646832	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1232
Epoch: 1232	max: 0.99999714/1.0	min: 2.9150387e-06	loss: 34343.99609375	train_loss: 34383.04965771321	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1233
Epoch: 1233	max: 0.9999989/1.0	min: 1.1103529e-06	loss: 34343.859375	train_loss: 34383.00737121423	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1234
Epoch: 1234	max: 0.99999905/1.0	min: 9.558696e-07	loss: 34343.875	train_loss: 34383.05288171219	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1235
Epoch: 1235	max: 0.99999905/1.0	min: 9.310983e-07	loss: 34344.03125	train_loss: 34382.9920950816	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1236
Epoch: 1236	max: 0.9999987/1.0	min: 1.3155317e-06	loss: 34344.08984375	train_loss: 34382.97374785163	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1237
Epoch: 1237	max: 0.9999988/1.0	min: 1.2067383e-06	loss: 34344.03515625	train_loss: 34382.96578438545	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1238
Epoch: 1238	max: 0.9999989/1.0	min: 1.0246555e-06	loss: 34344.05859375	train_loss: 34382.967438723215	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1239
Epoch: 1239	max: 0.9999989/1.0	min: 1.0143921e-06	loss: 34343.84375	train_loss: 34382.96766565635	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1240
Epoch: 1240	max: 0.9999968/1.0	min: 3.2445125e-06	loss: 34343.984375	train_loss: 34382.98304727177	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1241
Epoch: 1241	max: 0.99999857/1.0	min: 1.3801583e-06	loss: 34344.1796875	train_loss: 34382.96889128887	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1242
Epoch: 1242	max: 0.9999964/1.0	min: 3.5994526e-06	loss: 34344.01953125	train_loss: 34382.952271460425	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1243
Epoch: 1243	max: 0.9999993/1.0	min: 6.8855417e-07	loss: 34343.85546875	train_loss: 34382.93963771987	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1244
Epoch: 1244	max: 0.9999995/1.0	min: 5.077285e-07	loss: 34344.23828125	train_loss: 34382.93968271941	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1245
Epoch: 1245	max: 0.9999982/1.0	min: 1.7838014e-06	loss: 34344.0	train_loss: 34382.95135792147	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1246
Epoch: 1246	max: 0.9999994/1.0	min: 6.456252e-07	loss: 34343.7109375	train_loss: 34382.92588721665	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1247
Epoch: 1247	max: 0.99999905/1.0	min: 9.919377e-07	loss: 34343.8984375	train_loss: 34382.95769656571	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1248
Epoch: 1248	max: 0.99999774/1.0	min: 2.2540044e-06	loss: 34344.0390625	train_loss: 34382.89608881457	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1249
Epoch: 1249	max: 0.9999988/1.0	min: 1.2215651e-06	loss: 34343.94140625	train_loss: 34382.88905679038	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1250
Epoch: 1250	max: 0.99999857/1.0	min: 1.3963445e-06	loss: 34343.87109375	train_loss: 34382.885012154715	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1251
Epoch: 1251	max: 0.9999993/1.0	min: 7.3420176e-07	loss: 34343.953125	train_loss: 34382.874314361914	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1252
Epoch: 1252	max: 0.99999917/1.0	min: 8.0850816e-07	loss: 34344.06640625	train_loss: 34382.876150149415	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1253
Epoch: 1253	max: 0.9999988/1.0	min: 1.2162828e-06	loss: 34344.07421875	train_loss: 34382.8635401183	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1254
Epoch: 1254	max: 0.99999857/1.0	min: 1.4276432e-06	loss: 34343.9296875	train_loss: 34382.86265028877	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1255
Epoch: 1255	max: 0.9999989/1.0	min: 1.0492606e-06	loss: 34343.7109375	train_loss: 34382.84627481265	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1256
Epoch: 1256	max: 0.9999987/1.0	min: 1.2972563e-06	loss: 34343.92578125	train_loss: 34382.84115115586	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1257
Epoch: 1257	max: 0.9999989/1.0	min: 1.03097e-06	loss: 34343.80859375	train_loss: 34382.834588481666	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1258
Epoch: 1258	max: 0.99999917/1.0	min: 7.7763923e-07	loss: 34343.953125	train_loss: 34382.85949499876	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1259
Epoch: 1259	max: 0.9999994/1.0	min: 6.071066e-07	loss: 34344.03515625	train_loss: 34382.81618415552	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1260
Epoch: 1260	max: 0.99999917/1.0	min: 8.7661675e-07	loss: 34343.84375	train_loss: 34382.81229532469	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1261
Epoch: 1261	max: 0.9999976/1.0	min: 2.4016708e-06	loss: 34343.74609375	train_loss: 34382.80048657562	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1262
Epoch: 1262	max: 0.99999785/1.0	min: 2.1363985e-06	loss: 34344.07421875	train_loss: 34382.79854578921	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1263
Epoch: 1263	max: 0.99999917/1.0	min: 8.5793164e-07	loss: 34343.96484375	train_loss: 34382.783324333424	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1264
Epoch: 1264	max: 0.9999982/1.0	min: 1.84238e-06	loss: 34343.7890625	train_loss: 34382.762676804625	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1265
Epoch: 1265	max: 0.999998/1.0	min: 2.0085884e-06	loss: 34343.8515625	train_loss: 34382.77535893178	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1266
Epoch: 1266	max: 0.9999995/1.0	min: 5.100692e-07	loss: 34343.86328125	train_loss: 34382.744747150995	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1267
Epoch: 1267	max: 0.99999845/1.0	min: 1.4950003e-06	loss: 34343.84765625	train_loss: 34382.73439048371	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1268
Epoch: 1268	max: 0.999998/1.0	min: 2.0661594e-06	loss: 34343.76953125	train_loss: 34382.728546834354	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1269
Epoch: 1269	max: 0.99999833/1.0	min: 1.7017112e-06	loss: 34343.74609375	train_loss: 34382.73394193996	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1270
Epoch: 1270	max: 0.9999995/1.0	min: 5.0412336e-07	loss: 34343.7265625	train_loss: 34382.71501503856	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1271
Epoch: 1271	max: 0.9999987/1.0	min: 1.3338584e-06	loss: 34343.65625	train_loss: 34382.71994660055	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1272
Epoch: 1272	max: 0.9999982/1.0	min: 1.8011092e-06	loss: 34343.71875	train_loss: 34382.725927667845	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1273
Epoch: 1273	max: 0.99999964/1.0	min: 3.752749e-07	loss: 34343.796875	train_loss: 34382.67788848631	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1274
Epoch: 1274	max: 0.99999905/1.0	min: 9.906029e-07	loss: 34343.8671875	train_loss: 34382.666616344606	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1275
Epoch: 1275	max: 0.9999981/1.0	min: 1.8479279e-06	loss: 34343.81640625	train_loss: 34382.661365431064	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1276
Epoch: 1276	max: 0.99999857/1.0	min: 1.3855654e-06	loss: 34343.80078125	train_loss: 34382.658588524246	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1277
Epoch: 1277	max: 0.9999976/1.0	min: 2.4252952e-06	loss: 34343.93359375	train_loss: 34382.6725945087	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1278
Epoch: 1278	max: 0.9999995/1.0	min: 5.3371303e-07	loss: 34343.81640625	train_loss: 34382.673952720485	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1279
Epoch: 1279	max: 0.9999989/1.0	min: 1.0941992e-06	loss: 34343.80078125	train_loss: 34382.667989556234	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1280
Epoch: 1280	max: 0.9999993/1.0	min: 6.788858e-07	loss: 34343.81640625	train_loss: 34382.610578374675	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1281
Epoch: 1281	max: 0.99999833/1.0	min: 1.6343207e-06	loss: 34343.87890625	train_loss: 34382.59400790057	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1282
Epoch: 1282	max: 0.9999994/1.0	min: 5.909738e-07	loss: 34343.91796875	train_loss: 34382.58275414576	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1283
Epoch: 1283	max: 0.99999964/1.0	min: 3.7117e-07	loss: 34343.75	train_loss: 34382.584038809924	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1284
Epoch: 1284	max: 0.9999987/1.0	min: 1.2665358e-06	loss: 34343.82421875	train_loss: 34382.583105916325	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1285
Epoch: 1285	max: 0.9999988/1.0	min: 1.1664251e-06	loss: 34343.94921875	train_loss: 34382.55194059287	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1286
Epoch: 1286	max: 0.9999987/1.0	min: 1.2920681e-06	loss: 34343.9609375	train_loss: 34382.55079721758	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1287
Epoch: 1287	max: 0.9999981/1.0	min: 1.867802e-06	loss: 34343.96875	train_loss: 34382.52808116174	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1288
Epoch: 1288	max: 0.9999987/1.0	min: 1.3357782e-06	loss: 34343.83984375	train_loss: 34382.54672742088	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1289
Epoch: 1289	max: 0.99999964/1.0	min: 4.0656803e-07	loss: 34344.1015625	train_loss: 34382.56896203007	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1290
Epoch: 1290	max: 0.9999995/1.0	min: 4.7675985e-07	loss: 34344.18359375	train_loss: 34382.57182651663	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1291
Epoch: 1291	max: 0.99999976/1.0	min: 2.2039848e-07	loss: 34343.78125	train_loss: 34382.54441841246	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1292
Epoch: 1292	max: 0.99999857/1.0	min: 1.4153827e-06	loss: 34343.80078125	train_loss: 34382.515597903504	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1293
Epoch: 1293	max: 0.9999995/1.0	min: 4.872529e-07	loss: 34343.875	train_loss: 34382.49833646879	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1294
Epoch: 1294	max: 0.9999995/1.0	min: 4.643431e-07	loss: 34343.76953125	train_loss: 34382.444835408154	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1295
Epoch: 1295	max: 0.9999994/1.0	min: 5.758608e-07	loss: 34343.72265625	train_loss: 34382.44072254738	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1296
Epoch: 1296	max: 0.99999964/1.0	min: 4.003278e-07	loss: 34343.921875	train_loss: 34382.44464476496	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1297
Epoch: 1297	max: 0.9999993/1.0	min: 7.679655e-07	loss: 34344.11328125	train_loss: 34382.44149528134	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1298
Epoch: 1298	max: 0.9999957/1.0	min: 4.3479477e-06	loss: 34343.6953125	train_loss: 34382.53883556686	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1299
Epoch: 1299	max: 0.999997/1.0	min: 2.9323871e-06	loss: 34343.73828125	train_loss: 34382.4582384956	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1300
Epoch: 1300	max: 0.9999987/1.0	min: 1.3419786e-06	loss: 34343.63671875	train_loss: 34382.40931771027	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1301
Epoch: 1301	max: 0.99999905/1.0	min: 9.080769e-07	loss: 34343.78125	train_loss: 34382.38764051468	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1302
Epoch: 1302	max: 0.99999976/1.0	min: 2.877267e-07	loss: 34343.94921875	train_loss: 34382.36845280952	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1303
Epoch: 1303	max: 0.9999988/1.0	min: 1.2208977e-06	loss: 34343.71484375	train_loss: 34382.37368388455	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1304
Epoch: 1304	max: 0.9999995/1.0	min: 4.3142165e-07	loss: 34343.64453125	train_loss: 34382.33032610631	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1305
Epoch: 1305	max: 0.99999905/1.0	min: 9.639216e-07	loss: 34343.578125	train_loss: 34382.34409209324	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1306
Epoch: 1306	max: 0.9999989/1.0	min: 1.0637258e-06	loss: 34343.7109375	train_loss: 34382.33666475056	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1307
Epoch: 1307	max: 0.9999994/1.0	min: 5.8816306e-07	loss: 34343.73046875	train_loss: 34382.31323450855	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1308
Epoch: 1308	max: 0.9999995/1.0	min: 4.830025e-07	loss: 34343.61328125	train_loss: 34382.288844276445	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1309
Epoch: 1309	max: 0.9999993/1.0	min: 6.758477e-07	loss: 34343.859375	train_loss: 34382.27894534637	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1310
Epoch: 1310	max: 0.99999845/1.0	min: 1.4939856e-06	loss: 34343.859375	train_loss: 34382.29717015824	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1311
Epoch: 1311	max: 0.99999917/1.0	min: 8.405952e-07	loss: 34343.921875	train_loss: 34382.27259654094	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1312
Epoch: 1312	max: 0.9999993/1.0	min: 7.237433e-07	loss: 34343.80859375	train_loss: 34382.27532360956	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1313
Epoch: 1313	max: 0.99999917/1.0	min: 7.936024e-07	loss: 34343.58984375	train_loss: 34382.24961919748	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1314
Epoch: 1314	max: 0.99999964/1.0	min: 3.336103e-07	loss: 34343.6796875	train_loss: 34382.23325678574	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1315
Epoch: 1315	max: 0.9999989/1.0	min: 1.0380359e-06	loss: 34343.66015625	train_loss: 34382.21765259197	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1316
Epoch: 1316	max: 0.99999964/1.0	min: 3.6364602e-07	loss: 34343.36328125	train_loss: 34382.206855122786	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1317
Epoch: 1317	max: 0.99999976/1.0	min: 2.5638334e-07	loss: 34343.62890625	train_loss: 34382.22849941549	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1318
Epoch: 1318	max: 0.99999964/1.0	min: 3.6848562e-07	loss: 34343.65625	train_loss: 34382.20108550492	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1319
Epoch: 1319	max: 0.9999995/1.0	min: 5.254897e-07	loss: 34343.69140625	train_loss: 34382.18213295863	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1320
Epoch: 1320	max: 0.9999993/1.0	min: 7.4623904e-07	loss: 34343.78515625	train_loss: 34382.17110952403	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1321
Epoch: 1321	max: 0.9999995/1.0	min: 4.3785127e-07	loss: 34343.8203125	train_loss: 34382.159566901246	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1322
Epoch: 1322	max: 0.9999995/1.0	min: 4.4800512e-07	loss: 34343.6015625	train_loss: 34382.218727258296	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1323
Epoch: 1323	max: 0.99999714/1.0	min: 2.8233565e-06	loss: 34343.62109375	train_loss: 34382.16239171079	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1324
Epoch: 1324	max: 0.9999987/1.0	min: 1.3291461e-06	loss: 34343.57421875	train_loss: 34382.1427636876	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1325
Epoch: 1325	max: 0.9999989/1.0	min: 1.0769988e-06	loss: 34343.5234375	train_loss: 34382.12683820683	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1326
Epoch: 1326	max: 0.99999905/1.0	min: 9.0683756e-07	loss: 34343.6015625	train_loss: 34382.11184949059	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1327
Epoch: 1327	max: 0.9999988/1.0	min: 1.1385043e-06	loss: 34343.80859375	train_loss: 34382.103744251675	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1328
Epoch: 1328	max: 0.9999995/1.0	min: 5.060728e-07	loss: 34343.66015625	train_loss: 34382.090621806485	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1329
Epoch: 1329	max: 0.9999974/1.0	min: 2.5825718e-06	loss: 34343.53125	train_loss: 34382.075395512045	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1330
Epoch: 1330	max: 0.9999994/1.0	min: 5.385179e-07	loss: 34343.48828125	train_loss: 34382.113510602474	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1331
Epoch: 1331	max: 0.99999976/1.0	min: 2.667455e-07	loss: 34343.65625	train_loss: 34382.13078655317	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1332
Epoch: 1332	max: 0.9999994/1.0	min: 6.001303e-07	loss: 34343.875	train_loss: 34382.058093432584	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1333
Epoch: 1333	max: 0.99999905/1.0	min: 9.580672e-07	loss: 34343.4140625	train_loss: 34382.04474018333	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1334
Epoch: 1334	max: 0.9999987/1.0	min: 1.301663e-06	loss: 34343.6796875	train_loss: 34382.053547511765	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1335
Epoch: 1335	max: 0.99999917/1.0	min: 8.449015e-07	loss: 34343.52734375	train_loss: 34382.01637354066	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1336
Epoch: 1336	max: 0.99999964/1.0	min: 3.9433857e-07	loss: 34343.51171875	train_loss: 34382.01321341199	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1337
Epoch: 1337	max: 0.9999995/1.0	min: 5.23434e-07	loss: 34343.46875	train_loss: 34382.00172304673	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1338
Epoch: 1338	max: 0.99999905/1.0	min: 9.039244e-07	loss: 34343.57421875	train_loss: 34381.99963710052	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1339
Epoch: 1339	max: 0.99999833/1.0	min: 1.6457382e-06	loss: 34343.453125	train_loss: 34382.00933232302	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1340
Epoch: 1340	max: 0.99999964/1.0	min: 3.9950166e-07	loss: 34343.53515625	train_loss: 34381.96872096804	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1341
Epoch: 1341	max: 0.99999917/1.0	min: 8.7870256e-07	loss: 34343.50390625	train_loss: 34381.96150701025	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1342
Epoch: 1342	max: 0.9999993/1.0	min: 6.856827e-07	loss: 34343.34375	train_loss: 34381.95606932444	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1343
Epoch: 1343	max: 0.99999964/1.0	min: 3.4623682e-07	loss: 34343.4609375	train_loss: 34381.941457055924	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1344
Epoch: 1344	max: 0.99999976/1.0	min: 1.8013274e-07	loss: 34343.7109375	train_loss: 34381.94669974374	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1345
Epoch: 1345	max: 0.9999995/1.0	min: 4.840553e-07	loss: 34343.66015625	train_loss: 34381.967814203206	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1346
Epoch: 1346	max: 0.9999982/1.0	min: 1.7991899e-06	loss: 34343.51953125	train_loss: 34381.91452023721	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1347
Epoch: 1347	max: 0.99999917/1.0	min: 8.376215e-07	loss: 34343.39453125	train_loss: 34381.917609237586	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1348
Epoch: 1348	max: 0.99999964/1.0	min: 3.518268e-07	loss: 34343.578125	train_loss: 34381.88707681082	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1349
Epoch: 1349	max: 0.9999981/1.0	min: 1.9599765e-06	loss: 34343.44921875	train_loss: 34381.88073139245	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1350
Epoch: 1350	max: 0.9999993/1.0	min: 7.355362e-07	loss: 34343.32421875	train_loss: 34381.878552543974	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1351
Epoch: 1351	max: 0.99999976/1.0	min: 1.8592807e-07	loss: 34343.58203125	train_loss: 34381.885952790166	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1352
Epoch: 1352	max: 0.99999905/1.0	min: 9.608452e-07	loss: 34343.51953125	train_loss: 34381.86171158878	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1353
Epoch: 1353	max: 0.9999989/1.0	min: 1.0839108e-06	loss: 34343.28125	train_loss: 34381.84174002075	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1354
Epoch: 1354	max: 0.99999964/1.0	min: 3.906248e-07	loss: 34343.51953125	train_loss: 34381.872413736375	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1355
Epoch: 1355	max: 0.9999988/1.0	min: 1.1324987e-06	loss: 34343.43359375	train_loss: 34381.83466590022	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1356
Epoch: 1356	max: 0.99999917/1.0	min: 8.5846534e-07	loss: 34343.5234375	train_loss: 34381.809064067726	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1357
Epoch: 1357	max: 0.999997/1.0	min: 2.9426653e-06	loss: 34343.46875	train_loss: 34381.80974777035	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1358
Epoch: 1358	max: 0.99999917/1.0	min: 8.3484383e-07	loss: 34343.234375	train_loss: 34381.82222377059	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1359
Epoch: 1359	max: 0.9999995/1.0	min: 4.7097944e-07	loss: 34343.48828125	train_loss: 34381.801813819984	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1360
Epoch: 1360	max: 0.99999905/1.0	min: 9.5328056e-07	loss: 34343.328125	train_loss: 34381.78029484857	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1361
Epoch: 1361	max: 0.99999917/1.0	min: 8.07126e-07	loss: 34343.3984375	train_loss: 34381.79196037331	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1362
Epoch: 1362	max: 0.99999976/1.0	min: 2.6389668e-07	loss: 34343.61328125	train_loss: 34381.755068496066	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1363
Epoch: 1363	max: 0.999998/1.0	min: 1.9790402e-06	loss: 34343.39453125	train_loss: 34381.74623939366	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1364
Epoch: 1364	max: 0.9999987/1.0	min: 1.266925e-06	loss: 34343.5703125	train_loss: 34381.72096659002	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1365
Epoch: 1365	max: 0.9999987/1.0	min: 1.3012783e-06	loss: 34343.43359375	train_loss: 34381.720683044565	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1366
Epoch: 1366	max: 0.9999999/1.0	min: 1.4185731e-07	loss: 34343.57421875	train_loss: 34381.71915451196	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1367
Epoch: 1367	max: 0.99999964/1.0	min: 3.0656457e-07	loss: 34343.4609375	train_loss: 34381.73316727053	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1368
Epoch: 1368	max: 0.9999993/1.0	min: 6.691694e-07	loss: 34343.265625	train_loss: 34381.69793795677	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1369
Epoch: 1369	max: 0.9999987/1.0	min: 1.3329962e-06	loss: 34343.42578125	train_loss: 34381.67400449415	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1370
Epoch: 1370	max: 0.99999857/1.0	min: 1.4396284e-06	loss: 34343.1875	train_loss: 34381.669959374616	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1371
Epoch: 1371	max: 0.9999995/1.0	min: 4.2176953e-07	loss: 34343.88671875	train_loss: 34381.65659064164	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1372
Epoch: 1372	max: 0.99999917/1.0	min: 8.4778776e-07	loss: 34343.1796875	train_loss: 34381.78404335826	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1373
Epoch: 1373	max: 0.99999917/1.0	min: 8.6614614e-07	loss: 34343.24609375	train_loss: 34381.65323164406	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1374
Epoch: 1374	max: 0.99999976/1.0	min: 2.5106598e-07	loss: 34343.48046875	train_loss: 34381.63888792116	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1375
Epoch: 1375	max: 0.99999964/1.0	min: 4.1364498e-07	loss: 34343.50390625	train_loss: 34381.65169875666	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1376
Epoch: 1376	max: 0.9999994/1.0	min: 6.043338e-07	loss: 34343.39453125	train_loss: 34381.623470015795	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1377
Epoch: 1377	max: 0.9999987/1.0	min: 1.3464692e-06	loss: 34343.21875	train_loss: 34381.60116476217	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1378
Epoch: 1378	max: 0.99999964/1.0	min: 3.7404791e-07	loss: 34343.2890625	train_loss: 34381.59886978586	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1379
Epoch: 1379	max: 0.99999964/1.0	min: 3.76996e-07	loss: 34343.18359375	train_loss: 34381.5796564358	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1380
Epoch: 1380	max: 0.99999917/1.0	min: 8.684008e-07	loss: 34343.2109375	train_loss: 34381.5627133849	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1381
Epoch: 1381	max: 0.99999857/1.0	min: 1.4153368e-06	loss: 34343.31640625	train_loss: 34381.56234274356	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1382
Epoch: 1382	max: 0.9999987/1.0	min: 1.2820572e-06	loss: 34343.203125	train_loss: 34381.57869451025	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1383
Epoch: 1383	max: 0.9999995/1.0	min: 5.2309366e-07	loss: 34343.12109375	train_loss: 34381.54637952124	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1384
Epoch: 1384	max: 0.9999995/1.0	min: 5.3528e-07	loss: 34343.3515625	train_loss: 34381.5347594799	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1385
Epoch: 1385	max: 0.9999988/1.0	min: 1.1661671e-06	loss: 34343.359375	train_loss: 34381.52391749505	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1386
Epoch: 1386	max: 0.9999995/1.0	min: 4.657419e-07	loss: 34343.31640625	train_loss: 34381.5345519014	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1387
Epoch: 1387	max: 0.99999964/1.0	min: 3.1166203e-07	loss: 34342.9765625	train_loss: 34381.50178836864	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1388
Epoch: 1388	max: 0.99999964/1.0	min: 3.4165848e-07	loss: 34343.1953125	train_loss: 34381.519877214174	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1389
Epoch: 1389	max: 0.99999964/1.0	min: 3.614922e-07	loss: 34343.26171875	train_loss: 34381.49592149371	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1390
Epoch: 1390	max: 0.9999999/1.0	min: 1.6624007e-07	loss: 34343.390625	train_loss: 34381.50271642357	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1391
Epoch: 1391	max: 0.99999976/1.0	min: 2.5869275e-07	loss: 34343.54296875	train_loss: 34381.47145142373	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1392
Epoch: 1392	max: 0.99999976/1.0	min: 2.8633121e-07	loss: 34343.046875	train_loss: 34381.46260828921	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1393
Epoch: 1393	max: 0.99999964/1.0	min: 3.2902065e-07	loss: 34343.02734375	train_loss: 34381.474641552086	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1394
Epoch: 1394	max: 0.99999905/1.0	min: 9.380538e-07	loss: 34343.09375	train_loss: 34381.50004983819	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1395
Epoch: 1395	max: 0.99999964/1.0	min: 3.9834134e-07	loss: 34343.19140625	train_loss: 34381.420799365944	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1396
Epoch: 1396	max: 0.9999995/1.0	min: 5.1083447e-07	loss: 34343.015625	train_loss: 34381.41525619735	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1397
Epoch: 1397	max: 0.99999976/1.0	min: 2.2083252e-07	loss: 34343.12109375	train_loss: 34381.40511630203	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1398
Epoch: 1398	max: 0.9999994/1.0	min: 5.56895e-07	loss: 34343.171875	train_loss: 34381.39671251781	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1399
Epoch: 1399	max: 0.9999993/1.0	min: 6.5610504e-07	loss: 34343.140625	train_loss: 34381.39226917658	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1400
Epoch: 1400	max: 0.99999857/1.0	min: 1.4030322e-06	loss: 34343.09375	train_loss: 34381.39297029837	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1401
Epoch: 1401	max: 0.9999994/1.0	min: 6.3646854e-07	loss: 34343.03515625	train_loss: 34381.39970474498	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1402
Epoch: 1402	max: 0.99999976/1.0	min: 2.0913109e-07	loss: 34343.30078125	train_loss: 34381.36009015391	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1403
Epoch: 1403	max: 0.9999999/1.0	min: 1.7228959e-07	loss: 34343.00390625	train_loss: 34381.34618916837	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1404
Epoch: 1404	max: 0.9999994/1.0	min: 6.317914e-07	loss: 34343.078125	train_loss: 34381.336746523906	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1405
Epoch: 1405	max: 0.9999987/1.0	min: 1.2901398e-06	loss: 34343.00390625	train_loss: 34381.32522712669	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1406
Epoch: 1406	max: 0.99999964/1.0	min: 3.2736554e-07	loss: 34343.32421875	train_loss: 34381.351532984176	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1407
Epoch: 1407	max: 0.99999917/1.0	min: 8.570338e-07	loss: 34343.34375	train_loss: 34381.30248494209	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1408
Epoch: 1408	max: 0.9999993/1.0	min: 7.128585e-07	loss: 34343.54296875	train_loss: 34381.304300407224	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1409
Epoch: 1409	max: 0.99999857/1.0	min: 1.4424827e-06	loss: 34343.19921875	train_loss: 34381.33626265793	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1410
Epoch: 1410	max: 0.99999976/1.0	min: 2.3749784e-07	loss: 34343.2734375	train_loss: 34381.29146586229	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1411
Epoch: 1411	max: 0.99999964/1.0	min: 3.59682e-07	loss: 34343.10546875	train_loss: 34381.277218912575	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1412
Epoch: 1412	max: 0.9999995/1.0	min: 4.888042e-07	loss: 34342.94140625	train_loss: 34381.27059769061	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1413
Epoch: 1413	max: 0.9999995/1.0	min: 4.6062058e-07	loss: 34343.140625	train_loss: 34381.25759234098	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1414
Epoch: 1414	max: 0.99999833/1.0	min: 1.6904291e-06	loss: 34343.11328125	train_loss: 34381.23419403413	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1415
Epoch: 1415	max: 0.9999995/1.0	min: 4.2502566e-07	loss: 34343.046875	train_loss: 34381.23995397467	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1416
Epoch: 1416	max: 0.99999964/1.0	min: 3.638753e-07	loss: 34343.14453125	train_loss: 34381.21631857348	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1417
Epoch: 1417	max: 0.99999976/1.0	min: 2.851412e-07	loss: 34343.04296875	train_loss: 34381.21082282376	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1418
Epoch: 1418	max: 0.99999976/1.0	min: 2.2501244e-07	loss: 34342.93359375	train_loss: 34381.2102421846	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1419
Epoch: 1419	max: 0.9999993/1.0	min: 7.499947e-07	loss: 34343.19140625	train_loss: 34381.20249065171	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1420
Epoch: 1420	max: 0.99999964/1.0	min: 3.7703447e-07	loss: 34343.09765625	train_loss: 34381.176048344016	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1421
Epoch: 1421	max: 0.9999993/1.0	min: 7.196235e-07	loss: 34343.23828125	train_loss: 34381.16632699275	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1422
Epoch: 1422	max: 0.9999999/1.0	min: 1.400699e-07	loss: 34343.06640625	train_loss: 34381.17113323346	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1423
Epoch: 1423	max: 0.9999995/1.0	min: 4.9542234e-07	loss: 34343.12109375	train_loss: 34381.152866325254	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1424
Epoch: 1424	max: 0.9999993/1.0	min: 7.651955e-07	loss: 34343.30078125	train_loss: 34381.131650253934	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1425
Epoch: 1425	max: 0.9999982/1.0	min: 1.7749348e-06	loss: 34343.0234375	train_loss: 34381.146015750805	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1426
Epoch: 1426	max: 0.99999976/1.0	min: 2.1067686e-07	loss: 34343.0546875	train_loss: 34381.12136036015	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1427
Epoch: 1427	max: 0.9999995/1.0	min: 4.7154123e-07	loss: 34342.9609375	train_loss: 34381.10117782655	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1428
Epoch: 1428	max: 0.99999905/1.0	min: 1.000078e-06	loss: 34342.90625	train_loss: 34381.10570439273	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1429
Epoch: 1429	max: 0.9999994/1.0	min: 5.918875e-07	loss: 34343.0703125	train_loss: 34381.12080052722	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1430
Epoch: 1430	max: 0.99999964/1.0	min: 3.9911936e-07	loss: 34343.09765625	train_loss: 34381.08143657872	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1431
Epoch: 1431	max: 0.99999964/1.0	min: 3.8980087e-07	loss: 34342.921875	train_loss: 34381.08092803558	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1432
Epoch: 1432	max: 0.99999976/1.0	min: 2.948085e-07	loss: 34343.140625	train_loss: 34381.05421427908	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1433
Epoch: 1433	max: 0.99999976/1.0	min: 2.0761823e-07	loss: 34342.890625	train_loss: 34381.07634776028	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1434
Epoch: 1434	max: 0.99999964/1.0	min: 4.139666e-07	loss: 34342.95703125	train_loss: 34381.03420448563	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1435
Epoch: 1435	max: 0.99999964/1.0	min: 3.453675e-07	loss: 34343.171875	train_loss: 34381.013949372136	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1436
Epoch: 1436	max: 0.99999976/1.0	min: 1.9205979e-07	loss: 34343.1953125	train_loss: 34381.020561400655	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1437
Epoch: 1437	max: 0.99999976/1.0	min: 2.706432e-07	loss: 34343.203125	train_loss: 34381.01062182584	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1438
Epoch: 1438	max: 0.99999714/1.0	min: 2.8532693e-06	loss: 34343.1015625	train_loss: 34380.992771042365	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1439
Epoch: 1439	max: 0.99999976/1.0	min: 1.8979634e-07	loss: 34343.38671875	train_loss: 34380.988220766754	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1440
Epoch: 1440	max: 0.99999976/1.0	min: 2.2337127e-07	loss: 34342.9609375	train_loss: 34381.10771340425	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1441
Epoch: 1441	max: 0.9999999/1.0	min: 1.5673358e-07	loss: 34342.8125	train_loss: 34380.96120411015	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1442
Epoch: 1442	max: 0.99999964/1.0	min: 3.3057657e-07	loss: 34342.9765625	train_loss: 34380.95692238016	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1443
Epoch: 1443	max: 0.99999964/1.0	min: 3.293487e-07	loss: 34343.078125	train_loss: 34380.94787021553	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1444
Epoch: 1444	max: 0.99999976/1.0	min: 2.656235e-07	loss: 34342.87109375	train_loss: 34380.93209860414	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1445
Epoch: 1445	max: 0.9999993/1.0	min: 7.643043e-07	loss: 34343.0859375	train_loss: 34380.90628241902	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1446
Epoch: 1446	max: 0.9999994/1.0	min: 5.6498124e-07	loss: 34342.92578125	train_loss: 34380.91249670971	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1447
Epoch: 1447	max: 0.9999999/1.0	min: 7.643612e-08	loss: 34343.109375	train_loss: 34380.894045448564	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1448
Epoch: 1448	max: 0.9999999/1.0	min: 1.4458787e-07	loss: 34343.1796875	train_loss: 34380.93091119704	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1449
Epoch: 1449	max: 0.9999999/1.0	min: 1.1705198e-07	loss: 34342.94921875	train_loss: 34380.89874620649	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1450
Epoch: 1450	max: 0.9999999/1.0	min: 1.3079404e-07	loss: 34343.03125	train_loss: 34380.87116003964	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1451
Epoch: 1451	max: 0.99999976/1.0	min: 2.877481e-07	loss: 34342.8046875	train_loss: 34380.83550782702	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1452
Epoch: 1452	max: 0.99999964/1.0	min: 3.4323816e-07	loss: 34342.86328125	train_loss: 34380.83216576474	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1453
Epoch: 1453	max: 0.99999976/1.0	min: 1.8656607e-07	loss: 34343.00390625	train_loss: 34380.882806209745	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1454
Epoch: 1454	max: 0.99999964/1.0	min: 3.979062e-07	loss: 34342.953125	train_loss: 34380.82941934148	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1455
Epoch: 1455	max: 0.99999976/1.0	min: 2.2474823e-07	loss: 34342.92578125	train_loss: 34380.80207268828	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1456
Epoch: 1456	max: 0.9999995/1.0	min: 5.0977496e-07	loss: 34342.87109375	train_loss: 34380.81259628933	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1457
Epoch: 1457	max: 0.99999964/1.0	min: 3.3827658e-07	loss: 34343.2109375	train_loss: 34380.78399884259	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1458
Epoch: 1458	max: 0.99999964/1.0	min: 3.3030526e-07	loss: 34343.25	train_loss: 34380.80542733107	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1459
Epoch: 1459	max: 0.9999993/1.0	min: 7.3841284e-07	loss: 34343.18359375	train_loss: 34380.822098933175	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1460
Epoch: 1460	max: 0.9999989/1.0	min: 1.0779812e-06	loss: 34342.796875	train_loss: 34380.77789535721	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1461
Epoch: 1461	max: 0.99999976/1.0	min: 2.7120183e-07	loss: 34342.73046875	train_loss: 34380.7231425353	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1462
Epoch: 1462	max: 0.99999976/1.0	min: 2.4211968e-07	loss: 34342.890625	train_loss: 34380.70493852966	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1463
Epoch: 1463	max: 0.99999964/1.0	min: 2.9876614e-07	loss: 34342.78515625	train_loss: 34380.68973013827	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1464
Epoch: 1464	max: 0.99999976/1.0	min: 2.7993826e-07	loss: 34342.79296875	train_loss: 34380.67522286867	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1465
Epoch: 1465	max: 0.9999995/1.0	min: 5.143546e-07	loss: 34343.0	train_loss: 34380.672560638086	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1466
Epoch: 1466	max: 0.99999917/1.0	min: 7.936531e-07	loss: 34342.84375	train_loss: 34380.662254776726	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1467
Epoch: 1467	max: 0.99999917/1.0	min: 8.158322e-07	loss: 34342.9140625	train_loss: 34380.645438014835	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1468
Epoch: 1468	max: 0.99999976/1.0	min: 2.0596697e-07	loss: 34342.98046875	train_loss: 34380.63748325824	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1469
Epoch: 1469	max: 0.9999995/1.0	min: 4.4687565e-07	loss: 34342.75	train_loss: 34380.6367884267	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1470
Epoch: 1470	max: 0.9999974/1.0	min: 2.667389e-06	loss: 34342.796875	train_loss: 34380.61521864936	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1471
Epoch: 1471	max: 0.9999994/1.0	min: 5.4801654e-07	loss: 34342.76171875	train_loss: 34380.6132159281	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1472
Epoch: 1472	max: 0.9999995/1.0	min: 4.4413483e-07	loss: 34342.76953125	train_loss: 34380.585945725725	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1473
Epoch: 1473	max: 0.99999976/1.0	min: 2.540085e-07	loss: 34342.84375	train_loss: 34380.57166974405	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1474
Epoch: 1474	max: 0.9999993/1.0	min: 7.607497e-07	loss: 34342.890625	train_loss: 34380.55020351403	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1475
Epoch: 1475	max: 0.99999964/1.0	min: 3.4367054e-07	loss: 34342.9765625	train_loss: 34380.557887789546	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1476
Epoch: 1476	max: 0.99999976/1.0	min: 2.495373e-07	loss: 34342.72265625	train_loss: 34380.55667715688	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1477
Epoch: 1477	max: 0.99999964/1.0	min: 3.8389376e-07	loss: 34342.65625	train_loss: 34380.52026091989	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1478
Epoch: 1478	max: 0.9999999/1.0	min: 1.3064295e-07	loss: 34342.9609375	train_loss: 34380.52694746377	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1479
Epoch: 1479	max: 0.99999905/1.0	min: 9.733282e-07	loss: 34342.81640625	train_loss: 34380.513583085594	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1480
Epoch: 1480	max: 0.99999845/1.0	min: 1.5013427e-06	loss: 34342.62890625	train_loss: 34380.50933667782	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1481
Epoch: 1481	max: 0.9999982/1.0	min: 1.8084793e-06	loss: 34342.58984375	train_loss: 34380.5158112884	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1482
Epoch: 1482	max: 0.9999993/1.0	min: 7.402165e-07	loss: 34342.5625	train_loss: 34380.505995099404	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1483
Epoch: 1483	max: 0.9999995/1.0	min: 4.627662e-07	loss: 34342.5234375	train_loss: 34380.48454483696	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1484
Epoch: 1484	max: 0.99999905/1.0	min: 8.9418944e-07	loss: 34342.6796875	train_loss: 34380.45834107519	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1485
Epoch: 1485	max: 0.9999988/1.0	min: 1.2235366e-06	loss: 34342.76171875	train_loss: 34380.42388304379	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1486
Epoch: 1486	max: 0.9999995/1.0	min: 5.329287e-07	loss: 34342.80859375	train_loss: 34380.41441427056	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1487
Epoch: 1487	max: 0.99999857/1.0	min: 1.3844559e-06	loss: 34342.55859375	train_loss: 34380.40398502338	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1488
Epoch: 1488	max: 0.99999976/1.0	min: 2.575803e-07	loss: 34342.7109375	train_loss: 34380.40537710579	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1489
Epoch: 1489	max: 0.99999905/1.0	min: 9.831789e-07	loss: 34342.734375	train_loss: 34380.41047705314	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1490
Epoch: 1490	max: 0.99999964/1.0	min: 3.556493e-07	loss: 34342.92578125	train_loss: 34380.3796741453	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1491
Epoch: 1491	max: 0.99999964/1.0	min: 3.43604e-07	loss: 34342.84375	train_loss: 34380.42932992305	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1492
Epoch: 1492	max: 0.99999976/1.0	min: 2.8867768e-07	loss: 34342.7578125	train_loss: 34380.398846850614	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1493
Epoch: 1493	max: 0.9999945/1.0	min: 5.5202263e-06	loss: 34342.63671875	train_loss: 34380.47508090239	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1494
Epoch: 1494	max: 0.9999976/1.0	min: 2.3592402e-06	loss: 34342.453125	train_loss: 34380.468797418864	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1495
Epoch: 1495	max: 0.99999905/1.0	min: 9.0688434e-07	loss: 34342.734375	train_loss: 34380.381255903165	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1496
Epoch: 1496	max: 0.9999993/1.0	min: 6.9619506e-07	loss: 34342.49609375	train_loss: 34380.30313816115	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1497
Epoch: 1497	max: 0.99999976/1.0	min: 2.1083443e-07	loss: 34342.703125	train_loss: 34380.3083164948	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1498
Epoch: 1498	max: 0.99999976/1.0	min: 2.5691838e-07	loss: 34342.7890625	train_loss: 34380.311096788675	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1499
Epoch: 1499	max: 0.99999917/1.0	min: 8.164626e-07	loss: 34342.578125	train_loss: 34380.27167816332	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1500
Epoch: 1500	max: 0.99999964/1.0	min: 3.4597838e-07	loss: 34342.55859375	train_loss: 34380.26317276725	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1501
Epoch: 1501	max: 0.99999917/1.0	min: 7.792026e-07	loss: 34342.62890625	train_loss: 34380.25125030967	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1502
Epoch: 1502	max: 0.9999993/1.0	min: 7.680644e-07	loss: 34342.60546875	train_loss: 34380.23476693144	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1503
Epoch: 1503	max: 0.9999993/1.0	min: 7.7218687e-07	loss: 34342.7890625	train_loss: 34380.24124250976	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1504
Epoch: 1504	max: 0.99999917/1.0	min: 8.5282346e-07	loss: 34342.81640625	train_loss: 34380.26475839604	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1505
Epoch: 1505	max: 0.99999976/1.0	min: 2.0766834e-07	loss: 34342.6015625	train_loss: 34380.21159265453	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1506
Epoch: 1506	max: 0.9999988/1.0	min: 1.1427195e-06	loss: 34342.234375	train_loss: 34380.21589228756	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1507
Epoch: 1507	max: 0.9999974/1.0	min: 2.576508e-06	loss: 34342.6015625	train_loss: 34380.21658131271	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1508
Epoch: 1508	max: 0.9999988/1.0	min: 1.2488674e-06	loss: 34342.93359375	train_loss: 34380.18736403366	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1509
Epoch: 1509	max: 0.99999917/1.0	min: 8.108153e-07	loss: 34342.53515625	train_loss: 34380.174462231356	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1510
Epoch: 1510	max: 0.9999987/1.0	min: 1.3485806e-06	loss: 34342.56640625	train_loss: 34380.19095964171	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1511
Epoch: 1511	max: 0.99999964/1.0	min: 3.5515782e-07	loss: 34342.59375	train_loss: 34380.146279941626	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1512
Epoch: 1512	max: 0.9999995/1.0	min: 4.293063e-07	loss: 34342.43359375	train_loss: 34380.14270659142	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1513
Epoch: 1513	max: 0.99999964/1.0	min: 3.854624e-07	loss: 34342.265625	train_loss: 34380.13177218816	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1514
Epoch: 1514	max: 0.99999964/1.0	min: 4.0866448e-07	loss: 34342.19921875	train_loss: 34380.14711267497	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1515
Epoch: 1515	max: 0.99999845/1.0	min: 1.5470238e-06	loss: 34342.546875	train_loss: 34380.16018624969	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1516
Epoch: 1516	max: 0.999997/1.0	min: 2.9903915e-06	loss: 34342.62109375	train_loss: 34380.111024982965	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1517
Epoch: 1517	max: 0.99999785/1.0	min: 2.1948008e-06	loss: 34342.68359375	train_loss: 34380.11612444646	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1518
Epoch: 1518	max: 0.9999994/1.0	min: 6.008129e-07	loss: 34342.61328125	train_loss: 34380.08239753654	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1519
Epoch: 1519	max: 0.99999917/1.0	min: 8.6910006e-07	loss: 34342.6484375	train_loss: 34380.04964029403	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1520
Epoch: 1520	max: 0.99999905/1.0	min: 9.1387597e-07	loss: 34342.63671875	train_loss: 34380.04139521786	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1521
Epoch: 1521	max: 0.99999917/1.0	min: 7.762137e-07	loss: 34342.76953125	train_loss: 34380.02491909761	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1522
Epoch: 1522	max: 0.9999989/1.0	min: 1.0827474e-06	loss: 34342.44921875	train_loss: 34380.021818484456	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1523
Epoch: 1523	max: 0.9999994/1.0	min: 6.0744304e-07	loss: 34342.67578125	train_loss: 34380.009509901836	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1524
Epoch: 1524	max: 0.9999994/1.0	min: 6.1729145e-07	loss: 34342.3984375	train_loss: 34379.99452650811	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1525
Epoch: 1525	max: 0.9999994/1.0	min: 5.9411565e-07	loss: 34342.36328125	train_loss: 34379.998487918834	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1526
Epoch: 1526	max: 0.99999964/1.0	min: 3.5776006e-07	loss: 34342.46875	train_loss: 34379.98302017528	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1527
Epoch: 1527	max: 0.99999964/1.0	min: 4.0941694e-07	loss: 34342.36328125	train_loss: 34379.961561203236	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1528
Epoch: 1528	max: 0.9999989/1.0	min: 1.1298589e-06	loss: 34342.43359375	train_loss: 34379.944326865014	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1529
Epoch: 1529	max: 0.99999964/1.0	min: 3.3616337e-07	loss: 34342.15625	train_loss: 34379.992548947885	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1530
Epoch: 1530	max: 0.9999999/1.0	min: 1.493655e-07	loss: 34342.62109375	train_loss: 34379.949575843086	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1531
Epoch: 1531	max: 0.99999976/1.0	min: 2.4928897e-07	loss: 34342.6484375	train_loss: 34379.969339348754	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1532
Epoch: 1532	max: 0.99999917/1.0	min: 8.819298e-07	loss: 34342.58984375	train_loss: 34379.93616259445	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1533
Epoch: 1533	max: 0.9999994/1.0	min: 5.397313e-07	loss: 34342.48828125	train_loss: 34379.90038554441	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1534
Epoch: 1534	max: 0.9999995/1.0	min: 4.61324e-07	loss: 34342.44140625	train_loss: 34379.874729518924	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1535
Epoch: 1535	max: 0.99999964/1.0	min: 3.9535527e-07	loss: 34342.44921875	train_loss: 34379.8661423495	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1536
