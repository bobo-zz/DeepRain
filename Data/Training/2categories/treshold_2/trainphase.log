Epoch: 0	max: 0.57067263/1.0	min: 0.42932737	loss: 36486.92578125	train_loss: 36780.34063341927	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1
Epoch: 1	max: 0.64984673/1.0	min: 0.3501533	loss: 36082.28125	train_loss: 36314.21610180153	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_2
Epoch: 2	max: 0.7137596/1.0	min: 0.28624043	loss: 35807.30078125	train_loss: 35989.054732499535	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_3
Epoch: 3	max: 0.7644988/1.0	min: 0.23550126	loss: 35625.2890625	train_loss: 35774.892935943884	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_4
Epoch: 4	max: 0.80337906/1.0	min: 0.19662096	loss: 35507.80859375	train_loss: 35637.50167030534	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_5
Epoch: 5	max: 0.8324368/1.0	min: 0.16756317	loss: 35433.76171875	train_loss: 35552.62813303217	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_6
Epoch: 6	max: 0.85358393/1.0	min: 0.14641611	loss: 35388.54296875	train_loss: 35502.09039051855	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_7
Epoch: 7	max: 0.8688628/1.0	min: 0.13113716	loss: 35361.23828125	train_loss: 35472.861096111264	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_8
Epoch: 8	max: 0.8796909/1.0	min: 0.1203091	loss: 35344.921875	train_loss: 35456.60561971618	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_9
Epoch: 9	max: 0.8871623/1.0	min: 0.11283759	loss: 35335.265625	train_loss: 35447.50345528691	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_10
Epoch: 10	max: 0.8923104/1.0	min: 0.1076896	loss: 35329.3203125	train_loss: 35442.3240764934	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_11
Epoch: 11	max: 0.89585835/1.0	min: 0.104141615	loss: 35325.3359375	train_loss: 35438.85234297581	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_12
Epoch: 12	max: 0.8980906/1.0	min: 0.10190938	loss: 35322.57421875	train_loss: 35436.08358349204	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_13
Epoch: 13	max: 0.8991203/1.0	min: 0.1008797	loss: 35320.59375	train_loss: 35433.44208414623	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_14
Epoch: 14	max: 0.9000061/1.0	min: 0.09999391	loss: 35318.5859375	train_loss: 35430.62172906602	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_15
Epoch: 15	max: 0.9006265/1.0	min: 0.09937346	loss: 35316.55078125	train_loss: 35427.46671195652	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_16
Epoch: 16	max: 0.9009635/1.0	min: 0.09903654	loss: 35314.41015625	train_loss: 35423.841534861574	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_17
Epoch: 17	max: 0.90160733/1.0	min: 0.098392695	loss: 35311.75	train_loss: 35419.615739773006	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_18
Epoch: 18	max: 0.9021137/1.0	min: 0.09788635	loss: 35308.73828125	train_loss: 35414.669378735445	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_19
Epoch: 19	max: 0.9025631/1.0	min: 0.09743691	loss: 35305.1484375	train_loss: 35408.784775931344	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_20
Epoch: 20	max: 0.9029191/1.0	min: 0.09708089	loss: 35300.7890625	train_loss: 35401.67678575576	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_21
Epoch: 21	max: 0.90366143/1.0	min: 0.09633849	loss: 35295.1015625	train_loss: 35393.05313477409	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_22
Epoch: 22	max: 0.9049944/1.0	min: 0.095005594	loss: 35287.50390625	train_loss: 35382.25334157841	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_23
Epoch: 23	max: 0.90600854/1.0	min: 0.09399146	loss: 35277.44140625	train_loss: 35368.2308384236	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_24
Epoch: 24	max: 0.90761757/1.0	min: 0.09238247	loss: 35262.96875	train_loss: 35349.03033694491	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_25
Epoch: 25	max: 0.91110426/1.0	min: 0.08889577	loss: 35240.8359375	train_loss: 35321.67022646863	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_26
Epoch: 26	max: 0.91757566/1.0	min: 0.08242433	loss: 35207.9453125	train_loss: 35282.5678026872	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_27
Epoch: 27	max: 0.9273279/1.0	min: 0.07267215	loss: 35160.984375	train_loss: 35228.91442152855	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_28
Epoch: 28	max: 0.94089764/1.0	min: 0.05910234	loss: 35099.67578125	train_loss: 35159.26483775006	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_29
Epoch: 29	max: 0.9568369/1.0	min: 0.043163165	loss: 35032.40625	train_loss: 35078.20394805602	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_30
Epoch: 30	max: 0.9685478/1.0	min: 0.031452157	loss: 34981.34375	train_loss: 35004.757859918864	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_31
Epoch: 31	max: 0.9753612/1.0	min: 0.024638744	loss: 34952.99609375	train_loss: 34959.56819219931	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_32
Epoch: 32	max: 0.9797029/1.0	min: 0.020297155	loss: 34937.78515625	train_loss: 34935.15273035891	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_33
Epoch: 33	max: 0.9821311/1.0	min: 0.017868845	loss: 34925.07421875	train_loss: 34919.922537412516	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_34
Epoch: 34	max: 0.98384815/1.0	min: 0.01615191	loss: 34914.8984375	train_loss: 34908.621731969215	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_35
Epoch: 35	max: 0.9853698/1.0	min: 0.014630153	loss: 34907.875	train_loss: 34899.38573843754	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_36
Epoch: 36	max: 0.98622143/1.0	min: 0.013778539	loss: 34898.9296875	train_loss: 34891.4752115462	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_37
Epoch: 37	max: 0.9869926/1.0	min: 0.0130074145	loss: 34891.234375	train_loss: 34884.34380758005	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_38
Epoch: 38	max: 0.98770976/1.0	min: 0.012290241	loss: 34884.72265625	train_loss: 34877.871696647	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_39
Epoch: 39	max: 0.9885217/1.0	min: 0.011478298	loss: 34880.3515625	train_loss: 34871.89009419903	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_40
Epoch: 40	max: 0.988858/1.0	min: 0.011141954	loss: 34872.98828125	train_loss: 34866.28972926731	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_41
Epoch: 41	max: 0.9895383/1.0	min: 0.010461738	loss: 34869.62890625	train_loss: 34860.867776848754	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_42
Epoch: 42	max: 0.9898018/1.0	min: 0.010198151	loss: 34862.953125	train_loss: 34855.73711077821	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_43
Epoch: 43	max: 0.9897803/1.0	min: 0.010219703	loss: 34854.84375	train_loss: 34850.66483136303	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_44
Epoch: 44	max: 0.99025375/1.0	min: 0.009746205	loss: 34850.64453125	train_loss: 34845.67665220875	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_45
Epoch: 45	max: 0.9905725/1.0	min: 0.009427414	loss: 34845.703125	train_loss: 34840.74201621144	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_46
Epoch: 46	max: 0.9905641/1.0	min: 0.009435947	loss: 34838.984375	train_loss: 34835.83030868714	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_47
Epoch: 47	max: 0.9908731/1.0	min: 0.00912684	loss: 34834.4765625	train_loss: 34831.03130177366	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_48
Epoch: 48	max: 0.9910779/1.0	min: 0.008922155	loss: 34829.453125	train_loss: 34826.149607487925	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_49
Epoch: 49	max: 0.99118376/1.0	min: 0.0088162245	loss: 34823.90234375	train_loss: 34821.30515588226	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_50
Epoch: 50	max: 0.9915615/1.0	min: 0.008438498	loss: 34820.23828125	train_loss: 34816.46510552149	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_51
Epoch: 51	max: 0.99171937/1.0	min: 0.008280642	loss: 34815.2265625	train_loss: 34811.455708844296	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_52
Epoch: 52	max: 0.9917801/1.0	min: 0.008219903	loss: 34809.671875	train_loss: 34806.49340006813	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_53
Epoch: 53	max: 0.99184/1.0	min: 0.0081600305	loss: 34804.265625	train_loss: 34801.51809368419	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_54
Epoch: 54	max: 0.99205786/1.0	min: 0.007942155	loss: 34799.84765625	train_loss: 34796.47309366484	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_55
Epoch: 55	max: 0.99222356/1.0	min: 0.0077764285	loss: 34795.33984375	train_loss: 34791.516080801746	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_56
Epoch: 56	max: 0.9923936/1.0	min: 0.0076064346	loss: 34790.81640625	train_loss: 34786.52137042456	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_57
Epoch: 57	max: 0.99260485/1.0	min: 0.007395177	loss: 34786.640625	train_loss: 34781.54878288353	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_58
Epoch: 58	max: 0.9923935/1.0	min: 0.0076064593	loss: 34780.19140625	train_loss: 34776.586840877775	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_59
Epoch: 59	max: 0.99285567/1.0	min: 0.007144291	loss: 34777.50390625	train_loss: 34771.79315745773	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_60
Epoch: 60	max: 0.9928255/1.0	min: 0.007174531	loss: 34771.3359375	train_loss: 34767.30087657159	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_61
Epoch: 61	max: 0.99359554/1.0	min: 0.006404522	loss: 34769.43359375	train_loss: 34763.00424931097	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_62
Epoch: 62	max: 0.9939335/1.0	min: 0.006066518	loss: 34765.7734375	train_loss: 34758.71496907129	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_63
Epoch: 63	max: 0.9942485/1.0	min: 0.005751492	loss: 34762.1640625	train_loss: 34754.74368264586	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_64
Epoch: 64	max: 0.9944793/1.0	min: 0.005520734	loss: 34758.1953125	train_loss: 34751.029588888116	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_65
Epoch: 65	max: 0.9947345/1.0	min: 0.00526549	loss: 34754.63671875	train_loss: 34747.389930168465	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_66
Epoch: 66	max: 0.99502003/1.0	min: 0.004979994	loss: 34751.7734375	train_loss: 34744.03243692323	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_67
Epoch: 67	max: 0.9953211/1.0	min: 0.004678926	loss: 34749.30859375	train_loss: 34740.834351871206	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_68
Epoch: 68	max: 0.9954314/1.0	min: 0.004568539	loss: 34745.98046875	train_loss: 34737.72990359455	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_69
Epoch: 69	max: 0.9957552/1.0	min: 0.004244817	loss: 34744.11328125	train_loss: 34734.910901887466	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_70
Epoch: 70	max: 0.99578696/1.0	min: 0.004213017	loss: 34740.91015625	train_loss: 34732.24430296203	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_71
Epoch: 71	max: 0.996197/1.0	min: 0.0038030741	loss: 34740.55078125	train_loss: 34729.93150683606	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_72
Epoch: 72	max: 0.996327/1.0	min: 0.0036729833	loss: 34738.61328125	train_loss: 34727.83613394958	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_73
Epoch: 73	max: 0.9962411/1.0	min: 0.0037589192	loss: 34734.8984375	train_loss: 34725.677933001985	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_74
Epoch: 74	max: 0.9964122/1.0	min: 0.003587807	loss: 34733.42578125	train_loss: 34723.56638931469	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_75
Epoch: 75	max: 0.99653035/1.0	min: 0.003469693	loss: 34731.80078125	train_loss: 34721.58003675446	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_76
Epoch: 76	max: 0.9965146/1.0	min: 0.003485368	loss: 34729.20703125	train_loss: 34719.6023744271	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_77
Epoch: 77	max: 0.9966696/1.0	min: 0.0033304775	loss: 34727.9765625	train_loss: 34717.72099658971	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_78
Epoch: 78	max: 0.9966557/1.0	min: 0.0033442765	loss: 34725.71875	train_loss: 34715.807019250125	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_79
Epoch: 79	max: 0.9967578/1.0	min: 0.003242192	loss: 34724.44140625	train_loss: 34713.959728318936	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_80
Epoch: 80	max: 0.99661535/1.0	min: 0.0033846954	loss: 34721.4296875	train_loss: 34712.16143026911	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_81
Epoch: 81	max: 0.9966749/1.0	min: 0.0033251292	loss: 34719.90625	train_loss: 34710.317894137865	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_82
Epoch: 82	max: 0.9967636/1.0	min: 0.003236434	loss: 34718.5859375	train_loss: 34708.44768924966	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_83
Epoch: 83	max: 0.99676126/1.0	min: 0.003238779	loss: 34716.71875	train_loss: 34706.60119621346	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_84
Epoch: 84	max: 0.99672663/1.0	min: 0.0032733947	loss: 34714.66796875	train_loss: 34704.8166651183	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_85
Epoch: 85	max: 0.99684024/1.0	min: 0.0031597414	loss: 34713.76171875	train_loss: 34702.97278640995	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_86
Epoch: 86	max: 0.9967939/1.0	min: 0.003206116	loss: 34711.88671875	train_loss: 34701.14598188019	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_87
Epoch: 87	max: 0.99663216/1.0	min: 0.0033678864	loss: 34709.20703125	train_loss: 34699.35817404465	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_88
Epoch: 88	max: 0.99680567/1.0	min: 0.003194312	loss: 34708.7109375	train_loss: 34697.48734884027	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_89
Epoch: 89	max: 0.9967013/1.0	min: 0.0032986512	loss: 34706.44921875	train_loss: 34695.6904733564	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_90
Epoch: 90	max: 0.9966685/1.0	min: 0.0033315322	loss: 34704.703125	train_loss: 34693.83028304224	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_91
Epoch: 91	max: 0.9968322/1.0	min: 0.0031677643	loss: 34704.50390625	train_loss: 34692.04834692029	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_92
Epoch: 92	max: 0.99646676/1.0	min: 0.00353328	loss: 34700.82421875	train_loss: 34690.19148608788	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_93
Epoch: 93	max: 0.9964586/1.0	min: 0.0035414028	loss: 34699.2890625	train_loss: 34688.3385639245	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_94
Epoch: 94	max: 0.9962864/1.0	min: 0.0037135913	loss: 34697.25	train_loss: 34686.50690863836	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_95
Epoch: 95	max: 0.9962202/1.0	min: 0.0037798113	loss: 34695.609375	train_loss: 34684.76767610786	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_96
Epoch: 96	max: 0.9961635/1.0	min: 0.0038365473	loss: 34694.09375	train_loss: 34682.955449976	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_97
Epoch: 97	max: 0.99610233/1.0	min: 0.0038977137	loss: 34692.609375	train_loss: 34681.09211211368	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_98
Epoch: 98	max: 0.99586654/1.0	min: 0.004133428	loss: 34690.6015625	train_loss: 34679.316221413195	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_99
Epoch: 99	max: 0.9959843/1.0	min: 0.004015656	loss: 34689.93359375	train_loss: 34677.58976052505	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_100
Epoch: 100	max: 0.9960018/1.0	min: 0.0039982074	loss: 34688.87109375	train_loss: 34675.89854395051	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_101
Epoch: 101	max: 0.9959454/1.0	min: 0.0040546446	loss: 34686.90625	train_loss: 34674.25991586538	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_102
Epoch: 102	max: 0.9956221/1.0	min: 0.0043779262	loss: 34683.95703125	train_loss: 34672.67533657717	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_103
Epoch: 103	max: 0.995795/1.0	min: 0.0042049787	loss: 34683.00390625	train_loss: 34671.21903257773	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_104
Epoch: 104	max: 0.99600995/1.0	min: 0.003990036	loss: 34682.51171875	train_loss: 34669.59051342051	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_105
Epoch: 105	max: 0.99605125/1.0	min: 0.0039487965	loss: 34681.35546875	train_loss: 34668.16292154403	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_106
Epoch: 106	max: 0.9959972/1.0	min: 0.004002758	loss: 34679.5390625	train_loss: 34666.89075951474	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_107
Epoch: 107	max: 0.9958169/1.0	min: 0.004183092	loss: 34677.41796875	train_loss: 34665.57707065604	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_108
Epoch: 108	max: 0.9960932/1.0	min: 0.0039067697	loss: 34677.4765625	train_loss: 34664.31072276028	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_109
Epoch: 109	max: 0.99608576/1.0	min: 0.0039142254	loss: 34676.12109375	train_loss: 34662.94568120587	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_110
Epoch: 110	max: 0.99625254/1.0	min: 0.003747478	loss: 34675.76171875	train_loss: 34661.8417037308	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_111
Epoch: 111	max: 0.9959686/1.0	min: 0.0040314784	loss: 34673.03125	train_loss: 34660.564434012296	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_112
Epoch: 112	max: 0.9960633/1.0	min: 0.0039366838	loss: 34672.203125	train_loss: 34659.47296834355	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_113
Epoch: 113	max: 0.99612314/1.0	min: 0.0038767972	loss: 34671.3359375	train_loss: 34658.3269163028	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_114
Epoch: 114	max: 0.99614185/1.0	min: 0.003858183	loss: 34670.25	train_loss: 34657.22951117924	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_115
Epoch: 115	max: 0.9961241/1.0	min: 0.0038759396	loss: 34669.09375	train_loss: 34656.11402737133	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_116
Epoch: 116	max: 0.99618953/1.0	min: 0.003810517	loss: 34668.3359375	train_loss: 34655.11507639276	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_117
Epoch: 117	max: 0.9958717/1.0	min: 0.004128277	loss: 34666.18359375	train_loss: 34654.06276322309	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_118
Epoch: 118	max: 0.99592614/1.0	min: 0.0040738774	loss: 34665.2421875	train_loss: 34653.181603125384	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_119
Epoch: 119	max: 0.9958424/1.0	min: 0.0041576354	loss: 34664.0859375	train_loss: 34652.154336793945	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_120
Epoch: 120	max: 0.9959941/1.0	min: 0.004005837	loss: 34663.40625	train_loss: 34651.33360042735	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_121
Epoch: 121	max: 0.99628216/1.0	min: 0.0037177957	loss: 34663.44140625	train_loss: 34650.19067658011	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_122
Epoch: 122	max: 0.9961054/1.0	min: 0.0038945503	loss: 34661.765625	train_loss: 34649.32224699616	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_123
Epoch: 123	max: 0.9964085/1.0	min: 0.0035914278	loss: 34662.0859375	train_loss: 34648.351751691596	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_124
Epoch: 124	max: 0.9962398/1.0	min: 0.0037601762	loss: 34660.32421875	train_loss: 34647.47524977162	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_125
Epoch: 125	max: 0.9963012/1.0	min: 0.0036987786	loss: 34659.5859375	train_loss: 34646.60435682599	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_126
Epoch: 126	max: 0.996258/1.0	min: 0.00374194	loss: 34658.52734375	train_loss: 34645.74416747956	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_127
Epoch: 127	max: 0.99602354/1.0	min: 0.0039764056	loss: 34657.09375	train_loss: 34644.89007387665	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_128
Epoch: 128	max: 0.99626726/1.0	min: 0.003732802	loss: 34656.75	train_loss: 34644.19583362365	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_129
Epoch: 129	max: 0.99652857/1.0	min: 0.0034714972	loss: 34657.0390625	train_loss: 34643.295971622225	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_130
Epoch: 130	max: 0.9964665/1.0	min: 0.003533451	loss: 34655.78125	train_loss: 34642.45462982317	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_131
Epoch: 131	max: 0.99650747/1.0	min: 0.0034925432	loss: 34655.12890625	train_loss: 34641.66847535767	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_132
Epoch: 132	max: 0.9965456/1.0	min: 0.0034543998	loss: 34654.55859375	train_loss: 34640.94827569522	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_133
Epoch: 133	max: 0.99661475/1.0	min: 0.0033852984	loss: 34653.99609375	train_loss: 34640.19250317416	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_134
Epoch: 134	max: 0.9964864/1.0	min: 0.0035135911	loss: 34652.5546875	train_loss: 34639.594226124114	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_135
Epoch: 135	max: 0.9963406/1.0	min: 0.0036594048	loss: 34651.296875	train_loss: 34638.717798719495	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_136
Epoch: 136	max: 0.99637043/1.0	min: 0.003629542	loss: 34650.62109375	train_loss: 34637.98836641041	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_137
Epoch: 137	max: 0.9965739/1.0	min: 0.003426146	loss: 34650.484375	train_loss: 34637.23881011551	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_138
Epoch: 138	max: 0.99660933/1.0	min: 0.003390755	loss: 34649.890625	train_loss: 34636.55798456274	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_139
Epoch: 139	max: 0.996646/1.0	min: 0.0033540304	loss: 34649.23046875	train_loss: 34635.87928608479	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_140
Epoch: 140	max: 0.9966061/1.0	min: 0.0033939485	loss: 34648.36328125	train_loss: 34635.216794697604	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_141
Epoch: 141	max: 0.99651366/1.0	min: 0.0034863385	loss: 34647.30859375	train_loss: 34634.581475287996	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_142
Epoch: 142	max: 0.9966271/1.0	min: 0.0033729526	loss: 34646.98828125	train_loss: 34633.90330422395	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_143
Epoch: 143	max: 0.9968773/1.0	min: 0.003122639	loss: 34647.4296875	train_loss: 34633.31826865013	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_144
Epoch: 144	max: 0.9967686/1.0	min: 0.0032314153	loss: 34646.11328125	train_loss: 34632.67873912269	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_145
Epoch: 145	max: 0.9968137/1.0	min: 0.0031863207	loss: 34645.68359375	train_loss: 34632.01140665645	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_146
Epoch: 146	max: 0.99670804/1.0	min: 0.0032918854	loss: 34644.5234375	train_loss: 34631.43375390964	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_147
Epoch: 147	max: 0.99652267/1.0	min: 0.0034773848	loss: 34643.34375	train_loss: 34630.81353692478	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_148
Epoch: 148	max: 0.996766/1.0	min: 0.0032339857	loss: 34643.5	train_loss: 34630.210518472064	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_149
Epoch: 149	max: 0.996648/1.0	min: 0.0033519794	loss: 34642.4453125	train_loss: 34629.637051165926	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_150
Epoch: 150	max: 0.9965138/1.0	min: 0.003486241	loss: 34641.453125	train_loss: 34629.06419836957	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_151
Epoch: 151	max: 0.9967141/1.0	min: 0.003285905	loss: 34641.3515625	train_loss: 34628.514239207856	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_152
Epoch: 152	max: 0.9968622/1.0	min: 0.0031378607	loss: 34641.42578125	train_loss: 34627.96230732457	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_153
Epoch: 153	max: 0.9968009/1.0	min: 0.0031991242	loss: 34640.42578125	train_loss: 34627.40765466292	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_154
Epoch: 154	max: 0.9965881/1.0	min: 0.0034119422	loss: 34639.26171875	train_loss: 34626.866522668155	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_155
Epoch: 155	max: 0.9966858/1.0	min: 0.003314148	loss: 34638.90625	train_loss: 34626.35855339558	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_156
Epoch: 156	max: 0.9967353/1.0	min: 0.0032647126	loss: 34638.421875	train_loss: 34625.78957975272	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_157
Epoch: 157	max: 0.9970591/1.0	min: 0.0029409553	loss: 34639.17578125	train_loss: 34625.31606415676	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_158
Epoch: 158	max: 0.99673945/1.0	min: 0.003260513	loss: 34637.2890625	train_loss: 34624.93483631782	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_159
Epoch: 159	max: 0.9968605/1.0	min: 0.0031394958	loss: 34636.99609375	train_loss: 34624.33971649325	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_160
Epoch: 160	max: 0.99657285/1.0	min: 0.003427139	loss: 34635.9140625	train_loss: 34623.849326071475	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_161
Epoch: 161	max: 0.9968567/1.0	min: 0.0031432465	loss: 34635.88671875	train_loss: 34623.44225930571	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_162
Epoch: 162	max: 0.9970879/1.0	min: 0.00291212	loss: 34636.12890625	train_loss: 34622.91331057228	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_163
Epoch: 163	max: 0.9973279/1.0	min: 0.00267205	loss: 34636.87890625	train_loss: 34622.4332240764	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_164
Epoch: 164	max: 0.99716896/1.0	min: 0.0028310132	loss: 34635.28515625	train_loss: 34622.1403250031	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_165
Epoch: 165	max: 0.99703634/1.0	min: 0.0029636964	loss: 34634.30859375	train_loss: 34621.51139794686	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_166
Epoch: 166	max: 0.9971198/1.0	min: 0.0028802287	loss: 34633.9765625	train_loss: 34621.05785391893	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_167
Epoch: 167	max: 0.99708885/1.0	min: 0.002911223	loss: 34633.30078125	train_loss: 34620.63630456073	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_168
Epoch: 168	max: 0.9971902/1.0	min: 0.0028097734	loss: 34633.19140625	train_loss: 34620.277798584015	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_169
Epoch: 169	max: 0.9968899/1.0	min: 0.0031101392	loss: 34631.83984375	train_loss: 34619.8612349808	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_170
Epoch: 170	max: 0.9971554/1.0	min: 0.0028446012	loss: 34631.984375	train_loss: 34619.44495734238	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_171
Epoch: 171	max: 0.9974075/1.0	min: 0.002592535	loss: 34632.53125	train_loss: 34619.10004606404	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_172
Epoch: 172	max: 0.9971763/1.0	min: 0.002823708	loss: 34631.078125	train_loss: 34618.65538581537	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_173
Epoch: 173	max: 0.99697566/1.0	min: 0.003024329	loss: 34630.03515625	train_loss: 34618.20350918958	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_174
Epoch: 174	max: 0.99729687/1.0	min: 0.0027031126	loss: 34630.47265625	train_loss: 34617.80254929626	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_175
Epoch: 175	max: 0.9972089/1.0	min: 0.0027911605	loss: 34629.703125	train_loss: 34617.44637458581	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_176
Epoch: 176	max: 0.99729687/1.0	min: 0.0027031896	loss: 34629.515625	train_loss: 34617.0708941069	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_177
Epoch: 177	max: 0.9969355/1.0	min: 0.0030645602	loss: 34628.3046875	train_loss: 34616.66802342686	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_178
Epoch: 178	max: 0.9972255/1.0	min: 0.0027744528	loss: 34628.40625	train_loss: 34616.37861980134	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_179
Epoch: 179	max: 0.99739146/1.0	min: 0.0026085405	loss: 34628.48046875	train_loss: 34615.98981075034	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_180
Epoch: 180	max: 0.9972518/1.0	min: 0.0027481497	loss: 34627.6015625	train_loss: 34615.57221506101	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_181
Epoch: 181	max: 0.997306/1.0	min: 0.0026939523	loss: 34627.36328125	train_loss: 34615.25122805184	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_182
Epoch: 182	max: 0.997235/1.0	min: 0.0027650464	loss: 34626.76171875	train_loss: 34614.89052096882	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_183
Epoch: 183	max: 0.9972933/1.0	min: 0.0027066898	loss: 34626.49609375	train_loss: 34614.51888383733	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_184
Epoch: 184	max: 0.99739563/1.0	min: 0.0026043542	loss: 34626.4765625	train_loss: 34614.19106609222	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_185
Epoch: 185	max: 0.9974625/1.0	min: 0.0025374754	loss: 34626.15625	train_loss: 34613.84001697402	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_186
Epoch: 186	max: 0.9974981/1.0	min: 0.002501844	loss: 34625.92578125	train_loss: 34613.502489490435	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_187
Epoch: 187	max: 0.99734926/1.0	min: 0.0026507515	loss: 34624.9140625	train_loss: 34613.23295533723	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_188
Epoch: 188	max: 0.99747026/1.0	min: 0.0025297597	loss: 34625.015625	train_loss: 34612.84366193639	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_189
Epoch: 189	max: 0.99739873/1.0	min: 0.002601272	loss: 34624.23828125	train_loss: 34612.53988071736	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_190
Epoch: 190	max: 0.99731404/1.0	min: 0.0026858882	loss: 34623.796875	train_loss: 34612.24698986978	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_191
Epoch: 191	max: 0.99762887/1.0	min: 0.002371208	loss: 34624.328125	train_loss: 34611.958845263536	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_192
Epoch: 192	max: 0.99762625/1.0	min: 0.0023738265	loss: 34623.953125	train_loss: 34611.620030212594	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_193
Epoch: 193	max: 0.997361/1.0	min: 0.0026390008	loss: 34622.8046875	train_loss: 34611.32768710129	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_194
Epoch: 194	max: 0.99774534/1.0	min: 0.0022546775	loss: 34623.765625	train_loss: 34611.058151012636	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_195
Epoch: 195	max: 0.9974322/1.0	min: 0.0025678887	loss: 34622.2265625	train_loss: 34610.71562035489	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_196
Epoch: 196	max: 0.99742305/1.0	min: 0.002577015	loss: 34621.87109375	train_loss: 34610.3740458163	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_197
Epoch: 197	max: 0.9976096/1.0	min: 0.0023904003	loss: 34622.03515625	train_loss: 34610.083731071165	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_198
Epoch: 198	max: 0.99778146/1.0	min: 0.0022185557	loss: 34622.30078125	train_loss: 34609.81228322804	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_199
Epoch: 199	max: 0.99751943/1.0	min: 0.0024804967	loss: 34621.0	train_loss: 34609.58550008516	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_200
Epoch: 200	max: 0.99735165/1.0	min: 0.0026483345	loss: 34620.33984375	train_loss: 34609.35606874381	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_201
Epoch: 201	max: 0.99773175/1.0	min: 0.002268318	loss: 34621.046875	train_loss: 34608.97462510064	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_202
Epoch: 202	max: 0.99758136/1.0	min: 0.0024185968	loss: 34620.21484375	train_loss: 34608.71023976526	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_203
Epoch: 203	max: 0.99773836/1.0	min: 0.0022616477	loss: 34620.26953125	train_loss: 34608.5195752818	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_204
Epoch: 204	max: 0.9972356/1.0	min: 0.0027644548	loss: 34619.06640625	train_loss: 34608.23947107643	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_205
Epoch: 205	max: 0.99779034/1.0	min: 0.0022096604	loss: 34619.86328125	train_loss: 34607.94266720473	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_206
Epoch: 206	max: 0.99764013/1.0	min: 0.002359846	loss: 34619.01953125	train_loss: 34607.667005372845	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_207
Epoch: 207	max: 0.99780697/1.0	min: 0.002193041	loss: 34619.203125	train_loss: 34607.35835210733	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_208
Epoch: 208	max: 0.997678/1.0	min: 0.0023220466	loss: 34618.45703125	train_loss: 34607.15799675616	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_209
Epoch: 209	max: 0.99786454/1.0	min: 0.0021354416	loss: 34618.80859375	train_loss: 34606.877957388824	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_210
Epoch: 210	max: 0.997682/1.0	min: 0.0023180512	loss: 34617.875	train_loss: 34606.68840773257	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_211
Epoch: 211	max: 0.9977303/1.0	min: 0.0022696923	loss: 34617.67578125	train_loss: 34606.34232646631	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_212
Epoch: 212	max: 0.99765956/1.0	min: 0.0023403917	loss: 34617.26171875	train_loss: 34606.108277108106	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_213
Epoch: 213	max: 0.99786156/1.0	min: 0.0021384268	loss: 34617.5859375	train_loss: 34605.883907004834	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_214
Epoch: 214	max: 0.9979511/1.0	min: 0.0020489488	loss: 34617.69140625	train_loss: 34605.651041666664	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_215
Epoch: 215	max: 0.99782205/1.0	min: 0.0021779933	loss: 34616.8515625	train_loss: 34605.446101685404	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_216
Epoch: 216	max: 0.99738187/1.0	min: 0.002618099	loss: 34615.8203125	train_loss: 34605.17634979252	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_217
Epoch: 217	max: 0.9978532/1.0	min: 0.0021467172	loss: 34616.35546875	train_loss: 34605.02856889864	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_218
Epoch: 218	max: 0.99772245/1.0	min: 0.002277568	loss: 34615.58984375	train_loss: 34604.71392440465	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_219
Epoch: 219	max: 0.99807656/1.0	min: 0.0019233732	loss: 34616.6484375	train_loss: 34604.55875003871	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_220
Epoch: 220	max: 0.99781203/1.0	min: 0.0021879151	loss: 34615.34375	train_loss: 34604.292193112844	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_221
Epoch: 221	max: 0.9978446/1.0	min: 0.0021553843	loss: 34615.05078125	train_loss: 34604.02063204509	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_222
Epoch: 222	max: 0.9976865/1.0	min: 0.002313477	loss: 34614.50390625	train_loss: 34603.79948690852	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_223
Epoch: 223	max: 0.9979633/1.0	min: 0.0020367021	loss: 34614.88671875	train_loss: 34603.58692894138	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_224
Epoch: 224	max: 0.99788886/1.0	min: 0.0021111076	loss: 34614.3515625	train_loss: 34603.3717876138	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_225
Epoch: 225	max: 0.99781847/1.0	min: 0.0021815568	loss: 34613.99609375	train_loss: 34603.16532877725	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_226
Epoch: 226	max: 0.99764556/1.0	min: 0.0023544007	loss: 34613.53125	train_loss: 34602.97021950096	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_227
Epoch: 227	max: 0.9979845/1.0	min: 0.0020154382	loss: 34614.1015625	train_loss: 34602.7709973639	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_228
Epoch: 228	max: 0.99781656/1.0	min: 0.0021833854	loss: 34613.2265625	train_loss: 34602.51156778382	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_229
Epoch: 229	max: 0.9979512/1.0	min: 0.002048875	loss: 34613.453125	train_loss: 34602.31911589945	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_230
Epoch: 230	max: 0.9979146/1.0	min: 0.0020853428	loss: 34612.984375	train_loss: 34602.11618976836	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_231
Epoch: 231	max: 0.99818987/1.0	min: 0.0018100938	loss: 34613.66015625	train_loss: 34601.89479544082	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_232
Epoch: 232	max: 0.99798054/1.0	min: 0.0020194876	loss: 34612.59375	train_loss: 34601.719064029014	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_233
Epoch: 233	max: 0.9978728/1.0	min: 0.0021271177	loss: 34612.078125	train_loss: 34601.48842108727	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_234
Epoch: 234	max: 0.9978005/1.0	min: 0.0021994987	loss: 34611.80859375	train_loss: 34601.30307332311	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_235
Epoch: 235	max: 0.9979007/1.0	min: 0.0020993014	loss: 34611.69921875	train_loss: 34601.10804582017	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_236
Epoch: 236	max: 0.99793845/1.0	min: 0.002061461	loss: 34611.515625	train_loss: 34600.90453663059	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_237
Epoch: 237	max: 0.99799037/1.0	min: 0.0020095836	loss: 34611.47265625	train_loss: 34600.72753700607	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_238
Epoch: 238	max: 0.9979792/1.0	min: 0.0020208054	loss: 34611.13671875	train_loss: 34600.50655638393	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_239
Epoch: 239	max: 0.99800926/1.0	min: 0.0019907448	loss: 34611.1015625	train_loss: 34600.341685827756	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_240
Epoch: 240	max: 0.9982065/1.0	min: 0.0017935402	loss: 34611.10546875	train_loss: 34600.20564836105	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_241
Epoch: 241	max: 0.9976205/1.0	min: 0.0023794249	loss: 34610.13671875	train_loss: 34599.958425751734	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_242
Epoch: 242	max: 0.9980866/1.0	min: 0.0019134624	loss: 34610.39453125	train_loss: 34599.8984118551	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_243
Epoch: 243	max: 0.99800426/1.0	min: 0.0019956904	loss: 34609.96484375	train_loss: 34599.57198280534	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_244
Epoch: 244	max: 0.99815303/1.0	min: 0.0018468923	loss: 34610.19140625	train_loss: 34599.394082222374	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_245
Epoch: 245	max: 0.99827194/1.0	min: 0.0017280944	loss: 34610.328125	train_loss: 34599.22386446333	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_246
Epoch: 246	max: 0.99818003/1.0	min: 0.0018199577	loss: 34609.69140625	train_loss: 34599.130503975444	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_247
Epoch: 247	max: 0.9980489/1.0	min: 0.0019511064	loss: 34609.328125	train_loss: 34598.92912524774	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_248
Epoch: 248	max: 0.99809366/1.0	min: 0.0019063615	loss: 34609.0234375	train_loss: 34598.66846519649	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_249
Epoch: 249	max: 0.9981035/1.0	min: 0.0018964706	loss: 34608.89453125	train_loss: 34598.50235207249	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_250
Epoch: 250	max: 0.99829775/1.0	min: 0.0017022962	loss: 34609.30078125	train_loss: 34598.34208163012	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_251
Epoch: 251	max: 0.9979419/1.0	min: 0.0020581048	loss: 34608.265625	train_loss: 34598.17230225365	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_252
Epoch: 252	max: 0.9983931/1.0	min: 0.0016068413	loss: 34609.08984375	train_loss: 34598.05976518952	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_253
Epoch: 253	max: 0.99822885/1.0	min: 0.0017711188	loss: 34608.375	train_loss: 34597.824207137215	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_254
Epoch: 254	max: 0.99841535/1.0	min: 0.001584649	loss: 34608.7265625	train_loss: 34597.78354013765	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_255
Epoch: 255	max: 0.9981654/1.0	min: 0.0018346441	loss: 34607.7890625	train_loss: 34597.503645930105	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_256
Epoch: 256	max: 0.9980844/1.0	min: 0.0019156092	loss: 34607.42578125	train_loss: 34597.36042934396	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_257
Epoch: 257	max: 0.9983352/1.0	min: 0.0016648329	loss: 34607.796875	train_loss: 34597.25739202047	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_258
Epoch: 258	max: 0.9984511/1.0	min: 0.0015488481	loss: 34607.9140625	train_loss: 34597.073623110984	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_259
Epoch: 259	max: 0.9979917/1.0	min: 0.0020082719	loss: 34606.80078125	train_loss: 34596.86071917968	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_260
Epoch: 260	max: 0.9985189/1.0	min: 0.0014811172	loss: 34607.90625	train_loss: 34596.714634236036	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_261
Epoch: 261	max: 0.9980197/1.0	min: 0.0019803357	loss: 34606.48046875	train_loss: 34596.609396773965	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_262
Epoch: 262	max: 0.9983169/1.0	min: 0.0016830859	loss: 34606.81640625	train_loss: 34596.52294105351	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_263
Epoch: 263	max: 0.9983583/1.0	min: 0.0016417298	loss: 34606.53515625	train_loss: 34596.223437693545	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_264
Epoch: 264	max: 0.99815816/1.0	min: 0.0018418413	loss: 34606.09375	train_loss: 34596.07003185774	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_265
Epoch: 265	max: 0.9983707/1.0	min: 0.0016293165	loss: 34606.25	train_loss: 34595.926637208904	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_266
Epoch: 266	max: 0.9984988/1.0	min: 0.0015011829	loss: 34606.57421875	train_loss: 34595.77334943639	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_267
Epoch: 267	max: 0.9982457/1.0	min: 0.001754287	loss: 34605.73828125	train_loss: 34595.68897288802	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_268
Epoch: 268	max: 0.99856865/1.0	min: 0.001431286	loss: 34606.421875	train_loss: 34595.50641848213	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_269
Epoch: 269	max: 0.99838686/1.0	min: 0.0016131218	loss: 34605.4296875	train_loss: 34595.328897250096	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_270
Epoch: 270	max: 0.9986987/1.0	min: 0.0013012368	loss: 34606.5546875	train_loss: 34595.257726371856	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_271
Epoch: 271	max: 0.99842143/1.0	min: 0.0015785625	loss: 34605.46875	train_loss: 34595.1195366693	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_272
Epoch: 272	max: 0.9983967/1.0	min: 0.0016033379	loss: 34605.1328125	train_loss: 34594.87579402406	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_273
Epoch: 273	max: 0.9986633/1.0	min: 0.0013366451	loss: 34605.703125	train_loss: 34594.76254761241	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_274
Epoch: 274	max: 0.9982463/1.0	min: 0.0017536925	loss: 34604.4453125	train_loss: 34594.623081471414	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_275
Epoch: 275	max: 0.9984333/1.0	min: 0.0015667097	loss: 34604.64453125	train_loss: 34594.481156807415	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_276
Epoch: 276	max: 0.9985812/1.0	min: 0.0014188673	loss: 34604.83984375	train_loss: 34594.32565583194	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_277
Epoch: 277	max: 0.99851006/1.0	min: 0.001489972	loss: 34604.4453125	train_loss: 34594.17275563607	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_278
Epoch: 278	max: 0.9983222/1.0	min: 0.0016778319	loss: 34603.9765625	train_loss: 34594.01480533104	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_279
Epoch: 279	max: 0.9984925/1.0	min: 0.0015074571	loss: 34604.06640625	train_loss: 34593.92986169175	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_280
Epoch: 280	max: 0.9985297/1.0	min: 0.001470347	loss: 34604.1328125	train_loss: 34593.80043238263	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_281
Epoch: 281	max: 0.9985582/1.0	min: 0.0014417348	loss: 34604.01171875	train_loss: 34593.66066576087	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_282
Epoch: 282	max: 0.99865025/1.0	min: 0.0013497709	loss: 34604.0859375	train_loss: 34593.45959332032	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_283
Epoch: 283	max: 0.9983833/1.0	min: 0.0016167023	loss: 34603.24609375	train_loss: 34593.362994317475	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_284
Epoch: 284	max: 0.99859494/1.0	min: 0.0014050056	loss: 34603.59375	train_loss: 34593.194868794904	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_285
Epoch: 285	max: 0.9985782/1.0	min: 0.0014218234	loss: 34603.328125	train_loss: 34593.04855304719	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_286
Epoch: 286	max: 0.9984711/1.0	min: 0.001528914	loss: 34602.86328125	train_loss: 34592.91714375852	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_287
Epoch: 287	max: 0.99848086/1.0	min: 0.0015192082	loss: 34602.87890625	train_loss: 34592.797667572464	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_288
Epoch: 288	max: 0.99867153/1.0	min: 0.0013284675	loss: 34603.13671875	train_loss: 34592.66210671374	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_289
Epoch: 289	max: 0.99866676/1.0	min: 0.0013331947	loss: 34602.98828125	train_loss: 34592.55156849994	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_290
Epoch: 290	max: 0.9987123/1.0	min: 0.0012877458	loss: 34603.05078125	train_loss: 34592.40168666001	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_291
Epoch: 291	max: 0.9983546/1.0	min: 0.0016453092	loss: 34602.078125	train_loss: 34592.40086553945	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_292
Epoch: 292	max: 0.9986154/1.0	min: 0.0013845776	loss: 34602.296875	train_loss: 34592.200027773906	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_293
Epoch: 293	max: 0.9987866/1.0	min: 0.0012133757	loss: 34602.80078125	train_loss: 34592.130687360645	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_294
Epoch: 294	max: 0.998638/1.0	min: 0.0013620399	loss: 34602.0234375	train_loss: 34591.88814615462	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_295
Epoch: 295	max: 0.9987392/1.0	min: 0.0012608225	loss: 34602.109375	train_loss: 34591.74769679797	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_296
Epoch: 296	max: 0.9986584/1.0	min: 0.0013415501	loss: 34601.6640625	train_loss: 34591.64720944816	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_297
Epoch: 297	max: 0.9987116/1.0	min: 0.0012884198	loss: 34601.875	train_loss: 34591.52438490958	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_298
Epoch: 298	max: 0.99847907/1.0	min: 0.0015209798	loss: 34601.28125	train_loss: 34591.43956562384	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_299
Epoch: 299	max: 0.9988875/1.0	min: 0.0011124754	loss: 34601.94140625	train_loss: 34591.28784412548	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_300
Epoch: 300	max: 0.998558/1.0	min: 0.0014419935	loss: 34601.12109375	train_loss: 34591.138981791155	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_301
Epoch: 301	max: 0.9988267/1.0	min: 0.0011733097	loss: 34601.5859375	train_loss: 34591.04035006736	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_302
Epoch: 302	max: 0.9988041/1.0	min: 0.0011959404	loss: 34601.36328125	train_loss: 34590.89954797241	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_303
Epoch: 303	max: 0.99874485/1.0	min: 0.001255106	loss: 34600.96875	train_loss: 34590.76901206181	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_304
Epoch: 304	max: 0.9986578/1.0	min: 0.0013422167	loss: 34600.71484375	train_loss: 34590.648672175	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_305
Epoch: 305	max: 0.99880016/1.0	min: 0.0011997934	loss: 34600.7109375	train_loss: 34590.561045498886	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_306
Epoch: 306	max: 0.9986242/1.0	min: 0.0013757809	loss: 34600.3046875	train_loss: 34590.395012696645	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_307
Epoch: 307	max: 0.9985707/1.0	min: 0.0014293412	loss: 34600.16015625	train_loss: 34590.27984824028	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_308
Epoch: 308	max: 0.9987979/1.0	min: 0.0012021278	loss: 34600.44140625	train_loss: 34590.20639593398	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_309
Epoch: 309	max: 0.99874425/1.0	min: 0.0012557063	loss: 34600.0625	train_loss: 34590.055980873745	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_310
Epoch: 310	max: 0.9989421/1.0	min: 0.0010579671	loss: 34600.69921875	train_loss: 34589.93393100458	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_311
Epoch: 311	max: 0.9988642/1.0	min: 0.0011358096	loss: 34600.12890625	train_loss: 34589.86569477347	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_312
Epoch: 312	max: 0.99878234/1.0	min: 0.0012177003	loss: 34599.75390625	train_loss: 34589.71949999226	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_313
Epoch: 313	max: 0.99889624/1.0	min: 0.0011037235	loss: 34599.8515625	train_loss: 34589.557590211974	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_314
Epoch: 314	max: 0.99890244/1.0	min: 0.0010975291	loss: 34600.00390625	train_loss: 34589.468987094326	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_315
Epoch: 315	max: 0.99882966/1.0	min: 0.0011702997	loss: 34599.32421875	train_loss: 34589.39621365199	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_316
Epoch: 316	max: 0.99898404/1.0	min: 0.0010159605	loss: 34599.84375	train_loss: 34589.227009592156	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_317
Epoch: 317	max: 0.9987571/1.0	min: 0.0012428754	loss: 34599.125	train_loss: 34589.122500348385	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_318
Epoch: 318	max: 0.99895537/1.0	min: 0.0010446059	loss: 34599.37109375	train_loss: 34588.9872830345	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_319
Epoch: 319	max: 0.9988876/1.0	min: 0.0011124426	loss: 34599.0703125	train_loss: 34588.879384309585	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_320
Epoch: 320	max: 0.99891365/1.0	min: 0.0010863142	loss: 34599.01171875	train_loss: 34588.75929942013	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_321
Epoch: 321	max: 0.9989353/1.0	min: 0.0010646755	loss: 34598.9296875	train_loss: 34588.64568236715	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_322
Epoch: 322	max: 0.9990583/1.0	min: 0.0009417385	loss: 34599.125	train_loss: 34588.5335720728	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_323
Epoch: 323	max: 0.9987809/1.0	min: 0.0012191231	loss: 34598.30859375	train_loss: 34588.47039853137	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_324
Epoch: 324	max: 0.9989191/1.0	min: 0.0010809469	loss: 34598.453125	train_loss: 34588.35050283352	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_325
Epoch: 325	max: 0.9988539/1.0	min: 0.001146089	loss: 34598.10546875	train_loss: 34588.19409848027	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_326
Epoch: 326	max: 0.99877626/1.0	min: 0.0012237857	loss: 34597.9765625	train_loss: 34588.09509756674	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_327
Epoch: 327	max: 0.99885774/1.0	min: 0.0011423256	loss: 34597.84375	train_loss: 34587.983896940415	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_328
Epoch: 328	max: 0.9988636/1.0	min: 0.0011364666	loss: 34597.921875	train_loss: 34587.92252579973	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_329
Epoch: 329	max: 0.9989114/1.0	min: 0.0010886156	loss: 34597.75390625	train_loss: 34587.74870614239	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_330
Epoch: 330	max: 0.99905366/1.0	min: 0.00094635185	loss: 34597.9921875	train_loss: 34587.63437732256	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_331
Epoch: 331	max: 0.99903584/1.0	min: 0.00096423336	loss: 34597.890625	train_loss: 34587.5475945087	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_332
Epoch: 332	max: 0.9989133/1.0	min: 0.0010867175	loss: 34597.38671875	train_loss: 34587.42035324151	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_333
Epoch: 333	max: 0.9989899/1.0	min: 0.0010101488	loss: 34597.55859375	train_loss: 34587.32254408987	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_334
Epoch: 334	max: 0.9990964/1.0	min: 0.0009035828	loss: 34597.64453125	train_loss: 34587.23357952434	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_335
Epoch: 335	max: 0.99895453/1.0	min: 0.0010454616	loss: 34596.99609375	train_loss: 34587.157438858696	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_336
Epoch: 336	max: 0.99907327/1.0	min: 0.000926726	loss: 34597.1796875	train_loss: 34586.99572697959	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_337
Epoch: 337	max: 0.9990357/1.0	min: 0.0009642885	loss: 34597.0859375	train_loss: 34586.92808832296	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_338
Epoch: 338	max: 0.99903524/1.0	min: 0.0009647645	loss: 34596.91015625	train_loss: 34586.7776239084	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_339
Epoch: 339	max: 0.99897444/1.0	min: 0.0010255738	loss: 34596.640625	train_loss: 34586.665686838074	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_340
Epoch: 340	max: 0.99879813/1.0	min: 0.0012018238	loss: 34596.359375	train_loss: 34586.55990212359	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_341
Epoch: 341	max: 0.999099/1.0	min: 0.0009009483	loss: 34596.78515625	train_loss: 34586.48292872461	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_342
Epoch: 342	max: 0.99914336/1.0	min: 0.0008566398	loss: 34596.49609375	train_loss: 34586.350773314596	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_343
Epoch: 343	max: 0.9989796/1.0	min: 0.0010203884	loss: 34596.0390625	train_loss: 34586.237571902486	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_344
Epoch: 344	max: 0.9990995/1.0	min: 0.00090054056	loss: 34596.328125	train_loss: 34586.16167897622	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_345
Epoch: 345	max: 0.9991302/1.0	min: 0.0008698264	loss: 34596.359375	train_loss: 34586.02153590673	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_346
Epoch: 346	max: 0.99898154/1.0	min: 0.0010183976	loss: 34595.8203125	train_loss: 34585.95367176855	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_347
Epoch: 347	max: 0.99899477/1.0	min: 0.001005279	loss: 34595.75390625	train_loss: 34585.81897315899	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_348
Epoch: 348	max: 0.99898106/1.0	min: 0.0010189548	loss: 34595.5859375	train_loss: 34585.7106331483	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_349
Epoch: 349	max: 0.99916935/1.0	min: 0.0008306852	loss: 34595.94921875	train_loss: 34585.60879871563	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_350
Epoch: 350	max: 0.99908733/1.0	min: 0.0009126371	loss: 34595.625	train_loss: 34585.4958150432	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_351
Epoch: 351	max: 0.99922395/1.0	min: 0.0007760711	loss: 34596.0	train_loss: 34585.40775433931	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_352
Epoch: 352	max: 0.9990983/1.0	min: 0.00090167945	loss: 34595.23828125	train_loss: 34585.379127860615	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_353
Epoch: 353	max: 0.9989549/1.0	min: 0.0010451126	loss: 34595.0390625	train_loss: 34585.1868956514	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_354
Epoch: 354	max: 0.999252/1.0	min: 0.00074791245	loss: 34595.62890625	train_loss: 34585.18031168711	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_355
Epoch: 355	max: 0.9992586/1.0	min: 0.00074135285	loss: 34595.67578125	train_loss: 34585.07320940558	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_356
Epoch: 356	max: 0.99904996/1.0	min: 0.00094999967	loss: 34594.72265625	train_loss: 34584.89062306454	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_357
Epoch: 357	max: 0.9991216/1.0	min: 0.0008783511	loss: 34594.78515625	train_loss: 34584.81043727936	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_358
Epoch: 358	max: 0.9990885/1.0	min: 0.0009114792	loss: 34594.65625	train_loss: 34584.67661301561	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_359
Epoch: 359	max: 0.9991516/1.0	min: 0.00084841496	loss: 34594.9140625	train_loss: 34584.614062693545	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_360
Epoch: 360	max: 0.99903214/1.0	min: 0.00096786156	loss: 34594.265625	train_loss: 34584.485255152205	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_361
Epoch: 361	max: 0.9992649/1.0	min: 0.00073514855	loss: 34594.75	train_loss: 34584.4249180331	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_362
Epoch: 362	max: 0.99876595/1.0	min: 0.0012340612	loss: 34594.1015625	train_loss: 34584.29238762696	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_363
Epoch: 363	max: 0.99915516/1.0	min: 0.0008448001	loss: 34594.375	train_loss: 34584.38682084572	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_364
Epoch: 364	max: 0.99923325/1.0	min: 0.00076676905	loss: 34594.30859375	train_loss: 34584.13829905627	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_365
Epoch: 365	max: 0.9991936/1.0	min: 0.0008063394	loss: 34593.96875	train_loss: 34583.97297414995	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_366
Epoch: 366	max: 0.9991709/1.0	min: 0.00082911464	loss: 34593.82421875	train_loss: 34583.89456318515	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_367
Epoch: 367	max: 0.99917835/1.0	min: 0.0008216124	loss: 34593.828125	train_loss: 34583.77721117072	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_368
Epoch: 368	max: 0.99921834/1.0	min: 0.00078159315	loss: 34593.7265625	train_loss: 34583.68807338118	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_369
Epoch: 369	max: 0.99921227/1.0	min: 0.0007877046	loss: 34593.66015625	train_loss: 34583.577778068095	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_370
Epoch: 370	max: 0.9991341/1.0	min: 0.0008659509	loss: 34593.359375	train_loss: 34583.5133711523	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_371
Epoch: 371	max: 0.9991371/1.0	min: 0.0008629296	loss: 34593.34375	train_loss: 34583.418668904065	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_372
Epoch: 372	max: 0.9992955/1.0	min: 0.0007045362	loss: 34593.53515625	train_loss: 34583.285078831446	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_373
Epoch: 373	max: 0.9992717/1.0	min: 0.00072836474	loss: 34593.453125	train_loss: 34583.19509040552	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_374
Epoch: 374	max: 0.999131/1.0	min: 0.0008690158	loss: 34593.0234375	train_loss: 34583.07585808792	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_375
Epoch: 375	max: 0.9990982/1.0	min: 0.00090181606	loss: 34592.94921875	train_loss: 34582.9900459092	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_376
Epoch: 376	max: 0.99915195/1.0	min: 0.0008481006	loss: 34592.73046875	train_loss: 34582.92558141335	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_377
Epoch: 377	max: 0.99940515/1.0	min: 0.0005948875	loss: 34593.42578125	train_loss: 34582.8129877369	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_378
Epoch: 378	max: 0.9992601/1.0	min: 0.00073982944	loss: 34592.66796875	train_loss: 34582.70848091246	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_379
Epoch: 379	max: 0.9993806/1.0	min: 0.0006193875	loss: 34593.125	train_loss: 34582.59263807599	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_380
Epoch: 380	max: 0.99926513/1.0	min: 0.0007348851	loss: 34592.58203125	train_loss: 34582.50017322402	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_381
Epoch: 381	max: 0.99909246/1.0	min: 0.00090760196	loss: 34592.30859375	train_loss: 34582.3793939869	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_382
Epoch: 382	max: 0.9993057/1.0	min: 0.000694228	loss: 34592.6015625	train_loss: 34582.30417653753	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_383
Epoch: 383	max: 0.99928623/1.0	min: 0.0007137739	loss: 34592.3359375	train_loss: 34582.185033735135	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_384
Epoch: 384	max: 0.9992167/1.0	min: 0.0007833059	loss: 34592.2109375	train_loss: 34582.06942702527	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_385
Epoch: 385	max: 0.99929035/1.0	min: 0.0007095801	loss: 34592.09375	train_loss: 34581.9799810131	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_386
Epoch: 386	max: 0.9992174/1.0	min: 0.00078259193	loss: 34591.8984375	train_loss: 34581.866543958255	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_387
Epoch: 387	max: 0.9994399/1.0	min: 0.00056010165	loss: 34592.48828125	train_loss: 34581.83400832637	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_388
Epoch: 388	max: 0.99931073/1.0	min: 0.0006892147	loss: 34591.8359375	train_loss: 34581.74409489967	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_389
Epoch: 389	max: 0.9992225/1.0	min: 0.00077745307	loss: 34591.55078125	train_loss: 34581.622207125605	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_390
Epoch: 390	max: 0.9992505/1.0	min: 0.00074946065	loss: 34591.5390625	train_loss: 34581.492633624424	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_391
Epoch: 391	max: 0.99941885/1.0	min: 0.00058115146	loss: 34591.83984375	train_loss: 34581.36750830314	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_392
Epoch: 392	max: 0.9992613/1.0	min: 0.0007386139	loss: 34591.33984375	train_loss: 34581.26245712947	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_393
Epoch: 393	max: 0.9992242/1.0	min: 0.0007757768	loss: 34591.21875	train_loss: 34581.17284224808	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_394
Epoch: 394	max: 0.9994129/1.0	min: 0.0005871612	loss: 34591.703125	train_loss: 34581.0675665606	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_395
Epoch: 395	max: 0.9993038/1.0	min: 0.0006961162	loss: 34591.1484375	train_loss: 34580.975675573674	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_396
Epoch: 396	max: 0.9994357/1.0	min: 0.0005642102	loss: 34591.515625	train_loss: 34580.852151848754	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_397
Epoch: 397	max: 0.9993755/1.0	min: 0.00062444585	loss: 34590.99609375	train_loss: 34580.78874072913	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_398
Epoch: 398	max: 0.9993044/1.0	min: 0.00069555984	loss: 34590.74609375	train_loss: 34580.64024516521	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_399
Epoch: 399	max: 0.9991371/1.0	min: 0.0008629078	loss: 34590.703125	train_loss: 34580.632331053355	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_400
Epoch: 400	max: 0.99927086/1.0	min: 0.00072916516	loss: 34590.609375	train_loss: 34580.48242550399	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_401
Epoch: 401	max: 0.99946195/1.0	min: 0.00053809746	loss: 34590.953125	train_loss: 34580.37877028366	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_402
Epoch: 402	max: 0.9994337/1.0	min: 0.0005663111	loss: 34590.640625	train_loss: 34580.256289289915	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_403
Epoch: 403	max: 0.9992654/1.0	min: 0.00073463586	loss: 34590.30859375	train_loss: 34580.15949625681	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_404
Epoch: 404	max: 0.99948525/1.0	min: 0.0005147685	loss: 34590.7109375	train_loss: 34580.072970859655	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_405
Epoch: 405	max: 0.9993523/1.0	min: 0.00064772845	loss: 34590.37109375	train_loss: 34579.968163070575	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_406
Epoch: 406	max: 0.99953496/1.0	min: 0.00046501862	loss: 34590.8203125	train_loss: 34579.945527336495	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_407
Epoch: 407	max: 0.99914956/1.0	min: 0.0008503792	loss: 34590.01953125	train_loss: 34579.82092362273	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_408
Epoch: 408	max: 0.9992962/1.0	min: 0.0007037779	loss: 34589.88671875	train_loss: 34579.74437409033	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_409
Epoch: 409	max: 0.9995407/1.0	min: 0.0004593911	loss: 34590.35546875	train_loss: 34579.71289086693	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_410
Epoch: 410	max: 0.99941206/1.0	min: 0.0005878981	loss: 34589.98046875	train_loss: 34579.49703535318	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_411
Epoch: 411	max: 0.9994172/1.0	min: 0.00058287143	loss: 34589.9140625	train_loss: 34579.40233358881	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_412
Epoch: 412	max: 0.99945/1.0	min: 0.00054996175	loss: 34589.76171875	train_loss: 34579.278614865914	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_413
Epoch: 413	max: 0.99943215/1.0	min: 0.00056783314	loss: 34589.65625	train_loss: 34579.18110135637	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_414
Epoch: 414	max: 0.9994905/1.0	min: 0.0005095328	loss: 34589.73828125	train_loss: 34579.09771044299	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_415
Epoch: 415	max: 0.9992957/1.0	min: 0.00070424686	loss: 34589.18359375	train_loss: 34579.009551514304	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_416
Epoch: 416	max: 0.9995472/1.0	min: 0.00045284675	loss: 34590.0390625	train_loss: 34579.00092515174	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_417
Epoch: 417	max: 0.99938464/1.0	min: 0.00061538856	loss: 34589.2734375	train_loss: 34578.85227233138	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_418
Epoch: 418	max: 0.99942374/1.0	min: 0.0005763228	loss: 34589.17578125	train_loss: 34578.72949424393	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_419
Epoch: 419	max: 0.99945706/1.0	min: 0.0005428905	loss: 34589.078125	train_loss: 34578.65130876069	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_420
Epoch: 420	max: 0.9995448/1.0	min: 0.00045521976	loss: 34589.33984375	train_loss: 34578.55849891227	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_421
Epoch: 421	max: 0.9994861/1.0	min: 0.0005138558	loss: 34588.91796875	train_loss: 34578.466932599404	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_422
Epoch: 422	max: 0.9994659/1.0	min: 0.000534159	loss: 34588.87109375	train_loss: 34578.36854909885	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_423
Epoch: 423	max: 0.99935263/1.0	min: 0.0006473671	loss: 34588.51953125	train_loss: 34578.29348890592	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_424
Epoch: 424	max: 0.999448/1.0	min: 0.0005519973	loss: 34588.625	train_loss: 34578.24141137898	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_425
Epoch: 425	max: 0.99953365/1.0	min: 0.00046636723	loss: 34589.0546875	train_loss: 34578.18660242862	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_426
Epoch: 426	max: 0.9993579/1.0	min: 0.00064211944	loss: 34588.234375	train_loss: 34578.049275942954	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_427
Epoch: 427	max: 0.99939144/1.0	min: 0.00060860557	loss: 34588.37890625	train_loss: 34577.96306989734	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_428
Epoch: 428	max: 0.99938583/1.0	min: 0.0006141241	loss: 34588.31640625	train_loss: 34577.86534493838	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_429
Epoch: 429	max: 0.9995278/1.0	min: 0.00047224318	loss: 34588.53515625	train_loss: 34577.799215943574	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_430
Epoch: 430	max: 0.99928623/1.0	min: 0.0007137759	loss: 34587.9921875	train_loss: 34577.71826661789	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_431
Epoch: 431	max: 0.99953747/1.0	min: 0.00046257913	loss: 34588.30078125	train_loss: 34577.645847849315	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_432
Epoch: 432	max: 0.99951017/1.0	min: 0.0004898053	loss: 34588.0859375	train_loss: 34577.51195874752	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_433
Epoch: 433	max: 0.9993987/1.0	min: 0.0006013131	loss: 34587.73046875	train_loss: 34577.483411622845	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_434
Epoch: 434	max: 0.99948955/1.0	min: 0.0005104554	loss: 34587.87109375	train_loss: 34577.38194396058	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_435
Epoch: 435	max: 0.99941957/1.0	min: 0.0005804147	loss: 34587.65625	train_loss: 34577.268798676916	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_436
Epoch: 436	max: 0.9994836/1.0	min: 0.000516337	loss: 34587.7890625	train_loss: 34577.18031507417	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_437
Epoch: 437	max: 0.99947196/1.0	min: 0.0005280383	loss: 34587.63671875	train_loss: 34577.12673030472	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_438
Epoch: 438	max: 0.99946946/1.0	min: 0.0005305318	loss: 34587.46875	train_loss: 34577.06630512201	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_439
Epoch: 439	max: 0.9994848/1.0	min: 0.00051514537	loss: 34587.4140625	train_loss: 34576.95566384476	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_440
Epoch: 440	max: 0.99956375/1.0	min: 0.00043623225	loss: 34587.61328125	train_loss: 34576.894392864335	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_441
Epoch: 441	max: 0.9994586/1.0	min: 0.0005414457	loss: 34587.140625	train_loss: 34576.81952525006	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_442
Epoch: 442	max: 0.99951494/1.0	min: 0.00048503882	loss: 34587.3984375	train_loss: 34576.71576309535	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_443
Epoch: 443	max: 0.9994711/1.0	min: 0.00052887195	loss: 34587.12890625	train_loss: 34576.61820119921	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_444
Epoch: 444	max: 0.9994721/1.0	min: 0.0005279661	loss: 34587.1640625	train_loss: 34576.53236192401	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_445
Epoch: 445	max: 0.99955505/1.0	min: 0.00044487134	loss: 34587.38671875	train_loss: 34576.4627079656	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_446
Epoch: 446	max: 0.99942577/1.0	min: 0.0005742068	loss: 34586.81640625	train_loss: 34576.41089511334	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_447
Epoch: 447	max: 0.9995353/1.0	min: 0.00046474303	loss: 34586.859375	train_loss: 34576.311057595536	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_448
Epoch: 448	max: 0.99948525/1.0	min: 0.00051471445	loss: 34586.80859375	train_loss: 34576.22411317044	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_449
Epoch: 449	max: 0.99949455/1.0	min: 0.00050547416	loss: 34586.6953125	train_loss: 34576.15667870525	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_450
Epoch: 450	max: 0.9994721/1.0	min: 0.00052788685	loss: 34586.515625	train_loss: 34576.123608885326	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_451
Epoch: 451	max: 0.99954/1.0	min: 0.00046007143	loss: 34586.46875	train_loss: 34576.01767320466	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_452
Epoch: 452	max: 0.99956936/1.0	min: 0.00043058617	loss: 34586.67578125	train_loss: 34575.924161266725	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_453
Epoch: 453	max: 0.9994679/1.0	min: 0.00053212023	loss: 34586.296875	train_loss: 34575.86958021724	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_454
Epoch: 454	max: 0.99949/1.0	min: 0.00050996867	loss: 34586.3046875	train_loss: 34575.75883103787	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_455
Epoch: 455	max: 0.9995408/1.0	min: 0.000459281	loss: 34586.46484375	train_loss: 34575.69664603462	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_456
Epoch: 456	max: 0.9995091/1.0	min: 0.00049085595	loss: 34586.21875	train_loss: 34575.71736372399	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_457
Epoch: 457	max: 0.999605/1.0	min: 0.00039503723	loss: 34586.35546875	train_loss: 34575.56361289174	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_458
Epoch: 458	max: 0.9995597/1.0	min: 0.00044033315	loss: 34586.03125	train_loss: 34575.56808913586	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_459
Epoch: 459	max: 0.9995048/1.0	min: 0.0004951676	loss: 34585.78125	train_loss: 34575.39375029032	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_460
Epoch: 460	max: 0.99955016/1.0	min: 0.00044986486	loss: 34585.76953125	train_loss: 34575.33482460826	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_461
Epoch: 461	max: 0.9995683/1.0	min: 0.0004316512	loss: 34585.8515625	train_loss: 34575.25201385018	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_462
Epoch: 462	max: 0.9996001/1.0	min: 0.00039994752	loss: 34586.10546875	train_loss: 34575.194283317076	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_463
Epoch: 463	max: 0.99949753/1.0	min: 0.00050248613	loss: 34585.67578125	train_loss: 34575.12220422241	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_464
Epoch: 464	max: 0.9995291/1.0	min: 0.00047089823	loss: 34585.703125	train_loss: 34575.069099448	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_465
Epoch: 465	max: 0.99955076/1.0	min: 0.00044919745	loss: 34585.59765625	train_loss: 34574.95429208472	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_466
Epoch: 466	max: 0.9994881/1.0	min: 0.0005118462	loss: 34585.375	train_loss: 34574.91879616081	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_467
Epoch: 467	max: 0.99962723/1.0	min: 0.00037270586	loss: 34585.71484375	train_loss: 34574.81765946287	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_468
Epoch: 468	max: 0.99949956/1.0	min: 0.0005004422	loss: 34585.23046875	train_loss: 34574.75247981311	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_469
Epoch: 469	max: 0.9996113/1.0	min: 0.00038875447	loss: 34585.33984375	train_loss: 34574.67105533104	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_470
Epoch: 470	max: 0.99953866/1.0	min: 0.0004613835	loss: 34585.1015625	train_loss: 34574.61449623746	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_471
Epoch: 471	max: 0.9995302/1.0	min: 0.000469867	loss: 34585.31640625	train_loss: 34574.53854524728	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_472
Epoch: 472	max: 0.99947995/1.0	min: 0.0005200692	loss: 34585.01953125	train_loss: 34574.463714890684	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_473
Epoch: 473	max: 0.999597/1.0	min: 0.00040296972	loss: 34585.07421875	train_loss: 34574.450985344665	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_474
Epoch: 474	max: 0.9995059/1.0	min: 0.00049407454	loss: 34584.734375	train_loss: 34574.31656399031	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_475
Epoch: 475	max: 0.9995964/1.0	min: 0.00040356404	loss: 34585.0078125	train_loss: 34574.24928823316	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_476
Epoch: 476	max: 0.9995609/1.0	min: 0.0004390853	loss: 34584.8046875	train_loss: 34574.17797606605	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_477
Epoch: 477	max: 0.99948967/1.0	min: 0.000510345	loss: 34584.609375	train_loss: 34574.11890038555	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_478
Epoch: 478	max: 0.999671/1.0	min: 0.0003290736	loss: 34585.125	train_loss: 34574.07467745494	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_479
Epoch: 479	max: 0.99956435/1.0	min: 0.00043565297	loss: 34584.50390625	train_loss: 34573.977430555555	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_480
Epoch: 480	max: 0.99963963/1.0	min: 0.00036037146	loss: 34584.625	train_loss: 34573.92349643487	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_481
Epoch: 481	max: 0.9995639/1.0	min: 0.00043613586	loss: 34584.39453125	train_loss: 34573.849065267714	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_482
Epoch: 482	max: 0.99959654/1.0	min: 0.00040345138	loss: 34584.48046875	train_loss: 34573.75130934132	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_483
Epoch: 483	max: 0.99964356/1.0	min: 0.0003564629	loss: 34584.50390625	train_loss: 34573.72317011566	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_484
Epoch: 484	max: 0.99959475/1.0	min: 0.0004052596	loss: 34584.40625	train_loss: 34573.634941026416	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_485
Epoch: 485	max: 0.9995449/1.0	min: 0.00045501345	loss: 34584.06640625	train_loss: 34573.566237864645	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_486
Epoch: 486	max: 0.99960274/1.0	min: 0.00039727162	loss: 34584.23828125	train_loss: 34573.49456521739	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_487
Epoch: 487	max: 0.99958843/1.0	min: 0.00041155293	loss: 34584.0078125	train_loss: 34573.431943767035	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_488
Epoch: 488	max: 0.9995565/1.0	min: 0.0004435568	loss: 34583.98046875	train_loss: 34573.34709206228	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_489
Epoch: 489	max: 0.99966216/1.0	min: 0.0003378654	loss: 34584.11328125	train_loss: 34573.29988513022	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_490
Epoch: 490	max: 0.9996582/1.0	min: 0.00034173133	loss: 34584.11328125	train_loss: 34573.28174983355	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_491
Epoch: 491	max: 0.99961287/1.0	min: 0.00038712387	loss: 34583.79296875	train_loss: 34573.223919624055	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_492
Epoch: 492	max: 0.9995741/1.0	min: 0.00042589413	loss: 34583.70703125	train_loss: 34573.08668458906	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_493
Epoch: 493	max: 0.99957794/1.0	min: 0.0004221178	loss: 34583.6640625	train_loss: 34573.01697014741	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_494
Epoch: 494	max: 0.9994973/1.0	min: 0.0005027362	loss: 34583.46484375	train_loss: 34572.95428579447	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_495
Epoch: 495	max: 0.99959236/1.0	min: 0.00040764286	loss: 34583.546875	train_loss: 34572.892516915956	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_496
Epoch: 496	max: 0.99957997/1.0	min: 0.0004200501	loss: 34583.43359375	train_loss: 34572.82074459231	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_497
Epoch: 497	max: 0.99960154/1.0	min: 0.00039851898	loss: 34583.50390625	train_loss: 34572.74806260064	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_498
Epoch: 498	max: 0.999587/1.0	min: 0.00041300946	loss: 34583.35546875	train_loss: 34572.69025464899	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_499
Epoch: 499	max: 0.999688/1.0	min: 0.00031202598	loss: 34583.92578125	train_loss: 34572.653028420355	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_500
Epoch: 500	max: 0.99964/1.0	min: 0.00036003804	loss: 34583.17578125	train_loss: 34572.60037944769	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_501
Epoch: 501	max: 0.9995876/1.0	min: 0.0004124319	loss: 34583.08984375	train_loss: 34572.50394737861	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_502
Epoch: 502	max: 0.9996393/1.0	min: 0.00036072137	loss: 34583.0390625	train_loss: 34572.46425391738	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_503
Epoch: 503	max: 0.9995103/1.0	min: 0.00048976287	loss: 34582.87890625	train_loss: 34572.42616882664	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_504
Epoch: 504	max: 0.9996008/1.0	min: 0.00039915828	loss: 34583.015625	train_loss: 34572.38284395129	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_505
Epoch: 505	max: 0.9995382/1.0	min: 0.00046184793	loss: 34582.7890625	train_loss: 34572.339051177536	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_506
Epoch: 506	max: 0.99959666/1.0	min: 0.0004033137	loss: 34582.88671875	train_loss: 34572.21117846525	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_507
Epoch: 507	max: 0.99953294/1.0	min: 0.00046710402	loss: 34582.6875	train_loss: 34572.14244385219	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_508
Epoch: 508	max: 0.99971956/1.0	min: 0.0002804542	loss: 34583.265625	train_loss: 34572.11333786232	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_509
Epoch: 509	max: 0.9996401/1.0	min: 0.00035994078	loss: 34582.74609375	train_loss: 34572.02014043726	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_510
Epoch: 510	max: 0.99959046/1.0	min: 0.0004095374	loss: 34582.62109375	train_loss: 34571.94386574074	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_511
Epoch: 511	max: 0.99957687/1.0	min: 0.0004231161	loss: 34582.578125	train_loss: 34571.902200041804	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_512
Epoch: 512	max: 0.9996246/1.0	min: 0.00037541997	loss: 34582.67578125	train_loss: 34571.817801719466	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_513
Epoch: 513	max: 0.99960667/1.0	min: 0.00039334115	loss: 34582.3828125	train_loss: 34571.774775389415	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_514
Epoch: 514	max: 0.9996057/1.0	min: 0.00039426354	loss: 34582.38671875	train_loss: 34571.70351789917	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_515
Epoch: 515	max: 0.999689/1.0	min: 0.000311093	loss: 34582.5390625	train_loss: 34571.627019656575	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_516
Epoch: 516	max: 0.9996648/1.0	min: 0.00033521332	loss: 34582.24609375	train_loss: 34571.57248989688	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_517
Epoch: 517	max: 0.9996506/1.0	min: 0.00034935563	loss: 34582.13671875	train_loss: 34571.49961532655	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_518
Epoch: 518	max: 0.9997209/1.0	min: 0.00027910553	loss: 34582.75390625	train_loss: 34571.457452697265	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_519
Epoch: 519	max: 0.9994716/1.0	min: 0.0005284212	loss: 34582.03515625	train_loss: 34571.52514119209	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_520
Epoch: 520	max: 0.999627/1.0	min: 0.00037297103	loss: 34582.1015625	train_loss: 34571.35490359455	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_521
Epoch: 521	max: 0.9996321/1.0	min: 0.00036787053	loss: 34582.14453125	train_loss: 34571.27461281045	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_522
Epoch: 522	max: 0.9996301/1.0	min: 0.00036985095	loss: 34581.98046875	train_loss: 34571.23510273443	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_523
Epoch: 523	max: 0.99963796/1.0	min: 0.0003619987	loss: 34581.85546875	train_loss: 34571.14607429859	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_524
Epoch: 524	max: 0.9996877/1.0	min: 0.0003123239	loss: 34582.078125	train_loss: 34571.0888000511	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_525
Epoch: 525	max: 0.9996376/1.0	min: 0.0003623884	loss: 34581.7734375	train_loss: 34571.06514190821	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_526
Epoch: 526	max: 0.9996239/1.0	min: 0.00037605647	loss: 34581.7890625	train_loss: 34571.01976882819	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_527
Epoch: 527	max: 0.9997087/1.0	min: 0.0002912684	loss: 34581.82421875	train_loss: 34570.93493115555	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_528
Epoch: 528	max: 0.99959165/1.0	min: 0.00040841146	loss: 34581.625	train_loss: 34570.86870683915	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_529
Epoch: 529	max: 0.99964845/1.0	min: 0.0003516005	loss: 34581.546875	train_loss: 34570.81432175539	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_530
Epoch: 530	max: 0.99963284/1.0	min: 0.00036711027	loss: 34581.46484375	train_loss: 34570.742169113095	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_531
Epoch: 531	max: 0.99965954/1.0	min: 0.00034051243	loss: 34581.53515625	train_loss: 34570.675434318095	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_532
Epoch: 532	max: 0.9996277/1.0	min: 0.0003723112	loss: 34581.35546875	train_loss: 34570.61646702357	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_533
Epoch: 533	max: 0.9996233/1.0	min: 0.00037664198	loss: 34581.37890625	train_loss: 34570.56888074059	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_534
Epoch: 534	max: 0.9996635/1.0	min: 0.0003365024	loss: 34581.328125	train_loss: 34570.522381704446	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_535
Epoch: 535	max: 0.99956733/1.0	min: 0.00043265062	loss: 34581.19140625	train_loss: 34570.44580894649	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_536
Epoch: 536	max: 0.9995552/1.0	min: 0.0004447972	loss: 34581.1953125	train_loss: 34570.40855900842	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_537
Epoch: 537	max: 0.99964726/1.0	min: 0.00035279075	loss: 34581.31640625	train_loss: 34570.33767457884	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_538
Epoch: 538	max: 0.9996295/1.0	min: 0.0003704413	loss: 34581.22265625	train_loss: 34570.306345224824	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_539
Epoch: 539	max: 0.99953616/1.0	min: 0.00046388814	loss: 34581.046875	train_loss: 34570.28886605042	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_540
Epoch: 540	max: 0.99971026/1.0	min: 0.00028977272	loss: 34581.37109375	train_loss: 34570.22335785566	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_541
Epoch: 541	max: 0.9996221/1.0	min: 0.00037784496	loss: 34581.00390625	train_loss: 34570.11986327883	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_542
Epoch: 542	max: 0.99971503/1.0	min: 0.0002849607	loss: 34581.11328125	train_loss: 34570.11142659173	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_543
Epoch: 543	max: 0.9996799/1.0	min: 0.00032004275	loss: 34580.9453125	train_loss: 34570.02188283863	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_544
Epoch: 544	max: 0.9996995/1.0	min: 0.00030054583	loss: 34581.01171875	train_loss: 34569.94229366019	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_545
Epoch: 545	max: 0.9996512/1.0	min: 0.00034876613	loss: 34580.75390625	train_loss: 34569.90477178945	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_546
Epoch: 546	max: 0.9996076/1.0	min: 0.00039236032	loss: 34580.6015625	train_loss: 34569.81939605785	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_547
Epoch: 547	max: 0.9996394/1.0	min: 0.00036060723	loss: 34580.66015625	train_loss: 34569.78014049532	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_548
Epoch: 548	max: 0.9996519/1.0	min: 0.0003481013	loss: 34580.59375	train_loss: 34569.73178341385	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_549
Epoch: 549	max: 0.9997135/1.0	min: 0.00028644686	loss: 34580.765625	train_loss: 34569.67193161232	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_550
Epoch: 550	max: 0.9995633/1.0	min: 0.00043668243	loss: 34580.453125	train_loss: 34569.61865022684	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_551
Epoch: 551	max: 0.99976474/1.0	min: 0.00023522148	loss: 34581.0703125	train_loss: 34569.60449763099	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_552
Epoch: 552	max: 0.999532/1.0	min: 0.00046801768	loss: 34580.34375	train_loss: 34569.54175811734	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_553
Epoch: 553	max: 0.999696/1.0	min: 0.0003040371	loss: 34580.57421875	train_loss: 34569.50052402685	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_554
Epoch: 554	max: 0.9995315/1.0	min: 0.00046845595	loss: 34580.28125	train_loss: 34569.39765218553	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_555
Epoch: 555	max: 0.9997423/1.0	min: 0.00025763255	loss: 34580.72265625	train_loss: 34569.38680536201	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_556
Epoch: 556	max: 0.99965787/1.0	min: 0.00034215752	loss: 34580.328125	train_loss: 34569.28517270144	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_557
Epoch: 557	max: 0.999691/1.0	min: 0.0003089607	loss: 34580.265625	train_loss: 34569.22973569305	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_558
Epoch: 558	max: 0.9997081/1.0	min: 0.0002918744	loss: 34580.10546875	train_loss: 34569.16606957606	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_559
Epoch: 559	max: 0.9997042/1.0	min: 0.0002958488	loss: 34580.1015625	train_loss: 34569.138807599404	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_560
Epoch: 560	max: 0.9996594/1.0	min: 0.0003406275	loss: 34579.890625	train_loss: 34569.06538190573	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_561
Epoch: 561	max: 0.99970955/1.0	min: 0.00029037418	loss: 34580.0	train_loss: 34569.01979205376	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_562
Epoch: 562	max: 0.9997054/1.0	min: 0.00029455527	loss: 34580.05859375	train_loss: 34568.96017637882	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_563
Epoch: 563	max: 0.999678/1.0	min: 0.00032202544	loss: 34580.015625	train_loss: 34568.89695057987	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_564
Epoch: 564	max: 0.9996922/1.0	min: 0.00030777472	loss: 34579.9765625	train_loss: 34568.84838059736	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_565
Epoch: 565	max: 0.9996985/1.0	min: 0.0003015366	loss: 34579.90625	train_loss: 34568.800697541184	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_566
Epoch: 566	max: 0.99973756/1.0	min: 0.0002624059	loss: 34580.17578125	train_loss: 34568.75268206909	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_567
Epoch: 567	max: 0.9995951/1.0	min: 0.00040490855	loss: 34579.69921875	train_loss: 34568.71085233959	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_568
Epoch: 568	max: 0.99965644/1.0	min: 0.0003435803	loss: 34579.73828125	train_loss: 34568.70204114022	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_569
Epoch: 569	max: 0.99975485/1.0	min: 0.0002451422	loss: 34580.1484375	train_loss: 34568.59041084092	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_570
Epoch: 570	max: 0.9994771/1.0	min: 0.0005229194	loss: 34579.59765625	train_loss: 34568.58051723337	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_571
Epoch: 571	max: 0.99964356/1.0	min: 0.00035647838	loss: 34579.5390625	train_loss: 34568.49899501038	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_572
Epoch: 572	max: 0.99971527/1.0	min: 0.00028472446	loss: 34579.86328125	train_loss: 34568.42614511721	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_573
Epoch: 573	max: 0.9996489/1.0	min: 0.00035111545	loss: 34579.5390625	train_loss: 34568.41140559194	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_574
Epoch: 574	max: 0.9997484/1.0	min: 0.00025163818	loss: 34579.81640625	train_loss: 34568.33163835083	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_575
Epoch: 575	max: 0.9996488/1.0	min: 0.00035122022	loss: 34579.2578125	train_loss: 34568.2657159668	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_576
Epoch: 576	max: 0.99974483/1.0	min: 0.0002551465	loss: 34579.40625	train_loss: 34568.22931279419	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_577
Epoch: 577	max: 0.9997638/1.0	min: 0.00023623332	loss: 34579.50390625	train_loss: 34568.18667210532	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_578
Epoch: 578	max: 0.9996797/1.0	min: 0.00032032238	loss: 34579.12109375	train_loss: 34568.116457346245	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_579
Epoch: 579	max: 0.99970144/1.0	min: 0.00029854593	loss: 34579.09375	train_loss: 34568.09681674254	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_580
Epoch: 580	max: 0.9997323/1.0	min: 0.0002677091	loss: 34579.2265625	train_loss: 34567.99688196767	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_581
Epoch: 581	max: 0.9996488/1.0	min: 0.00035118609	loss: 34579.01171875	train_loss: 34567.964203595315	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_582
Epoch: 582	max: 0.99972147/1.0	min: 0.00027854144	loss: 34579.359375	train_loss: 34567.94996293587	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_583
Epoch: 583	max: 0.99967825/1.0	min: 0.0003217793	loss: 34579.12109375	train_loss: 34567.861302722034	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_584
Epoch: 584	max: 0.99975413/1.0	min: 0.00024590886	loss: 34579.13671875	train_loss: 34567.82054911046	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_585
Epoch: 585	max: 0.99967146/1.0	min: 0.00032859898	loss: 34578.87890625	train_loss: 34567.81422788539	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_586
Epoch: 586	max: 0.9997905/1.0	min: 0.00020947443	loss: 34579.2890625	train_loss: 34567.703897250096	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_587
Epoch: 587	max: 0.999739/1.0	min: 0.0002610489	loss: 34578.92578125	train_loss: 34567.645884623125	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_588
Epoch: 588	max: 0.99971503/1.0	min: 0.00028492976	loss: 34578.76171875	train_loss: 34567.588451667594	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_589
Epoch: 589	max: 0.99973124/1.0	min: 0.00026869922	loss: 34578.8828125	train_loss: 34567.52589118435	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_590
Epoch: 590	max: 0.99966836/1.0	min: 0.00033163442	loss: 34578.76953125	train_loss: 34567.48789367336	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_591
Epoch: 591	max: 0.99969995/1.0	min: 0.0003001095	loss: 34578.8515625	train_loss: 34567.46350392512	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_592
Epoch: 592	max: 0.99970883/1.0	min: 0.00029109238	loss: 34578.7890625	train_loss: 34567.37406130001	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_593
Epoch: 593	max: 0.9996648/1.0	min: 0.0003352229	loss: 34578.6484375	train_loss: 34567.320932816176	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_594
Epoch: 594	max: 0.99970573/1.0	min: 0.00029419884	loss: 34578.68359375	train_loss: 34567.265657902884	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_595
Epoch: 595	max: 0.99974173/1.0	min: 0.0002582949	loss: 34578.87109375	train_loss: 34567.21464149402	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_596
Epoch: 596	max: 0.9996877/1.0	min: 0.0003123623	loss: 34578.609375	train_loss: 34567.21978208612	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_597
Epoch: 597	max: 0.9997559/1.0	min: 0.00024405589	loss: 34578.6875	train_loss: 34567.11725330577	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_598
Epoch: 598	max: 0.9997607/1.0	min: 0.00023928384	loss: 34578.84375	train_loss: 34567.06573174083	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_599
Epoch: 599	max: 0.99975854/1.0	min: 0.00024143275	loss: 34578.671875	train_loss: 34567.005884777966	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_600
Epoch: 600	max: 0.999647/1.0	min: 0.00035296468	loss: 34578.453125	train_loss: 34566.96744065868	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_601
Epoch: 601	max: 0.99972457/1.0	min: 0.00027542247	loss: 34578.4296875	train_loss: 34566.91609038229	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_602
Epoch: 602	max: 0.999765/1.0	min: 0.00023505536	loss: 34578.51953125	train_loss: 34566.86723927366	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_603
Epoch: 603	max: 0.99970657/1.0	min: 0.00029343524	loss: 34578.19140625	train_loss: 34566.81829913369	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_604
Epoch: 604	max: 0.999736/1.0	min: 0.0002639334	loss: 34578.28125	train_loss: 34566.74131896058	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_605
Epoch: 605	max: 0.9997434/1.0	min: 0.00025655082	loss: 34578.5	train_loss: 34566.67741816858	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_606
Epoch: 606	max: 0.9997081/1.0	min: 0.00029184268	loss: 34578.26171875	train_loss: 34566.65275261675	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_607
Epoch: 607	max: 0.9996618/1.0	min: 0.00033818826	loss: 34578.125	train_loss: 34566.582581889474	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_608
Epoch: 608	max: 0.9997205/1.0	min: 0.0002794426	loss: 34578.11328125	train_loss: 34566.54864207853	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_609
Epoch: 609	max: 0.9997305/1.0	min: 0.00026950432	loss: 34578.12109375	train_loss: 34566.48413597021	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_610
Epoch: 610	max: 0.9997693/1.0	min: 0.0002306958	loss: 34578.328125	train_loss: 34566.41005899294	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_611
Epoch: 611	max: 0.9997546/1.0	min: 0.00024539567	loss: 34578.1640625	train_loss: 34566.3348410597	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_612
Epoch: 612	max: 0.9997602/1.0	min: 0.00023979887	loss: 34577.92578125	train_loss: 34566.27997840022	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_613
Epoch: 613	max: 0.9997751/1.0	min: 0.00022486443	loss: 34577.99609375	train_loss: 34566.23695303791	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_614
Epoch: 614	max: 0.99969816/1.0	min: 0.00030188466	loss: 34577.734375	train_loss: 34566.16346734485	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_615
Epoch: 615	max: 0.9997435/1.0	min: 0.0002564381	loss: 34577.79296875	train_loss: 34566.10141588861	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_616
Epoch: 616	max: 0.9997062/1.0	min: 0.00029379776	loss: 34577.56640625	train_loss: 34566.04908288043	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_617
Epoch: 617	max: 0.99976796/1.0	min: 0.00023209766	loss: 34577.86328125	train_loss: 34565.977523941685	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_618
Epoch: 618	max: 0.99967885/1.0	min: 0.00032119453	loss: 34577.328125	train_loss: 34565.938379184474	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_619
Epoch: 619	max: 0.99983776/1.0	min: 0.0001621727	loss: 34577.83984375	train_loss: 34565.87066698021	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_620
Epoch: 620	max: 0.99972504/1.0	min: 0.00027493213	loss: 34577.38671875	train_loss: 34565.84509563127	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_621
Epoch: 621	max: 0.99977654/1.0	min: 0.00022343254	loss: 34577.65625	train_loss: 34565.75510817308	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_622
Epoch: 622	max: 0.99971217/1.0	min: 0.00028784308	loss: 34577.3359375	train_loss: 34565.703705155305	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_623
Epoch: 623	max: 0.99975866/1.0	min: 0.00024138442	loss: 34577.3125	train_loss: 34565.66646779775	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_624
Epoch: 624	max: 0.9998148/1.0	min: 0.00018516851	loss: 34577.53515625	train_loss: 34565.5816102866	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_625
Epoch: 625	max: 0.99972945/1.0	min: 0.00027058207	loss: 34577.15625	train_loss: 34565.5730569878	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_626
Epoch: 626	max: 0.99984205/1.0	min: 0.00015796527	loss: 34577.8203125	train_loss: 34565.52383717329	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_627
Epoch: 627	max: 0.9997186/1.0	min: 0.0002814182	loss: 34577.2265625	train_loss: 34565.49591617119	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_628
Epoch: 628	max: 0.9997135/1.0	min: 0.00028647415	loss: 34577.109375	train_loss: 34565.35960628794	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_629
Epoch: 629	max: 0.9996443/1.0	min: 0.00035567384	loss: 34576.921875	train_loss: 34565.303310901305	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_630
Epoch: 630	max: 0.99971384/1.0	min: 0.00028614388	loss: 34576.921875	train_loss: 34565.28241902019	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_631
Epoch: 631	max: 0.9998604/1.0	min: 0.00013957285	loss: 34577.5390625	train_loss: 34565.22847522219	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_632
Epoch: 632	max: 0.99971944/1.0	min: 0.00028052105	loss: 34576.80078125	train_loss: 34565.16777278428	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_633
Epoch: 633	max: 0.99973744/1.0	min: 0.00026259013	loss: 34576.76953125	train_loss: 34565.12407920305	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_634
Epoch: 634	max: 0.99970895/1.0	min: 0.00029098193	loss: 34576.69921875	train_loss: 34565.08712781029	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_635
Epoch: 635	max: 0.9998275/1.0	min: 0.00017251463	loss: 34576.90234375	train_loss: 34565.01804723306	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_636
Epoch: 636	max: 0.99973387/1.0	min: 0.00026616023	loss: 34576.6796875	train_loss: 34564.94269139803	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_637
Epoch: 637	max: 0.99978954/1.0	min: 0.000210506	loss: 34576.90625	train_loss: 34564.90031538384	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_638
Epoch: 638	max: 0.99974805/1.0	min: 0.00025199566	loss: 34576.91796875	train_loss: 34564.836226851854	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_639
Epoch: 639	max: 0.9997279/1.0	min: 0.00027211517	loss: 34576.703125	train_loss: 34564.8124787099	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_640
Epoch: 640	max: 0.9997168/1.0	min: 0.0002831808	loss: 34576.5546875	train_loss: 34564.74824114719	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_641
Epoch: 641	max: 0.99981004/1.0	min: 0.00018992936	loss: 34576.87890625	train_loss: 34564.695481853094	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_642
Epoch: 642	max: 0.99982446/1.0	min: 0.00017560655	loss: 34576.87890625	train_loss: 34564.65237907221	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_643
Epoch: 643	max: 0.9997185/1.0	min: 0.00028150217	loss: 34576.56640625	train_loss: 34564.600790249904	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_644
Epoch: 644	max: 0.9997687/1.0	min: 0.00023132729	loss: 34576.71484375	train_loss: 34564.5464071016	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_645
Epoch: 645	max: 0.99976116/1.0	min: 0.00023888699	loss: 34576.6953125	train_loss: 34564.51050521414	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_646
Epoch: 646	max: 0.9997286/1.0	min: 0.00027135425	loss: 34576.34375	train_loss: 34564.451557274246	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_647
Epoch: 647	max: 0.9997774/1.0	min: 0.00022266716	loss: 34576.2890625	train_loss: 34564.40480082141	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_648
Epoch: 648	max: 0.9997794/1.0	min: 0.00022060236	loss: 34576.33984375	train_loss: 34564.355446976035	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_649
Epoch: 649	max: 0.9997334/1.0	min: 0.00026656504	loss: 34576.25	train_loss: 34564.32211102982	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_650
Epoch: 650	max: 0.9996979/1.0	min: 0.00030207552	loss: 34576.09375	train_loss: 34564.266094349994	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_651
Epoch: 651	max: 0.9998616/1.0	min: 0.00013835549	loss: 34576.44921875	train_loss: 34564.23598240276	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_652
Epoch: 652	max: 0.99977785/1.0	min: 0.00022216499	loss: 34576.0703125	train_loss: 34564.18093587421	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_653
Epoch: 653	max: 0.99979645/1.0	min: 0.00020361385	loss: 34576.25390625	train_loss: 34564.16009479902	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_654
Epoch: 654	max: 0.99979097/1.0	min: 0.00020903668	loss: 34576.0390625	train_loss: 34564.07173942075	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_655
Epoch: 655	max: 0.9998683/1.0	min: 0.00013169594	loss: 34576.67578125	train_loss: 34564.0625014516	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_656
Epoch: 656	max: 0.9997565/1.0	min: 0.00024353918	loss: 34576.046875	train_loss: 34564.01532306763	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_657
Epoch: 657	max: 0.99978393/1.0	min: 0.00021611027	loss: 34576.25390625	train_loss: 34563.941334637835	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_658
Epoch: 658	max: 0.99973375/1.0	min: 0.0002662836	loss: 34575.89453125	train_loss: 34563.89282900951	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_659
Epoch: 659	max: 0.9998554/1.0	min: 0.0001445227	loss: 34576.2734375	train_loss: 34563.87671482101	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_660
Epoch: 660	max: 0.9997451/1.0	min: 0.00025498116	loss: 34575.76171875	train_loss: 34563.881247193574	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_661
Epoch: 661	max: 0.999845/1.0	min: 0.000154967	loss: 34576.171875	train_loss: 34563.77721262232	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_662
Epoch: 662	max: 0.9998349/1.0	min: 0.00016506496	loss: 34575.953125	train_loss: 34563.72134690868	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_663
Epoch: 663	max: 0.9997919/1.0	min: 0.00020804447	loss: 34575.8515625	train_loss: 34563.66926889787	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_664
Epoch: 664	max: 0.99980706/1.0	min: 0.00019292267	loss: 34575.98046875	train_loss: 34563.634764415336	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_665
Epoch: 665	max: 0.99981767/1.0	min: 0.00018239321	loss: 34575.74609375	train_loss: 34563.5870794237	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_666
Epoch: 666	max: 0.9998104/1.0	min: 0.00018967455	loss: 34575.89453125	train_loss: 34563.55601474436	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_667
Epoch: 667	max: 0.9998399/1.0	min: 0.00016010554	loss: 34575.66015625	train_loss: 34563.48124051623	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_668
Epoch: 668	max: 0.99984574/1.0	min: 0.00015423184	loss: 34575.88671875	train_loss: 34563.47403671962	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_669
Epoch: 669	max: 0.9998093/1.0	min: 0.00019064457	loss: 34575.671875	train_loss: 34563.40564371594	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_670
Epoch: 670	max: 0.9997527/1.0	min: 0.00024735596	loss: 34575.61328125	train_loss: 34563.388499860645	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_671
Epoch: 671	max: 0.99977094/1.0	min: 0.00022908236	loss: 34575.55859375	train_loss: 34563.34443515422	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_672
Epoch: 672	max: 0.9997615/1.0	min: 0.00023849032	loss: 34575.5234375	train_loss: 34563.29264407593	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_673
Epoch: 673	max: 0.9998827/1.0	min: 0.00011732028	loss: 34575.87890625	train_loss: 34563.26959995897	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_674
Epoch: 674	max: 0.99984527/1.0	min: 0.00015472737	loss: 34575.44921875	train_loss: 34563.21153797767	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_675
Epoch: 675	max: 0.99982834/1.0	min: 0.00017166401	loss: 34575.34765625	train_loss: 34563.1307207474	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_676
Epoch: 676	max: 0.9997737/1.0	min: 0.00022631866	loss: 34575.328125	train_loss: 34563.09951865013	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_677
Epoch: 677	max: 0.9998863/1.0	min: 0.000113705486	loss: 34575.60546875	train_loss: 34563.067354143444	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_678
Epoch: 678	max: 0.9998165/1.0	min: 0.00018349773	loss: 34575.1328125	train_loss: 34563.085311861294	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_679
Epoch: 679	max: 0.9998369/1.0	min: 0.00016301159	loss: 34575.390625	train_loss: 34562.97489461399	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_680
Epoch: 680	max: 0.999814/1.0	min: 0.000185997	loss: 34575.2265625	train_loss: 34562.92743607163	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_681
Epoch: 681	max: 0.99981433/1.0	min: 0.00018565929	loss: 34575.3125	train_loss: 34562.904729209244	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_682
Epoch: 682	max: 0.9998623/1.0	min: 0.00013762747	loss: 34575.19140625	train_loss: 34562.88001139988	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_683
Epoch: 683	max: 0.99987113/1.0	min: 0.00012888885	loss: 34575.375	train_loss: 34562.844186930975	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_684
Epoch: 684	max: 0.9998847/1.0	min: 0.00011525538	loss: 34575.23046875	train_loss: 34562.75300577543	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_685
Epoch: 685	max: 0.9998301/1.0	min: 0.00016984632	loss: 34575.00390625	train_loss: 34562.7078417255	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_686
Epoch: 686	max: 0.9998099/1.0	min: 0.00019010402	loss: 34575.05078125	train_loss: 34562.68139022436	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_687
Epoch: 687	max: 0.99981695/1.0	min: 0.0001831127	loss: 34574.8984375	train_loss: 34562.62778513254	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_688
Epoch: 688	max: 0.9998784/1.0	min: 0.00012159162	loss: 34574.92578125	train_loss: 34562.60786920909	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_689
Epoch: 689	max: 0.9998466/1.0	min: 0.00015338151	loss: 34574.89453125	train_loss: 34562.598845108696	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_690
Epoch: 690	max: 0.99988925/1.0	min: 0.000110725996	loss: 34574.98828125	train_loss: 34562.520509143134	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_691
Epoch: 691	max: 0.99978083/1.0	min: 0.00021914786	loss: 34574.8046875	train_loss: 34562.54351648628	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_692
Epoch: 692	max: 0.9997814/1.0	min: 0.00021861777	loss: 34574.953125	train_loss: 34562.44660635761	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_693
Epoch: 693	max: 0.9998573/1.0	min: 0.00014264483	loss: 34574.87890625	train_loss: 34562.39960845566	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_694
Epoch: 694	max: 0.99988174/1.0	min: 0.000118189135	loss: 34574.9609375	train_loss: 34562.34728173773	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_695
Epoch: 695	max: 0.9998124/1.0	min: 0.00018765118	loss: 34575.01171875	train_loss: 34562.33275172643	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_696
Epoch: 696	max: 0.99985886/1.0	min: 0.00014113022	loss: 34574.91015625	train_loss: 34562.29075312771	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_697
Epoch: 697	max: 0.9998927/1.0	min: 0.0001072678	loss: 34574.71875	train_loss: 34562.224221556426	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_698
Epoch: 698	max: 0.99989986/1.0	min: 0.00010016043	loss: 34574.90625	train_loss: 34562.17790735709	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_699
Epoch: 699	max: 0.9998853/1.0	min: 0.00011469601	loss: 34575.0390625	train_loss: 34562.1650423286	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_700
Epoch: 700	max: 0.99986076/1.0	min: 0.00013918424	loss: 34574.83984375	train_loss: 34562.098775431994	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_701
Epoch: 701	max: 0.9998913/1.0	min: 0.00010866538	loss: 34574.8125	train_loss: 34562.04805611684	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_702
Epoch: 702	max: 0.9998938/1.0	min: 0.00010615317	loss: 34574.6484375	train_loss: 34562.01766207575	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_703
Epoch: 703	max: 0.9998592/1.0	min: 0.00014075552	loss: 34574.5390625	train_loss: 34561.97208190109	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_704
Epoch: 704	max: 0.99985933/1.0	min: 0.000140638	loss: 34574.53515625	train_loss: 34561.92935411634	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_705
Epoch: 705	max: 0.99987614/1.0	min: 0.00012383566	loss: 34574.4765625	train_loss: 34561.89443592841	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_706
Epoch: 706	max: 0.99989474/1.0	min: 0.000105286104	loss: 34574.51171875	train_loss: 34561.83274882324	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_707
Epoch: 707	max: 0.9998852/1.0	min: 0.000114784525	loss: 34574.3984375	train_loss: 34561.82854838273	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_708
Epoch: 708	max: 0.9999225/1.0	min: 7.7447134e-05	loss: 34574.48046875	train_loss: 34561.76851948625	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_709
Epoch: 709	max: 0.99981314/1.0	min: 0.00018686146	loss: 34574.31640625	train_loss: 34561.748350017035	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_710
Epoch: 710	max: 0.9998683/1.0	min: 0.00013171378	loss: 34574.19921875	train_loss: 34561.67585673309	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_711
Epoch: 711	max: 0.99988437/1.0	min: 0.00011558467	loss: 34574.25390625	train_loss: 34561.61543832451	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_712
Epoch: 712	max: 0.9999566/1.0	min: 4.3400414e-05	loss: 34574.625	train_loss: 34561.57927853648	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_713
Epoch: 713	max: 0.99991536/1.0	min: 8.459295e-05	loss: 34574.21484375	train_loss: 34561.56045324694	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_714
Epoch: 714	max: 0.99992573/1.0	min: 7.427897e-05	loss: 34574.2890625	train_loss: 34561.4752386427	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_715
Epoch: 715	max: 0.99989617/1.0	min: 0.00010378283	loss: 34574.34375	train_loss: 34561.438837889415	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_716
Epoch: 716	max: 0.9998927/1.0	min: 0.00010728846	loss: 34574.015625	train_loss: 34561.39207804952	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_717
Epoch: 717	max: 0.99988115/1.0	min: 0.000118853575	loss: 34573.953125	train_loss: 34561.336662331225	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_718
Epoch: 718	max: 0.9999441/1.0	min: 5.5957236e-05	loss: 34574.17578125	train_loss: 34561.35639390174	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_719
Epoch: 719	max: 0.9999521/1.0	min: 4.7944275e-05	loss: 34574.24609375	train_loss: 34561.25285771244	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_720
Epoch: 720	max: 0.9999217/1.0	min: 7.828918e-05	loss: 34574.0390625	train_loss: 34561.22196577326	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_721
Epoch: 721	max: 0.9999579/1.0	min: 4.2135525e-05	loss: 34574.5	train_loss: 34561.15457050121	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_722
Epoch: 722	max: 0.999884/1.0	min: 0.00011598302	loss: 34573.90234375	train_loss: 34561.141633860556	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_723
Epoch: 723	max: 0.99994075/1.0	min: 5.9221642e-05	loss: 34574.10546875	train_loss: 34561.11579348213	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_724
Epoch: 724	max: 0.9999256/1.0	min: 7.439295e-05	loss: 34573.75	train_loss: 34561.067658979	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_725
Epoch: 725	max: 0.99991286/1.0	min: 8.710048e-05	loss: 34573.78125	train_loss: 34560.97787861545	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_726
Epoch: 726	max: 0.9999187/1.0	min: 8.134895e-05	loss: 34573.9296875	train_loss: 34560.93780677103	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_727
Epoch: 727	max: 0.99994063/1.0	min: 5.936985e-05	loss: 34574.10546875	train_loss: 34560.90174714325	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_728
Epoch: 728	max: 0.999907/1.0	min: 9.294221e-05	loss: 34573.78515625	train_loss: 34560.84766495959	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_729
Epoch: 729	max: 0.99993/1.0	min: 6.9913425e-05	loss: 34573.89453125	train_loss: 34560.808363429795	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_730
Epoch: 730	max: 0.99992156/1.0	min: 7.8413505e-05	loss: 34573.8203125	train_loss: 34560.74187105165	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_731
Epoch: 731	max: 0.9999155/1.0	min: 8.45399e-05	loss: 34573.80078125	train_loss: 34560.70028470674	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_732
Epoch: 732	max: 0.99994814/1.0	min: 5.187385e-05	loss: 34573.765625	train_loss: 34560.66119075545	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_733
Epoch: 733	max: 0.99993837/1.0	min: 6.16137e-05	loss: 34573.7109375	train_loss: 34560.61101578952	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_734
Epoch: 734	max: 0.9999263/1.0	min: 7.36065e-05	loss: 34573.734375	train_loss: 34560.555138946955	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_735
Epoch: 735	max: 0.9999554/1.0	min: 4.456677e-05	loss: 34573.88671875	train_loss: 34560.50502349653	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_736
Epoch: 736	max: 0.9999527/1.0	min: 4.7382084e-05	loss: 34573.7578125	train_loss: 34560.474731551156	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_737
Epoch: 737	max: 0.99992275/1.0	min: 7.720829e-05	loss: 34573.5546875	train_loss: 34560.403087452	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_738
Epoch: 738	max: 0.9999703/1.0	min: 2.9630917e-05	loss: 34574.09375	train_loss: 34560.37134632804	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_739
Epoch: 739	max: 0.9999423/1.0	min: 5.7639885e-05	loss: 34573.703125	train_loss: 34560.34311274852	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_740
Epoch: 740	max: 0.99995995/1.0	min: 4.0085015e-05	loss: 34573.7109375	train_loss: 34560.26247987118	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_741
Epoch: 741	max: 0.99994564/1.0	min: 5.4306296e-05	loss: 34573.6875	train_loss: 34560.286238658184	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_742
Epoch: 742	max: 0.9999602/1.0	min: 3.9864903e-05	loss: 34573.48828125	train_loss: 34560.140837901024	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_743
Epoch: 743	max: 0.999948/1.0	min: 5.198031e-05	loss: 34573.4296875	train_loss: 34560.09519966246	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_744
Epoch: 744	max: 0.9999646/1.0	min: 3.534647e-05	loss: 34574.078125	train_loss: 34560.04142521755	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_745
Epoch: 745	max: 0.9999249/1.0	min: 7.5095086e-05	loss: 34573.390625	train_loss: 34559.997833732035	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_746
Epoch: 746	max: 0.9999387/1.0	min: 6.12811e-05	loss: 34573.25	train_loss: 34559.96660260281	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_747
Epoch: 747	max: 0.9999422/1.0	min: 5.776402e-05	loss: 34573.2734375	train_loss: 34559.885154411306	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_748
Epoch: 748	max: 0.9999646/1.0	min: 3.5400008e-05	loss: 34573.93359375	train_loss: 34559.82098362211	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_749
Epoch: 749	max: 0.99994326/1.0	min: 5.6740468e-05	loss: 34573.38671875	train_loss: 34559.79224053171	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_750
Epoch: 750	max: 0.9999498/1.0	min: 5.0148694e-05	loss: 34573.51171875	train_loss: 34559.693451551466	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_751
Epoch: 751	max: 0.9999254/1.0	min: 7.456497e-05	loss: 34573.14453125	train_loss: 34559.675018677226	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_752
Epoch: 752	max: 0.999946/1.0	min: 5.4011598e-05	loss: 34573.11328125	train_loss: 34559.61845909978	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_753
Epoch: 753	max: 0.9999254/1.0	min: 7.460196e-05	loss: 34573.07421875	train_loss: 34559.572323446984	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_754
Epoch: 754	max: 0.9999615/1.0	min: 3.8509683e-05	loss: 34573.41015625	train_loss: 34559.544022126225	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_755
Epoch: 755	max: 0.99995244/1.0	min: 4.7604182e-05	loss: 34573.61328125	train_loss: 34559.49081332063	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_756
Epoch: 756	max: 0.9999664/1.0	min: 3.3649958e-05	loss: 34573.57421875	train_loss: 34559.462209583646	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_757
Epoch: 757	max: 0.9999479/1.0	min: 5.2126554e-05	loss: 34573.140625	train_loss: 34559.39153660349	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_758
Epoch: 758	max: 0.99993837/1.0	min: 6.157381e-05	loss: 34573.046875	train_loss: 34559.3562366453	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_759
Epoch: 759	max: 0.9999393/1.0	min: 6.0626826e-05	loss: 34573.1484375	train_loss: 34559.28622269061	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_760
Epoch: 760	max: 0.9999387/1.0	min: 6.132243e-05	loss: 34572.953125	train_loss: 34559.25081966896	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_761
Epoch: 761	max: 0.9999454/1.0	min: 5.458251e-05	loss: 34573.11328125	train_loss: 34559.192432045864	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_762
Epoch: 762	max: 0.99990654/1.0	min: 9.351064e-05	loss: 34572.77734375	train_loss: 34559.18149038462	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_763
Epoch: 763	max: 0.9999633/1.0	min: 3.666502e-05	loss: 34573.0859375	train_loss: 34559.21014105661	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_764
Epoch: 764	max: 0.99993825/1.0	min: 6.1743616e-05	loss: 34573.0234375	train_loss: 34559.0854028281	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_765
Epoch: 765	max: 0.9999553/1.0	min: 4.471573e-05	loss: 34572.75390625	train_loss: 34559.05325477285	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_766
Epoch: 766	max: 0.9999356/1.0	min: 6.4402215e-05	loss: 34572.73046875	train_loss: 34558.996288747985	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_767
Epoch: 767	max: 0.9999497/1.0	min: 5.0291652e-05	loss: 34572.67578125	train_loss: 34558.97137206971	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_768
Epoch: 768	max: 0.9999131/1.0	min: 8.691687e-05	loss: 34572.640625	train_loss: 34558.936685169705	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_769
Epoch: 769	max: 0.9999473/1.0	min: 5.2647196e-05	loss: 34572.6640625	train_loss: 34558.88963646182	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_770
Epoch: 770	max: 0.99994934/1.0	min: 5.064829e-05	loss: 34572.80078125	train_loss: 34558.871323102474	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_771
Epoch: 771	max: 0.99992776/1.0	min: 7.220791e-05	loss: 34572.7890625	train_loss: 34558.8275462963	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_772
Epoch: 772	max: 0.9999218/1.0	min: 7.816892e-05	loss: 34572.89453125	train_loss: 34558.77077865648	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_773
Epoch: 773	max: 0.99993503/1.0	min: 6.4936765e-05	loss: 34572.55078125	train_loss: 34558.76717917751	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_774
Epoch: 774	max: 0.9999565/1.0	min: 4.3473316e-05	loss: 34573.01171875	train_loss: 34558.708659459	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_775
Epoch: 775	max: 0.9999566/1.0	min: 4.3390854e-05	loss: 34572.71484375	train_loss: 34558.66226493791	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_776
Epoch: 776	max: 0.9999385/1.0	min: 6.154065e-05	loss: 34572.41015625	train_loss: 34558.62084697835	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_777
Epoch: 777	max: 0.999943/1.0	min: 5.6962584e-05	loss: 34572.5390625	train_loss: 34558.61698524402	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_778
Epoch: 778	max: 0.9999653/1.0	min: 3.4692595e-05	loss: 34572.87109375	train_loss: 34558.5449424393	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_779
Epoch: 779	max: 0.999936/1.0	min: 6.3958185e-05	loss: 34572.39453125	train_loss: 34558.54798934334	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_780
Epoch: 780	max: 0.9999291/1.0	min: 7.097675e-05	loss: 34572.265625	train_loss: 34558.47522751378	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_781
Epoch: 781	max: 0.99996364/1.0	min: 3.6394453e-05	loss: 34572.74609375	train_loss: 34558.4678867831	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_782
Epoch: 782	max: 0.9999434/1.0	min: 5.659143e-05	loss: 34572.23828125	train_loss: 34558.41714908104	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_783
Epoch: 783	max: 0.9999578/1.0	min: 4.2197487e-05	loss: 34572.37890625	train_loss: 34558.38766615958	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_784
Epoch: 784	max: 0.9998784/1.0	min: 0.00012159638	loss: 34572.25	train_loss: 34558.33509557321	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_785
Epoch: 785	max: 0.9999323/1.0	min: 6.7734145e-05	loss: 34572.22265625	train_loss: 34558.34053712994	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_786
Epoch: 786	max: 0.9999399/1.0	min: 6.012099e-05	loss: 34572.1796875	train_loss: 34558.27160074477	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_787
Epoch: 787	max: 0.999938/1.0	min: 6.194041e-05	loss: 34572.140625	train_loss: 34558.21018121749	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_788
Epoch: 788	max: 0.9999597/1.0	min: 4.0331146e-05	loss: 34572.20703125	train_loss: 34558.21331424966	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_789
Epoch: 789	max: 0.9999602/1.0	min: 3.9865703e-05	loss: 34572.34375	train_loss: 34558.18860273055	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_790
Epoch: 790	max: 0.99995315/1.0	min: 4.6899047e-05	loss: 34572.08984375	train_loss: 34558.11245625852	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_791
Epoch: 791	max: 0.9999535/1.0	min: 4.6548117e-05	loss: 34572.17578125	train_loss: 34558.089969555156	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_792
Epoch: 792	max: 0.99995136/1.0	min: 4.8693313e-05	loss: 34572.08203125	train_loss: 34558.05337186842	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_793
Epoch: 793	max: 0.9999534/1.0	min: 4.66167e-05	loss: 34572.28515625	train_loss: 34558.01484307259	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_794
Epoch: 794	max: 0.99993443/1.0	min: 6.5522036e-05	loss: 34572.0234375	train_loss: 34557.98146648164	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_795
Epoch: 795	max: 0.99997115/1.0	min: 2.8798999e-05	loss: 34572.0	train_loss: 34557.975952345005	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_796
Epoch: 796	max: 0.9999622/1.0	min: 3.784296e-05	loss: 34571.90625	train_loss: 34557.93375826443	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_797
Epoch: 797	max: 0.999936/1.0	min: 6.400523e-05	loss: 34571.88671875	train_loss: 34557.90143843676	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_798
Epoch: 798	max: 0.9999671/1.0	min: 3.286443e-05	loss: 34572.37109375	train_loss: 34557.858432429086	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_799
Epoch: 799	max: 0.99994886/1.0	min: 5.1196148e-05	loss: 34571.921875	train_loss: 34557.83992262015	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_800
Epoch: 800	max: 0.99992/1.0	min: 7.9952784e-05	loss: 34571.6953125	train_loss: 34557.77366056221	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_801
Epoch: 801	max: 0.9999281/1.0	min: 7.183368e-05	loss: 34571.609375	train_loss: 34557.75373399371	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_802
Epoch: 802	max: 0.999956/1.0	min: 4.39688e-05	loss: 34571.66015625	train_loss: 34557.72212980382	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_803
Epoch: 803	max: 0.99991417/1.0	min: 8.5799795e-05	loss: 34571.6015625	train_loss: 34557.70242629753	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_804
Epoch: 804	max: 0.9999434/1.0	min: 5.6575675e-05	loss: 34571.6953125	train_loss: 34557.70683867134	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_805
Epoch: 805	max: 0.9999635/1.0	min: 3.6525464e-05	loss: 34571.59375	train_loss: 34557.62819980568	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_806
Epoch: 806	max: 0.9999169/1.0	min: 8.304715e-05	loss: 34571.5859375	train_loss: 34557.594315639326	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_807
Epoch: 807	max: 0.99996173/1.0	min: 3.823451e-05	loss: 34571.56640625	train_loss: 34557.55250090967	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_808
Epoch: 808	max: 0.9999418/1.0	min: 5.81544e-05	loss: 34571.46875	train_loss: 34557.51677369782	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_809
Epoch: 809	max: 0.9999385/1.0	min: 6.154135e-05	loss: 34571.671875	train_loss: 34557.483296946615	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_810
Epoch: 810	max: 0.9999443/1.0	min: 5.5611876e-05	loss: 34571.44140625	train_loss: 34557.47324850195	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_811
Epoch: 811	max: 0.9998975/1.0	min: 0.00010251058	loss: 34571.28515625	train_loss: 34557.44774828131	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_812
Epoch: 812	max: 0.9999441/1.0	min: 5.5875327e-05	loss: 34571.34375	train_loss: 34557.54803482674	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_813
Epoch: 813	max: 0.9999454/1.0	min: 5.4652097e-05	loss: 34571.43359375	train_loss: 34557.36249690326	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_814
Epoch: 814	max: 0.9999479/1.0	min: 5.2068717e-05	loss: 34571.359375	train_loss: 34557.34552917518	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_815
Epoch: 815	max: 0.9999411/1.0	min: 5.8904152e-05	loss: 34571.36328125	train_loss: 34557.30088673278	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_816
Epoch: 816	max: 0.99992216/1.0	min: 7.786554e-05	loss: 34571.234375	train_loss: 34557.27392814009	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_817
Epoch: 817	max: 0.99995124/1.0	min: 4.871551e-05	loss: 34571.13671875	train_loss: 34557.243977320235	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_818
Epoch: 818	max: 0.9999676/1.0	min: 3.2373016e-05	loss: 34571.49609375	train_loss: 34557.237951737276	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_819
Epoch: 819	max: 0.9999356/1.0	min: 6.434347e-05	loss: 34571.171875	train_loss: 34557.22096707389	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_820
Epoch: 820	max: 0.99993956/1.0	min: 6.0422044e-05	loss: 34571.05078125	train_loss: 34557.15226149278	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_821
Epoch: 821	max: 0.9999267/1.0	min: 7.33085e-05	loss: 34571.28515625	train_loss: 34557.12137003747	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_822
Epoch: 822	max: 0.99992895/1.0	min: 7.104575e-05	loss: 34571.09375	train_loss: 34557.090607290505	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_823
Epoch: 823	max: 0.9999465/1.0	min: 5.3489544e-05	loss: 34571.09375	train_loss: 34557.06440062554	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_824
Epoch: 824	max: 0.9999621/1.0	min: 3.7848662e-05	loss: 34571.41015625	train_loss: 34557.047431929735	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_825
Epoch: 825	max: 0.9999608/1.0	min: 3.919309e-05	loss: 34571.13671875	train_loss: 34557.04088086833	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_826
Epoch: 826	max: 0.99995947/1.0	min: 4.0492654e-05	loss: 34571.05859375	train_loss: 34556.96207845597	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_827
Epoch: 827	max: 0.99995685/1.0	min: 4.3127737e-05	loss: 34570.8984375	train_loss: 34556.95624158073	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_828
Epoch: 828	max: 0.9999368/1.0	min: 6.3222506e-05	loss: 34570.81640625	train_loss: 34556.91408717717	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_829
Epoch: 829	max: 0.9999604/1.0	min: 3.9577397e-05	loss: 34571.35546875	train_loss: 34556.8978529899	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_830
Epoch: 830	max: 0.9999403/1.0	min: 5.9686263e-05	loss: 34570.8046875	train_loss: 34556.873065987704	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_831
Epoch: 831	max: 0.99996567/1.0	min: 3.4323897e-05	loss: 34570.7578125	train_loss: 34556.838216024866	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_832
Epoch: 832	max: 0.9999558/1.0	min: 4.422574e-05	loss: 34570.8828125	train_loss: 34556.82458648814	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_833
Epoch: 833	max: 0.99991083/1.0	min: 8.911975e-05	loss: 34570.9765625	train_loss: 34556.773634917314	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_834
Epoch: 834	max: 0.9999541/1.0	min: 4.5871693e-05	loss: 34570.8828125	train_loss: 34556.735850791214	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_835
Epoch: 835	max: 0.9999596/1.0	min: 4.043154e-05	loss: 34570.7734375	train_loss: 34556.715468420975	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_836
Epoch: 836	max: 0.99994504/1.0	min: 5.492168e-05	loss: 34570.78125	train_loss: 34556.66054043958	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_837
Epoch: 837	max: 0.9999609/1.0	min: 3.915742e-05	loss: 34570.84375	train_loss: 34556.67001453533	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_838
Epoch: 838	max: 0.9999651/1.0	min: 3.4943154e-05	loss: 34570.74609375	train_loss: 34556.6385787308	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_839
Epoch: 839	max: 0.9999275/1.0	min: 7.2452014e-05	loss: 34570.484375	train_loss: 34556.63230492459	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_840
Epoch: 840	max: 0.99997735/1.0	min: 2.2641367e-05	loss: 34570.7890625	train_loss: 34556.57988336895	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_841
Epoch: 841	max: 0.99996114/1.0	min: 3.8919643e-05	loss: 34570.6953125	train_loss: 34556.54908288043	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_842
Epoch: 842	max: 0.999962/1.0	min: 3.7996026e-05	loss: 34570.5546875	train_loss: 34556.49930952326	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_843
Epoch: 843	max: 0.99995947/1.0	min: 4.0507333e-05	loss: 34570.421875	train_loss: 34556.47887537935	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_844
Epoch: 844	max: 0.99995446/1.0	min: 4.5559205e-05	loss: 34570.7734375	train_loss: 34556.43124700003	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_845
Epoch: 845	max: 0.99994683/1.0	min: 5.3203286e-05	loss: 34570.48828125	train_loss: 34556.42306772962	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_846
Epoch: 846	max: 0.99995375/1.0	min: 4.62956e-05	loss: 34570.3984375	train_loss: 34556.385619890374	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_847
Epoch: 847	max: 0.9999713/1.0	min: 2.8691897e-05	loss: 34570.62890625	train_loss: 34556.37356727285	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_848
Epoch: 848	max: 0.99994946/1.0	min: 5.0498777e-05	loss: 34570.40234375	train_loss: 34556.33167609238	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_849
Epoch: 849	max: 0.99991035/1.0	min: 8.968627e-05	loss: 34570.34765625	train_loss: 34556.3346605777	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_850
Epoch: 850	max: 0.99994063/1.0	min: 5.937585e-05	loss: 34570.2109375	train_loss: 34556.295477111205	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_851
Epoch: 851	max: 0.9999796/1.0	min: 2.039245e-05	loss: 34570.78515625	train_loss: 34556.307255860585	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_852
Epoch: 852	max: 0.9999515/1.0	min: 4.851079e-05	loss: 34570.30078125	train_loss: 34556.24694245092	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_853
Epoch: 853	max: 0.9999604/1.0	min: 3.9579812e-05	loss: 34570.1328125	train_loss: 34556.31463481667	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_854
Epoch: 854	max: 0.99995756/1.0	min: 4.2383766e-05	loss: 34570.109375	train_loss: 34556.16454636597	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_855
Epoch: 855	max: 0.99992645/1.0	min: 7.35247e-05	loss: 34570.2109375	train_loss: 34556.13127090301	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_856
Epoch: 856	max: 0.9999794/1.0	min: 2.0680342e-05	loss: 34570.62109375	train_loss: 34556.12498451629	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_857
Epoch: 857	max: 0.99995947/1.0	min: 4.048594e-05	loss: 34570.359375	train_loss: 34556.08195334758	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_858
Epoch: 858	max: 0.9999286/1.0	min: 7.141752e-05	loss: 34570.19921875	train_loss: 34556.06774897807	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_859
Epoch: 859	max: 0.9999645/1.0	min: 3.5573925e-05	loss: 34570.19140625	train_loss: 34556.02039107984	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_860
Epoch: 860	max: 0.9999536/1.0	min: 4.6348523e-05	loss: 34570.3359375	train_loss: 34555.983682587794	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_861
Epoch: 861	max: 0.9999486/1.0	min: 5.1334595e-05	loss: 34570.078125	train_loss: 34555.9574976968	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_862
Epoch: 862	max: 0.9999728/1.0	min: 2.7173068e-05	loss: 34570.14453125	train_loss: 34555.97121191007	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_863
Epoch: 863	max: 0.9999647/1.0	min: 3.527438e-05	loss: 34570.12109375	train_loss: 34555.90175875604	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_864
Epoch: 864	max: 0.99994755/1.0	min: 5.248539e-05	loss: 34570.03125	train_loss: 34555.936575332125	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_865
Epoch: 865	max: 0.9999573/1.0	min: 4.2699965e-05	loss: 34570.15625	train_loss: 34555.88533586105	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_866
Epoch: 866	max: 0.9999629/1.0	min: 3.709766e-05	loss: 34570.078125	train_loss: 34555.81255225753	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_867
Epoch: 867	max: 0.9999685/1.0	min: 3.1527066e-05	loss: 34570.0546875	train_loss: 34555.78842815171	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_868
Epoch: 868	max: 0.999959/1.0	min: 4.1036506e-05	loss: 34569.9140625	train_loss: 34555.77161622848	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_869
Epoch: 869	max: 0.9999467/1.0	min: 5.3246175e-05	loss: 34569.90625	train_loss: 34555.776283599655	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_870
Epoch: 870	max: 0.99995196/1.0	min: 4.7989928e-05	loss: 34570.03515625	train_loss: 34555.720445466366	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_871
Epoch: 871	max: 0.99996436/1.0	min: 3.5601646e-05	loss: 34569.75390625	train_loss: 34555.684442934784	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_872
Epoch: 872	max: 0.99993956/1.0	min: 6.0491926e-05	loss: 34569.73828125	train_loss: 34555.70384354097	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_873
Epoch: 873	max: 0.9999715/1.0	min: 2.8457629e-05	loss: 34569.86328125	train_loss: 34555.6569041868	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_874
Epoch: 874	max: 0.99996436/1.0	min: 3.569197e-05	loss: 34569.76953125	train_loss: 34555.593611614335	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_875
Epoch: 875	max: 0.99991965/1.0	min: 8.038342e-05	loss: 34569.75390625	train_loss: 34555.58361494333	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_876
Epoch: 876	max: 0.9999759/1.0	min: 2.4100726e-05	loss: 34570.0234375	train_loss: 34555.62205906262	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_877
Epoch: 877	max: 0.99996614/1.0	min: 3.3902164e-05	loss: 34569.8125	train_loss: 34555.52996969064	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_878
Epoch: 878	max: 0.99996316/1.0	min: 3.6789035e-05	loss: 34569.82421875	train_loss: 34555.49968693872	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_879
Epoch: 879	max: 0.99996364/1.0	min: 3.640528e-05	loss: 34569.68359375	train_loss: 34555.48183615524	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_880
Epoch: 880	max: 0.9999685/1.0	min: 3.1440144e-05	loss: 34569.53125	train_loss: 34555.446643615294	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_881
Epoch: 881	max: 0.99997294/1.0	min: 2.7028364e-05	loss: 34569.8359375	train_loss: 34555.44226075731	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_882
Epoch: 882	max: 0.9999653/1.0	min: 3.465074e-05	loss: 34569.703125	train_loss: 34555.39461931361	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_883
Epoch: 883	max: 0.99997604/1.0	min: 2.3903667e-05	loss: 34569.76953125	train_loss: 34555.377104333114	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_884
Epoch: 884	max: 0.99997365/1.0	min: 2.6329453e-05	loss: 34569.546875	train_loss: 34555.363995920045	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_885
Epoch: 885	max: 0.9999589/1.0	min: 4.1174728e-05	loss: 34569.53515625	train_loss: 34555.33197560541	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_886
Epoch: 886	max: 0.9999484/1.0	min: 5.1662853e-05	loss: 34569.58984375	train_loss: 34555.286275431994	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_887
Epoch: 887	max: 0.9999746/1.0	min: 2.5370096e-05	loss: 34569.671875	train_loss: 34555.28725429286	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_888
Epoch: 888	max: 0.99998045/1.0	min: 1.9504481e-05	loss: 34569.93359375	train_loss: 34555.236773523626	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_889
Epoch: 889	max: 0.9999764/1.0	min: 2.3608814e-05	loss: 34569.328125	train_loss: 34555.23228905379	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_890
Epoch: 890	max: 0.9999759/1.0	min: 2.4113762e-05	loss: 34569.67578125	train_loss: 34555.193737032394	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_891
Epoch: 891	max: 0.99998236/1.0	min: 1.7623284e-05	loss: 34569.5390625	train_loss: 34555.14192272854	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_892
Epoch: 892	max: 0.99997306/1.0	min: 2.690913e-05	loss: 34569.37890625	train_loss: 34555.16948857302	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_893
Epoch: 893	max: 0.99997365/1.0	min: 2.6349197e-05	loss: 34569.3671875	train_loss: 34555.08469396445	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_894
Epoch: 894	max: 0.9999691/1.0	min: 3.0924344e-05	loss: 34569.46484375	train_loss: 34555.06103872476	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_895
Epoch: 895	max: 0.9999671/1.0	min: 3.2852055e-05	loss: 34569.296875	train_loss: 34555.0854255698	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_896
Epoch: 896	max: 0.9999833/1.0	min: 1.6641405e-05	loss: 34569.3984375	train_loss: 34555.020061567106	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_897
Epoch: 897	max: 0.9999809/1.0	min: 1.9094616e-05	loss: 34569.26171875	train_loss: 34554.99645471402	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_898
Epoch: 898	max: 0.9999615/1.0	min: 3.84652e-05	loss: 34569.265625	train_loss: 34554.96726501533	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_899
Epoch: 899	max: 0.9999714/1.0	min: 2.86039e-05	loss: 34569.1796875	train_loss: 34554.93567872848	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_900
Epoch: 900	max: 0.99997294/1.0	min: 2.7025631e-05	loss: 34569.14453125	train_loss: 34554.91823729561	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_901
Epoch: 901	max: 0.99995756/1.0	min: 4.2459218e-05	loss: 34569.1484375	train_loss: 34554.87397372027	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_902
Epoch: 902	max: 0.9999739/1.0	min: 2.605718e-05	loss: 34569.140625	train_loss: 34554.88524924904	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_903
Epoch: 903	max: 0.99997115/1.0	min: 2.8849689e-05	loss: 34569.4296875	train_loss: 34554.83187399356	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_904
Epoch: 904	max: 0.9999628/1.0	min: 3.720714e-05	loss: 34569.19921875	train_loss: 34554.841519377864	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_905
Epoch: 905	max: 0.9999597/1.0	min: 4.0274226e-05	loss: 34569.03125	train_loss: 34554.811237593676	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_906
Epoch: 906	max: 0.999977/1.0	min: 2.2953736e-05	loss: 34569.24609375	train_loss: 34554.75910345442	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_907
Epoch: 907	max: 0.9999745/1.0	min: 2.552023e-05	loss: 34569.09375	train_loss: 34554.728603446674	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_908
Epoch: 908	max: 0.99998045/1.0	min: 1.9571617e-05	loss: 34569.390625	train_loss: 34554.69787795739	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_909
Epoch: 909	max: 0.9999627/1.0	min: 3.7324487e-05	loss: 34569.1015625	train_loss: 34554.71010428279	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_910
Epoch: 910	max: 0.99997854/1.0	min: 2.1413065e-05	loss: 34569.14453125	train_loss: 34554.64098499629	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_911
Epoch: 911	max: 0.9999882/1.0	min: 1.1786801e-05	loss: 34569.23046875	train_loss: 34554.63128058033	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_912
Epoch: 912	max: 0.9999875/1.0	min: 1.2562276e-05	loss: 34569.03125	train_loss: 34554.620354402796	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_913
Epoch: 913	max: 0.9999764/1.0	min: 2.357266e-05	loss: 34569.078125	train_loss: 34554.58314269014	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_914
Epoch: 914	max: 0.9999769/1.0	min: 2.3168423e-05	loss: 34568.91015625	train_loss: 34554.55843746129	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_915
Epoch: 915	max: 0.99996734/1.0	min: 3.263146e-05	loss: 34568.8828125	train_loss: 34554.506854445375	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_916
Epoch: 916	max: 0.9999825/1.0	min: 1.7533483e-05	loss: 34568.76171875	train_loss: 34554.51335131379	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_917
Epoch: 917	max: 0.9999808/1.0	min: 1.9233403e-05	loss: 34568.8984375	train_loss: 34554.48576417921	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_918
Epoch: 918	max: 0.99996305/1.0	min: 3.6919046e-05	loss: 34568.76171875	train_loss: 34554.46508713459	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_919
Epoch: 919	max: 0.9999788/1.0	min: 2.1262711e-05	loss: 34568.875	train_loss: 34554.4017848848	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_920
Epoch: 920	max: 0.9999776/1.0	min: 2.2421962e-05	loss: 34568.6953125	train_loss: 34554.374146460425	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_921
Epoch: 921	max: 0.99997485/1.0	min: 2.5097954e-05	loss: 34568.93359375	train_loss: 34554.38710681051	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_922
Epoch: 922	max: 0.99996173/1.0	min: 3.828318e-05	loss: 34568.76953125	train_loss: 34554.33192528335	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_923
Epoch: 923	max: 0.99998915/1.0	min: 1.0906937e-05	loss: 34568.984375	train_loss: 34554.330301429145	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_924
Epoch: 924	max: 0.99996686/1.0	min: 3.309812e-05	loss: 34568.515625	train_loss: 34554.307923595625	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_925
Epoch: 925	max: 0.9999715/1.0	min: 2.8486791e-05	loss: 34568.60546875	train_loss: 34554.26265986932	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_926
Epoch: 926	max: 0.9999801/1.0	min: 1.9865509e-05	loss: 34568.484375	train_loss: 34554.221548196925	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_927
Epoch: 927	max: 0.9999591/1.0	min: 4.094082e-05	loss: 34568.7109375	train_loss: 34554.22692685108	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_928
Epoch: 928	max: 0.9999796/1.0	min: 2.0385665e-05	loss: 34569.0546875	train_loss: 34554.20770188824	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_929
Epoch: 929	max: 0.99998367/1.0	min: 1.6321947e-05	loss: 34568.6015625	train_loss: 34554.21552696876	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_930
Epoch: 930	max: 0.9999838/1.0	min: 1.6181037e-05	loss: 34568.5	train_loss: 34554.14744992955	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_931
Epoch: 931	max: 0.99996686/1.0	min: 3.3175453e-05	loss: 34569.02734375	train_loss: 34554.118768290136	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_932
Epoch: 932	max: 0.99997103/1.0	min: 2.8955583e-05	loss: 34568.4609375	train_loss: 34554.11223368017	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_933
Epoch: 933	max: 0.99996686/1.0	min: 3.319824e-05	loss: 34568.3359375	train_loss: 34554.09148163632	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_934
Epoch: 934	max: 0.9999809/1.0	min: 1.901642e-05	loss: 34568.3984375	train_loss: 34554.02184993574	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_935
Epoch: 935	max: 0.9999831/1.0	min: 1.6892876e-05	loss: 34568.37109375	train_loss: 34553.99305507169	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_936
Epoch: 936	max: 0.9999801/1.0	min: 1.99597e-05	loss: 34568.56640625	train_loss: 34553.967990814286	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_937
Epoch: 937	max: 0.9999752/1.0	min: 2.4774119e-05	loss: 34568.28515625	train_loss: 34553.9495429402	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_938
Epoch: 938	max: 0.9999845/1.0	min: 1.5549354e-05	loss: 34568.60546875	train_loss: 34553.9165481195	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_939
Epoch: 939	max: 0.99998164/1.0	min: 1.8379737e-05	loss: 34568.47265625	train_loss: 34553.93196070234	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_940
Epoch: 940	max: 0.9999862/1.0	min: 1.3815852e-05	loss: 34568.46484375	train_loss: 34553.87671965967	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_941
Epoch: 941	max: 0.99998796/1.0	min: 1.20482855e-05	loss: 34568.3671875	train_loss: 34553.85552439459	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_942
Epoch: 942	max: 0.999985/1.0	min: 1.5000508e-05	loss: 34568.35546875	train_loss: 34553.81799429812	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_943
Epoch: 943	max: 0.99997044/1.0	min: 2.9564928e-05	loss: 34568.2109375	train_loss: 34553.80404637758	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_944
Epoch: 944	max: 0.9999833/1.0	min: 1.6734424e-05	loss: 34568.484375	train_loss: 34553.815478195065	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_945
Epoch: 945	max: 0.9999883/1.0	min: 1.1704785e-05	loss: 34568.7890625	train_loss: 34553.806250870955	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_946
Epoch: 946	max: 0.9999863/1.0	min: 1.3697008e-05	loss: 34568.05078125	train_loss: 34553.791513281154	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_947
Epoch: 947	max: 0.9999764/1.0	min: 2.3632894e-05	loss: 34568.14453125	train_loss: 34553.71416198285	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_948
Epoch: 948	max: 0.99998343/1.0	min: 1.6572843e-05	loss: 34568.7265625	train_loss: 34553.70688318701	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_949
Epoch: 949	max: 0.99998033/1.0	min: 1.9613224e-05	loss: 34568.30078125	train_loss: 34553.67232886628	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_950
Epoch: 950	max: 0.9999796/1.0	min: 2.0336673e-05	loss: 34568.08984375	train_loss: 34553.62451565016	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_951
Epoch: 951	max: 0.9999727/1.0	min: 2.7331604e-05	loss: 34567.96875	train_loss: 34553.60747437446	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_952
Epoch: 952	max: 0.9999825/1.0	min: 1.757552e-05	loss: 34568.14453125	train_loss: 34553.683654233246	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_953
Epoch: 953	max: 0.99997234/1.0	min: 2.7628304e-05	loss: 34568.28515625	train_loss: 34553.57281699028	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_954
Epoch: 954	max: 0.99996495/1.0	min: 3.4989636e-05	loss: 34568.0234375	train_loss: 34553.52994065868	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_955
Epoch: 955	max: 0.9999708/1.0	min: 2.921214e-05	loss: 34568.1015625	train_loss: 34553.58053078162	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_956
Epoch: 956	max: 0.9999833/1.0	min: 1.6716114e-05	loss: 34568.05078125	train_loss: 34553.4873740013	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_957
Epoch: 957	max: 0.9999777/1.0	min: 2.2302815e-05	loss: 34568.0234375	train_loss: 34553.459222195124	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_958
Epoch: 958	max: 0.9999678/1.0	min: 3.222388e-05	loss: 34568.046875	train_loss: 34553.44289897653	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_959
Epoch: 959	max: 0.99998677/1.0	min: 1.3230266e-05	loss: 34568.37109375	train_loss: 34553.43822870216	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_960
Epoch: 960	max: 0.99997246/1.0	min: 2.7493235e-05	loss: 34567.859375	train_loss: 34553.40460485569	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_961
Epoch: 961	max: 0.9999758/1.0	min: 2.420733e-05	loss: 34567.8828125	train_loss: 34553.38730519556	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_962
Epoch: 962	max: 0.9999819/1.0	min: 1.8158404e-05	loss: 34568.15625	train_loss: 34553.35146911387	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_963
Epoch: 963	max: 0.99998355/1.0	min: 1.6482907e-05	loss: 34567.90625	train_loss: 34553.35590858417	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_964
Epoch: 964	max: 0.99997973/1.0	min: 2.0213276e-05	loss: 34567.94140625	train_loss: 34553.32129668339	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_965
Epoch: 965	max: 0.9999871/1.0	min: 1.2841219e-05	loss: 34567.9609375	train_loss: 34553.27619021352	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_966
Epoch: 966	max: 0.9999802/1.0	min: 1.9785835e-05	loss: 34567.890625	train_loss: 34553.27652843583	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_967
Epoch: 967	max: 0.99998343/1.0	min: 1.6570568e-05	loss: 34568.01953125	train_loss: 34553.24353942153	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_968
Epoch: 968	max: 0.9999771/1.0	min: 2.2900214e-05	loss: 34567.78125	train_loss: 34553.22361817556	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_969
Epoch: 969	max: 0.99998844/1.0	min: 1.1588319e-05	loss: 34567.92578125	train_loss: 34553.216095027405	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_970
Epoch: 970	max: 0.999977/1.0	min: 2.3047287e-05	loss: 34567.6953125	train_loss: 34553.185180346525	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_971
Epoch: 971	max: 0.9999844/1.0	min: 1.5607726e-05	loss: 34567.62109375	train_loss: 34553.152197622476	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_972
Epoch: 972	max: 0.99998164/1.0	min: 1.8387818e-05	loss: 34567.75	train_loss: 34553.15094392574	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_973
Epoch: 973	max: 0.9999914/1.0	min: 8.545644e-06	loss: 34567.8671875	train_loss: 34553.09866027189	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_974
Epoch: 974	max: 0.99998033/1.0	min: 1.968109e-05	loss: 34567.93359375	train_loss: 34553.119311671624	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_975
Epoch: 975	max: 0.99997795/1.0	min: 2.2060145e-05	loss: 34567.5390625	train_loss: 34553.086806523286	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_976
Epoch: 976	max: 0.99996936/1.0	min: 3.0633993e-05	loss: 34568.05078125	train_loss: 34553.04043813096	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_977
Epoch: 977	max: 0.9999759/1.0	min: 2.4046292e-05	loss: 34567.87109375	train_loss: 34553.03294256317	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_978
Epoch: 978	max: 0.9999845/1.0	min: 1.5495056e-05	loss: 34567.7265625	train_loss: 34553.02824374071	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_979
Epoch: 979	max: 0.99998546/1.0	min: 1.4556577e-05	loss: 34567.73046875	train_loss: 34552.99846179007	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_980
Epoch: 980	max: 0.9999846/1.0	min: 1.5435002e-05	loss: 34567.5703125	train_loss: 34552.9504047055	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_981
Epoch: 981	max: 0.9999831/1.0	min: 1.6902173e-05	loss: 34567.83203125	train_loss: 34552.95992912331	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_982
Epoch: 982	max: 0.9999777/1.0	min: 2.2240538e-05	loss: 34567.53125	train_loss: 34552.94538120897	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_983
Epoch: 983	max: 0.9999864/1.0	min: 1.3619261e-05	loss: 34567.6484375	train_loss: 34552.898020407534	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_984
Epoch: 984	max: 0.99996257/1.0	min: 3.7485253e-05	loss: 34567.57421875	train_loss: 34552.883233947265	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_985
Epoch: 985	max: 0.9999808/1.0	min: 1.9156501e-05	loss: 34567.31640625	train_loss: 34552.862039166044	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_986
Epoch: 986	max: 0.99998176/1.0	min: 1.819078e-05	loss: 34567.61328125	train_loss: 34552.870997944534	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_987
Epoch: 987	max: 0.9999691/1.0	min: 3.0830703e-05	loss: 34567.390625	train_loss: 34552.82723855754	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_988
Epoch: 988	max: 0.99996865/1.0	min: 3.1344407e-05	loss: 34567.44140625	train_loss: 34552.78646704292	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_989
Epoch: 989	max: 0.99997914/1.0	min: 2.0903086e-05	loss: 34567.296875	train_loss: 34552.80825407609	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_990
Epoch: 990	max: 0.99998295/1.0	min: 1.7044373e-05	loss: 34567.546875	train_loss: 34552.77138590827	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_991
Epoch: 991	max: 0.99997866/1.0	min: 2.1291908e-05	loss: 34567.62109375	train_loss: 34552.71411649944	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_992
Epoch: 992	max: 0.99998903/1.0	min: 1.1009055e-05	loss: 34567.65234375	train_loss: 34552.71127088366	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_993
Epoch: 993	max: 0.9999747/1.0	min: 2.522751e-05	loss: 34567.2734375	train_loss: 34552.694033642234	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_994
Epoch: 994	max: 0.999977/1.0	min: 2.3026088e-05	loss: 34567.36328125	train_loss: 34552.671965482936	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_995
Epoch: 995	max: 0.9999858/1.0	min: 1.4138058e-05	loss: 34567.515625	train_loss: 34552.64383496687	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_996
Epoch: 996	max: 0.99998045/1.0	min: 1.9573017e-05	loss: 34567.40625	train_loss: 34552.6216255187	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_997
Epoch: 997	max: 0.9999858/1.0	min: 1.4229743e-05	loss: 34567.68359375	train_loss: 34552.613274959745	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_998
Epoch: 998	max: 0.99998057/1.0	min: 1.9485968e-05	loss: 34567.2265625	train_loss: 34552.616331541096	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_999
Epoch: 999	max: 0.99998283/1.0	min: 1.7121756e-05	loss: 34567.21875	train_loss: 34552.5689417077	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1000
Epoch: 1000	max: 0.99995387/1.0	min: 4.6107027e-05	loss: 34567.22265625	train_loss: 34552.53561882587	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1001
Epoch: 1001	max: 0.9999808/1.0	min: 1.9184346e-05	loss: 34567.3359375	train_loss: 34552.531946767	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1002
Epoch: 1002	max: 0.9999809/1.0	min: 1.9063265e-05	loss: 34567.1796875	train_loss: 34552.50623993559	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1003
Epoch: 1003	max: 0.99998665/1.0	min: 1.3397431e-05	loss: 34567.09375	train_loss: 34552.4780044206	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1004
Epoch: 1004	max: 0.9999833/1.0	min: 1.6641594e-05	loss: 34567.20703125	train_loss: 34552.4533795135	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1005
Epoch: 1005	max: 0.9999685/1.0	min: 3.145946e-05	loss: 34567.2734375	train_loss: 34552.430902971326	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1006
Epoch: 1006	max: 0.9999846/1.0	min: 1.535708e-05	loss: 34567.44140625	train_loss: 34552.42932363279	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1007
Epoch: 1007	max: 0.9999795/1.0	min: 2.0492342e-05	loss: 34567.30859375	train_loss: 34552.41125317416	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1008
Epoch: 1008	max: 0.999969/1.0	min: 3.0957035e-05	loss: 34566.99609375	train_loss: 34552.40129327697	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1009
Epoch: 1009	max: 0.99997973/1.0	min: 2.0243233e-05	loss: 34567.37109375	train_loss: 34552.39661719621	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1010
Epoch: 1010	max: 0.99996746/1.0	min: 3.249417e-05	loss: 34567.265625	train_loss: 34552.36368189102	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1011
Epoch: 1011	max: 0.9999918/1.0	min: 8.18068e-06	loss: 34567.2109375	train_loss: 34552.32516180478	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1012
Epoch: 1012	max: 0.99996567/1.0	min: 3.4341054e-05	loss: 34567.06640625	train_loss: 34552.31648270082	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1013
Epoch: 1013	max: 0.9999931/1.0	min: 6.9590965e-06	loss: 34567.203125	train_loss: 34552.29429792983	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1014
Epoch: 1014	max: 0.9999738/1.0	min: 2.6205007e-05	loss: 34567.0234375	train_loss: 34552.31024421683	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1015
Epoch: 1015	max: 0.99998224/1.0	min: 1.7821363e-05	loss: 34567.09375	train_loss: 34552.30185881952	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1016
Epoch: 1016	max: 0.99999225/1.0	min: 7.788582e-06	loss: 34567.4609375	train_loss: 34552.22360559504	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1017
Epoch: 1017	max: 0.9999746/1.0	min: 2.5381762e-05	loss: 34566.90234375	train_loss: 34552.223167696335	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1018
Epoch: 1018	max: 0.99997354/1.0	min: 2.6477637e-05	loss: 34566.82421875	train_loss: 34552.19327300492	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1019
Epoch: 1019	max: 0.99996483/1.0	min: 3.5217075e-05	loss: 34566.890625	train_loss: 34552.1826168246	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1020
Epoch: 1020	max: 0.99997973/1.0	min: 2.0214355e-05	loss: 34566.875	train_loss: 34552.170689528364	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1021
Epoch: 1021	max: 0.9999672/1.0	min: 3.2776108e-05	loss: 34566.984375	train_loss: 34552.12806577481	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1022
Epoch: 1022	max: 0.9999857/1.0	min: 1.4331941e-05	loss: 34566.87890625	train_loss: 34552.16659892543	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1023
Epoch: 1023	max: 0.9999906/1.0	min: 9.43181e-06	loss: 34567.16015625	train_loss: 34552.11856845349	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1024
Epoch: 1024	max: 0.9999832/1.0	min: 1.6791542e-05	loss: 34567.03125	train_loss: 34552.10116137511	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1025
Epoch: 1025	max: 0.9999838/1.0	min: 1.6181702e-05	loss: 34567.015625	train_loss: 34552.0549860453	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1026
Epoch: 1026	max: 0.99998343/1.0	min: 1.6536911e-05	loss: 34566.74609375	train_loss: 34552.036206239165	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1027
Epoch: 1027	max: 0.99998415/1.0	min: 1.5902067e-05	loss: 34566.6953125	train_loss: 34552.01649499102	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1028
Epoch: 1028	max: 0.99997866/1.0	min: 2.1304175e-05	loss: 34566.9609375	train_loss: 34552.018965610674	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1029
Epoch: 1029	max: 0.9999902/1.0	min: 9.786142e-06	loss: 34567.73828125	train_loss: 34552.12577273396	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1030
Epoch: 1030	max: 0.99997675/1.0	min: 2.3297283e-05	loss: 34566.703125	train_loss: 34552.0678723639	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1031
Epoch: 1031	max: 0.9999819/1.0	min: 1.8120432e-05	loss: 34566.8046875	train_loss: 34551.977942485755	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1032
Epoch: 1032	max: 0.99999106/1.0	min: 8.992557e-06	loss: 34566.92578125	train_loss: 34551.974967193884	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1033
Epoch: 1033	max: 0.9999801/1.0	min: 1.9875475e-05	loss: 34566.62109375	train_loss: 34551.933187786446	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1034
Epoch: 1034	max: 0.9999726/1.0	min: 2.746572e-05	loss: 34567.17578125	train_loss: 34551.89565236746	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1035
Epoch: 1035	max: 0.9999882/1.0	min: 1.1856396e-05	loss: 34566.609375	train_loss: 34551.93250843862	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1036
Epoch: 1036	max: 0.9999788/1.0	min: 2.1219157e-05	loss: 34566.546875	train_loss: 34551.891240961384	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1037
Epoch: 1037	max: 0.9999751/1.0	min: 2.4866526e-05	loss: 34566.69921875	train_loss: 34551.908201915336	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1038
Epoch: 1038	max: 0.9999924/1.0	min: 7.60742e-06	loss: 34566.92578125	train_loss: 34551.8522636218	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1039
Epoch: 1039	max: 0.99997175/1.0	min: 2.824641e-05	loss: 34566.71875	train_loss: 34551.85073266985	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1040
Epoch: 1040	max: 0.9999738/1.0	min: 2.6220256e-05	loss: 34566.5234375	train_loss: 34551.798610627244	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1041
Epoch: 1041	max: 0.99998236/1.0	min: 1.7699653e-05	loss: 34566.59765625	train_loss: 34551.77395184953	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1042
Epoch: 1042	max: 0.99997985/1.0	min: 2.0153953e-05	loss: 34566.74609375	train_loss: 34551.76000199353	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1043
Epoch: 1043	max: 0.99996984/1.0	min: 3.0153547e-05	loss: 34566.5703125	train_loss: 34551.744235220795	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1044
Epoch: 1044	max: 0.9999825/1.0	min: 1.754961e-05	loss: 34566.52734375	train_loss: 34551.75191417379	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1045
Epoch: 1045	max: 0.99998605/1.0	min: 1.3890574e-05	loss: 34566.53125	train_loss: 34551.70511997941	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1046
Epoch: 1046	max: 0.99998367/1.0	min: 1.6365966e-05	loss: 34566.5546875	train_loss: 34551.684917123435	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1047
Epoch: 1047	max: 0.9999864/1.0	min: 1.3540314e-05	loss: 34566.3828125	train_loss: 34551.6819398961	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1048
Epoch: 1048	max: 0.99998057/1.0	min: 1.9435078e-05	loss: 34566.59375	train_loss: 34551.67253789638	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1049
Epoch: 1049	max: 0.9999751/1.0	min: 2.4971065e-05	loss: 34566.39453125	train_loss: 34551.64169676313	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1050
Epoch: 1050	max: 0.99998736/1.0	min: 1.2682701e-05	loss: 34566.53515625	train_loss: 34551.63696068298	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1051
Epoch: 1051	max: 0.9999647/1.0	min: 3.522997e-05	loss: 34566.85546875	train_loss: 34551.62221244813	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1052
Epoch: 1052	max: 0.9999896/1.0	min: 1.036703e-05	loss: 34566.453125	train_loss: 34551.59174389167	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1053
Epoch: 1053	max: 0.99998844/1.0	min: 1.1542887e-05	loss: 34566.44140625	train_loss: 34551.62267599173	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1054
Epoch: 1054	max: 0.9999542/1.0	min: 4.5725035e-05	loss: 34566.5859375	train_loss: 34551.56988573021	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1055
Epoch: 1055	max: 0.9999825/1.0	min: 1.758085e-05	loss: 34566.453125	train_loss: 34551.55567894138	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1056
Epoch: 1056	max: 0.99997854/1.0	min: 2.1513097e-05	loss: 34566.44921875	train_loss: 34551.52265363713	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1057
Epoch: 1057	max: 0.9999881/1.0	min: 1.1975703e-05	loss: 34566.828125	train_loss: 34551.51565596742	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1058
Epoch: 1058	max: 0.9999677/1.0	min: 3.2256747e-05	loss: 34566.328125	train_loss: 34551.56175000774	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1059
Epoch: 1059	max: 0.9999602/1.0	min: 3.9768533e-05	loss: 34566.44921875	train_loss: 34551.496179878144	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1060
Epoch: 1060	max: 0.9999883/1.0	min: 1.1659074e-05	loss: 34566.26171875	train_loss: 34551.46183458751	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1061
Epoch: 1061	max: 0.9999794/1.0	min: 2.0636644e-05	loss: 34566.203125	train_loss: 34551.44841359702	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1062
Epoch: 1062	max: 0.99998176/1.0	min: 1.8221666e-05	loss: 34566.58984375	train_loss: 34551.42761074725	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1063
Epoch: 1063	max: 0.9999795/1.0	min: 2.0490057e-05	loss: 34566.42578125	train_loss: 34551.41250832249	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1064
Epoch: 1064	max: 0.99998164/1.0	min: 1.8394729e-05	loss: 34566.26953125	train_loss: 34551.39691574151	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1065
Epoch: 1065	max: 0.99997365/1.0	min: 2.6381507e-05	loss: 34566.33984375	train_loss: 34551.41080124334	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1066
Epoch: 1066	max: 0.9999887/1.0	min: 1.1381515e-05	loss: 34566.09765625	train_loss: 34551.37313421281	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1067
Epoch: 1067	max: 0.9999925/1.0	min: 7.522894e-06	loss: 34566.34375	train_loss: 34551.36475317029	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1068
Epoch: 1068	max: 0.999982/1.0	min: 1.8058277e-05	loss: 34566.4609375	train_loss: 34551.365623161306	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1069
Epoch: 1069	max: 0.9999827/1.0	min: 1.7240185e-05	loss: 34566.49609375	train_loss: 34551.31684366484	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1070
Epoch: 1070	max: 0.9999913/1.0	min: 8.717533e-06	loss: 34566.21484375	train_loss: 34551.31674592391	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1071
Epoch: 1071	max: 0.9999733/1.0	min: 2.6666854e-05	loss: 34566.44140625	train_loss: 34551.29383245076	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1072
Epoch: 1072	max: 0.99997723/1.0	min: 2.2727078e-05	loss: 34566.42578125	train_loss: 34551.26095133857	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1073
Epoch: 1073	max: 0.99999106/1.0	min: 8.943261e-06	loss: 34566.06640625	train_loss: 34551.24318619937	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1074
Epoch: 1074	max: 0.999982/1.0	min: 1.8042252e-05	loss: 34566.17578125	train_loss: 34551.25390383067	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1075
Epoch: 1075	max: 0.9999807/1.0	min: 1.9348901e-05	loss: 34565.953125	train_loss: 34551.235304022666	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1076
Epoch: 1076	max: 0.9999833/1.0	min: 1.6737968e-05	loss: 34566.28515625	train_loss: 34551.226005570265	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1077
Epoch: 1077	max: 0.9999871/1.0	min: 1.2825736e-05	loss: 34566.11328125	train_loss: 34551.21032879661	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1078
Epoch: 1078	max: 0.9999864/1.0	min: 1.3620067e-05	loss: 34566.02734375	train_loss: 34551.164302013654	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1079
Epoch: 1079	max: 0.99997926/1.0	min: 2.0732787e-05	loss: 34566.03125	train_loss: 34551.1601122182	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1080
Epoch: 1080	max: 0.9999801/1.0	min: 1.9871932e-05	loss: 34565.94921875	train_loss: 34551.1567106404	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1081
Epoch: 1081	max: 0.9999784/1.0	min: 2.155834e-05	loss: 34566.2890625	train_loss: 34551.12682514245	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1082
Epoch: 1082	max: 0.99998915/1.0	min: 1.0829109e-05	loss: 34566.109375	train_loss: 34551.11622992924	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1083
Epoch: 1083	max: 0.9999713/1.0	min: 2.8676168e-05	loss: 34566.01171875	train_loss: 34551.09820930881	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1084
Epoch: 1084	max: 0.999982/1.0	min: 1.7950946e-05	loss: 34566.265625	train_loss: 34551.10548423371	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1085
Epoch: 1085	max: 0.99996865/1.0	min: 3.132836e-05	loss: 34566.03515625	train_loss: 34551.07453519835	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1086
Epoch: 1086	max: 0.9999881/1.0	min: 1.1933521e-05	loss: 34566.11328125	train_loss: 34551.064089983585	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1087
Epoch: 1087	max: 0.99997425/1.0	min: 2.5768282e-05	loss: 34565.87109375	train_loss: 34551.042588431344	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1088
Epoch: 1088	max: 0.99998534/1.0	min: 1.4721045e-05	loss: 34566.046875	train_loss: 34551.025358447914	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1089
Epoch: 1089	max: 0.99997604/1.0	min: 2.398226e-05	loss: 34566.6796875	train_loss: 34551.010775211354	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1090
Epoch: 1090	max: 0.9999529/1.0	min: 4.7072444e-05	loss: 34566.01953125	train_loss: 34551.0599432522	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1091
Epoch: 1091	max: 0.9999913/1.0	min: 8.761565e-06	loss: 34566.078125	train_loss: 34550.98934285194	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1092
Epoch: 1092	max: 0.999995/1.0	min: 5.0439057e-06	loss: 34566.2109375	train_loss: 34550.97715475195	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1093
Epoch: 1093	max: 0.99998/1.0	min: 2.0029333e-05	loss: 34566.1796875	train_loss: 34550.97623201954	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1094
Epoch: 1094	max: 0.999984/1.0	min: 1.5961443e-05	loss: 34565.8515625	train_loss: 34550.923616917506	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1095
Epoch: 1095	max: 0.9999658/1.0	min: 3.4242552e-05	loss: 34566.23828125	train_loss: 34550.89484431128	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1096
Epoch: 1096	max: 0.9999876/1.0	min: 1.2403544e-05	loss: 34565.90625	train_loss: 34550.89542543432	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1097
Epoch: 1097	max: 0.99998903/1.0	min: 1.0972235e-05	loss: 34565.75	train_loss: 34550.875662412516	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1098
Epoch: 1098	max: 0.9999882/1.0	min: 1.1744545e-05	loss: 34565.66015625	train_loss: 34550.85538746051	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1099
Epoch: 1099	max: 0.99998176/1.0	min: 1.8194736e-05	loss: 34565.71484375	train_loss: 34550.85285974467	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1100
Epoch: 1100	max: 0.9999503/1.0	min: 4.9718943e-05	loss: 34565.94921875	train_loss: 34550.856285515765	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1101
Epoch: 1101	max: 0.9999801/1.0	min: 1.9898347e-05	loss: 34565.69921875	train_loss: 34550.819902181654	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1102
Epoch: 1102	max: 0.9999906/1.0	min: 9.414664e-06	loss: 34566.11328125	train_loss: 34550.81470594497	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1103
Epoch: 1103	max: 0.9999763/1.0	min: 2.3767807e-05	loss: 34565.9140625	train_loss: 34550.82164942168	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1104
Epoch: 1104	max: 0.999992/1.0	min: 8.0254995e-06	loss: 34565.84375	train_loss: 34550.75847878344	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1105
Epoch: 1105	max: 0.9999474/1.0	min: 5.253351e-05	loss: 34565.9296875	train_loss: 34550.742220402884	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1106
Epoch: 1106	max: 0.9999862/1.0	min: 1.3791157e-05	loss: 34565.609375	train_loss: 34550.746506487674	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1107
Epoch: 1107	max: 0.99997103/1.0	min: 2.896898e-05	loss: 34565.6953125	train_loss: 34550.723569788956	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1108
Epoch: 1108	max: 0.9999814/1.0	min: 1.8572087e-05	loss: 34565.68359375	train_loss: 34550.71259232163	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1109
Epoch: 1109	max: 0.99997497/1.0	min: 2.5088577e-05	loss: 34565.4765625	train_loss: 34550.688672407254	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1110
Epoch: 1110	max: 0.9999877/1.0	min: 1.2259402e-05	loss: 34565.82421875	train_loss: 34550.70983235012	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1111
Epoch: 1111	max: 0.9999844/1.0	min: 1.5650638e-05	loss: 34565.65625	train_loss: 34550.674713357796	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1112
Epoch: 1112	max: 0.99998057/1.0	min: 1.9438135e-05	loss: 34565.83984375	train_loss: 34550.63477602812	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1113
Epoch: 1113	max: 0.9999714/1.0	min: 2.8655422e-05	loss: 34565.68359375	train_loss: 34550.624376296764	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1114
Epoch: 1114	max: 0.9999709/1.0	min: 2.9127517e-05	loss: 34565.6953125	train_loss: 34550.60002622553	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1115
Epoch: 1115	max: 0.9999871/1.0	min: 1.2924802e-05	loss: 34566.0859375	train_loss: 34550.58340542937	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1116
Epoch: 1116	max: 0.9999685/1.0	min: 3.1505035e-05	loss: 34565.6875	train_loss: 34550.634823446984	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1117
Epoch: 1117	max: 0.99999034/1.0	min: 9.659068e-06	loss: 34565.80859375	train_loss: 34550.55578829509	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1118
Epoch: 1118	max: 0.9999769/1.0	min: 2.3176159e-05	loss: 34565.42578125	train_loss: 34550.619418606	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1119
Epoch: 1119	max: 0.9999701/1.0	min: 2.9947902e-05	loss: 34565.7734375	train_loss: 34550.54300842701	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1120
Epoch: 1120	max: 0.99998283/1.0	min: 1.7172024e-05	loss: 34565.453125	train_loss: 34550.51820981203	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1121
Epoch: 1121	max: 0.99998116/1.0	min: 1.8856943e-05	loss: 34565.58984375	train_loss: 34550.510068767035	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1122
Epoch: 1122	max: 0.9999771/1.0	min: 2.2831697e-05	loss: 34565.53125	train_loss: 34550.47927214945	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1123
Epoch: 1123	max: 0.9999789/1.0	min: 2.1109905e-05	loss: 34565.54296875	train_loss: 34550.464499721296	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1124
Epoch: 1124	max: 0.99994564/1.0	min: 5.4365475e-05	loss: 34565.66015625	train_loss: 34550.435883403785	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1125
Epoch: 1125	max: 0.9999763/1.0	min: 2.3736251e-05	loss: 34565.43359375	train_loss: 34550.44424605939	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1126
Epoch: 1126	max: 0.9999908/1.0	min: 9.162242e-06	loss: 34565.48828125	train_loss: 34550.42967879041	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1127
Epoch: 1127	max: 0.99999/1.0	min: 9.992944e-06	loss: 34565.421875	train_loss: 34550.45771350102	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1128
Epoch: 1128	max: 0.99998367/1.0	min: 1.6336118e-05	loss: 34565.30078125	train_loss: 34550.3951597919	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1129
Epoch: 1129	max: 0.999992/1.0	min: 7.976603e-06	loss: 34565.44921875	train_loss: 34550.379258988294	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1130
Epoch: 1130	max: 0.9999788/1.0	min: 2.125531e-05	loss: 34565.41015625	train_loss: 34550.371389875974	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1131
Epoch: 1131	max: 0.99996185/1.0	min: 3.8134076e-05	loss: 34565.52734375	train_loss: 34550.36166997631	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1132
Epoch: 1132	max: 0.9999906/1.0	min: 9.418139e-06	loss: 34565.53515625	train_loss: 34550.32442536077	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1133
Epoch: 1133	max: 0.9999764/1.0	min: 2.355639e-05	loss: 34565.359375	train_loss: 34550.293559066486	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1134
Epoch: 1134	max: 0.9999809/1.0	min: 1.9028988e-05	loss: 34565.359375	train_loss: 34550.31197452155	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1135
Epoch: 1135	max: 0.99999166/1.0	min: 8.286185e-06	loss: 34565.234375	train_loss: 34550.268102393784	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1136
Epoch: 1136	max: 0.9999821/1.0	min: 1.7861925e-05	loss: 34565.55859375	train_loss: 34550.25238497538	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1137
Epoch: 1137	max: 0.9999821/1.0	min: 1.7914024e-05	loss: 34565.2421875	train_loss: 34550.260315538675	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1138
Epoch: 1138	max: 0.9999856/1.0	min: 1.4367822e-05	loss: 34565.23046875	train_loss: 34550.254282213864	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1139
Epoch: 1139	max: 0.9999802/1.0	min: 1.9767334e-05	loss: 34565.26171875	train_loss: 34550.235698373435	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1140
Epoch: 1140	max: 0.99999297/1.0	min: 7.076713e-06	loss: 34565.4140625	train_loss: 34550.190549323364	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1141
Epoch: 1141	max: 0.9999925/1.0	min: 7.526016e-06	loss: 34565.3984375	train_loss: 34550.19534588675	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1142
Epoch: 1142	max: 0.99998295/1.0	min: 1.706301e-05	loss: 34565.51171875	train_loss: 34550.18568937353	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1143
Epoch: 1143	max: 0.9999871/1.0	min: 1.2923225e-05	loss: 34565.37109375	train_loss: 34550.174673196925	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1144
Epoch: 1144	max: 0.9999703/1.0	min: 2.9741106e-05	loss: 34565.17578125	train_loss: 34550.194097996406	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1145
Epoch: 1145	max: 0.9999831/1.0	min: 1.6901287e-05	loss: 34565.06640625	train_loss: 34550.13628859315	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1146
Epoch: 1146	max: 0.99999607/1.0	min: 3.9567312e-06	loss: 34565.51171875	train_loss: 34550.11522493961	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1147
Epoch: 1147	max: 0.99996805/1.0	min: 3.1932257e-05	loss: 34565.390625	train_loss: 34550.100615574294	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1148
Epoch: 1148	max: 0.99997807/1.0	min: 2.1981039e-05	loss: 34565.0625	train_loss: 34550.064406431935	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1149
Epoch: 1149	max: 0.99997926/1.0	min: 2.0789572e-05	loss: 34565.1640625	train_loss: 34550.060142604976	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1150
Epoch: 1150	max: 0.99998605/1.0	min: 1.3988868e-05	loss: 34565.08203125	train_loss: 34550.04859078874	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1151
Epoch: 1151	max: 0.99998295/1.0	min: 1.7023709e-05	loss: 34564.98046875	train_loss: 34550.01658934489	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1152
Epoch: 1152	max: 0.9999901/1.0	min: 9.909251e-06	loss: 34565.078125	train_loss: 34550.03955797876	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1153
Epoch: 1153	max: 0.9999831/1.0	min: 1.6961225e-05	loss: 34564.98046875	train_loss: 34550.02289702171	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1154
Epoch: 1154	max: 0.9999788/1.0	min: 2.1214626e-05	loss: 34565.0703125	train_loss: 34549.97317156726	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1155
Epoch: 1155	max: 0.9999894/1.0	min: 1.0642967e-05	loss: 34565.49609375	train_loss: 34549.99556923928	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1156
Epoch: 1156	max: 0.9999789/1.0	min: 2.1111435e-05	loss: 34564.93359375	train_loss: 34549.957070443146	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1157
Epoch: 1157	max: 0.9999877/1.0	min: 1.2244483e-05	loss: 34565.25	train_loss: 34549.955072560544	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1158
Epoch: 1158	max: 0.999974/1.0	min: 2.5991192e-05	loss: 34565.078125	train_loss: 34549.90803594931	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1159
Epoch: 1159	max: 0.9999771/1.0	min: 2.2926786e-05	loss: 34565.05078125	train_loss: 34549.89993216199	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1160
Epoch: 1160	max: 0.99997675/1.0	min: 2.3218632e-05	loss: 34564.8984375	train_loss: 34549.897982665985	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1161
Epoch: 1161	max: 0.9999881/1.0	min: 1.1934955e-05	loss: 34564.8515625	train_loss: 34549.861982069866	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1162
Epoch: 1162	max: 0.99998677/1.0	min: 1.3234152e-05	loss: 34564.90234375	train_loss: 34549.848467693235	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1163
Epoch: 1163	max: 0.99998903/1.0	min: 1.0983123e-05	loss: 34564.96484375	train_loss: 34549.85514746299	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1164
Epoch: 1164	max: 0.9999931/1.0	min: 6.9632524e-06	loss: 34564.8203125	train_loss: 34549.80475378964	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1165
Epoch: 1165	max: 0.9999795/1.0	min: 2.05029e-05	loss: 34564.80859375	train_loss: 34549.81998250341	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1166
Epoch: 1166	max: 0.9999865/1.0	min: 1.3528337e-05	loss: 34564.796875	train_loss: 34549.824329071445	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1167
Epoch: 1167	max: 0.9999956/1.0	min: 4.3995096e-06	loss: 34565.13671875	train_loss: 34549.77593279682	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1168
Epoch: 1168	max: 0.9999856/1.0	min: 1.4443877e-05	loss: 34564.74609375	train_loss: 34549.75672428543	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1169
Epoch: 1169	max: 0.9999969/1.0	min: 3.1451007e-06	loss: 34564.87890625	train_loss: 34549.73592627431	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1170
Epoch: 1170	max: 0.9999925/1.0	min: 7.4813547e-06	loss: 34564.73828125	train_loss: 34549.735405150655	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1171
Epoch: 1171	max: 0.9999881/1.0	min: 1.1937892e-05	loss: 34564.640625	train_loss: 34549.70243452326	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1172
Epoch: 1172	max: 0.9999931/1.0	min: 6.9118055e-06	loss: 34564.80078125	train_loss: 34549.69171350489	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1173
Epoch: 1173	max: 0.9999939/1.0	min: 6.0942334e-06	loss: 34564.63671875	train_loss: 34549.67763881147	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1174
Epoch: 1174	max: 0.99998677/1.0	min: 1.3223933e-05	loss: 34564.6953125	train_loss: 34549.657099184784	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1175
Epoch: 1175	max: 0.9999933/1.0	min: 6.6709486e-06	loss: 34564.86328125	train_loss: 34549.64808185851	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1176
Epoch: 1176	max: 0.99999523/1.0	min: 4.8121497e-06	loss: 34564.7109375	train_loss: 34549.60951822433	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1177
Epoch: 1177	max: 0.9999956/1.0	min: 4.358883e-06	loss: 34564.80859375	train_loss: 34549.618196360556	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1178
Epoch: 1178	max: 0.99997675/1.0	min: 2.3263716e-05	loss: 34564.6796875	train_loss: 34549.62418613744	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1179
Epoch: 1179	max: 0.9999893/1.0	min: 1.075708e-05	loss: 34564.859375	train_loss: 34549.60238700762	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1180
Epoch: 1180	max: 0.99999404/1.0	min: 5.99286e-06	loss: 34564.74609375	train_loss: 34549.570456208196	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1181
Epoch: 1181	max: 0.9999887/1.0	min: 1.13258175e-05	loss: 34564.4765625	train_loss: 34549.54115812353	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1182
Epoch: 1182	max: 0.9999777/1.0	min: 2.2244845e-05	loss: 34564.87109375	train_loss: 34549.532931918126	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1183
Epoch: 1183	max: 0.99999/1.0	min: 1.0065827e-05	loss: 34564.4296875	train_loss: 34549.51345244178	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1184
Epoch: 1184	max: 0.9999813/1.0	min: 1.8743023e-05	loss: 34564.4609375	train_loss: 34549.47306705221	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1185
Epoch: 1185	max: 0.9999908/1.0	min: 9.200382e-06	loss: 34564.64453125	train_loss: 34549.51055795553	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1186
Epoch: 1186	max: 0.9999814/1.0	min: 1.8583833e-05	loss: 34564.3515625	train_loss: 34549.50045386628	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1187
Epoch: 1187	max: 0.99998426/1.0	min: 1.579405e-05	loss: 34564.41015625	train_loss: 34549.441585764274	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1188
Epoch: 1188	max: 0.9999957/1.0	min: 4.3485697e-06	loss: 34564.38671875	train_loss: 34549.47101546048	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1189
Epoch: 1189	max: 0.9999813/1.0	min: 1.8713337e-05	loss: 34564.41015625	train_loss: 34549.43942336724	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1190
Epoch: 1190	max: 0.99999166/1.0	min: 8.331605e-06	loss: 34564.4453125	train_loss: 34549.38113832373	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1191
Epoch: 1191	max: 0.9999914/1.0	min: 8.551115e-06	loss: 34564.66796875	train_loss: 34549.35322506348	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1192
Epoch: 1192	max: 0.99999404/1.0	min: 5.968535e-06	loss: 34564.21484375	train_loss: 34549.35648390081	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1193
Epoch: 1193	max: 0.9999826/1.0	min: 1.742259e-05	loss: 34564.53125	train_loss: 34549.33203366933	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1194
Epoch: 1194	max: 0.9999895/1.0	min: 1.0437454e-05	loss: 34564.30078125	train_loss: 34549.31174226588	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1195
Epoch: 1195	max: 0.99999404/1.0	min: 6.0102543e-06	loss: 34564.44140625	train_loss: 34549.29183553589	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1196
Epoch: 1196	max: 0.99999166/1.0	min: 8.365634e-06	loss: 34564.40625	train_loss: 34549.28411932522	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1197
Epoch: 1197	max: 0.99998796/1.0	min: 1.2014401e-05	loss: 34564.734375	train_loss: 34549.254528985504	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1198
Epoch: 1198	max: 0.9999912/1.0	min: 8.827848e-06	loss: 34564.30078125	train_loss: 34549.26619209092	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1199
Epoch: 1199	max: 0.99997926/1.0	min: 2.0714111e-05	loss: 34564.2890625	train_loss: 34549.21660066735	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1200
Epoch: 1200	max: 0.99998915/1.0	min: 1.0850592e-05	loss: 34564.0390625	train_loss: 34549.22399317168	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1201
Epoch: 1201	max: 0.9999927/1.0	min: 7.301976e-06	loss: 34564.0859375	train_loss: 34549.286817361884	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1202
Epoch: 1202	max: 0.99999213/1.0	min: 7.898839e-06	loss: 34564.26171875	train_loss: 34549.182111668524	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1203
Epoch: 1203	max: 0.99999225/1.0	min: 7.783279e-06	loss: 34564.29296875	train_loss: 34549.152951969525	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1204
Epoch: 1204	max: 0.99998736/1.0	min: 1.2576565e-05	loss: 34564.0546875	train_loss: 34549.16738907857	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1205
Epoch: 1205	max: 0.99999654/1.0	min: 3.5144358e-06	loss: 34564.08984375	train_loss: 34549.14224208008	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1206
Epoch: 1206	max: 0.99998677/1.0	min: 1.3213937e-05	loss: 34564.04296875	train_loss: 34549.130034141584	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1207
Epoch: 1207	max: 0.99999285/1.0	min: 7.1347254e-06	loss: 34564.40625	train_loss: 34549.1481375031	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1208
Epoch: 1208	max: 0.9999894/1.0	min: 1.05783765e-05	loss: 34564.03515625	train_loss: 34549.09792721494	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1209
Epoch: 1209	max: 0.99998736/1.0	min: 1.2598869e-05	loss: 34564.109375	train_loss: 34549.06594319026	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1210
Epoch: 1210	max: 0.99999464/1.0	min: 5.3191698e-06	loss: 34564.39453125	train_loss: 34549.07682194893	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1211
Epoch: 1211	max: 0.99998665/1.0	min: 1.3291701e-05	loss: 34563.98828125	train_loss: 34549.054127183204	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1212
Epoch: 1212	max: 0.9999932/1.0	min: 6.8259674e-06	loss: 34564.0390625	train_loss: 34549.04953964991	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1213
Epoch: 1213	max: 0.999987/1.0	min: 1.2948475e-05	loss: 34564.19140625	train_loss: 34549.013226476374	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1214
Epoch: 1214	max: 0.9999932/1.0	min: 6.852429e-06	loss: 34563.99609375	train_loss: 34548.98669029868	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1215
Epoch: 1215	max: 0.999995/1.0	min: 4.992403e-06	loss: 34563.93359375	train_loss: 34548.97318124458	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1216
Epoch: 1216	max: 0.99999416/1.0	min: 5.8715655e-06	loss: 34564.1484375	train_loss: 34549.02333104949	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1217
Epoch: 1217	max: 0.99998045/1.0	min: 1.951129e-05	loss: 34564.0546875	train_loss: 34548.98483418881	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1218
Epoch: 1218	max: 0.9999932/1.0	min: 6.8033833e-06	loss: 34564.07421875	train_loss: 34548.94026142311	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1219
Epoch: 1219	max: 0.9999963/1.0	min: 3.7460231e-06	loss: 34563.8046875	train_loss: 34548.9240136876	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1220
Epoch: 1220	max: 0.99999344/1.0	min: 6.5217578e-06	loss: 34564.05859375	train_loss: 34548.92379739951	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1221
Epoch: 1221	max: 0.99999213/1.0	min: 7.883998e-06	loss: 34564.12109375	train_loss: 34548.92124113558	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1222
Epoch: 1222	max: 0.9999845/1.0	min: 1.5440166e-05	loss: 34563.92578125	train_loss: 34548.89897846216	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1223
Epoch: 1223	max: 0.999992/1.0	min: 8.015258e-06	loss: 34563.9765625	train_loss: 34548.86490510421	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1224
Epoch: 1224	max: 0.9999907/1.0	min: 9.33896e-06	loss: 34563.9453125	train_loss: 34548.84095228694	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1225
Epoch: 1225	max: 0.9999887/1.0	min: 1.1349151e-05	loss: 34563.8359375	train_loss: 34548.83019788183	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1226
Epoch: 1226	max: 0.9999913/1.0	min: 8.727964e-06	loss: 34563.7734375	train_loss: 34548.819623474854	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1227
Epoch: 1227	max: 0.9999862/1.0	min: 1.3780191e-05	loss: 34563.85546875	train_loss: 34548.80192559303	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1228
Epoch: 1228	max: 0.99999833/1.0	min: 1.689865e-06	loss: 34563.98828125	train_loss: 34548.79385616019	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1229
Epoch: 1229	max: 0.999992/1.0	min: 8.018912e-06	loss: 34564.046875	train_loss: 34548.78691316735	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1230
Epoch: 1230	max: 0.9999914/1.0	min: 8.523896e-06	loss: 34564.08203125	train_loss: 34548.75040838288	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1231
Epoch: 1231	max: 0.99998486/1.0	min: 1.5137432e-05	loss: 34563.9296875	train_loss: 34548.7591107124	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1232
Epoch: 1232	max: 0.9999957/1.0	min: 4.2602983e-06	loss: 34563.6953125	train_loss: 34548.73365307197	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1233
Epoch: 1233	max: 0.99999475/1.0	min: 5.276367e-06	loss: 34563.89453125	train_loss: 34548.71864113016	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1234
Epoch: 1234	max: 0.9999957/1.0	min: 4.3110267e-06	loss: 34563.921875	train_loss: 34548.714926491084	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1235
Epoch: 1235	max: 0.999997/1.0	min: 3.0223796e-06	loss: 34563.7109375	train_loss: 34548.69376074182	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1236
Epoch: 1236	max: 0.9999975/1.0	min: 2.4815356e-06	loss: 34563.76953125	train_loss: 34548.695876203856	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1237
Epoch: 1237	max: 0.9999919/1.0	min: 8.082382e-06	loss: 34563.734375	train_loss: 34548.6770596239	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1238
Epoch: 1238	max: 0.99998665/1.0	min: 1.3366803e-05	loss: 34563.8984375	train_loss: 34548.63608198238	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1239
Epoch: 1239	max: 0.9999944/1.0	min: 5.6057183e-06	loss: 34563.796875	train_loss: 34548.65405131302	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1240
Epoch: 1240	max: 0.9999845/1.0	min: 1.5450934e-05	loss: 34563.73828125	train_loss: 34548.62407823532	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1241
Epoch: 1241	max: 0.9999933/1.0	min: 6.7198594e-06	loss: 34563.81640625	train_loss: 34548.607006476064	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1242
Epoch: 1242	max: 0.9999945/1.0	min: 5.457704e-06	loss: 34563.9453125	train_loss: 34548.61450833411	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1243
Epoch: 1243	max: 0.99998295/1.0	min: 1.704782e-05	loss: 34563.625	train_loss: 34548.61303592995	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1244
Epoch: 1244	max: 0.99999845/1.0	min: 1.5257157e-06	loss: 34563.78125	train_loss: 34548.638763083734	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1245
Epoch: 1245	max: 0.99998724/1.0	min: 1.2741872e-05	loss: 34563.76171875	train_loss: 34548.60773033956	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1246
Epoch: 1246	max: 0.9999901/1.0	min: 9.879492e-06	loss: 34563.64453125	train_loss: 34548.55018464325	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1247
Epoch: 1247	max: 0.99999213/1.0	min: 7.860379e-06	loss: 34563.63671875	train_loss: 34548.51894722377	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1248
Epoch: 1248	max: 0.9999956/1.0	min: 4.3616938e-06	loss: 34563.46875	train_loss: 34548.521188974824	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1249
Epoch: 1249	max: 0.9999964/1.0	min: 3.5738262e-06	loss: 34563.578125	train_loss: 34548.49848404791	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1250
Epoch: 1250	max: 0.99998784/1.0	min: 1.21888625e-05	loss: 34563.5703125	train_loss: 34548.50100692509	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1251
Epoch: 1251	max: 0.9999957/1.0	min: 4.2588317e-06	loss: 34563.35546875	train_loss: 34548.48002698037	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1252
Epoch: 1252	max: 0.99999595/1.0	min: 4.018711e-06	loss: 34563.578125	train_loss: 34548.46596535132	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1253
Epoch: 1253	max: 0.9999949/1.0	min: 5.1646016e-06	loss: 34563.30859375	train_loss: 34548.47807748436	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1254
Epoch: 1254	max: 0.9999963/1.0	min: 3.677586e-06	loss: 34563.81640625	train_loss: 34548.47148964914	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1255
Epoch: 1255	max: 0.9999893/1.0	min: 1.0748968e-05	loss: 34563.4609375	train_loss: 34548.45440530936	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1256
Epoch: 1256	max: 0.99999666/1.0	min: 3.280642e-06	loss: 34563.5390625	train_loss: 34548.5391321767	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1257
Epoch: 1257	max: 0.99998593/1.0	min: 1.4025896e-05	loss: 34563.5	train_loss: 34548.43350568639	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1258
Epoch: 1258	max: 0.99999595/1.0	min: 4.0706336e-06	loss: 34563.53125	train_loss: 34548.39293497615	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1259
Epoch: 1259	max: 0.9999958/1.0	min: 4.1728717e-06	loss: 34563.5390625	train_loss: 34548.37085568794	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1260
Epoch: 1260	max: 0.9999945/1.0	min: 5.4601924e-06	loss: 34563.36328125	train_loss: 34548.35626664499	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1261
Epoch: 1261	max: 0.99999213/1.0	min: 7.905598e-06	loss: 34563.390625	train_loss: 34548.35361941425	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1262
Epoch: 1262	max: 0.99999404/1.0	min: 5.9510967e-06	loss: 34563.35546875	train_loss: 34548.345285306736	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1263
Epoch: 1263	max: 0.9999949/1.0	min: 5.0998146e-06	loss: 34563.3515625	train_loss: 34548.32701646306	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1264
Epoch: 1264	max: 0.9999908/1.0	min: 9.225079e-06	loss: 34563.5	train_loss: 34548.31423224018	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1265
Epoch: 1265	max: 0.999997/1.0	min: 2.9460714e-06	loss: 34563.14453125	train_loss: 34548.322561025176	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1266
Epoch: 1266	max: 0.9999988/1.0	min: 1.194405e-06	loss: 34563.546875	train_loss: 34548.33127545135	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1267
Epoch: 1267	max: 0.9999962/1.0	min: 3.8353623e-06	loss: 34563.234375	train_loss: 34548.31988282702	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1268
Epoch: 1268	max: 0.99999404/1.0	min: 5.943349e-06	loss: 34563.6640625	train_loss: 34548.27421023396	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1269
Epoch: 1269	max: 0.9999931/1.0	min: 6.9081943e-06	loss: 34563.28125	train_loss: 34548.28868266521	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1270
Epoch: 1270	max: 0.99999046/1.0	min: 9.560434e-06	loss: 34563.41015625	train_loss: 34548.25044128577	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1271
Epoch: 1271	max: 0.99999464/1.0	min: 5.3431772e-06	loss: 34563.57421875	train_loss: 34548.312108552425	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1272
Epoch: 1272	max: 0.9999932/1.0	min: 6.836039e-06	loss: 34563.48046875	train_loss: 34548.251615628484	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1273
Epoch: 1273	max: 0.9999968/1.0	min: 3.2667554e-06	loss: 34563.05078125	train_loss: 34548.22920392435	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1274
Epoch: 1274	max: 0.9999943/1.0	min: 5.780315e-06	loss: 34563.28125	train_loss: 34548.19225591865	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1275
Epoch: 1275	max: 0.99999166/1.0	min: 8.399514e-06	loss: 34563.33984375	train_loss: 34548.199605842776	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1276
Epoch: 1276	max: 0.9999939/1.0	min: 6.0906486e-06	loss: 34563.109375	train_loss: 34548.16173800787	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1277
Epoch: 1277	max: 0.9999945/1.0	min: 5.49869e-06	loss: 34563.14453125	train_loss: 34548.16988389152	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1278
Epoch: 1278	max: 0.9999957/1.0	min: 4.319504e-06	loss: 34563.3359375	train_loss: 34548.154742273626	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1279
Epoch: 1279	max: 0.99999213/1.0	min: 7.925323e-06	loss: 34563.0625	train_loss: 34548.130173011115	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1280
Epoch: 1280	max: 0.9999944/1.0	min: 5.554695e-06	loss: 34563.28515625	train_loss: 34548.10822872151	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1281
Epoch: 1281	max: 0.9999976/1.0	min: 2.3762093e-06	loss: 34563.234375	train_loss: 34548.11197142481	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1282
Epoch: 1282	max: 0.99999666/1.0	min: 3.38208e-06	loss: 34563.28125	train_loss: 34548.10247410349	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1283
Epoch: 1283	max: 0.99999654/1.0	min: 3.4762288e-06	loss: 34563.0859375	train_loss: 34548.075094547414	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1284
Epoch: 1284	max: 0.99999535/1.0	min: 4.649928e-06	loss: 34563.25390625	train_loss: 34548.09158663524	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1285
Epoch: 1285	max: 0.9999856/1.0	min: 1.4418443e-05	loss: 34563.18359375	train_loss: 34548.05315122553	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1286
Epoch: 1286	max: 0.99999857/1.0	min: 1.4602339e-06	loss: 34563.06640625	train_loss: 34548.126635466986	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1287
Epoch: 1287	max: 0.99999845/1.0	min: 1.5518867e-06	loss: 34562.99609375	train_loss: 34548.069651055215	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1288
Epoch: 1288	max: 0.99999535/1.0	min: 4.702901e-06	loss: 34563.18359375	train_loss: 34548.03792880203	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1289
Epoch: 1289	max: 0.99999654/1.0	min: 3.4814973e-06	loss: 34563.0234375	train_loss: 34548.02907453859	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1290
Epoch: 1290	max: 0.9999956/1.0	min: 4.4012595e-06	loss: 34563.0859375	train_loss: 34547.99215895191	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1291
Epoch: 1291	max: 0.99999344/1.0	min: 6.5884788e-06	loss: 34563.34375	train_loss: 34547.99849614456	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1292
Epoch: 1292	max: 0.9999981/1.0	min: 1.9016645e-06	loss: 34563.37109375	train_loss: 34547.99162040908	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1293
Epoch: 1293	max: 0.9999883/1.0	min: 1.1642518e-05	loss: 34563.21484375	train_loss: 34547.979788434444	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1294
Epoch: 1294	max: 0.99999845/1.0	min: 1.5397085e-06	loss: 34563.04296875	train_loss: 34547.96437198068	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1295
Epoch: 1295	max: 0.9999907/1.0	min: 9.311905e-06	loss: 34563.07421875	train_loss: 34547.954588210705	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1296
Epoch: 1296	max: 0.9999974/1.0	min: 2.60316e-06	loss: 34562.96875	train_loss: 34547.916288767345	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1297
Epoch: 1297	max: 0.99999666/1.0	min: 3.295147e-06	loss: 34563.24609375	train_loss: 34547.9366837181	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1298
Epoch: 1298	max: 0.99999523/1.0	min: 4.8035295e-06	loss: 34562.81640625	train_loss: 34547.89407593212	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1299
Epoch: 1299	max: 0.99998426/1.0	min: 1.5751588e-05	loss: 34563.078125	train_loss: 34547.87887866964	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1300
Epoch: 1300	max: 0.9999989/1.0	min: 1.0373075e-06	loss: 34562.921875	train_loss: 34547.92604350536	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1301
Epoch: 1301	max: 0.9999957/1.0	min: 4.244733e-06	loss: 34562.80078125	train_loss: 34547.865191068995	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1302
Epoch: 1302	max: 0.9999962/1.0	min: 3.867427e-06	loss: 34563.06640625	train_loss: 34547.85041525378	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1303
Epoch: 1303	max: 0.9999945/1.0	min: 5.492584e-06	loss: 34562.86328125	train_loss: 34547.81006083163	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1304
Epoch: 1304	max: 0.9999975/1.0	min: 2.5466368e-06	loss: 34563.06640625	train_loss: 34547.807621179396	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1305
Epoch: 1305	max: 0.9999962/1.0	min: 3.844444e-06	loss: 34562.8359375	train_loss: 34547.79097280286	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1306
Epoch: 1306	max: 0.99999774/1.0	min: 2.2997956e-06	loss: 34563.140625	train_loss: 34547.775566026416	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1307
Epoch: 1307	max: 0.9999968/1.0	min: 3.2284318e-06	loss: 34562.78125	train_loss: 34547.8268224328	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1308
Epoch: 1308	max: 0.99999905/1.0	min: 1.000222e-06	loss: 34562.6640625	train_loss: 34547.73376726434	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1309
Epoch: 1309	max: 0.99999607/1.0	min: 3.8906355e-06	loss: 34562.74609375	train_loss: 34547.74741325251	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1310
Epoch: 1310	max: 0.9999963/1.0	min: 3.7456016e-06	loss: 34562.69140625	train_loss: 34547.693288488634	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1311
Epoch: 1311	max: 0.9999982/1.0	min: 1.8315603e-06	loss: 34562.82421875	train_loss: 34547.67111871749	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1312
Epoch: 1312	max: 0.99999654/1.0	min: 3.4373352e-06	loss: 34562.484375	train_loss: 34547.66768133361	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1313
Epoch: 1313	max: 0.9999951/1.0	min: 4.9395794e-06	loss: 34562.63671875	train_loss: 34547.68841450669	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1314
Epoch: 1314	max: 0.9999956/1.0	min: 4.4122917e-06	loss: 34562.7421875	train_loss: 34547.64420899526	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1315
Epoch: 1315	max: 0.99999785/1.0	min: 2.1376538e-06	loss: 34562.67578125	train_loss: 34547.623578885636	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1316
Epoch: 1316	max: 0.99999654/1.0	min: 3.4724483e-06	loss: 34562.63671875	train_loss: 34547.58363623343	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1317
Epoch: 1317	max: 0.9999958/1.0	min: 4.1469584e-06	loss: 34562.7265625	train_loss: 34547.55308735523	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1318
Epoch: 1318	max: 0.99999404/1.0	min: 5.990323e-06	loss: 34562.49609375	train_loss: 34547.555379912206	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1319
Epoch: 1319	max: 0.9999964/1.0	min: 3.5195874e-06	loss: 34562.515625	train_loss: 34547.53092193887	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1320
Epoch: 1320	max: 0.9999956/1.0	min: 4.434857e-06	loss: 34562.5078125	train_loss: 34547.49261862458	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1321
Epoch: 1321	max: 0.99998355/1.0	min: 1.6424157e-05	loss: 34562.75390625	train_loss: 34547.4994624249	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1322
Epoch: 1322	max: 0.9999982/1.0	min: 1.7376789e-06	loss: 34562.328125	train_loss: 34547.484944026386	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1323
Epoch: 1323	max: 0.9999858/1.0	min: 1.4181203e-05	loss: 34562.49609375	train_loss: 34547.47849796389	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1324
Epoch: 1324	max: 0.9999914/1.0	min: 8.597356e-06	loss: 34562.43359375	train_loss: 34547.46104927304	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1325
Epoch: 1325	max: 0.9999957/1.0	min: 4.3260925e-06	loss: 34562.21484375	train_loss: 34547.398629110925	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1326
Epoch: 1326	max: 0.9999958/1.0	min: 4.2196407e-06	loss: 34562.5234375	train_loss: 34547.40147762991	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1327
Epoch: 1327	max: 0.99999416/1.0	min: 5.8728424e-06	loss: 34562.359375	train_loss: 34547.38898082342	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1328
Epoch: 1328	max: 0.999998/1.0	min: 2.0269924e-06	loss: 34562.38671875	train_loss: 34547.36589219079	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1329
Epoch: 1329	max: 0.99998426/1.0	min: 1.5774318e-05	loss: 34562.42578125	train_loss: 34547.372380349625	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1330
Epoch: 1330	max: 0.99999654/1.0	min: 3.465101e-06	loss: 34562.375	train_loss: 34547.31721479004	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1331
Epoch: 1331	max: 0.99999607/1.0	min: 3.8878097e-06	loss: 34562.38671875	train_loss: 34547.28419432444	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1332
Epoch: 1332	max: 0.9999976/1.0	min: 2.432738e-06	loss: 34562.30859375	train_loss: 34547.26800658832	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1333
Epoch: 1333	max: 0.9999968/1.0	min: 3.1925363e-06	loss: 34562.05859375	train_loss: 34547.285492052986	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1334
Epoch: 1334	max: 0.9999989/1.0	min: 1.1300615e-06	loss: 34562.0703125	train_loss: 34547.257968304846	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1335
Epoch: 1335	max: 0.99999464/1.0	min: 5.3376466e-06	loss: 34562.3984375	train_loss: 34547.230303751705	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1336
Epoch: 1336	max: 0.9999974/1.0	min: 2.582301e-06	loss: 34562.1171875	train_loss: 34547.1945673464	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1337
Epoch: 1337	max: 0.9999957/1.0	min: 4.278188e-06	loss: 34562.2890625	train_loss: 34547.16989018178	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1338
Epoch: 1338	max: 0.99999213/1.0	min: 7.913201e-06	loss: 34562.11328125	train_loss: 34547.17961685557	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1339
Epoch: 1339	max: 0.9999945/1.0	min: 5.5181e-06	loss: 34562.3203125	train_loss: 34547.14259046358	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1340
Epoch: 1340	max: 0.9999949/1.0	min: 5.097792e-06	loss: 34561.9609375	train_loss: 34547.12311098724	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1341
Epoch: 1341	max: 0.9999981/1.0	min: 1.8874056e-06	loss: 34562.359375	train_loss: 34547.118657484825	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1342
Epoch: 1342	max: 0.99999046/1.0	min: 9.52862e-06	loss: 34562.1015625	train_loss: 34547.183486331756	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1343
Epoch: 1343	max: 0.9999982/1.0	min: 1.732569e-06	loss: 34561.92578125	train_loss: 34547.08821989579	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1344
Epoch: 1344	max: 0.99999857/1.0	min: 1.3996297e-06	loss: 34561.80859375	train_loss: 34547.051856884056	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1345
Epoch: 1345	max: 0.99998975/1.0	min: 1.0201692e-05	loss: 34562.05859375	train_loss: 34547.08087142326	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1346
Epoch: 1346	max: 0.9999976/1.0	min: 2.3718937e-06	loss: 34562.2265625	train_loss: 34547.028908088694	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1347
Epoch: 1347	max: 0.9999958/1.0	min: 4.173127e-06	loss: 34561.96484375	train_loss: 34547.03885588923	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1348
Epoch: 1348	max: 0.9999932/1.0	min: 6.763398e-06	loss: 34561.921875	train_loss: 34546.989852362814	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1349
Epoch: 1349	max: 0.99999726/1.0	min: 2.7223234e-06	loss: 34561.640625	train_loss: 34546.95567739301	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1350
Epoch: 1350	max: 0.99999785/1.0	min: 2.1989847e-06	loss: 34561.9140625	train_loss: 34546.94642442401	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1351
Epoch: 1351	max: 0.99999726/1.0	min: 2.7234373e-06	loss: 34561.8515625	train_loss: 34546.92283547395	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1352
Epoch: 1352	max: 0.9999908/1.0	min: 9.234578e-06	loss: 34561.75390625	train_loss: 34546.96454278537	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1353
Epoch: 1353	max: 0.9999949/1.0	min: 5.1777793e-06	loss: 34561.7109375	train_loss: 34546.90964915846	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1354
Epoch: 1354	max: 0.99999654/1.0	min: 3.4684367e-06	loss: 34561.81640625	train_loss: 34546.88759745061	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1355
Epoch: 1355	max: 0.9999962/1.0	min: 3.8262215e-06	loss: 34561.46484375	train_loss: 34546.85452424362	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1356
Epoch: 1356	max: 0.99999785/1.0	min: 2.1279718e-06	loss: 34561.75390625	train_loss: 34546.87703562415	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1357
Epoch: 1357	max: 0.9999919/1.0	min: 8.100145e-06	loss: 34561.75	train_loss: 34546.85082799145	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1358
Epoch: 1358	max: 0.9999989/1.0	min: 1.0567894e-06	loss: 34561.4765625	train_loss: 34546.82826919206	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1359
Epoch: 1359	max: 0.99999785/1.0	min: 2.1775006e-06	loss: 34561.55859375	train_loss: 34546.79682709727	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1360
Epoch: 1360	max: 0.99999714/1.0	min: 2.8138143e-06	loss: 34561.51171875	train_loss: 34546.77158913198	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1361
Epoch: 1361	max: 0.999997/1.0	min: 3.019026e-06	loss: 34561.44140625	train_loss: 34546.79435163895	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1362
Epoch: 1362	max: 0.99999654/1.0	min: 3.504666e-06	loss: 34561.69140625	train_loss: 34546.7672517574	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1363
Epoch: 1363	max: 0.9999974/1.0	min: 2.5899885e-06	loss: 34561.51171875	train_loss: 34546.73722593831	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1364
Epoch: 1364	max: 0.99998903/1.0	min: 1.09167795e-05	loss: 34561.5625	train_loss: 34546.76258632169	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1365
Epoch: 1365	max: 0.9999989/1.0	min: 1.0622407e-06	loss: 34561.5	train_loss: 34546.74134460548	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1366
Epoch: 1366	max: 0.99999666/1.0	min: 3.363825e-06	loss: 34561.2734375	train_loss: 34546.66671360167	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1367
Epoch: 1367	max: 0.99999607/1.0	min: 3.8990975e-06	loss: 34561.46875	train_loss: 34546.65055828456	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1368
Epoch: 1368	max: 0.999998/1.0	min: 1.981794e-06	loss: 34561.359375	train_loss: 34546.629203343706	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1369
Epoch: 1369	max: 0.9999956/1.0	min: 4.4552726e-06	loss: 34561.44140625	train_loss: 34546.6236292077	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1370
Epoch: 1370	max: 0.99999917/1.0	min: 8.4006143e-07	loss: 34561.2421875	train_loss: 34546.61271948161	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1371
Epoch: 1371	max: 0.9999958/1.0	min: 4.132966e-06	loss: 34561.296875	train_loss: 34546.59432047798	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1372
Epoch: 1372	max: 0.9999969/1.0	min: 3.1322595e-06	loss: 34561.42578125	train_loss: 34546.57565147715	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1373
Epoch: 1373	max: 0.99999726/1.0	min: 2.7308654e-06	loss: 34561.31640625	train_loss: 34546.57092991298	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1374
Epoch: 1374	max: 0.999992/1.0	min: 8.029633e-06	loss: 34561.453125	train_loss: 34546.59489531076	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1375
Epoch: 1375	max: 0.999998/1.0	min: 2.030293e-06	loss: 34561.265625	train_loss: 34546.535532213864	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1376
Epoch: 1376	max: 0.99999714/1.0	min: 2.9067771e-06	loss: 34561.28515625	train_loss: 34546.501837722964	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1377
Epoch: 1377	max: 0.99999726/1.0	min: 2.7639337e-06	loss: 34561.32421875	train_loss: 34546.50364641397	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1378
Epoch: 1378	max: 0.9999869/1.0	min: 1.312647e-05	loss: 34561.3515625	train_loss: 34546.5409239324	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1379
Epoch: 1379	max: 0.9999914/1.0	min: 8.602096e-06	loss: 34561.37890625	train_loss: 34546.473952043074	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1380
Epoch: 1380	max: 0.9999988/1.0	min: 1.1875787e-06	loss: 34561.15234375	train_loss: 34546.447513122446	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1381
Epoch: 1381	max: 0.99999213/1.0	min: 7.875521e-06	loss: 34561.4453125	train_loss: 34546.43048539499	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1382
Epoch: 1382	max: 0.9999988/1.0	min: 1.1977334e-06	loss: 34561.03515625	train_loss: 34546.41499297426	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1383
Epoch: 1383	max: 0.99999785/1.0	min: 2.1138014e-06	loss: 34561.40625	train_loss: 34546.40824110848	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1384
Epoch: 1384	max: 0.99999857/1.0	min: 1.4167899e-06	loss: 34561.16796875	train_loss: 34546.415077166945	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1385
Epoch: 1385	max: 0.9999938/1.0	min: 6.1662104e-06	loss: 34561.12890625	train_loss: 34546.37400613929	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1386
Epoch: 1386	max: 0.9999981/1.0	min: 1.8868296e-06	loss: 34561.12890625	train_loss: 34546.40150714573	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1387
Epoch: 1387	max: 0.9999914/1.0	min: 8.6000455e-06	loss: 34561.296875	train_loss: 34546.35434714868	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1388
Epoch: 1388	max: 0.99999917/1.0	min: 8.432102e-07	loss: 34561.09375	train_loss: 34546.3936027112	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1389
Epoch: 1389	max: 0.9999969/1.0	min: 3.100241e-06	loss: 34561.0	train_loss: 34546.28048887882	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1390
Epoch: 1390	max: 0.9999976/1.0	min: 2.3502841e-06	loss: 34561.5234375	train_loss: 34546.2765516614	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1391
Epoch: 1391	max: 0.9999901/1.0	min: 9.932972e-06	loss: 34561.13671875	train_loss: 34546.35186152917	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1392
Epoch: 1392	max: 0.999998/1.0	min: 1.9809306e-06	loss: 34561.19921875	train_loss: 34546.31721285458	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1393
Epoch: 1393	max: 0.9999958/1.0	min: 4.2150878e-06	loss: 34561.12890625	train_loss: 34546.23716932599	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1394
Epoch: 1394	max: 0.9999968/1.0	min: 3.211714e-06	loss: 34561.1640625	train_loss: 34546.20237404001	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1395
Epoch: 1395	max: 0.99999726/1.0	min: 2.7741164e-06	loss: 34561.00390625	train_loss: 34546.19702199848	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1396
Epoch: 1396	max: 0.99999845/1.0	min: 1.5167311e-06	loss: 34560.91015625	train_loss: 34546.192538496376	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1397
Epoch: 1397	max: 0.99999166/1.0	min: 8.359684e-06	loss: 34561.12890625	train_loss: 34546.16614796234	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1398
Epoch: 1398	max: 0.99999857/1.0	min: 1.4238035e-06	loss: 34560.8984375	train_loss: 34546.15454630791	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1399
Epoch: 1399	max: 0.99999607/1.0	min: 3.983356e-06	loss: 34560.94140625	train_loss: 34546.14619284575	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1400
Epoch: 1400	max: 0.9999968/1.0	min: 3.2663381e-06	loss: 34560.8671875	train_loss: 34546.11853506674	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1401
Epoch: 1401	max: 0.9999951/1.0	min: 4.9122013e-06	loss: 34560.96484375	train_loss: 34546.123812109035	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1402
Epoch: 1402	max: 0.99999714/1.0	min: 2.807882e-06	loss: 34560.82421875	train_loss: 34546.07901579726	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1403
Epoch: 1403	max: 0.99999785/1.0	min: 2.1061508e-06	loss: 34560.8515625	train_loss: 34546.048116116224	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1404
Epoch: 1404	max: 0.9999987/1.0	min: 1.3026055e-06	loss: 34560.69140625	train_loss: 34546.05609942091	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1405
Epoch: 1405	max: 0.9999963/1.0	min: 3.6597146e-06	loss: 34561.01171875	train_loss: 34546.04431921993	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1406
Epoch: 1406	max: 0.99999833/1.0	min: 1.7044724e-06	loss: 34560.78125	train_loss: 34546.03817460594	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1407
Epoch: 1407	max: 0.99999714/1.0	min: 2.8719699e-06	loss: 34560.890625	train_loss: 34545.99192959943	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1408
Epoch: 1408	max: 0.99999905/1.0	min: 9.76425e-07	loss: 34560.984375	train_loss: 34545.99822614734	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1409
Epoch: 1409	max: 0.9999969/1.0	min: 3.0679903e-06	loss: 34560.78125	train_loss: 34546.01127456104	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1410
Epoch: 1410	max: 0.9999964/1.0	min: 3.551172e-06	loss: 34560.90625	train_loss: 34545.94778311966	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1411
Epoch: 1411	max: 0.99999344/1.0	min: 6.5370014e-06	loss: 34560.79296875	train_loss: 34545.94795779527	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1412
Epoch: 1412	max: 0.99999106/1.0	min: 8.9418445e-06	loss: 34561.015625	train_loss: 34545.94488911727	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1413
Epoch: 1413	max: 0.99999917/1.0	min: 8.639204e-07	loss: 34560.734375	train_loss: 34545.92057146507	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1414
Epoch: 1414	max: 0.999997/1.0	min: 2.9422586e-06	loss: 34560.68359375	train_loss: 34545.911197529575	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1415
Epoch: 1415	max: 0.99999917/1.0	min: 8.5246734e-07	loss: 34560.4765625	train_loss: 34545.89865282036	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1416
Epoch: 1416	max: 0.99999595/1.0	min: 4.053414e-06	loss: 34560.76953125	train_loss: 34545.85379602533	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1417
Epoch: 1417	max: 0.99999857/1.0	min: 1.4589631e-06	loss: 34560.74609375	train_loss: 34545.83621959386	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1418
Epoch: 1418	max: 0.9999926/1.0	min: 7.3695837e-06	loss: 34560.83984375	train_loss: 34545.871461972005	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1419
Epoch: 1419	max: 0.9999969/1.0	min: 3.137231e-06	loss: 34560.59375	train_loss: 34545.811233238885	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1420
Epoch: 1420	max: 0.9999981/1.0	min: 1.8896513e-06	loss: 34560.5390625	train_loss: 34545.779950819866	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1421
Epoch: 1421	max: 0.99999833/1.0	min: 1.6778165e-06	loss: 34560.61328125	train_loss: 34545.76698272792	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1422
Epoch: 1422	max: 0.9999974/1.0	min: 2.6077917e-06	loss: 34560.87109375	train_loss: 34545.73619675539	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1423
Epoch: 1423	max: 0.9999982/1.0	min: 1.7897074e-06	loss: 34560.67578125	train_loss: 34545.72175771089	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1424
Epoch: 1424	max: 0.99999356/1.0	min: 6.452512e-06	loss: 34560.7265625	train_loss: 34545.74228620866	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1425
Epoch: 1425	max: 0.99999595/1.0	min: 4.034001e-06	loss: 34560.74609375	train_loss: 34545.68557663276	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1426
Epoch: 1426	max: 0.9999987/1.0	min: 1.2656593e-06	loss: 34560.59765625	train_loss: 34545.68267972718	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1427
Epoch: 1427	max: 0.9999987/1.0	min: 1.3288179e-06	loss: 34560.61328125	train_loss: 34545.65907190635	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1428
Epoch: 1428	max: 0.99999535/1.0	min: 4.646497e-06	loss: 34560.85546875	train_loss: 34545.64709912672	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1429
Epoch: 1429	max: 0.99999857/1.0	min: 1.460245e-06	loss: 34560.51953125	train_loss: 34545.64873652917	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1430
Epoch: 1430	max: 0.9999981/1.0	min: 1.9437337e-06	loss: 34560.65625	train_loss: 34545.60162733804	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1431
Epoch: 1431	max: 0.9999938/1.0	min: 6.1931555e-06	loss: 34560.63671875	train_loss: 34545.62214519076	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1432
Epoch: 1432	max: 0.9999987/1.0	min: 1.2715052e-06	loss: 34560.39453125	train_loss: 34545.61140239843	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1433
Epoch: 1433	max: 0.99999857/1.0	min: 1.4536064e-06	loss: 34560.5703125	train_loss: 34545.56910428667	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1434
Epoch: 1434	max: 0.999998/1.0	min: 1.9909057e-06	loss: 34560.56640625	train_loss: 34545.54793369875	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1435
Epoch: 1435	max: 0.9999981/1.0	min: 1.890814e-06	loss: 34560.3984375	train_loss: 34545.512568902515	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1436
Epoch: 1436	max: 0.9999975/1.0	min: 2.546032e-06	loss: 34560.765625	train_loss: 34545.53834589449	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1437
Epoch: 1437	max: 0.9999982/1.0	min: 1.7291883e-06	loss: 34560.36328125	train_loss: 34545.51408485461	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1438
Epoch: 1438	max: 0.99999845/1.0	min: 1.4975419e-06	loss: 34560.71484375	train_loss: 34545.47140690806	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1439
Epoch: 1439	max: 0.9999956/1.0	min: 4.435166e-06	loss: 34560.41015625	train_loss: 34545.56037195745	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1440
Epoch: 1440	max: 0.9999975/1.0	min: 2.4606818e-06	loss: 34560.56640625	train_loss: 34545.49925242707	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1441
Epoch: 1441	max: 0.99999654/1.0	min: 3.5003238e-06	loss: 34560.44921875	train_loss: 34545.43761322464	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1442
Epoch: 1442	max: 0.99999976/1.0	min: 2.5712967e-07	loss: 34560.3203125	train_loss: 34545.42613979468	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1443
Epoch: 1443	max: 0.9999956/1.0	min: 4.396272e-06	loss: 34560.453125	train_loss: 34545.44915439583	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1444
Epoch: 1444	max: 0.99999523/1.0	min: 4.7321887e-06	loss: 34560.5859375	train_loss: 34545.37090165521	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1445
Epoch: 1445	max: 0.99999917/1.0	min: 8.4025373e-07	loss: 34560.5859375	train_loss: 34545.38368732968	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1446
Epoch: 1446	max: 0.99999547/1.0	min: 4.521442e-06	loss: 34560.3359375	train_loss: 34545.42053033646	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1447
Epoch: 1447	max: 0.99999845/1.0	min: 1.4967022e-06	loss: 34560.37890625	train_loss: 34545.40981415676	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1448
Epoch: 1448	max: 0.9999987/1.0	min: 1.3579722e-06	loss: 34560.24609375	train_loss: 34545.34886688266	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1449
Epoch: 1449	max: 0.9999975/1.0	min: 2.5401507e-06	loss: 34560.4140625	train_loss: 34545.325554220086	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1450
Epoch: 1450	max: 0.9999975/1.0	min: 2.4929616e-06	loss: 34560.3359375	train_loss: 34545.31362208519	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1451
Epoch: 1451	max: 0.99999344/1.0	min: 6.5874924e-06	loss: 34560.48046875	train_loss: 34545.29436276787	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1452
Epoch: 1452	max: 0.99999774/1.0	min: 2.2805605e-06	loss: 34560.5	train_loss: 34545.28998523241	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1453
Epoch: 1453	max: 0.9999989/1.0	min: 1.0371522e-06	loss: 34560.16796875	train_loss: 34545.245510207635	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1454
Epoch: 1454	max: 0.999998/1.0	min: 2.0751186e-06	loss: 34560.4609375	train_loss: 34545.21938531602	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1455
Epoch: 1455	max: 0.99999714/1.0	min: 2.8845582e-06	loss: 34560.1953125	train_loss: 34545.20457466246	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1456
Epoch: 1456	max: 0.999998/1.0	min: 2.080532e-06	loss: 34560.19921875	train_loss: 34545.18763257928	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1457
Epoch: 1457	max: 0.999998/1.0	min: 1.982724e-06	loss: 34560.21875	train_loss: 34545.16650602316	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1458
Epoch: 1458	max: 0.9999949/1.0	min: 5.086821e-06	loss: 34560.32421875	train_loss: 34545.180656683544	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1459
Epoch: 1459	max: 0.9999987/1.0	min: 1.2756068e-06	loss: 34560.15625	train_loss: 34545.172997569054	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1460
Epoch: 1460	max: 0.9999969/1.0	min: 3.0632134e-06	loss: 34560.32421875	train_loss: 34545.11427172364	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1461
Epoch: 1461	max: 0.99999845/1.0	min: 1.4976674e-06	loss: 34560.24609375	train_loss: 34545.100295738885	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1462
Epoch: 1462	max: 0.99999595/1.0	min: 4.081568e-06	loss: 34560.11328125	train_loss: 34545.096046427905	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1463
Epoch: 1463	max: 0.9999982/1.0	min: 1.7314755e-06	loss: 34560.10546875	train_loss: 34545.06407498374	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1464
Epoch: 1464	max: 0.99999094/1.0	min: 9.107455e-06	loss: 34560.33203125	train_loss: 34545.05656538384	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1465
Epoch: 1465	max: 0.9999982/1.0	min: 1.8153704e-06	loss: 34560.1328125	train_loss: 34545.090962931994	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1466
Epoch: 1466	max: 0.9999949/1.0	min: 5.1784705e-06	loss: 34560.171875	train_loss: 34545.032961917816	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1467
Epoch: 1467	max: 0.9999989/1.0	min: 1.1322849e-06	loss: 34560.109375	train_loss: 34545.03055274914	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1468
Epoch: 1468	max: 0.999998/1.0	min: 2.0108328e-06	loss: 34559.9140625	train_loss: 34544.98124874195	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1469
Epoch: 1469	max: 0.99999726/1.0	min: 2.6961607e-06	loss: 34560.2109375	train_loss: 34545.03190370293	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1470
Epoch: 1470	max: 0.9999987/1.0	min: 1.300988e-06	loss: 34560.16015625	train_loss: 34544.992280402264	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1471
Epoch: 1471	max: 0.9999943/1.0	min: 5.696265e-06	loss: 34560.1015625	train_loss: 34544.932627953516	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1472
Epoch: 1472	max: 0.9999975/1.0	min: 2.459762e-06	loss: 34560.1953125	train_loss: 34544.92615431066	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1473
Epoch: 1473	max: 0.99999726/1.0	min: 2.7181832e-06	loss: 34560.078125	train_loss: 34544.90243568453	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1474
Epoch: 1474	max: 0.9999974/1.0	min: 2.6423768e-06	loss: 34560.03125	train_loss: 34544.91812552258	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1475
Epoch: 1475	max: 0.9999975/1.0	min: 2.5015493e-06	loss: 34560.078125	train_loss: 34544.8998126471	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1476
Epoch: 1476	max: 0.99999905/1.0	min: 9.809088e-07	loss: 34560.02734375	train_loss: 34544.86001467082	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1477
Epoch: 1477	max: 0.99999607/1.0	min: 3.899986e-06	loss: 34559.9453125	train_loss: 34544.866768472064	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1478
Epoch: 1478	max: 0.9999969/1.0	min: 3.0690849e-06	loss: 34560.21484375	train_loss: 34544.84342339047	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1479
Epoch: 1479	max: 0.99999607/1.0	min: 3.886445e-06	loss: 34559.953125	train_loss: 34544.81308112304	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1480
Epoch: 1480	max: 0.99999857/1.0	min: 1.4880861e-06	loss: 34560.04296875	train_loss: 34544.79670903397	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1481
Epoch: 1481	max: 0.9999976/1.0	min: 2.3367115e-06	loss: 34559.88671875	train_loss: 34544.78207644308	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1482
Epoch: 1482	max: 0.9999933/1.0	min: 6.6225834e-06	loss: 34560.09765625	train_loss: 34544.769484315	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1483
Epoch: 1483	max: 0.99999833/1.0	min: 1.6336069e-06	loss: 34559.7265625	train_loss: 34544.76542177629	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1484
Epoch: 1484	max: 0.99999607/1.0	min: 3.876695e-06	loss: 34559.890625	train_loss: 34544.765275648766	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1485
Epoch: 1485	max: 0.9999963/1.0	min: 3.655445e-06	loss: 34560.046875	train_loss: 34544.721783839654	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1486
Epoch: 1486	max: 0.9999976/1.0	min: 2.3666698e-06	loss: 34559.7890625	train_loss: 34544.70995041342	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1487
Epoch: 1487	max: 0.99999785/1.0	min: 2.1407386e-06	loss: 34559.86328125	train_loss: 34544.68259601836	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1488
Epoch: 1488	max: 0.99999964/1.0	min: 3.659603e-07	loss: 34560.09375	train_loss: 34544.71868371036	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1489
Epoch: 1489	max: 0.99999774/1.0	min: 2.2169988e-06	loss: 34559.81640625	train_loss: 34544.689571914096	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1490
Epoch: 1490	max: 0.999998/1.0	min: 2.0830435e-06	loss: 34559.78515625	train_loss: 34544.646234458225	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1491
Epoch: 1491	max: 0.99999535/1.0	min: 4.643981e-06	loss: 34559.78515625	train_loss: 34544.61543735678	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1492
Epoch: 1492	max: 0.9999987/1.0	min: 1.3155743e-06	loss: 34559.8515625	train_loss: 34544.611476913786	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1493
Epoch: 1493	max: 0.9999981/1.0	min: 1.9505562e-06	loss: 34559.70703125	train_loss: 34544.58619733603	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1494
Epoch: 1494	max: 0.99999833/1.0	min: 1.6305033e-06	loss: 34559.80078125	train_loss: 34544.57393230134	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1495
Epoch: 1495	max: 0.99999475/1.0	min: 5.2737664e-06	loss: 34559.97265625	train_loss: 34544.54793369875	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1496
Epoch: 1496	max: 0.9999989/1.0	min: 1.0420787e-06	loss: 34559.53125	train_loss: 34544.55871278103	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1497
Epoch: 1497	max: 0.9999949/1.0	min: 5.1790134e-06	loss: 34560.05078125	train_loss: 34544.53676897529	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1498
Epoch: 1498	max: 0.9999976/1.0	min: 2.3815428e-06	loss: 34559.7109375	train_loss: 34544.542160693825	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1499
Epoch: 1499	max: 0.99999905/1.0	min: 9.909108e-07	loss: 34559.703125	train_loss: 34544.493767322405	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1500
Epoch: 1500	max: 0.9999995/1.0	min: 4.2840082e-07	loss: 34559.73046875	train_loss: 34544.48020407531	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1501
Epoch: 1501	max: 0.9999969/1.0	min: 3.1161853e-06	loss: 34559.7109375	train_loss: 34544.4902094559	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1502
Epoch: 1502	max: 0.9999994/1.0	min: 6.378479e-07	loss: 34559.73046875	train_loss: 34544.445698625044	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1503
Epoch: 1503	max: 0.9999994/1.0	min: 6.032668e-07	loss: 34559.8046875	train_loss: 34544.43078152096	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1504
Epoch: 1504	max: 0.9999988/1.0	min: 1.2190292e-06	loss: 34559.62109375	train_loss: 34544.42962556516	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1505
Epoch: 1505	max: 0.9999987/1.0	min: 1.2933355e-06	loss: 34559.63671875	train_loss: 34544.402959711384	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1506
Epoch: 1506	max: 0.9999993/1.0	min: 7.22593e-07	loss: 34559.6015625	train_loss: 34544.410904306795	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1507
Epoch: 1507	max: 0.99999774/1.0	min: 2.2828583e-06	loss: 34559.58984375	train_loss: 34544.47150029419	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1508
Epoch: 1508	max: 0.9999995/1.0	min: 4.4609686e-07	loss: 34559.828125	train_loss: 34544.41603715703	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1509
Epoch: 1509	max: 0.99999416/1.0	min: 5.840854e-06	loss: 34559.6015625	train_loss: 34544.380970422244	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1510
Epoch: 1510	max: 0.99999774/1.0	min: 2.239302e-06	loss: 34559.49609375	train_loss: 34544.35625212901	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1511
Epoch: 1511	max: 0.99999845/1.0	min: 1.5075465e-06	loss: 34559.5546875	train_loss: 34544.318447196674	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1512
Epoch: 1512	max: 0.99999905/1.0	min: 9.3848337e-07	loss: 34559.44921875	train_loss: 34544.31958718491	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1513
Epoch: 1513	max: 0.9999989/1.0	min: 1.0902202e-06	loss: 34559.515625	train_loss: 34544.25394689474	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1514
Epoch: 1514	max: 0.999997/1.0	min: 3.023325e-06	loss: 34559.546875	train_loss: 34544.23736625945	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1515
Epoch: 1515	max: 0.9999975/1.0	min: 2.5376253e-06	loss: 34559.48828125	train_loss: 34544.21880322526	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1516
Epoch: 1516	max: 0.99999917/1.0	min: 8.9142753e-07	loss: 34559.4609375	train_loss: 34544.23278404868	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1517
Epoch: 1517	max: 0.99999/1.0	min: 9.980076e-06	loss: 34559.74609375	train_loss: 34544.19988261411	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1518
Epoch: 1518	max: 0.9999962/1.0	min: 3.8290905e-06	loss: 34559.55859375	train_loss: 34544.20825736637	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1519
Epoch: 1519	max: 0.9999982/1.0	min: 1.8038527e-06	loss: 34559.609375	train_loss: 34544.194938471606	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1520
Epoch: 1520	max: 0.9999975/1.0	min: 2.5247737e-06	loss: 34559.66796875	train_loss: 34544.16443120587	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1521
Epoch: 1521	max: 0.99999475/1.0	min: 5.2459563e-06	loss: 34559.546875	train_loss: 34544.14368400068	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1522
Epoch: 1522	max: 0.9999993/1.0	min: 7.6457115e-07	loss: 34559.50390625	train_loss: 34544.16846858355	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1523
Epoch: 1523	max: 0.9999974/1.0	min: 2.5688284e-06	loss: 34559.5390625	train_loss: 34544.08730490524	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1524
Epoch: 1524	max: 0.9999982/1.0	min: 1.8073828e-06	loss: 34559.359375	train_loss: 34544.076020666886	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1525
Epoch: 1525	max: 0.9999995/1.0	min: 4.558694e-07	loss: 34559.5859375	train_loss: 34544.11420156308	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1526
Epoch: 1526	max: 0.99999845/1.0	min: 1.5509856e-06	loss: 34559.421875	train_loss: 34544.10759776028	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1527
Epoch: 1527	max: 0.9999993/1.0	min: 6.8479983e-07	loss: 34559.32421875	train_loss: 34544.03992620076	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1528
Epoch: 1528	max: 0.9999987/1.0	min: 1.299143e-06	loss: 34559.2578125	train_loss: 34544.012274712004	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1529
Epoch: 1529	max: 0.9999989/1.0	min: 1.093568e-06	loss: 34559.32421875	train_loss: 34544.00820249598	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1530
Epoch: 1530	max: 0.99999523/1.0	min: 4.7673575e-06	loss: 34559.65234375	train_loss: 34544.0269484315	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1531
Epoch: 1531	max: 0.99999905/1.0	min: 9.835551e-07	loss: 34559.09765625	train_loss: 34544.07942659947	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1532
Epoch: 1532	max: 0.99999964/1.0	min: 3.5814307e-07	loss: 34559.21484375	train_loss: 34543.983482751144	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1533
Epoch: 1533	max: 0.9999987/1.0	min: 1.3163235e-06	loss: 34559.1640625	train_loss: 34543.94158528041	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1534
Epoch: 1534	max: 0.99999726/1.0	min: 2.789184e-06	loss: 34559.3125	train_loss: 34543.91966905503	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1535
Epoch: 1535	max: 0.9999988/1.0	min: 1.2036718e-06	loss: 34559.35546875	train_loss: 34543.931240709775	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1536
