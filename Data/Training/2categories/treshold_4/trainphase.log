Epoch: 0	max: 0.588045/1.0	min: 0.41195503	loss: 36330.74609375	train_loss: 36649.87830867552	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1
Epoch: 1	max: 0.6656735/1.0	min: 0.3343265	loss: 35886.46484375	train_loss: 36149.00598493822	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_2
Epoch: 2	max: 0.7291753/1.0	min: 0.2708247	loss: 35568.71875	train_loss: 35786.41272557832	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_3
Epoch: 3	max: 0.77877605/1.0	min: 0.22122395	loss: 35347.2265625	train_loss: 35533.86371527778	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_4
Epoch: 4	max: 0.8166963/1.0	min: 0.18330365	loss: 35193.94921875	train_loss: 35361.88896146879	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_5
Epoch: 5	max: 0.8451435/1.0	min: 0.15485649	loss: 35088.47265625	train_loss: 35246.0854696016	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_6
Epoch: 6	max: 0.86685276/1.0	min: 0.13314725	loss: 35014.34765625	train_loss: 35167.99454683049	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_7
Epoch: 7	max: 0.88393456/1.0	min: 0.11606539	loss: 34961.53515625	train_loss: 35114.54595129986	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_8
Epoch: 8	max: 0.8974556/1.0	min: 0.10254439	loss: 34923.03125	train_loss: 35077.591276961015	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_9
Epoch: 9	max: 0.90818846/1.0	min: 0.091811515	loss: 34894.75390625	train_loss: 35051.78135451505	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_10
Epoch: 10	max: 0.9168757/1.0	min: 0.08312431	loss: 34873.74609375	train_loss: 35033.76577499845	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_11
Epoch: 11	max: 0.92402893/1.0	min: 0.07597104	loss: 34858.078125	train_loss: 35021.22975214449	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_12
Epoch: 12	max: 0.92980164/1.0	min: 0.070198394	loss: 34846.59375	train_loss: 35012.499204040476	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_13
Epoch: 13	max: 0.93429846/1.0	min: 0.06570149	loss: 34838.32421875	train_loss: 35006.65684709061	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_14
Epoch: 14	max: 0.9375883/1.0	min: 0.06241168	loss: 34832.55078125	train_loss: 35002.61996101976	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_15
Epoch: 15	max: 0.9400347/1.0	min: 0.05996534	loss: 34828.42578125	train_loss: 34999.68643307553	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_16
Epoch: 16	max: 0.9417919/1.0	min: 0.058208138	loss: 34825.35546875	train_loss: 34997.28303401384	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_17
Epoch: 17	max: 0.94302803/1.0	min: 0.056971963	loss: 34822.984375	train_loss: 34995.06470110631	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_18
Epoch: 18	max: 0.9436875/1.0	min: 0.056312535	loss: 34821.3359375	train_loss: 34992.803007517345	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_19
Epoch: 19	max: 0.9440914/1.0	min: 0.05590855	loss: 34819.9140625	train_loss: 34990.36618347811	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_20
Epoch: 20	max: 0.9444832/1.0	min: 0.055516813	loss: 34818.42578125	train_loss: 34987.68506421869	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_21
Epoch: 21	max: 0.9448342/1.0	min: 0.05516582	loss: 34816.859375	train_loss: 34984.68575324384	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_22
Epoch: 22	max: 0.9451006/1.0	min: 0.054899376	loss: 34815.21484375	train_loss: 34981.31650737799	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_23
Epoch: 23	max: 0.9451997/1.0	min: 0.054800298	loss: 34813.58984375	train_loss: 34977.459964929396	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_24
Epoch: 24	max: 0.94548315/1.0	min: 0.05451683	loss: 34811.484375	train_loss: 34972.98214050694	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_25
Epoch: 25	max: 0.9457797/1.0	min: 0.054220367	loss: 34809.04296875	train_loss: 34967.727118462004	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_26
Epoch: 26	max: 0.94631517/1.0	min: 0.053684797	loss: 34805.890625	train_loss: 34961.528493899415	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_27
Epoch: 27	max: 0.94700146/1.0	min: 0.052998558	loss: 34801.9609375	train_loss: 34953.993078781124	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_28
Epoch: 28	max: 0.9476205/1.0	min: 0.052379496	loss: 34797.203125	train_loss: 34944.73259582482	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_29
Epoch: 29	max: 0.9486138/1.0	min: 0.051386226	loss: 34790.828125	train_loss: 34933.09112744642	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_30
Epoch: 30	max: 0.9498566/1.0	min: 0.050143454	loss: 34782.37109375	train_loss: 34918.43979933111	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_31
Epoch: 31	max: 0.95194316/1.0	min: 0.048056792	loss: 34769.7265625	train_loss: 34899.00806798123	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_32
Epoch: 32	max: 0.9546548/1.0	min: 0.045345176	loss: 34749.06640625	train_loss: 34870.264429367184	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_33
Epoch: 33	max: 0.9611237/1.0	min: 0.03887628	loss: 34716.31640625	train_loss: 34827.05230542782	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_34
Epoch: 34	max: 0.9697194/1.0	min: 0.030280618	loss: 34682.23828125	train_loss: 34777.68456003035	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_35
Epoch: 35	max: 0.9758965/1.0	min: 0.024103515	loss: 34656.828125	train_loss: 34737.72055046529	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_36
Epoch: 36	max: 0.9802744/1.0	min: 0.019725554	loss: 34638.671875	train_loss: 34709.664075080516	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_37
Epoch: 37	max: 0.98380554/1.0	min: 0.01619449	loss: 34625.90625	train_loss: 34689.87415807321	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_38
Epoch: 38	max: 0.9863717/1.0	min: 0.013628268	loss: 34616.37109375	train_loss: 34675.70385273443	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_39
Epoch: 39	max: 0.98823345/1.0	min: 0.011766538	loss: 34609.2109375	train_loss: 34665.557917789236	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_40
Epoch: 40	max: 0.98940593/1.0	min: 0.010594109	loss: 34602.48046875	train_loss: 34657.929680242014	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_41
Epoch: 41	max: 0.99033207/1.0	min: 0.009667865	loss: 34597.13671875	train_loss: 34651.650029902914	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_42
Epoch: 42	max: 0.9910222/1.0	min: 0.008977717	loss: 34592.33984375	train_loss: 34646.23450225675	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_43
Epoch: 43	max: 0.9914431/1.0	min: 0.008556959	loss: 34587.4140625	train_loss: 34641.366594764186	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_44
Epoch: 44	max: 0.9918105/1.0	min: 0.008189552	loss: 34583.19921875	train_loss: 34636.894016416605	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_45
Epoch: 45	max: 0.99213237/1.0	min: 0.007867627	loss: 34579.48046875	train_loss: 34632.703753058035	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_46
Epoch: 46	max: 0.99242276/1.0	min: 0.007577223	loss: 34575.2890625	train_loss: 34628.7585320087	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_47
Epoch: 47	max: 0.9927135/1.0	min: 0.007286414	loss: 34571.25	train_loss: 34624.95394321736	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_48
Epoch: 48	max: 0.9929309/1.0	min: 0.007069122	loss: 34567.078125	train_loss: 34621.308105529235	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_49
Epoch: 49	max: 0.99328655/1.0	min: 0.006713456	loss: 34564.3046875	train_loss: 34617.753060452276	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_50
Epoch: 50	max: 0.9934988/1.0	min: 0.0065011983	loss: 34560.79296875	train_loss: 34614.22299979484	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_51
Epoch: 51	max: 0.99371195/1.0	min: 0.006288126	loss: 34557.5390625	train_loss: 34610.753613511086	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_52
Epoch: 52	max: 0.9938526/1.0	min: 0.0061473404	loss: 34553.875	train_loss: 34607.29223230599	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_53
Epoch: 53	max: 0.9941506/1.0	min: 0.005849378	loss: 34551.50390625	train_loss: 34603.81947202481	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_54
Epoch: 54	max: 0.9942947/1.0	min: 0.005705269	loss: 34548.12109375	train_loss: 34600.342039049916	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_55
Epoch: 55	max: 0.9943979/1.0	min: 0.0056021204	loss: 34544.61328125	train_loss: 34596.850790249904	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_56
Epoch: 56	max: 0.9945628/1.0	min: 0.0054372065	loss: 34541.60546875	train_loss: 34593.36511413431	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_57
Epoch: 57	max: 0.99468476/1.0	min: 0.0053152163	loss: 34538.3359375	train_loss: 34589.86984392419	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_58
Epoch: 58	max: 0.9948329/1.0	min: 0.0051671625	loss: 34535.296875	train_loss: 34586.36153400997	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_59
Epoch: 59	max: 0.994873/1.0	min: 0.005126982	loss: 34531.6953125	train_loss: 34582.87205664329	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_60
Epoch: 60	max: 0.99502313/1.0	min: 0.004976909	loss: 34528.765625	train_loss: 34579.38621891645	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_61
Epoch: 61	max: 0.99515367/1.0	min: 0.004846366	loss: 34525.90625	train_loss: 34575.93618727162	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_62
Epoch: 62	max: 0.99528694/1.0	min: 0.004713083	loss: 34522.96875	train_loss: 34572.50707847532	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_63
Epoch: 63	max: 0.9954075/1.0	min: 0.0045924815	loss: 34520.1953125	train_loss: 34569.13472764152	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_64
Epoch: 64	max: 0.9955621/1.0	min: 0.0044379258	loss: 34517.71875	train_loss: 34565.88940759321	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_65
Epoch: 65	max: 0.9955546/1.0	min: 0.0044453186	loss: 34514.53515625	train_loss: 34562.74346006751	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_66
Epoch: 66	max: 0.99577385/1.0	min: 0.0042261034	loss: 34512.51171875	train_loss: 34559.70552449136	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_67
Epoch: 67	max: 0.9959286/1.0	min: 0.0040713595	loss: 34510.53125	train_loss: 34556.735239668495	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_68
Epoch: 68	max: 0.9959223/1.0	min: 0.0040776366	loss: 34507.65234375	train_loss: 34553.845225791214	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_69
Epoch: 69	max: 0.9960233/1.0	min: 0.003976672	loss: 34505.60546875	train_loss: 34551.03618349746	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_70
Epoch: 70	max: 0.9961526/1.0	min: 0.003847354	loss: 34503.71484375	train_loss: 34548.31862525935	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_71
Epoch: 71	max: 0.9962171/1.0	min: 0.0037829338	loss: 34501.61328125	train_loss: 34545.78081113356	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_72
Epoch: 72	max: 0.9963814/1.0	min: 0.0036186238	loss: 34499.8984375	train_loss: 34543.46321360554	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_73
Epoch: 73	max: 0.99622476/1.0	min: 0.0037752392	loss: 34497.34375	train_loss: 34541.33665797643	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_74
Epoch: 74	max: 0.9966293/1.0	min: 0.003370727	loss: 34496.796875	train_loss: 34539.28561156788	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_75
Epoch: 75	max: 0.9966468/1.0	min: 0.0033531121	loss: 34494.92578125	train_loss: 34537.32550970442	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_76
Epoch: 76	max: 0.9965899/1.0	min: 0.0034101184	loss: 34492.953125	train_loss: 34535.45719382897	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_77
Epoch: 77	max: 0.99677086/1.0	min: 0.0032292246	loss: 34491.83203125	train_loss: 34533.67237289809	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_78
Epoch: 78	max: 0.9967673/1.0	min: 0.0032327056	loss: 34490.328125	train_loss: 34531.965616000096	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_79
Epoch: 79	max: 0.9969379/1.0	min: 0.0030620946	loss: 34489.453125	train_loss: 34530.3168668904	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_80
Epoch: 80	max: 0.9968579/1.0	min: 0.0031420502	loss: 34487.7734375	train_loss: 34528.73601724111	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_81
Epoch: 81	max: 0.9970548/1.0	min: 0.0029452424	loss: 34487.08984375	train_loss: 34527.17037888641	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_82
Epoch: 82	max: 0.996958/1.0	min: 0.0030420409	loss: 34485.44140625	train_loss: 34525.6714341981	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_83
Epoch: 83	max: 0.99707305/1.0	min: 0.0029268973	loss: 34484.6171875	train_loss: 34524.19778360352	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_84
Epoch: 84	max: 0.9969894/1.0	min: 0.0030106225	loss: 34483.12890625	train_loss: 34522.761332624956	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_85
Epoch: 85	max: 0.99702114/1.0	min: 0.002978837	loss: 34482.109375	train_loss: 34521.35326715982	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_86
Epoch: 86	max: 0.9969818/1.0	min: 0.0030181657	loss: 34480.9375	train_loss: 34519.978667800846	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_87
Epoch: 87	max: 0.9969879/1.0	min: 0.0030121196	loss: 34479.87109375	train_loss: 34518.604122150995	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_88
Epoch: 88	max: 0.9969292/1.0	min: 0.0030708325	loss: 34478.73046875	train_loss: 34517.2636029241	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_89
Epoch: 89	max: 0.99693227/1.0	min: 0.0030676604	loss: 34477.640625	train_loss: 34515.94472605444	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_90
Epoch: 90	max: 0.99696606/1.0	min: 0.0030338964	loss: 34476.75	train_loss: 34514.635638761145	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_91
Epoch: 91	max: 0.9968966/1.0	min: 0.0031033577	loss: 34475.57421875	train_loss: 34513.33879618017	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_92
Epoch: 92	max: 0.9969433/1.0	min: 0.0030567413	loss: 34474.6953125	train_loss: 34512.06160823501	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_93
Epoch: 93	max: 0.99687696/1.0	min: 0.0031230398	loss: 34473.359375	train_loss: 34510.781449352784	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_94
Epoch: 94	max: 0.9968996/1.0	min: 0.003100354	loss: 34472.484375	train_loss: 34509.55092592593	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_95
Epoch: 95	max: 0.99695766/1.0	min: 0.0030423761	loss: 34471.78515625	train_loss: 34508.293088264894	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_96
Epoch: 96	max: 0.99698776/1.0	min: 0.0030122313	loss: 34470.9296875	train_loss: 34507.06542884073	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_97
Epoch: 97	max: 0.99715567/1.0	min: 0.002844268	loss: 34470.57421875	train_loss: 34505.85568019943	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_98
Epoch: 98	max: 0.9969188/1.0	min: 0.0030811995	loss: 34468.35546875	train_loss: 34504.72978359578	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_99
Epoch: 99	max: 0.9969496/1.0	min: 0.0030504689	loss: 34467.43359375	train_loss: 34503.49935887758	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_100
Epoch: 100	max: 0.99707675/1.0	min: 0.0029232255	loss: 34466.80859375	train_loss: 34502.340745192305	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_101
Epoch: 101	max: 0.99711704/1.0	min: 0.0028829607	loss: 34466.140625	train_loss: 34501.16333863651	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_102
Epoch: 102	max: 0.9971348/1.0	min: 0.0028651825	loss: 34465.24609375	train_loss: 34500.05537604128	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_103
Epoch: 103	max: 0.99714273/1.0	min: 0.0028572513	loss: 34464.3125	train_loss: 34498.95452434039	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_104
Epoch: 104	max: 0.99715614/1.0	min: 0.0028438843	loss: 34463.4765625	train_loss: 34497.887583418495	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_105
Epoch: 105	max: 0.9971608/1.0	min: 0.0028392435	loss: 34462.61328125	train_loss: 34496.85568648969	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_106
Epoch: 106	max: 0.997218/1.0	min: 0.00278193	loss: 34461.87109375	train_loss: 34495.858525815216	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_107
Epoch: 107	max: 0.99725336/1.0	min: 0.0027466097	loss: 34461.08984375	train_loss: 34494.8726038957	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_108
Epoch: 108	max: 0.9973116/1.0	min: 0.0026883748	loss: 34460.390625	train_loss: 34493.92901589403	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_109
Epoch: 109	max: 0.9972915/1.0	min: 0.002708468	loss: 34459.5234375	train_loss: 34493.02059769061	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_110
Epoch: 110	max: 0.9972778/1.0	min: 0.00272223	loss: 34458.6640625	train_loss: 34492.12896286232	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_111
Epoch: 111	max: 0.99726933/1.0	min: 0.0027306057	loss: 34457.81640625	train_loss: 34491.27822438607	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_112
Epoch: 112	max: 0.9973416/1.0	min: 0.0026583865	loss: 34457.2109375	train_loss: 34490.47140594033	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_113
Epoch: 113	max: 0.9973456/1.0	min: 0.002654392	loss: 34456.50390625	train_loss: 34489.693540582804	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_114
Epoch: 114	max: 0.9974191/1.0	min: 0.0025808376	loss: 34455.90234375	train_loss: 34488.924262394714	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_115
Epoch: 115	max: 0.9973943/1.0	min: 0.0026057123	loss: 34455.203125	train_loss: 34488.211700072774	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_116
Epoch: 116	max: 0.9973367/1.0	min: 0.0026633525	loss: 34454.3828125	train_loss: 34487.55030464202	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_117
Epoch: 117	max: 0.99740475/1.0	min: 0.0025952267	loss: 34453.82421875	train_loss: 34486.842194370896	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_118
Epoch: 118	max: 0.99741435/1.0	min: 0.002585637	loss: 34453.1953125	train_loss: 34486.12703901121	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_119
Epoch: 119	max: 0.9975866/1.0	min: 0.0024134228	loss: 34452.91015625	train_loss: 34485.50603332482	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_120
Epoch: 120	max: 0.99761236/1.0	min: 0.0023876657	loss: 34452.32421875	train_loss: 34484.867157016444	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_121
Epoch: 121	max: 0.99760723/1.0	min: 0.002392739	loss: 34451.69921875	train_loss: 34484.281324999225	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_122
Epoch: 122	max: 0.99767715/1.0	min: 0.002322913	loss: 34451.34375	train_loss: 34483.68451212762	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_123
Epoch: 123	max: 0.99769056/1.0	min: 0.0023094444	loss: 34450.69921875	train_loss: 34483.11457655921	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_124
Epoch: 124	max: 0.9977791/1.0	min: 0.0022208844	loss: 34450.375	train_loss: 34482.57464406819	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_125
Epoch: 125	max: 0.9977456/1.0	min: 0.0022543706	loss: 34449.67578125	train_loss: 34482.04028522931	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_126
Epoch: 126	max: 0.99793077/1.0	min: 0.0020692488	loss: 34449.671875	train_loss: 34481.5030899681	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_127
Epoch: 127	max: 0.9978771/1.0	min: 0.0021229521	loss: 34448.96875	train_loss: 34481.00419850505	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_128
Epoch: 128	max: 0.997968/1.0	min: 0.0020319181	loss: 34448.67578125	train_loss: 34480.49457973337	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_129
Epoch: 129	max: 0.9980229/1.0	min: 0.0019770607	loss: 34448.3125	train_loss: 34480.10797324028	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_130
Epoch: 130	max: 0.99801886/1.0	min: 0.0019810898	loss: 34447.8515625	train_loss: 34479.60879000604	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_131
Epoch: 131	max: 0.99794334/1.0	min: 0.0020566816	loss: 34447.08984375	train_loss: 34479.1450886636	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_132
Epoch: 132	max: 0.99794143/1.0	min: 0.002058584	loss: 34446.53515625	train_loss: 34478.628813347736	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_133
Epoch: 133	max: 0.9980069/1.0	min: 0.0019931528	loss: 34446.21484375	train_loss: 34478.19452960486	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_134
Epoch: 134	max: 0.9980281/1.0	min: 0.0019718965	loss: 34445.87109375	train_loss: 34477.779612597544	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_135
Epoch: 135	max: 0.998111/1.0	min: 0.0018890316	loss: 34445.6171875	train_loss: 34477.33613830438	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_136
Epoch: 136	max: 0.9981341/1.0	min: 0.0018659926	loss: 34445.234375	train_loss: 34476.9198301824	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_137
Epoch: 137	max: 0.9978915/1.0	min: 0.0021084733	loss: 34444.328125	train_loss: 34476.51045682754	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_138
Epoch: 138	max: 0.99805176/1.0	min: 0.0019481898	loss: 34444.10546875	train_loss: 34476.12376227084	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_139
Epoch: 139	max: 0.9980015/1.0	min: 0.0019985058	loss: 34443.6484375	train_loss: 34475.717487593676	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_140
Epoch: 140	max: 0.9979365/1.0	min: 0.0020635102	loss: 34443.203125	train_loss: 34475.37515628871	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_141
Epoch: 141	max: 0.99813783/1.0	min: 0.0018621536	loss: 34443.0859375	train_loss: 34474.96313570312	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_142
Epoch: 142	max: 0.9981254/1.0	min: 0.0018746102	loss: 34442.62890625	train_loss: 34474.59423193051	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_143
Epoch: 143	max: 0.9981963/1.0	min: 0.0018036565	loss: 34442.390625	train_loss: 34474.24740018813	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_144
Epoch: 144	max: 0.99807906/1.0	min: 0.0019209407	loss: 34441.8203125	train_loss: 34473.8759328936	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_145
Epoch: 145	max: 0.9982413/1.0	min: 0.0017586647	loss: 34441.77734375	train_loss: 34473.55939793525	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_146
Epoch: 146	max: 0.9982128/1.0	min: 0.0017872074	loss: 34441.34375	train_loss: 34473.192345433854	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_147
Epoch: 147	max: 0.9983133/1.0	min: 0.0016867572	loss: 34441.13671875	train_loss: 34472.86772410737	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_148
Epoch: 148	max: 0.9983133/1.0	min: 0.0016866566	loss: 34440.78125	train_loss: 34472.51568306392	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_149
Epoch: 149	max: 0.9981791/1.0	min: 0.0018208805	loss: 34440.171875	train_loss: 34472.19211172659	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_150
Epoch: 150	max: 0.9982687/1.0	min: 0.001731214	loss: 34440.03125	train_loss: 34471.87194245092	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_151
Epoch: 151	max: 0.99830973/1.0	min: 0.0016903051	loss: 34439.7734375	train_loss: 34471.55005593491	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_152
Epoch: 152	max: 0.9982077/1.0	min: 0.0017922634	loss: 34439.2890625	train_loss: 34471.24011268271	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_153
Epoch: 153	max: 0.99825305/1.0	min: 0.0017468907	loss: 34439.03125	train_loss: 34470.950027773906	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_154
Epoch: 154	max: 0.99812347/1.0	min: 0.00187654	loss: 34438.6484375	train_loss: 34470.64910910597	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_155
Epoch: 155	max: 0.998336/1.0	min: 0.0016640073	loss: 34438.640625	train_loss: 34470.36762152778	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_156
Epoch: 156	max: 0.9983504/1.0	min: 0.0016496668	loss: 34438.23828125	train_loss: 34470.06644834634	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_157
Epoch: 157	max: 0.99842846/1.0	min: 0.001571552	loss: 34438.19921875	train_loss: 34469.77532989982	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_158
Epoch: 158	max: 0.9984841/1.0	min: 0.0015159508	loss: 34437.95703125	train_loss: 34469.51773175244	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_159
Epoch: 159	max: 0.9983236/1.0	min: 0.001676323	loss: 34437.39453125	train_loss: 34469.224189621265	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_160
Epoch: 160	max: 0.9984326/1.0	min: 0.0015674185	loss: 34437.2734375	train_loss: 34468.96860580794	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_161
Epoch: 161	max: 0.9983891/1.0	min: 0.0016109571	loss: 34436.9140625	train_loss: 34468.688662246066	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_162
Epoch: 162	max: 0.9983724/1.0	min: 0.0016276488	loss: 34436.625	train_loss: 34468.42634592159	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_163
Epoch: 163	max: 0.99829656/1.0	min: 0.0017034106	loss: 34436.328125	train_loss: 34468.18911224142	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_164
Epoch: 164	max: 0.9985379/1.0	min: 0.0014621135	loss: 34436.35546875	train_loss: 34467.938856760185	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_165
Epoch: 165	max: 0.99858946/1.0	min: 0.0014104766	loss: 34436.1796875	train_loss: 34467.6871970999	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_166
Epoch: 166	max: 0.9983346/1.0	min: 0.001665456	loss: 34435.56640625	train_loss: 34467.435045831786	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_167
Epoch: 167	max: 0.9985537/1.0	min: 0.0014463016	loss: 34435.63671875	train_loss: 34467.25796685325	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_168
Epoch: 168	max: 0.9986577/1.0	min: 0.0013422825	loss: 34435.69921875	train_loss: 34467.02057881983	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_169
Epoch: 169	max: 0.9985569/1.0	min: 0.0014431352	loss: 34435.10546875	train_loss: 34466.74078719188	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_170
Epoch: 170	max: 0.9985625/1.0	min: 0.0014374829	loss: 34434.9375	train_loss: 34466.49038026059	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_171
Epoch: 171	max: 0.9987214/1.0	min: 0.0012785132	loss: 34435.03125	train_loss: 34466.27731229871	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_172
Epoch: 172	max: 0.9985304/1.0	min: 0.0014695519	loss: 34434.453125	train_loss: 34466.08997052289	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_173
Epoch: 173	max: 0.99860966/1.0	min: 0.0013903229	loss: 34434.2734375	train_loss: 34465.84022164933	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_174
Epoch: 174	max: 0.9985654/1.0	min: 0.0014346683	loss: 34434.04296875	train_loss: 34465.62687546451	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_175
Epoch: 175	max: 0.998582/1.0	min: 0.0014180236	loss: 34433.86328125	train_loss: 34465.425706250775	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_176
Epoch: 176	max: 0.9987024/1.0	min: 0.0012975815	loss: 34433.8515625	train_loss: 34465.22129707048	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_177
Epoch: 177	max: 0.9987674/1.0	min: 0.0012326526	loss: 34433.703125	train_loss: 34465.03014726945	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_178
Epoch: 178	max: 0.99859375/1.0	min: 0.0014062424	loss: 34433.30859375	train_loss: 34464.819872181964	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_179
Epoch: 179	max: 0.9985744/1.0	min: 0.0014256319	loss: 34433.0390625	train_loss: 34464.6140989835	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_180
Epoch: 180	max: 0.9986615/1.0	min: 0.0013385179	loss: 34432.953125	train_loss: 34464.46552261396	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_181
Epoch: 181	max: 0.9987135/1.0	min: 0.0012865498	loss: 34432.88671875	train_loss: 34464.25387818577	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_182
Epoch: 182	max: 0.9987741/1.0	min: 0.0012258693	loss: 34432.7109375	train_loss: 34464.03452093398	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_183
Epoch: 183	max: 0.9986278/1.0	min: 0.0013722641	loss: 34432.42578125	train_loss: 34463.85509327	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_184
Epoch: 184	max: 0.99863464/1.0	min: 0.0013652879	loss: 34432.171875	train_loss: 34463.6778957443	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_185
Epoch: 185	max: 0.99887294/1.0	min: 0.0011270822	loss: 34432.48828125	train_loss: 34463.530647103	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_186
Epoch: 186	max: 0.9987509/1.0	min: 0.0012490572	loss: 34432.0234375	train_loss: 34463.36018595937	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_187
Epoch: 187	max: 0.9987489/1.0	min: 0.0012510421	loss: 34431.75	train_loss: 34463.15649096525	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_188
Epoch: 188	max: 0.9987243/1.0	min: 0.001275679	loss: 34431.6484375	train_loss: 34462.95755285752	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_189
Epoch: 189	max: 0.9987835/1.0	min: 0.0012164388	loss: 34431.44921875	train_loss: 34462.78618446519	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_190
Epoch: 190	max: 0.9988918/1.0	min: 0.0011083062	loss: 34431.58984375	train_loss: 34462.60553649124	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_191
Epoch: 191	max: 0.9988605/1.0	min: 0.0011395833	loss: 34431.25390625	train_loss: 34462.46376956754	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_192
Epoch: 192	max: 0.99885225/1.0	min: 0.0011477366	loss: 34431.12109375	train_loss: 34462.291897470735	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_193
Epoch: 193	max: 0.998743/1.0	min: 0.0012570214	loss: 34430.78515625	train_loss: 34462.11501010312	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_194
Epoch: 194	max: 0.9989724/1.0	min: 0.0010275636	loss: 34430.98828125	train_loss: 34461.97274479747	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_195
Epoch: 195	max: 0.9988912/1.0	min: 0.0011088664	loss: 34430.60546875	train_loss: 34461.79788192509	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_196
Epoch: 196	max: 0.9988022/1.0	min: 0.0011977894	loss: 34430.40625	train_loss: 34461.632830886905	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_197
Epoch: 197	max: 0.9989279/1.0	min: 0.0010720432	loss: 34430.39453125	train_loss: 34461.48303565899	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_198
Epoch: 198	max: 0.9989705/1.0	min: 0.0010295627	loss: 34430.28125	train_loss: 34461.33422364672	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_199
Epoch: 199	max: 0.998971/1.0	min: 0.001029041	loss: 34430.140625	train_loss: 34461.16961486204	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_200
Epoch: 200	max: 0.998845/1.0	min: 0.0011549917	loss: 34429.78125	train_loss: 34461.02292121501	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_201
Epoch: 201	max: 0.9988747/1.0	min: 0.0011252397	loss: 34429.76953125	train_loss: 34460.878207063666	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_202
Epoch: 202	max: 0.998909/1.0	min: 0.0010910337	loss: 34429.671875	train_loss: 34460.73481918896	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_203
Epoch: 203	max: 0.9990283/1.0	min: 0.00097168575	loss: 34429.42578125	train_loss: 34460.58078771445	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_204
Epoch: 204	max: 0.9988826/1.0	min: 0.0011174217	loss: 34429.2109375	train_loss: 34460.44871407779	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_205
Epoch: 205	max: 0.99890757/1.0	min: 0.001092473	loss: 34429.265625	train_loss: 34460.31048276276	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_206
Epoch: 206	max: 0.99909127/1.0	min: 0.000908797	loss: 34429.26953125	train_loss: 34460.14575397931	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_207
Epoch: 207	max: 0.9990017/1.0	min: 0.000998343	loss: 34428.9609375	train_loss: 34460.005271719776	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_208
Epoch: 208	max: 0.99896383/1.0	min: 0.001036153	loss: 34428.80078125	train_loss: 34459.853667800846	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_209
Epoch: 209	max: 0.99898154/1.0	min: 0.001018418	loss: 34428.64453125	train_loss: 34459.71580228849	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_210
Epoch: 210	max: 0.99892825/1.0	min: 0.0010717666	loss: 34428.6015625	train_loss: 34459.586986521426	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_211
Epoch: 211	max: 0.99901414/1.0	min: 0.0009858608	loss: 34428.4140625	train_loss: 34459.4476616693	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_212
Epoch: 212	max: 0.9988901/1.0	min: 0.0011098571	loss: 34428.296875	train_loss: 34459.32612373034	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_213
Epoch: 213	max: 0.99894017/1.0	min: 0.0010598385	loss: 34428.15234375	train_loss: 34459.1812189358	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_214
Epoch: 214	max: 0.99909735/1.0	min: 0.0009026914	loss: 34428.265625	train_loss: 34459.06761059241	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_215
Epoch: 215	max: 0.99890435/1.0	min: 0.0010956028	loss: 34427.875	train_loss: 34458.92199257943	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_216
Epoch: 216	max: 0.9991136/1.0	min: 0.0008863621	loss: 34427.9921875	train_loss: 34458.817605269884	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_217
Epoch: 217	max: 0.9989666/1.0	min: 0.0010333773	loss: 34427.6875	train_loss: 34458.70068050911	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_218
Epoch: 218	max: 0.9990374/1.0	min: 0.0009626564	loss: 34427.65625	train_loss: 34458.53618833612	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_219
Epoch: 219	max: 0.99899/1.0	min: 0.0010100381	loss: 34427.44140625	train_loss: 34458.40728498931	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_220
Epoch: 220	max: 0.99914134/1.0	min: 0.00085858465	loss: 34427.515625	train_loss: 34458.31462126842	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_221
Epoch: 221	max: 0.99890566/1.0	min: 0.0010943704	loss: 34427.21484375	train_loss: 34458.158558524556	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_222
Epoch: 222	max: 0.9991505/1.0	min: 0.0008494649	loss: 34427.21875	train_loss: 34458.083771232035	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_223
Epoch: 223	max: 0.9989366/1.0	min: 0.0010633906	loss: 34426.98828125	train_loss: 34457.91907777081	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_224
Epoch: 224	max: 0.99903345/1.0	min: 0.0009666249	loss: 34426.98046875	train_loss: 34457.88563730955	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_225
Epoch: 225	max: 0.99926037/1.0	min: 0.0007395859	loss: 34427.14453125	train_loss: 34457.688011446335	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_226
Epoch: 226	max: 0.9990877/1.0	min: 0.0009122672	loss: 34426.78515625	train_loss: 34457.589720848046	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_227
Epoch: 227	max: 0.9991673/1.0	min: 0.0008326826	loss: 34426.73828125	train_loss: 34457.45573255373	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_228
Epoch: 228	max: 0.9991302/1.0	min: 0.0008697924	loss: 34426.5546875	train_loss: 34457.328481125354	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_229
Epoch: 229	max: 0.999054/1.0	min: 0.0009459885	loss: 34426.37109375	train_loss: 34457.22333511396	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_230
Epoch: 230	max: 0.99926037/1.0	min: 0.0007395719	loss: 34426.5546875	train_loss: 34457.13394668184	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_231
Epoch: 231	max: 0.9990792/1.0	min: 0.0009207008	loss: 34426.15625	train_loss: 34457.01355550523	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_232
Epoch: 232	max: 0.9991592/1.0	min: 0.00084081996	loss: 34426.25390625	train_loss: 34456.895685754214	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_233
Epoch: 233	max: 0.99909365/1.0	min: 0.0009063766	loss: 34426.015625	train_loss: 34456.77769455283	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_234
Epoch: 234	max: 0.99924755/1.0	min: 0.0007524929	loss: 34426.0859375	train_loss: 34456.672468703546	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_235
Epoch: 235	max: 0.99923444/1.0	min: 0.00076554104	loss: 34425.984375	train_loss: 34456.56723656401	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_236
Epoch: 236	max: 0.9992483/1.0	min: 0.0007516092	loss: 34425.921875	train_loss: 34456.4440583194	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_237
Epoch: 237	max: 0.99917716/1.0	min: 0.00082280603	loss: 34425.75	train_loss: 34456.347246899386	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_238
Epoch: 238	max: 0.99917126/1.0	min: 0.00082879595	loss: 34425.5859375	train_loss: 34456.25361302722	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_239
Epoch: 239	max: 0.9992379/1.0	min: 0.0007621447	loss: 34425.546875	train_loss: 34456.13776728756	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_240
Epoch: 240	max: 0.99930215/1.0	min: 0.0006978432	loss: 34425.53515625	train_loss: 34456.04922174997	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_241
Epoch: 241	max: 0.9991829/1.0	min: 0.0008170887	loss: 34425.32421875	train_loss: 34455.98352194429	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_242
Epoch: 242	max: 0.9992793/1.0	min: 0.00072075013	loss: 34425.328125	train_loss: 34455.81765994673	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_243
Epoch: 243	max: 0.9992186/1.0	min: 0.0007814171	loss: 34425.06640625	train_loss: 34455.71941870278	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_244
Epoch: 244	max: 0.99933356/1.0	min: 0.0006664692	loss: 34425.23828125	train_loss: 34455.64354851821	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_245
Epoch: 245	max: 0.99912316/1.0	min: 0.00087688444	loss: 34424.95703125	train_loss: 34455.54952513393	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_246
Epoch: 246	max: 0.99919623/1.0	min: 0.0008038224	loss: 34424.921875	train_loss: 34455.4255010916	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_247
Epoch: 247	max: 0.99931157/1.0	min: 0.00068846275	loss: 34424.98828125	train_loss: 34455.323508434754	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_248
Epoch: 248	max: 0.99921453/1.0	min: 0.00078545	loss: 34424.66015625	train_loss: 34455.22639701784	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_249
Epoch: 249	max: 0.99924505/1.0	min: 0.0007549234	loss: 34424.65625	train_loss: 34455.128858831136	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_250
Epoch: 250	max: 0.9992194/1.0	min: 0.0007806096	loss: 34424.51171875	train_loss: 34455.02449716648	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_251
Epoch: 251	max: 0.99927884/1.0	min: 0.00072120427	loss: 34424.53515625	train_loss: 34454.92730349235	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_252
Epoch: 252	max: 0.9993279/1.0	min: 0.00067211606	loss: 34424.42578125	train_loss: 34454.83890843707	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_253
Epoch: 253	max: 0.99935395/1.0	min: 0.0006460397	loss: 34424.46484375	train_loss: 34454.748155986774	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_254
Epoch: 254	max: 0.99926347/1.0	min: 0.0007365366	loss: 34424.2578125	train_loss: 34454.6458609137	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_255
Epoch: 255	max: 0.9992298/1.0	min: 0.0007701853	loss: 34424.11328125	train_loss: 34454.55029109377	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_256
Epoch: 256	max: 0.9993616/1.0	min: 0.0006384008	loss: 34424.21875	train_loss: 34454.49127250945	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_257
Epoch: 257	max: 0.9993636/1.0	min: 0.00063646835	loss: 34424.09375	train_loss: 34454.369965858416	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_258
Epoch: 258	max: 0.99920446/1.0	min: 0.00079561124	loss: 34423.9609375	train_loss: 34454.27440378035	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_259
Epoch: 259	max: 0.9992342/1.0	min: 0.00076583365	loss: 34423.90234375	train_loss: 34454.19546443391	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_260
Epoch: 260	max: 0.9993755/1.0	min: 0.000624447	loss: 34423.88671875	train_loss: 34454.10861920135	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_261
Epoch: 261	max: 0.9993272/1.0	min: 0.00067286694	loss: 34423.6640625	train_loss: 34454.03259708287	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_262
Epoch: 262	max: 0.9993451/1.0	min: 0.00065481383	loss: 34423.796875	train_loss: 34453.92400304255	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_263
Epoch: 263	max: 0.9993119/1.0	min: 0.00068812456	loss: 34423.53125	train_loss: 34453.83710555246	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_264
Epoch: 264	max: 0.99926776/1.0	min: 0.00073218567	loss: 34423.4609375	train_loss: 34453.73967430014	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_265
Epoch: 265	max: 0.99926466/1.0	min: 0.000735391	loss: 34423.484375	train_loss: 34453.67533173851	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_266
Epoch: 266	max: 0.9993438/1.0	min: 0.0006561526	loss: 34423.3984375	train_loss: 34453.57080362396	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_267
Epoch: 267	max: 0.9993345/1.0	min: 0.0006654425	loss: 34423.1953125	train_loss: 34453.490205584974	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_268
Epoch: 268	max: 0.9993079/1.0	min: 0.00069208274	loss: 34423.13671875	train_loss: 34453.39780218398	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_269
Epoch: 269	max: 0.9995136/1.0	min: 0.0004863249	loss: 34423.5546875	train_loss: 34453.34730157624	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_270
Epoch: 270	max: 0.9994025/1.0	min: 0.00059743016	loss: 34423.04296875	train_loss: 34453.267178209775	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_271
Epoch: 271	max: 0.999395/1.0	min: 0.0006049258	loss: 34422.921875	train_loss: 34453.154200343735	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_272
Epoch: 272	max: 0.99941397/1.0	min: 0.00058609556	loss: 34422.96875	train_loss: 34453.06683301979	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_273
Epoch: 273	max: 0.9994344/1.0	min: 0.0005655279	loss: 34422.9765625	train_loss: 34452.985259507	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_274
Epoch: 274	max: 0.99926287/1.0	min: 0.0007371584	loss: 34422.76953125	train_loss: 34452.927295750495	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_275
Epoch: 275	max: 0.99941015/1.0	min: 0.00058982655	loss: 34422.76171875	train_loss: 34452.844802408494	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_276
Epoch: 276	max: 0.9993425/1.0	min: 0.0006575155	loss: 34422.63671875	train_loss: 34452.735513052765	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_277
Epoch: 277	max: 0.99945813/1.0	min: 0.0005419176	loss: 34422.61328125	train_loss: 34452.66070543788	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_278
Epoch: 278	max: 0.99931705/1.0	min: 0.0006829635	loss: 34422.46484375	train_loss: 34452.591232445346	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_279
Epoch: 279	max: 0.9994778/1.0	min: 0.0005222161	loss: 34422.61328125	train_loss: 34452.525391834664	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_280
Epoch: 280	max: 0.99942005/1.0	min: 0.0005799546	loss: 34422.36328125	train_loss: 34452.434063099994	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_281
Epoch: 281	max: 0.9994252/1.0	min: 0.0005748344	loss: 34422.328125	train_loss: 34452.36094756441	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_282
Epoch: 282	max: 0.9993692/1.0	min: 0.0006308423	loss: 34422.26171875	train_loss: 34452.26633047659	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_283
Epoch: 283	max: 0.9994791/1.0	min: 0.0005209325	loss: 34422.16796875	train_loss: 34452.19821472811	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_284
Epoch: 284	max: 0.9993451/1.0	min: 0.0006548385	loss: 34422.01171875	train_loss: 34452.15389986297	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_285
Epoch: 285	max: 0.9994205/1.0	min: 0.00057946675	loss: 34422.046875	train_loss: 34452.0532712243	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_286
Epoch: 286	max: 0.9994562/1.0	min: 0.0005437235	loss: 34421.96875	train_loss: 34451.96813597408	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_287
Epoch: 287	max: 0.99942434/1.0	min: 0.0005756678	loss: 34421.86328125	train_loss: 34451.88746487133	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_288
Epoch: 288	max: 0.99954057/1.0	min: 0.00045947626	loss: 34421.94140625	train_loss: 34451.84557417472	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_289
Epoch: 289	max: 0.99943274/1.0	min: 0.0005672635	loss: 34421.80859375	train_loss: 34451.769970600304	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_290
Epoch: 290	max: 0.9995315/1.0	min: 0.00046845997	loss: 34421.91015625	train_loss: 34451.67749703874	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_291
Epoch: 291	max: 0.9993981/1.0	min: 0.00060184597	loss: 34421.546875	train_loss: 34451.64674058203	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_292
Epoch: 292	max: 0.9995196/1.0	min: 0.0004804156	loss: 34421.59375	train_loss: 34451.53504157376	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_293
Epoch: 293	max: 0.9994873/1.0	min: 0.00051271054	loss: 34421.55078125	train_loss: 34451.48184825189	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_294
Epoch: 294	max: 0.9993808/1.0	min: 0.0006190971	loss: 34421.53125	train_loss: 34451.42407513858	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_295
Epoch: 295	max: 0.9994986/1.0	min: 0.00050142664	loss: 34421.453125	train_loss: 34451.35042880203	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_296
Epoch: 296	max: 0.99951184/1.0	min: 0.00048821347	loss: 34421.390625	train_loss: 34451.25422705314	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_297
Epoch: 297	max: 0.99931324/1.0	min: 0.00068676646	loss: 34421.328125	train_loss: 34451.21490229778	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_298
Epoch: 298	max: 0.99964285/1.0	min: 0.0003570979	loss: 34421.7109375	train_loss: 34451.20392821752	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_299
Epoch: 299	max: 0.9995609/1.0	min: 0.00043905934	loss: 34421.2109375	train_loss: 34451.0728934411	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_300
Epoch: 300	max: 0.99949455/1.0	min: 0.00050537486	loss: 34421.0546875	train_loss: 34451.00337206197	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_301
Epoch: 301	max: 0.99952686/1.0	min: 0.00047319758	loss: 34421.05859375	train_loss: 34450.90366083318	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_302
Epoch: 302	max: 0.99943835/1.0	min: 0.0005615994	loss: 34420.9921875	train_loss: 34450.84608465332	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_303
Epoch: 303	max: 0.999566/1.0	min: 0.00043391634	loss: 34421.171875	train_loss: 34450.78472173835	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_304
Epoch: 304	max: 0.9994679/1.0	min: 0.0005321474	loss: 34420.921875	train_loss: 34450.71038976372	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_305
Epoch: 305	max: 0.99949443/1.0	min: 0.0005055006	loss: 34420.82421875	train_loss: 34450.64011210207	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_306
Epoch: 306	max: 0.9994962/1.0	min: 0.00050376996	loss: 34420.76953125	train_loss: 34450.59250259352	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_307
Epoch: 307	max: 0.99942005/1.0	min: 0.0005799618	loss: 34420.79296875	train_loss: 34450.53260192153	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_308
Epoch: 308	max: 0.9995735/1.0	min: 0.00042645392	loss: 34420.79296875	train_loss: 34450.485740469776	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_309
Epoch: 309	max: 0.999503/1.0	min: 0.0004970095	loss: 34420.6640625	train_loss: 34450.39370383919	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_310
Epoch: 310	max: 0.9996377/1.0	min: 0.00036226562	loss: 34420.78515625	train_loss: 34450.328990636226	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_311
Epoch: 311	max: 0.9994905/1.0	min: 0.0005094735	loss: 34420.64453125	train_loss: 34450.290813610955	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_312
Epoch: 312	max: 0.99956495/1.0	min: 0.00043509397	loss: 34420.671875	train_loss: 34450.19658216431	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_313
Epoch: 313	max: 0.9996124/1.0	min: 0.00038763444	loss: 34420.62109375	train_loss: 34450.14540607968	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_314
Epoch: 314	max: 0.9995431/1.0	min: 0.0004569889	loss: 34420.296875	train_loss: 34450.08004110925	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_315
Epoch: 315	max: 0.99958366/1.0	min: 0.00041639106	loss: 34420.40625	train_loss: 34450.013275346835	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_316
Epoch: 316	max: 0.9995703/1.0	min: 0.0004296569	loss: 34420.37109375	train_loss: 34449.95842284854	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_317
Epoch: 317	max: 0.9995554/1.0	min: 0.00044462932	loss: 34420.234375	train_loss: 34449.90434211647	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_318
Epoch: 318	max: 0.99955684/1.0	min: 0.0004431293	loss: 34420.30078125	train_loss: 34449.851981527936	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_319
Epoch: 319	max: 0.99958307/1.0	min: 0.00041696304	loss: 34420.18359375	train_loss: 34449.77689859331	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_320
Epoch: 320	max: 0.9996333/1.0	min: 0.00036666784	loss: 34420.1640625	train_loss: 34449.715043102784	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_321
Epoch: 321	max: 0.99951315/1.0	min: 0.00048684768	loss: 34420.0234375	train_loss: 34449.66415782159	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_322
Epoch: 322	max: 0.9995989/1.0	min: 0.00040105853	loss: 34420.109375	train_loss: 34449.59669335671	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_323
Epoch: 323	max: 0.99947613/1.0	min: 0.0005239058	loss: 34420.0234375	train_loss: 34449.54064474173	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_324
Epoch: 324	max: 0.99960035/1.0	min: 0.0003996552	loss: 34420.1171875	train_loss: 34449.482716307444	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_325
Epoch: 325	max: 0.9995635/1.0	min: 0.00043651077	loss: 34419.80078125	train_loss: 34449.4316655441	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_326
Epoch: 326	max: 0.99962604/1.0	min: 0.00037399348	loss: 34419.7890625	train_loss: 34449.366778149386	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_327
Epoch: 327	max: 0.9996344/1.0	min: 0.0003655497	loss: 34419.83984375	train_loss: 34449.29861014338	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_328
Epoch: 328	max: 0.99961287/1.0	min: 0.00038713161	loss: 34419.67578125	train_loss: 34449.241573957945	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_329
Epoch: 329	max: 0.99965346/1.0	min: 0.00034650025	loss: 34419.69140625	train_loss: 34449.188424667875	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_330
Epoch: 330	max: 0.9995859/1.0	min: 0.00041406875	loss: 34419.59375	train_loss: 34449.13575440511	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_331
Epoch: 331	max: 0.9995727/1.0	min: 0.00042730893	loss: 34419.46875	train_loss: 34449.076049698844	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_332
Epoch: 332	max: 0.9996/1.0	min: 0.00040008404	loss: 34419.62890625	train_loss: 34449.0494302962	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_333
Epoch: 333	max: 0.9995957/1.0	min: 0.00040426484	loss: 34419.484375	train_loss: 34448.96210893952	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_334
Epoch: 334	max: 0.9996239/1.0	min: 0.00037614256	loss: 34419.5390625	train_loss: 34448.91560651632	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_335
Epoch: 335	max: 0.9996117/1.0	min: 0.00038839845	loss: 34419.4296875	train_loss: 34448.85674518844	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_336
Epoch: 336	max: 0.9996766/1.0	min: 0.0003233754	loss: 34419.41796875	train_loss: 34448.802909776416	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_337
Epoch: 337	max: 0.99961025/1.0	min: 0.00038974	loss: 34419.34765625	train_loss: 34448.75106498901	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_338
Epoch: 338	max: 0.999468/1.0	min: 0.00053197995	loss: 34419.34375	train_loss: 34448.70613174316	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_339
Epoch: 339	max: 0.99969006/1.0	min: 0.00031000344	loss: 34419.23828125	train_loss: 34448.69098286727	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_340
Epoch: 340	max: 0.9996043/1.0	min: 0.00039570566	loss: 34419.125	train_loss: 34448.584025261676	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_341
Epoch: 341	max: 0.99952686/1.0	min: 0.00047314522	loss: 34419.13671875	train_loss: 34448.53919459541	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_342
Epoch: 342	max: 0.99973494/1.0	min: 0.0002650334	loss: 34419.35546875	train_loss: 34448.566759956026	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_343
Epoch: 343	max: 0.99960846/1.0	min: 0.0003916033	loss: 34418.984375	train_loss: 34448.4547744991	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_344
Epoch: 344	max: 0.99963784/1.0	min: 0.00036212747	loss: 34418.9296875	train_loss: 34448.37163035737	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_345
Epoch: 345	max: 0.9996642/1.0	min: 0.00033580937	loss: 34418.96484375	train_loss: 34448.323706335934	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_346
Epoch: 346	max: 0.99961793/1.0	min: 0.0003819946	loss: 34418.9375	train_loss: 34448.27768100458	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_347
Epoch: 347	max: 0.9996383/1.0	min: 0.00036166864	loss: 34418.88671875	train_loss: 34448.22140545646	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_348
Epoch: 348	max: 0.99958974/1.0	min: 0.00041026183	loss: 34418.81640625	train_loss: 34448.19757360569	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_349
Epoch: 349	max: 0.9996123/1.0	min: 0.00038772423	loss: 34418.74609375	train_loss: 34448.134673448534	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_350
Epoch: 350	max: 0.99969363/1.0	min: 0.0003063958	loss: 34418.87109375	train_loss: 34448.07688630311	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_351
Epoch: 351	max: 0.9997079/1.0	min: 0.00029215505	loss: 34418.81640625	train_loss: 34448.040409099005	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_352
Epoch: 352	max: 0.99962986/1.0	min: 0.00037012534	loss: 34418.61328125	train_loss: 34448.010516343056	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_353
Epoch: 353	max: 0.9995807/1.0	min: 0.0004193492	loss: 34418.640625	train_loss: 34447.9689319336	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_354
Epoch: 354	max: 0.9995571/1.0	min: 0.00044288603	loss: 34418.62109375	train_loss: 34447.91530603555	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_355
Epoch: 355	max: 0.99968004/1.0	min: 0.0003199183	loss: 34418.5	train_loss: 34447.85627487071	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_356
Epoch: 356	max: 0.99957865/1.0	min: 0.00042129925	loss: 34418.51953125	train_loss: 34447.79051506565	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_357
Epoch: 357	max: 0.99969876/1.0	min: 0.0003012165	loss: 34418.5390625	train_loss: 34447.74579617243	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_358
Epoch: 358	max: 0.9996301/1.0	min: 0.00036984356	loss: 34418.3046875	train_loss: 34447.70370902623	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_359
Epoch: 359	max: 0.9997043/1.0	min: 0.00029563167	loss: 34418.265625	train_loss: 34447.65414857008	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_360
Epoch: 360	max: 0.9996413/1.0	min: 0.00035871097	loss: 34418.2109375	train_loss: 34447.60712018456	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_361
Epoch: 361	max: 0.9996846/1.0	min: 0.00031546218	loss: 34418.21875	train_loss: 34447.57155022916	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_362
Epoch: 362	max: 0.9997272/1.0	min: 0.00027281657	loss: 34418.421875	train_loss: 34447.506379288985	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_363
Epoch: 363	max: 0.99962544/1.0	min: 0.00037451953	loss: 34418.24609375	train_loss: 34447.49672567896	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_364
Epoch: 364	max: 0.9997329/1.0	min: 0.00026705497	loss: 34418.2890625	train_loss: 34447.43396584293	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_365
Epoch: 365	max: 0.999647/1.0	min: 0.00035300152	loss: 34418.046875	train_loss: 34447.39784863511	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_366
Epoch: 366	max: 0.9996656/1.0	min: 0.0003344153	loss: 34418.1640625	train_loss: 34447.326910496406	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_367
Epoch: 367	max: 0.99971515/1.0	min: 0.00028482926	loss: 34418.12109375	train_loss: 34447.301984624675	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_368
Epoch: 368	max: 0.99968493/1.0	min: 0.0003150456	loss: 34418.1015625	train_loss: 34447.24435909049	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_369
Epoch: 369	max: 0.99962914/1.0	min: 0.00037086394	loss: 34418.0390625	train_loss: 34447.22389930169	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_370
Epoch: 370	max: 0.9997187/1.0	min: 0.00028121032	loss: 34417.9609375	train_loss: 34447.174649971355	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_371
Epoch: 371	max: 0.9996716/1.0	min: 0.0003283788	loss: 34417.921875	train_loss: 34447.11862022715	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_372
Epoch: 372	max: 0.9996407/1.0	min: 0.00035931304	loss: 34417.9921875	train_loss: 34447.0845212243	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_373
Epoch: 373	max: 0.99965644/1.0	min: 0.00034357354	loss: 34417.73828125	train_loss: 34447.02231928574	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_374
Epoch: 374	max: 0.99968624/1.0	min: 0.0003138013	loss: 34417.87109375	train_loss: 34446.99785647374	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_375
Epoch: 375	max: 0.99961936/1.0	min: 0.00038058232	loss: 34417.73046875	train_loss: 34446.94060980661	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_376
Epoch: 376	max: 0.99978226/1.0	min: 0.00021780595	loss: 34417.86328125	train_loss: 34446.92621866484	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_377
Epoch: 377	max: 0.9996413/1.0	min: 0.00035867727	loss: 34417.71875	train_loss: 34446.894989471075	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_378
Epoch: 378	max: 0.9996722/1.0	min: 0.00032784892	loss: 34417.64453125	train_loss: 34446.82710839759	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_379
Epoch: 379	max: 0.99970526/1.0	min: 0.00029471764	loss: 34417.57421875	train_loss: 34446.78531253871	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_380
Epoch: 380	max: 0.999724/1.0	min: 0.00027604785	loss: 34417.734375	train_loss: 34446.74027139075	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_381
Epoch: 381	max: 0.9997105/1.0	min: 0.0002894386	loss: 34417.56640625	train_loss: 34446.70719382897	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_382
Epoch: 382	max: 0.99967265/1.0	min: 0.00032741352	loss: 34417.46875	train_loss: 34446.666813278054	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_383
Epoch: 383	max: 0.9997334/1.0	min: 0.0002665838	loss: 34417.3203125	train_loss: 34446.62332243667	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_384
Epoch: 384	max: 0.99972767/1.0	min: 0.0002723036	loss: 34417.3359375	train_loss: 34446.589511334074	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_385
Epoch: 385	max: 0.99970883/1.0	min: 0.00029116566	loss: 34417.40625	train_loss: 34446.53812718707	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_386
Epoch: 386	max: 0.99972206/1.0	min: 0.0002779467	loss: 34417.3671875	train_loss: 34446.50197417317	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_387
Epoch: 387	max: 0.9997532/1.0	min: 0.00024679225	loss: 34417.21875	train_loss: 34446.45750785798	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_388
Epoch: 388	max: 0.99972934/1.0	min: 0.00027065896	loss: 34417.21875	train_loss: 34446.432609082745	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_389
Epoch: 389	max: 0.999765/1.0	min: 0.00023498813	loss: 34417.265625	train_loss: 34446.39552172364	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_390
Epoch: 390	max: 0.99968266/1.0	min: 0.000317375	loss: 34417.23828125	train_loss: 34446.35794130512	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_391
Epoch: 391	max: 0.99973446/1.0	min: 0.00026557775	loss: 34417.1640625	train_loss: 34446.311875329025	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_392
Epoch: 392	max: 0.9997515/1.0	min: 0.0002484467	loss: 34417.0703125	train_loss: 34446.26835835888	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_393
Epoch: 393	max: 0.9997502/1.0	min: 0.0002497878	loss: 34417.078125	train_loss: 34446.23887301808	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_394
Epoch: 394	max: 0.9997117/1.0	min: 0.00028823988	loss: 34417.23046875	train_loss: 34446.20255887681	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_395
Epoch: 395	max: 0.99968934/1.0	min: 0.00031072454	loss: 34417.21484375	train_loss: 34446.16846616422	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_396
Epoch: 396	max: 0.99979144/1.0	min: 0.00020858693	loss: 34417.0390625	train_loss: 34446.13875824508	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_397
Epoch: 397	max: 0.99968266/1.0	min: 0.00031740408	loss: 34416.96484375	train_loss: 34446.13016768859	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_398
Epoch: 398	max: 0.9997216/1.0	min: 0.00027843312	loss: 34416.98828125	train_loss: 34446.07623985817	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_399
Epoch: 399	max: 0.9997768/1.0	min: 0.00022317769	loss: 34416.84375	train_loss: 34446.02573441177	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_400
Epoch: 400	max: 0.99977714/1.0	min: 0.00022284406	loss: 34416.9765625	train_loss: 34445.99964677784	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_401
Epoch: 401	max: 0.9997086/1.0	min: 0.0002914023	loss: 34416.82421875	train_loss: 34445.97164545398	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_402
Epoch: 402	max: 0.9997491/1.0	min: 0.00025087374	loss: 34416.73828125	train_loss: 34445.90902690682	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_403
Epoch: 403	max: 0.9997819/1.0	min: 0.0002180873	loss: 34416.86328125	train_loss: 34445.882072185064	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_404
Epoch: 404	max: 0.999762/1.0	min: 0.00023799851	loss: 34416.9609375	train_loss: 34445.84383806361	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_405
Epoch: 405	max: 0.9997844/1.0	min: 0.00021560953	loss: 34416.796875	train_loss: 34445.81349434458	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_406
Epoch: 406	max: 0.99974805/1.0	min: 0.0002518998	loss: 34416.6484375	train_loss: 34445.76865642032	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_407
Epoch: 407	max: 0.9996948/1.0	min: 0.00030521155	loss: 34416.671875	train_loss: 34445.73694142512	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_408
Epoch: 408	max: 0.9997514/1.0	min: 0.0002486316	loss: 34416.65625	train_loss: 34445.732678565895	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_409
Epoch: 409	max: 0.9997849/1.0	min: 0.0002150847	loss: 34416.68359375	train_loss: 34445.672341930665	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_410
Epoch: 410	max: 0.9997483/1.0	min: 0.00025167773	loss: 34416.6953125	train_loss: 34445.66112349808	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_411
Epoch: 411	max: 0.99969447/1.0	min: 0.00030556443	loss: 34416.73046875	train_loss: 34445.61641379831	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_412
Epoch: 412	max: 0.9997135/1.0	min: 0.00028646298	loss: 34416.5234375	train_loss: 34445.597299156914	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_413
Epoch: 413	max: 0.9997799/1.0	min: 0.00022012247	loss: 34416.46875	train_loss: 34445.550540768614	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_414
Epoch: 414	max: 0.9997465/1.0	min: 0.00025349017	loss: 34416.5703125	train_loss: 34445.511886167624	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_415
Epoch: 415	max: 0.99975234/1.0	min: 0.0002476183	loss: 34416.62890625	train_loss: 34445.48235244023	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_416
Epoch: 416	max: 0.9997732/1.0	min: 0.00022680059	loss: 34416.37109375	train_loss: 34445.454879498015	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_417
Epoch: 417	max: 0.9997483/1.0	min: 0.00025170462	loss: 34416.3125	train_loss: 34445.42495722625	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_418
Epoch: 418	max: 0.99977905/1.0	min: 0.00022096484	loss: 34416.328125	train_loss: 34445.425664154434	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_419
Epoch: 419	max: 0.9998022/1.0	min: 0.00019787907	loss: 34416.37109375	train_loss: 34445.37087842964	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_420
Epoch: 420	max: 0.99981016/1.0	min: 0.00018981023	loss: 34416.2734375	train_loss: 34445.333418009875	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_421
Epoch: 421	max: 0.99972886/1.0	min: 0.000271112	loss: 34416.24609375	train_loss: 34445.307384568936	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_422
Epoch: 422	max: 0.9997595/1.0	min: 0.00024045432	loss: 34416.28125	train_loss: 34445.295495014245	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_423
Epoch: 423	max: 0.99984086/1.0	min: 0.00015913951	loss: 34416.35546875	train_loss: 34445.27044285349	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_424
Epoch: 424	max: 0.9998173/1.0	min: 0.00018265772	loss: 34416.29296875	train_loss: 34445.25142692075	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_425
Epoch: 425	max: 0.9998074/1.0	min: 0.00019265818	loss: 34416.23828125	train_loss: 34445.18981578255	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_426
Epoch: 426	max: 0.99984205/1.0	min: 0.00015790503	loss: 34416.37109375	train_loss: 34445.1683200367	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_427
Epoch: 427	max: 0.9997727/1.0	min: 0.0002272452	loss: 34416.140625	train_loss: 34445.16979244085	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_428
Epoch: 428	max: 0.99981934/1.0	min: 0.00018064547	loss: 34416.234375	train_loss: 34445.08515702419	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_429
Epoch: 429	max: 0.9998103/1.0	min: 0.00018975958	loss: 34416.12890625	train_loss: 34445.06905493233	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_430
Epoch: 430	max: 0.99975485/1.0	min: 0.00024518382	loss: 34415.9765625	train_loss: 34445.04937416775	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_431
Epoch: 431	max: 0.9998078/1.0	min: 0.00019221503	loss: 34415.89453125	train_loss: 34445.0089302304	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_432
Epoch: 432	max: 0.99981946/1.0	min: 0.00018057055	loss: 34416.078125	train_loss: 34444.98737013037	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_433
Epoch: 433	max: 0.9997671/1.0	min: 0.0002328304	loss: 34416.05078125	train_loss: 34444.95299242072	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_434
Epoch: 434	max: 0.9998467/1.0	min: 0.00015327786	loss: 34415.953125	train_loss: 34444.940662548	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_435
Epoch: 435	max: 0.99977344/1.0	min: 0.0002265672	loss: 34415.890625	train_loss: 34444.917089565526	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_436
Epoch: 436	max: 0.9998072/1.0	min: 0.00019279083	loss: 34415.94921875	train_loss: 34444.864406722256	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_437
Epoch: 437	max: 0.99977964/1.0	min: 0.00022040914	loss: 34415.8203125	train_loss: 34444.85130266397	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_438
Epoch: 438	max: 0.9998031/1.0	min: 0.00019684668	loss: 34415.765625	train_loss: 34444.81022970085	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_439
Epoch: 439	max: 0.9997857/1.0	min: 0.00021433628	loss: 34415.921875	train_loss: 34444.78660155766	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_440
Epoch: 440	max: 0.9997378/1.0	min: 0.0002621681	loss: 34415.94140625	train_loss: 34444.75892442401	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_441
Epoch: 441	max: 0.99977475/1.0	min: 0.0002252984	loss: 34416.0	train_loss: 34444.748857592436	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_442
Epoch: 442	max: 0.99983215/1.0	min: 0.00016777507	loss: 34416.01953125	train_loss: 34444.74653213257	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_443
Epoch: 443	max: 0.99976784/1.0	min: 0.00023219948	loss: 34415.828125	train_loss: 34444.692973975754	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_444
Epoch: 444	max: 0.999816/1.0	min: 0.00018403427	loss: 34415.85546875	train_loss: 34444.67160935758	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_445
Epoch: 445	max: 0.9997315/1.0	min: 0.00026844826	loss: 34415.6953125	train_loss: 34444.64528898412	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_446
Epoch: 446	max: 0.999846/1.0	min: 0.00015400378	loss: 34415.53515625	train_loss: 34444.617626850304	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_447
Epoch: 447	max: 0.99981076/1.0	min: 0.00018921681	loss: 34415.46875	train_loss: 34444.57881934767	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_448
Epoch: 448	max: 0.9998072/1.0	min: 0.00019280773	loss: 34415.578125	train_loss: 34444.57390230165	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_449
Epoch: 449	max: 0.9997731/1.0	min: 0.00022689014	loss: 34415.6796875	train_loss: 34444.52669053094	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_450
Epoch: 450	max: 0.99982566/1.0	min: 0.00017433958	loss: 34415.51171875	train_loss: 34444.51040940868	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_451
Epoch: 451	max: 0.9998467/1.0	min: 0.00015329059	loss: 34415.55859375	train_loss: 34444.48414371206	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_452
Epoch: 452	max: 0.999754/1.0	min: 0.00024600897	loss: 34415.609375	train_loss: 34444.453681929735	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_453
Epoch: 453	max: 0.99983525/1.0	min: 0.00016475772	loss: 34415.64453125	train_loss: 34444.45224775099	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_454
Epoch: 454	max: 0.9997725/1.0	min: 0.00022753509	loss: 34415.546875	train_loss: 34444.43812080004	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_455
Epoch: 455	max: 0.9998405/1.0	min: 0.00015948495	loss: 34415.32421875	train_loss: 34444.39093757742	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_456
Epoch: 456	max: 0.99980646/1.0	min: 0.00019353398	loss: 34415.43359375	train_loss: 34444.35902951969	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_457
Epoch: 457	max: 0.9998578/1.0	min: 0.00014221812	loss: 34415.43359375	train_loss: 34444.32729468599	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_458
Epoch: 458	max: 0.9998286/1.0	min: 0.00017137108	loss: 34415.390625	train_loss: 34444.30981212452	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_459
Epoch: 459	max: 0.9997931/1.0	min: 0.00020695003	loss: 34415.49609375	train_loss: 34444.28242143952	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_460
Epoch: 460	max: 0.9998416/1.0	min: 0.00015836809	loss: 34415.32421875	train_loss: 34444.26407469342	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_461
Epoch: 461	max: 0.9998442/1.0	min: 0.00015583712	loss: 34415.2890625	train_loss: 34444.24686212916	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_462
Epoch: 462	max: 0.9997367/1.0	min: 0.00026323958	loss: 34415.38671875	train_loss: 34444.22814619333	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_463
Epoch: 463	max: 0.9998331/1.0	min: 0.00016689466	loss: 34415.140625	train_loss: 34444.20423160148	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_464
Epoch: 464	max: 0.9998216/1.0	min: 0.00017845651	loss: 34415.15234375	train_loss: 34444.180953293384	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_465
Epoch: 465	max: 0.9997702/1.0	min: 0.00022972476	loss: 34415.234375	train_loss: 34444.14422157578	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_466
Epoch: 466	max: 0.9998709/1.0	min: 0.00012914141	loss: 34415.45703125	train_loss: 34444.12991607829	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_467
Epoch: 467	max: 0.99978477/1.0	min: 0.00021521107	loss: 34415.23828125	train_loss: 34444.15532726759	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_468
Epoch: 468	max: 0.9998473/1.0	min: 0.00015267835	loss: 34415.19140625	train_loss: 34444.11625557414	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_469
Epoch: 469	max: 0.99986327/1.0	min: 0.00013671332	loss: 34415.21875	train_loss: 34444.056789413786	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_470
Epoch: 470	max: 0.99978524/1.0	min: 0.00021481828	loss: 34415.19140625	train_loss: 34444.0369692958	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_471
Epoch: 471	max: 0.99989545/1.0	min: 0.00010456303	loss: 34415.09375	train_loss: 34444.03630978648	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_472
Epoch: 472	max: 0.9998715/1.0	min: 0.00012852078	loss: 34415.24609375	train_loss: 34443.99877485136	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_473
Epoch: 473	max: 0.99981076/1.0	min: 0.00018928468	loss: 34415.15234375	train_loss: 34443.96616325251	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_474
Epoch: 474	max: 0.999863/1.0	min: 0.00013693329	loss: 34415.00390625	train_loss: 34443.938856760185	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_475
Epoch: 475	max: 0.99989176/1.0	min: 0.000108188324	loss: 34415.1640625	train_loss: 34443.93621727131	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_476
Epoch: 476	max: 0.9998197/1.0	min: 0.00018036664	loss: 34415.04296875	train_loss: 34443.945467337115	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_477
Epoch: 477	max: 0.99987626/1.0	min: 0.00012377168	loss: 34415.1328125	train_loss: 34443.89139870169	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_478
Epoch: 478	max: 0.99984694/1.0	min: 0.00015298568	loss: 34414.8984375	train_loss: 34443.89517769494	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_479
Epoch: 479	max: 0.9998511/1.0	min: 0.0001488859	loss: 34414.859375	train_loss: 34443.83606524062	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_480
Epoch: 480	max: 0.99986815/1.0	min: 0.00013186735	loss: 34414.9453125	train_loss: 34443.8184980026	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_481
Epoch: 481	max: 0.99986863/1.0	min: 0.00013132223	loss: 34414.96875	train_loss: 34443.81492803945	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_482
Epoch: 482	max: 0.9998554/1.0	min: 0.000144605	loss: 34414.94140625	train_loss: 34443.77798777561	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_483
Epoch: 483	max: 0.99980193/1.0	min: 0.00019803006	loss: 34414.953125	train_loss: 34443.76110036929	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_484
Epoch: 484	max: 0.99984384/1.0	min: 0.00015610659	loss: 34414.90625	train_loss: 34443.75180288462	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_485
Epoch: 485	max: 0.9998853/1.0	min: 0.00011470236	loss: 34414.7734375	train_loss: 34443.73397581057	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_486
Epoch: 486	max: 0.99984574/1.0	min: 0.00015420625	loss: 34414.71484375	train_loss: 34443.70944622507	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_487
Epoch: 487	max: 0.9998683/1.0	min: 0.00013167696	loss: 34414.80859375	train_loss: 34443.67030485492	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_488
Epoch: 488	max: 0.9998342/1.0	min: 0.00016582597	loss: 34414.8203125	train_loss: 34443.66257945079	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_489
Epoch: 489	max: 0.99987066/1.0	min: 0.00012933204	loss: 34414.99609375	train_loss: 34443.645088179735	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_490
Epoch: 490	max: 0.999803/1.0	min: 0.00019700028	loss: 34414.765625	train_loss: 34443.6297651121	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_491
Epoch: 491	max: 0.99985766/1.0	min: 0.00014236168	loss: 34414.77734375	train_loss: 34443.61431575545	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_492
Epoch: 492	max: 0.99986875/1.0	min: 0.00013121685	loss: 34414.87890625	train_loss: 34443.576625983216	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_493
Epoch: 493	max: 0.9998324/1.0	min: 0.00016761868	loss: 34414.875	train_loss: 34443.57139442432	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_494
Epoch: 494	max: 0.9998105/1.0	min: 0.000189546	loss: 34414.69140625	train_loss: 34443.529804208476	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_495
Epoch: 495	max: 0.99989784/1.0	min: 0.00010214622	loss: 34414.60546875	train_loss: 34443.53651978431	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_496
Epoch: 496	max: 0.99985087/1.0	min: 0.00014906173	loss: 34414.62890625	train_loss: 34443.50350415738	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_497
Epoch: 497	max: 0.9998627/1.0	min: 0.00013728968	loss: 34414.671875	train_loss: 34443.4730515685	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_498
Epoch: 498	max: 0.9998149/1.0	min: 0.00018509931	loss: 34414.73828125	train_loss: 34443.460621535516	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_499
Epoch: 499	max: 0.9998902/1.0	min: 0.00010982524	loss: 34414.71484375	train_loss: 34443.46385859888	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_500
Epoch: 500	max: 0.99983203/1.0	min: 0.00016791814	loss: 34414.671875	train_loss: 34443.43253892218	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_501
Epoch: 501	max: 0.99984634/1.0	min: 0.00015366595	loss: 34414.61328125	train_loss: 34443.40372857441	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_502
Epoch: 502	max: 0.9998722/1.0	min: 0.00012783047	loss: 34414.6484375	train_loss: 34443.40633661201	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_503
Epoch: 503	max: 0.9997857/1.0	min: 0.00021428027	loss: 34414.56640625	train_loss: 34443.375302416236	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_504
Epoch: 504	max: 0.9999018/1.0	min: 9.825219e-05	loss: 34414.5390625	train_loss: 34443.370956332066	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_505
Epoch: 505	max: 0.99986565/1.0	min: 0.0001342892	loss: 34414.4765625	train_loss: 34443.31651850691	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_506
Epoch: 506	max: 0.9998746/1.0	min: 0.0001253741	loss: 34414.57421875	train_loss: 34443.30096560294	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_507
Epoch: 507	max: 0.99983704/1.0	min: 0.000162974	loss: 34414.4921875	train_loss: 34443.27944421219	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_508
Epoch: 508	max: 0.9998442/1.0	min: 0.0001557912	loss: 34414.32421875	train_loss: 34443.271004621885	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_509
Epoch: 509	max: 0.9998857/1.0	min: 0.00011429183	loss: 34414.34375	train_loss: 34443.25515123715	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_510
Epoch: 510	max: 0.9999037/1.0	min: 9.631948e-05	loss: 34414.55078125	train_loss: 34443.21660889307	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_511
Epoch: 511	max: 0.99981636/1.0	min: 0.00018362113	loss: 34414.37109375	train_loss: 34443.246469713864	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_512
Epoch: 512	max: 0.99987495/1.0	min: 0.00012498282	loss: 34414.31640625	train_loss: 34443.19651781014	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_513
Epoch: 513	max: 0.9998672/1.0	min: 0.00013278706	loss: 34414.35546875	train_loss: 34443.17519286898	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_514
Epoch: 514	max: 0.9998447/1.0	min: 0.00015526725	loss: 34414.3515625	train_loss: 34443.15003570931	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_515
Epoch: 515	max: 0.9998741/1.0	min: 0.00012591359	loss: 34414.40625	train_loss: 34443.14442141243	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_516
Epoch: 516	max: 0.9998516/1.0	min: 0.00014837399	loss: 34414.25390625	train_loss: 34443.11748846463	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_517
Epoch: 517	max: 0.9998838/1.0	min: 0.00011624356	loss: 34414.23828125	train_loss: 34443.10143379165	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_518
Epoch: 518	max: 0.99990165/1.0	min: 9.836112e-05	loss: 34414.16796875	train_loss: 34443.079573694726	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_519
Epoch: 519	max: 0.9999025/1.0	min: 9.7528384e-05	loss: 34414.32421875	train_loss: 34443.07470068051	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_520
Epoch: 520	max: 0.99983704/1.0	min: 0.00016298192	loss: 34414.2890625	train_loss: 34443.04523614595	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_521
Epoch: 521	max: 0.9998914/1.0	min: 0.00010857361	loss: 34414.1796875	train_loss: 34443.01243003298	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_522
Epoch: 522	max: 0.99981993/1.0	min: 0.00018013325	loss: 34414.26171875	train_loss: 34443.02333879134	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_523
Epoch: 523	max: 0.99981123/1.0	min: 0.00018876919	loss: 34414.140625	train_loss: 34443.014448237955	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_524
Epoch: 524	max: 0.9998808/1.0	min: 0.0001192019	loss: 34414.140625	train_loss: 34442.99992209758	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_525
Epoch: 525	max: 0.9998838/1.0	min: 0.00011623014	loss: 34413.984375	train_loss: 34442.973634143134	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_526
Epoch: 526	max: 0.99983716/1.0	min: 0.00016286061	loss: 34414.046875	train_loss: 34442.94340122941	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_527
Epoch: 527	max: 0.99991024/1.0	min: 8.9762245e-05	loss: 34414.0390625	train_loss: 34442.959270097854	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_528
Epoch: 528	max: 0.9999074/1.0	min: 9.264181e-05	loss: 34414.18359375	train_loss: 34442.89751912238	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_529
Epoch: 529	max: 0.99987686/1.0	min: 0.00012311462	loss: 34414.109375	train_loss: 34442.90893981094	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_530
Epoch: 530	max: 0.9998896/1.0	min: 0.0001103781	loss: 34413.92578125	train_loss: 34442.86379753499	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_531
Epoch: 531	max: 0.99991894/1.0	min: 8.109969e-05	loss: 34414.0546875	train_loss: 34442.8602367653	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_532
Epoch: 532	max: 0.99986017/1.0	min: 0.00013980288	loss: 34414.03125	train_loss: 34442.830408847396	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_533
Epoch: 533	max: 0.99991596/1.0	min: 8.400132e-05	loss: 34413.921875	train_loss: 34442.802762197294	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_534
Epoch: 534	max: 0.99988806/1.0	min: 0.000111917754	loss: 34413.8984375	train_loss: 34442.79649419748	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_535
Epoch: 535	max: 0.99988747/1.0	min: 0.000112546935	loss: 34413.9609375	train_loss: 34442.77789051855	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_536
Epoch: 536	max: 0.999846/1.0	min: 0.00015401933	loss: 34413.90625	train_loss: 34442.750179514274	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_537
Epoch: 537	max: 0.9998994/1.0	min: 0.00010059681	loss: 34413.9609375	train_loss: 34442.7497909699	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_538
Epoch: 538	max: 0.9999018/1.0	min: 9.825219e-05	loss: 34413.96875	train_loss: 34442.71647776539	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_539
Epoch: 539	max: 0.99990654/1.0	min: 9.3405106e-05	loss: 34413.87109375	train_loss: 34442.70869381348	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_540
Epoch: 540	max: 0.99986374/1.0	min: 0.00013627484	loss: 34413.8984375	train_loss: 34442.72219609346	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_541
Epoch: 541	max: 0.9999069/1.0	min: 9.3060335e-05	loss: 34413.78515625	train_loss: 34442.675236416915	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_542
Epoch: 542	max: 0.9999236/1.0	min: 7.644586e-05	loss: 34413.75390625	train_loss: 34442.65043489874	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_543
Epoch: 543	max: 0.99986744/1.0	min: 0.00013251245	loss: 34413.7734375	train_loss: 34442.631357998886	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_544
Epoch: 544	max: 0.99987483/1.0	min: 0.00012516147	loss: 34413.87890625	train_loss: 34442.605576168244	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_545
Epoch: 545	max: 0.9998697/1.0	min: 0.00013033125	loss: 34413.921875	train_loss: 34442.597243512326	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_546
Epoch: 546	max: 0.9998141/1.0	min: 0.0001859784	loss: 34413.82421875	train_loss: 34442.59258339914	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_547
Epoch: 547	max: 0.9999436/1.0	min: 5.6333414e-05	loss: 34413.7734375	train_loss: 34442.63643665614	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_548
Epoch: 548	max: 0.99986255/1.0	min: 0.0001374115	loss: 34413.69921875	train_loss: 34442.54893239812	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_549
Epoch: 549	max: 0.99990535/1.0	min: 9.465703e-05	loss: 34413.68359375	train_loss: 34442.54197005063	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_550
Epoch: 550	max: 0.99990857/1.0	min: 9.1387e-05	loss: 34413.671875	train_loss: 34442.50138095349	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_551
Epoch: 551	max: 0.99992275/1.0	min: 7.7228986e-05	loss: 34413.6953125	train_loss: 34442.505427040756	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_552
Epoch: 552	max: 0.99989367/1.0	min: 0.00010629367	loss: 34413.66015625	train_loss: 34442.48021859129	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_553
Epoch: 553	max: 0.999897/1.0	min: 0.000102974576	loss: 34413.68359375	train_loss: 34442.45852929905	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_554
Epoch: 554	max: 0.9999161/1.0	min: 8.3940155e-05	loss: 34413.64453125	train_loss: 34442.4635639245	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_555
Epoch: 555	max: 0.9998559/1.0	min: 0.00014409187	loss: 34413.76953125	train_loss: 34442.44236236916	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_556
Epoch: 556	max: 0.9999026/1.0	min: 9.740171e-05	loss: 34413.56640625	train_loss: 34442.419416476994	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_557
Epoch: 557	max: 0.99990535/1.0	min: 9.460396e-05	loss: 34413.57421875	train_loss: 34442.40006087034	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_558
Epoch: 558	max: 0.9999138/1.0	min: 8.6198605e-05	loss: 34413.63671875	train_loss: 34442.37556080066	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_559
Epoch: 559	max: 0.999874/1.0	min: 0.00012600451	loss: 34413.55078125	train_loss: 34442.374236459495	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_560
Epoch: 560	max: 0.999863/1.0	min: 0.00013698032	loss: 34413.52734375	train_loss: 34442.33629265762	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_561
Epoch: 561	max: 0.9999114/1.0	min: 8.861774e-05	loss: 34413.546875	train_loss: 34442.341102769264	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_562
Epoch: 562	max: 0.9998591/1.0	min: 0.00014083096	loss: 34413.48828125	train_loss: 34442.320304274275	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_563
Epoch: 563	max: 0.99994767/1.0	min: 5.231494e-05	loss: 34413.7734375	train_loss: 34442.33716168091	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_564
Epoch: 564	max: 0.99988604/1.0	min: 0.00011392363	loss: 34413.546875	train_loss: 34442.3279174215	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_565
Epoch: 565	max: 0.99989367/1.0	min: 0.00010638026	loss: 34413.375	train_loss: 34442.25664444754	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_566
Epoch: 566	max: 0.99995637/1.0	min: 4.3667027e-05	loss: 34413.68359375	train_loss: 34442.24964822944	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_567
Epoch: 567	max: 0.9999051/1.0	min: 9.4914176e-05	loss: 34413.30859375	train_loss: 34442.24662600257	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_568
Epoch: 568	max: 0.999931/1.0	min: 6.897131e-05	loss: 34413.40625	train_loss: 34442.21005928326	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_569
Epoch: 569	max: 0.99990904/1.0	min: 9.0964626e-05	loss: 34413.59375	train_loss: 34442.179957981076	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_570
Epoch: 570	max: 0.9999076/1.0	min: 9.232758e-05	loss: 34413.359375	train_loss: 34442.17677607844	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_571
Epoch: 571	max: 0.99990606/1.0	min: 9.388286e-05	loss: 34413.4765625	train_loss: 34442.15854739564	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_572
Epoch: 572	max: 0.9999237/1.0	min: 7.627801e-05	loss: 34413.421875	train_loss: 34442.14265239843	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_573
Epoch: 573	max: 0.9999286/1.0	min: 7.135162e-05	loss: 34413.328125	train_loss: 34442.11916312477	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_574
Epoch: 574	max: 0.99990416/1.0	min: 9.579699e-05	loss: 34413.4140625	train_loss: 34442.10170911139	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_575
Epoch: 575	max: 0.99991274/1.0	min: 8.7264096e-05	loss: 34413.32421875	train_loss: 34442.085703792734	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_576
Epoch: 576	max: 0.99992514/1.0	min: 7.4815536e-05	loss: 34413.18359375	train_loss: 34442.091640344355	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_577
Epoch: 577	max: 0.9999316/1.0	min: 6.840636e-05	loss: 34413.296875	train_loss: 34442.05675118838	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_578
Epoch: 578	max: 0.9998888/1.0	min: 0.000111175	loss: 34413.40625	train_loss: 34442.0380188011	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_579
Epoch: 579	max: 0.9999261/1.0	min: 7.388484e-05	loss: 34413.34765625	train_loss: 34442.018336584915	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_580
Epoch: 580	max: 0.999908/1.0	min: 9.2009504e-05	loss: 34413.24609375	train_loss: 34441.998467596466	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_581
Epoch: 581	max: 0.9999149/1.0	min: 8.505952e-05	loss: 34413.28125	train_loss: 34441.97310140669	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_582
Epoch: 582	max: 0.99993527/1.0	min: 6.4743544e-05	loss: 34413.328125	train_loss: 34441.95976557661	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_583
Epoch: 583	max: 0.999897/1.0	min: 0.00010296594	loss: 34413.27734375	train_loss: 34441.95576303729	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_584
Epoch: 584	max: 0.999951/1.0	min: 4.8950307e-05	loss: 34413.265625	train_loss: 34441.94466073254	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_585
Epoch: 585	max: 0.99994135/1.0	min: 5.8607297e-05	loss: 34413.1640625	train_loss: 34441.92076791466	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_586
Epoch: 586	max: 0.99988663/1.0	min: 0.0001133062	loss: 34413.10546875	train_loss: 34441.91313492893	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_587
Epoch: 587	max: 0.999913/1.0	min: 8.701763e-05	loss: 34413.0	train_loss: 34441.886981489224	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_588
Epoch: 588	max: 0.9999237/1.0	min: 7.628398e-05	loss: 34413.17578125	train_loss: 34441.8608425655	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_589
Epoch: 589	max: 0.99985385/1.0	min: 0.00014614602	loss: 34413.21875	train_loss: 34441.849598488014	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_590
Epoch: 590	max: 0.9999143/1.0	min: 8.570436e-05	loss: 34413.00390625	train_loss: 34441.83511686331	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_591
Epoch: 591	max: 0.9999249/1.0	min: 7.514258e-05	loss: 34412.9140625	train_loss: 34441.83001739982	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_592
Epoch: 592	max: 0.99993134/1.0	min: 6.8690984e-05	loss: 34412.96484375	train_loss: 34441.80528265515	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_593
Epoch: 593	max: 0.99994576/1.0	min: 5.4265405e-05	loss: 34413.046875	train_loss: 34441.792051823984	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_594
Epoch: 594	max: 0.99992526/1.0	min: 7.470005e-05	loss: 34412.953125	train_loss: 34441.76577838551	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_595
Epoch: 595	max: 0.99996674/1.0	min: 3.322677e-05	loss: 34413.0390625	train_loss: 34441.74324523102	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_596
Epoch: 596	max: 0.9999336/1.0	min: 6.6419256e-05	loss: 34413.04296875	train_loss: 34441.734371129074	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_597
Epoch: 597	max: 0.99994147/1.0	min: 5.8582827e-05	loss: 34412.89453125	train_loss: 34441.70663931856	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_598
Epoch: 598	max: 0.9999335/1.0	min: 6.6484514e-05	loss: 34412.93359375	train_loss: 34441.67728075065	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_599
Epoch: 599	max: 0.9999616/1.0	min: 3.8353774e-05	loss: 34413.18359375	train_loss: 34441.67339772622	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_600
Epoch: 600	max: 0.9999306/1.0	min: 6.9323694e-05	loss: 34413.15625	train_loss: 34441.6754115764	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_601
Epoch: 601	max: 0.9999442/1.0	min: 5.5838475e-05	loss: 34413.21875	train_loss: 34441.64862282067	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_602
Epoch: 602	max: 0.99991477/1.0	min: 8.5235726e-05	loss: 34412.80859375	train_loss: 34441.63802809132	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_603
Epoch: 603	max: 0.9999578/1.0	min: 4.2171378e-05	loss: 34412.86328125	train_loss: 34441.61589364239	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_604
Epoch: 604	max: 0.9999349/1.0	min: 6.513411e-05	loss: 34412.91015625	train_loss: 34441.595573206985	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_605
Epoch: 605	max: 0.99991786/1.0	min: 8.217446e-05	loss: 34412.8359375	train_loss: 34441.57248747755	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_606
Epoch: 606	max: 0.9999528/1.0	min: 4.715871e-05	loss: 34412.88671875	train_loss: 34441.55212881674	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_607
Epoch: 607	max: 0.99989486/1.0	min: 0.00010517572	loss: 34412.8203125	train_loss: 34441.52268460455	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_608
Epoch: 608	max: 0.99992824/1.0	min: 7.172567e-05	loss: 34412.953125	train_loss: 34441.50785024155	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_609
Epoch: 609	max: 0.99992955/1.0	min: 7.044735e-05	loss: 34412.87890625	train_loss: 34441.490547678215	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_610
Epoch: 610	max: 0.9999485/1.0	min: 5.1482646e-05	loss: 34412.8671875	train_loss: 34441.4661947038	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_611
Epoch: 611	max: 0.9999397/1.0	min: 6.0329465e-05	loss: 34412.9453125	train_loss: 34441.460463795214	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_612
Epoch: 612	max: 0.99995255/1.0	min: 4.747254e-05	loss: 34412.81640625	train_loss: 34441.457301731076	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_613
Epoch: 613	max: 0.99992585/1.0	min: 7.4183125e-05	loss: 34412.796875	train_loss: 34441.413496860674	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_614
Epoch: 614	max: 0.99994135/1.0	min: 5.8696012e-05	loss: 34412.7890625	train_loss: 34441.39564414174	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_615
Epoch: 615	max: 0.9999269/1.0	min: 7.3084666e-05	loss: 34412.796875	train_loss: 34441.38078558544	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_616
Epoch: 616	max: 0.9999527/1.0	min: 4.73171e-05	loss: 34412.6484375	train_loss: 34441.36109078874	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_617
Epoch: 617	max: 0.99996746/1.0	min: 3.2559376e-05	loss: 34412.76171875	train_loss: 34441.36223706723	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_618
Epoch: 618	max: 0.9999149/1.0	min: 8.5150095e-05	loss: 34412.56640625	train_loss: 34441.337478613124	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_619
Epoch: 619	max: 0.9999658/1.0	min: 3.4249937e-05	loss: 34412.62109375	train_loss: 34441.31970186114	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_620
Epoch: 620	max: 0.99992406/1.0	min: 7.598167e-05	loss: 34412.6328125	train_loss: 34441.29069167673	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_621
Epoch: 621	max: 0.9999213/1.0	min: 7.865375e-05	loss: 34412.64453125	train_loss: 34441.26809174873	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_622
Epoch: 622	max: 0.99994004/1.0	min: 5.9922026e-05	loss: 34412.484375	train_loss: 34441.24711519107	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_623
Epoch: 623	max: 0.9999267/1.0	min: 7.332634e-05	loss: 34412.60546875	train_loss: 34441.25350754444	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_624
Epoch: 624	max: 0.9999596/1.0	min: 4.0449046e-05	loss: 34412.68359375	train_loss: 34441.21960450731	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_625
Epoch: 625	max: 0.99990785/1.0	min: 9.211581e-05	loss: 34412.7265625	train_loss: 34441.22290592484	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_626
Epoch: 626	max: 0.9999465/1.0	min: 5.350296e-05	loss: 34412.5546875	train_loss: 34441.221758194755	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_627
Epoch: 627	max: 0.99993575/1.0	min: 6.4308384e-05	loss: 34412.49609375	train_loss: 34441.15763772761	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_628
Epoch: 628	max: 0.99995816/1.0	min: 4.1881136e-05	loss: 34412.46875	train_loss: 34441.12308001982	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_629
Epoch: 629	max: 0.9999554/1.0	min: 4.4588327e-05	loss: 34412.46484375	train_loss: 34441.10835791373	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_630
Epoch: 630	max: 0.99993706/1.0	min: 6.293294e-05	loss: 34412.38671875	train_loss: 34441.10099637681	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_631
Epoch: 631	max: 0.9999565/1.0	min: 4.3535383e-05	loss: 34412.44921875	train_loss: 34441.09301355599	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_632
Epoch: 632	max: 0.9999572/1.0	min: 4.2744818e-05	loss: 34412.421875	train_loss: 34441.06620060696	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_633
Epoch: 633	max: 0.99996054/1.0	min: 3.9431565e-05	loss: 34412.4140625	train_loss: 34441.03079371439	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_634
Epoch: 634	max: 0.99994683/1.0	min: 5.317965e-05	loss: 34412.38671875	train_loss: 34441.01653950669	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_635
Epoch: 635	max: 0.9999614/1.0	min: 3.857945e-05	loss: 34412.30078125	train_loss: 34441.00181788446	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_636
Epoch: 636	max: 0.99994135/1.0	min: 5.867642e-05	loss: 34412.2265625	train_loss: 34441.028442609626	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_637
Epoch: 637	max: 0.9999604/1.0	min: 3.952301e-05	loss: 34412.390625	train_loss: 34441.00377318686	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_638
Epoch: 638	max: 0.9999441/1.0	min: 5.5928638e-05	loss: 34412.24609375	train_loss: 34440.93707081088	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_639
Epoch: 639	max: 0.99991894/1.0	min: 8.10054e-05	loss: 34412.23828125	train_loss: 34440.92428707187	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_640
Epoch: 640	max: 0.99997675/1.0	min: 2.3231456e-05	loss: 34412.49609375	train_loss: 34440.96635196024	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_641
Epoch: 641	max: 0.9999167/1.0	min: 8.328443e-05	loss: 34412.28125	train_loss: 34440.916810858726	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_642
Epoch: 642	max: 0.9999685/1.0	min: 3.150774e-05	loss: 34412.33984375	train_loss: 34440.86329770144	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_643
Epoch: 643	max: 0.99994266/1.0	min: 5.734449e-05	loss: 34412.25	train_loss: 34440.845082083026	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_644
Epoch: 644	max: 0.999967/1.0	min: 3.3002652e-05	loss: 34412.2109375	train_loss: 34440.81014405658	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_645
Epoch: 645	max: 0.9999579/1.0	min: 4.208436e-05	loss: 34412.14453125	train_loss: 34440.78566188994	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_646
Epoch: 646	max: 0.9999471/1.0	min: 5.2930573e-05	loss: 34412.13671875	train_loss: 34440.78184999381	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_647
Epoch: 647	max: 0.99996674/1.0	min: 3.3245757e-05	loss: 34412.12109375	train_loss: 34440.78269627539	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_648
Epoch: 648	max: 0.9999461/1.0	min: 5.3866697e-05	loss: 34412.0546875	train_loss: 34440.75388592763	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_649
Epoch: 649	max: 0.9999784/1.0	min: 2.1578066e-05	loss: 34412.34375	train_loss: 34440.7237512387	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_650
Epoch: 650	max: 0.9999716/1.0	min: 2.8420638e-05	loss: 34412.25390625	train_loss: 34440.700278900345	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_651
Epoch: 651	max: 0.9999778/1.0	min: 2.2219914e-05	loss: 34412.328125	train_loss: 34440.6655982906	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_652
Epoch: 652	max: 0.999969/1.0	min: 3.09457e-05	loss: 34412.09765625	train_loss: 34440.69028658414	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_653
Epoch: 653	max: 0.999966/1.0	min: 3.4028548e-05	loss: 34412.2109375	train_loss: 34440.62575531478	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_654
Epoch: 654	max: 0.99991715/1.0	min: 8.279869e-05	loss: 34412.1484375	train_loss: 34440.608482751144	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_655
Epoch: 655	max: 0.99995923/1.0	min: 4.071484e-05	loss: 34411.98046875	train_loss: 34440.58190496098	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_656
Epoch: 656	max: 0.9999497/1.0	min: 5.0360286e-05	loss: 34411.98046875	train_loss: 34440.56765946287	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_657
Epoch: 657	max: 0.99994195/1.0	min: 5.8029145e-05	loss: 34411.9375	train_loss: 34440.534324968256	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_658
Epoch: 658	max: 0.9998971/1.0	min: 0.00010290597	loss: 34411.99609375	train_loss: 34440.53324594714	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_659
Epoch: 659	max: 0.9999753/1.0	min: 2.467556e-05	loss: 34411.97265625	train_loss: 34440.52959953317	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_660
Epoch: 660	max: 0.99995184/1.0	min: 4.8132006e-05	loss: 34412.046875	train_loss: 34440.468314036756	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_661
Epoch: 661	max: 0.9999776/1.0	min: 2.2447488e-05	loss: 34411.9609375	train_loss: 34440.47615073006	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_662
Epoch: 662	max: 0.9999763/1.0	min: 2.368332e-05	loss: 34411.953125	train_loss: 34440.43047862087	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_663
Epoch: 663	max: 0.9999598/1.0	min: 4.0175062e-05	loss: 34412.0859375	train_loss: 34440.40857981466	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_664
Epoch: 664	max: 0.9999392/1.0	min: 6.0767998e-05	loss: 34412.1015625	train_loss: 34440.41251848368	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_665
Epoch: 665	max: 0.9999709/1.0	min: 2.9083163e-05	loss: 34411.9140625	train_loss: 34440.3640946287	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_666
Epoch: 666	max: 0.99997425/1.0	min: 2.576811e-05	loss: 34411.890625	train_loss: 34440.32472971247	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_667
Epoch: 667	max: 0.99997735/1.0	min: 2.2689765e-05	loss: 34411.9140625	train_loss: 34440.30311590332	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_668
Epoch: 668	max: 0.9999753/1.0	min: 2.462321e-05	loss: 34412.0625	train_loss: 34440.303781702896	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_669
Epoch: 669	max: 0.9999492/1.0	min: 5.0799357e-05	loss: 34412.0234375	train_loss: 34440.31982185991	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_670
Epoch: 670	max: 0.9999386/1.0	min: 6.1422805e-05	loss: 34411.80859375	train_loss: 34440.29753257386	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_671
Epoch: 671	max: 0.9999752/1.0	min: 2.4851071e-05	loss: 34411.765625	train_loss: 34440.20631416063	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_672
Epoch: 672	max: 0.99994755/1.0	min: 5.2450065e-05	loss: 34411.6484375	train_loss: 34440.19493024588	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_673
Epoch: 673	max: 0.99998224/1.0	min: 1.7770992e-05	loss: 34411.69921875	train_loss: 34440.168860031124	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_674
Epoch: 674	max: 0.9999795/1.0	min: 2.0484391e-05	loss: 34411.7734375	train_loss: 34440.14968829354	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_675
Epoch: 675	max: 0.99996316/1.0	min: 3.682435e-05	loss: 34411.625	train_loss: 34440.13901614564	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_676
Epoch: 676	max: 0.9999598/1.0	min: 4.011415e-05	loss: 34411.53125	train_loss: 34440.08549331104	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_677
Epoch: 677	max: 0.99994755/1.0	min: 5.240876e-05	loss: 34411.6015625	train_loss: 34440.08611265948	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_678
Epoch: 678	max: 0.9999651/1.0	min: 3.4918005e-05	loss: 34411.53515625	train_loss: 34440.041886341816	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_679
Epoch: 679	max: 0.9999677/1.0	min: 3.229867e-05	loss: 34411.421875	train_loss: 34440.022391865634	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_680
Epoch: 680	max: 0.99997807/1.0	min: 2.198517e-05	loss: 34411.64453125	train_loss: 34440.009653610025	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_681
Epoch: 681	max: 0.9999763/1.0	min: 2.3706889e-05	loss: 34411.76171875	train_loss: 34439.96583083658	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_682
Epoch: 682	max: 0.99995875/1.0	min: 4.125986e-05	loss: 34411.74609375	train_loss: 34439.931514094045	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_683
Epoch: 683	max: 0.99997973/1.0	min: 2.02304e-05	loss: 34411.62890625	train_loss: 34439.9413806051	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_684
Epoch: 684	max: 0.9999796/1.0	min: 2.0386618e-05	loss: 34411.4375	train_loss: 34439.88545005342	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_685
Epoch: 685	max: 0.99996245/1.0	min: 3.7599857e-05	loss: 34411.3984375	train_loss: 34439.835648148146	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_686
Epoch: 686	max: 0.9999651/1.0	min: 3.487231e-05	loss: 34411.64453125	train_loss: 34439.83229979561	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_687
Epoch: 687	max: 0.9999832/1.0	min: 1.6773489e-05	loss: 34411.73828125	train_loss: 34439.79325713412	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_688
Epoch: 688	max: 0.9999621/1.0	min: 3.7850754e-05	loss: 34411.49609375	train_loss: 34439.784584804285	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_689
Epoch: 689	max: 0.9999683/1.0	min: 3.171218e-05	loss: 34411.5234375	train_loss: 34439.72176593661	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_690
Epoch: 690	max: 0.9999857/1.0	min: 1.4295574e-05	loss: 34411.28515625	train_loss: 34439.696358134366	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_691
Epoch: 691	max: 0.9999796/1.0	min: 2.0382808e-05	loss: 34411.3359375	train_loss: 34439.669269865604	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_692
Epoch: 692	max: 0.9999584/1.0	min: 4.161678e-05	loss: 34411.19921875	train_loss: 34439.6446677002	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_693
Epoch: 693	max: 0.9999448/1.0	min: 5.5162025e-05	loss: 34411.24609375	train_loss: 34439.60776469404	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_694
Epoch: 694	max: 0.99994767/1.0	min: 5.2330157e-05	loss: 34411.140625	train_loss: 34439.629639790815	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_695
Epoch: 695	max: 0.9999671/1.0	min: 3.2890614e-05	loss: 34411.12109375	train_loss: 34439.56019002385	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_696
Epoch: 696	max: 0.9999776/1.0	min: 2.2406208e-05	loss: 34411.484375	train_loss: 34439.51835400409	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_697
Epoch: 697	max: 0.9999691/1.0	min: 3.0880787e-05	loss: 34411.11328125	train_loss: 34439.49360764663	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_698
Epoch: 698	max: 0.9999784/1.0	min: 2.1579075e-05	loss: 34411.23046875	train_loss: 34439.439830782394	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_699
Epoch: 699	max: 0.99998784/1.0	min: 1.2139676e-05	loss: 34411.484375	train_loss: 34439.4238970759	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_700
Epoch: 700	max: 0.99998474/1.0	min: 1.5237993e-05	loss: 34411.30078125	train_loss: 34439.4807276183	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_701
Epoch: 701	max: 0.9999608/1.0	min: 3.9231913e-05	loss: 34411.01953125	train_loss: 34439.38304233634	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_702
Epoch: 702	max: 0.9999651/1.0	min: 3.4895667e-05	loss: 34410.8984375	train_loss: 34439.33657088056	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_703
Epoch: 703	max: 0.9999751/1.0	min: 2.4942932e-05	loss: 34410.96875	train_loss: 34439.27371281974	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_704
Epoch: 704	max: 0.9999697/1.0	min: 3.0222467e-05	loss: 34410.84765625	train_loss: 34439.24719067416	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_705
Epoch: 705	max: 0.9999684/1.0	min: 3.1627133e-05	loss: 34410.8984375	train_loss: 34439.217324530844	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_706
Epoch: 706	max: 0.99994266/1.0	min: 5.7385845e-05	loss: 34410.90234375	train_loss: 34439.18988110445	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_707
Epoch: 707	max: 0.99997723/1.0	min: 2.2783413e-05	loss: 34410.765625	train_loss: 34439.16446604422	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_708
Epoch: 708	max: 0.99995863/1.0	min: 4.1381656e-05	loss: 34410.76171875	train_loss: 34439.119702635326	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_709
Epoch: 709	max: 0.99995816/1.0	min: 4.1791045e-05	loss: 34410.8984375	train_loss: 34439.0919582443	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_710
Epoch: 710	max: 0.9999877/1.0	min: 1.2279833e-05	loss: 34410.87890625	train_loss: 34439.04693499938	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_711
Epoch: 711	max: 0.99998295/1.0	min: 1.701811e-05	loss: 34411.06640625	train_loss: 34439.03715897126	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_712
Epoch: 712	max: 0.99998486/1.0	min: 1.5168459e-05	loss: 34410.74609375	train_loss: 34438.97492461368	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_713
Epoch: 713	max: 0.99997747/1.0	min: 2.2558865e-05	loss: 34410.6015625	train_loss: 34438.94453154032	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_714
Epoch: 714	max: 0.9999498/1.0	min: 5.0149127e-05	loss: 34410.65625	train_loss: 34438.92532109346	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_715
Epoch: 715	max: 0.9999887/1.0	min: 1.1294364e-05	loss: 34411.18359375	train_loss: 34438.89997135513	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_716
Epoch: 716	max: 0.99997485/1.0	min: 2.5151818e-05	loss: 34410.58203125	train_loss: 34438.943785902855	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_717
Epoch: 717	max: 0.9999728/1.0	min: 2.7119428e-05	loss: 34410.48828125	train_loss: 34438.80575587607	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_718
Epoch: 718	max: 0.9999814/1.0	min: 1.864922e-05	loss: 34410.59375	train_loss: 34438.80189946426	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_719
Epoch: 719	max: 0.9999877/1.0	min: 1.2219296e-05	loss: 34410.53125	train_loss: 34438.78837637805	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_720
Epoch: 720	max: 0.9999863/1.0	min: 1.3659035e-05	loss: 34410.5703125	train_loss: 34438.71121185201	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_721
Epoch: 721	max: 0.99997413/1.0	min: 2.584706e-05	loss: 34410.43359375	train_loss: 34438.68008620556	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_722
Epoch: 722	max: 0.999956/1.0	min: 4.403779e-05	loss: 34410.35546875	train_loss: 34438.6433709394	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_723
Epoch: 723	max: 0.9999639/1.0	min: 3.607162e-05	loss: 34410.38671875	train_loss: 34438.60049557553	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_724
Epoch: 724	max: 0.99998915/1.0	min: 1.0866559e-05	loss: 34410.61328125	train_loss: 34438.58609862737	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_725
Epoch: 725	max: 0.99998236/1.0	min: 1.7687807e-05	loss: 34410.35546875	train_loss: 34438.524030235814	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_726
Epoch: 726	max: 0.9999715/1.0	min: 2.8520062e-05	loss: 34410.15625	train_loss: 34438.479746338104	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_727
Epoch: 727	max: 0.9999832/1.0	min: 1.6804055e-05	loss: 34410.1484375	train_loss: 34438.46369843924	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_728
Epoch: 728	max: 0.99997914/1.0	min: 2.0811489e-05	loss: 34410.5234375	train_loss: 34438.48748383888	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_729
Epoch: 729	max: 0.9999753/1.0	min: 2.4657353e-05	loss: 34410.2578125	train_loss: 34438.405757424436	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_730
Epoch: 730	max: 0.9999645/1.0	min: 3.5576708e-05	loss: 34410.203125	train_loss: 34438.34639674687	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_731
Epoch: 731	max: 0.9999696/1.0	min: 3.0392068e-05	loss: 34410.203125	train_loss: 34438.317103017	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_732
Epoch: 732	max: 0.9999523/1.0	min: 4.766555e-05	loss: 34410.15625	train_loss: 34438.28008146367	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_733
Epoch: 733	max: 0.9999614/1.0	min: 3.856676e-05	loss: 34410.07421875	train_loss: 34438.27747923247	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_734
Epoch: 734	max: 0.9999591/1.0	min: 4.093145e-05	loss: 34410.12890625	train_loss: 34438.21233587266	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_735
Epoch: 735	max: 0.999974/1.0	min: 2.5988118e-05	loss: 34410.16796875	train_loss: 34438.17312434194	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_736
Epoch: 736	max: 0.99997866/1.0	min: 2.1318505e-05	loss: 34410.01953125	train_loss: 34438.12469371284	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_737
Epoch: 737	max: 0.9999896/1.0	min: 1.0373221e-05	loss: 34410.38671875	train_loss: 34438.09700448254	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_738
Epoch: 738	max: 0.9999726/1.0	min: 2.7430933e-05	loss: 34410.25	train_loss: 34438.124419844695	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_739
Epoch: 739	max: 0.99996865/1.0	min: 3.1400505e-05	loss: 34410.12890625	train_loss: 34438.05612313034	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_740
Epoch: 740	max: 0.9999683/1.0	min: 3.1677693e-05	loss: 34409.96875	train_loss: 34438.01779271956	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_741
Epoch: 741	max: 0.99997365/1.0	min: 2.638762e-05	loss: 34409.76171875	train_loss: 34437.95810785179	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_742
Epoch: 742	max: 0.99997413/1.0	min: 2.5864321e-05	loss: 34409.88671875	train_loss: 34437.979021023006	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_743
Epoch: 743	max: 0.99998295/1.0	min: 1.7086983e-05	loss: 34409.8515625	train_loss: 34437.89760670212	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_744
Epoch: 744	max: 0.9999851/1.0	min: 1.4955615e-05	loss: 34409.87109375	train_loss: 34437.853418126004	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_745
Epoch: 745	max: 0.999972/1.0	min: 2.803355e-05	loss: 34409.703125	train_loss: 34437.807612469805	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_746
Epoch: 746	max: 0.99996614/1.0	min: 3.383224e-05	loss: 34409.61328125	train_loss: 34437.78475996377	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_747
Epoch: 747	max: 0.999984/1.0	min: 1.5972408e-05	loss: 34409.67578125	train_loss: 34437.79699596649	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_748
Epoch: 748	max: 0.99998534/1.0	min: 1.4686058e-05	loss: 34409.859375	train_loss: 34437.71804162022	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_749
Epoch: 749	max: 0.99998784/1.0	min: 1.2123756e-05	loss: 34409.8203125	train_loss: 34437.68367939428	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_750
Epoch: 750	max: 0.9999826/1.0	min: 1.743597e-05	loss: 34409.80078125	train_loss: 34437.667869557474	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_751
Epoch: 751	max: 0.9999732/1.0	min: 2.6871798e-05	loss: 34409.6640625	train_loss: 34437.614074790195	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_752
Epoch: 752	max: 0.9999703/1.0	min: 2.9729195e-05	loss: 34409.49609375	train_loss: 34437.56669415026	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_753
Epoch: 753	max: 0.99997115/1.0	min: 2.8809409e-05	loss: 34409.6015625	train_loss: 34437.53592704849	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_754
Epoch: 754	max: 0.9999827/1.0	min: 1.7297893e-05	loss: 34409.625	train_loss: 34437.50500027096	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_755
Epoch: 755	max: 0.99997795/1.0	min: 2.2083172e-05	loss: 34409.53515625	train_loss: 34437.464705364335	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_756
Epoch: 756	max: 0.9999807/1.0	min: 1.9300687e-05	loss: 34409.46875	train_loss: 34437.43310940016	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_757
Epoch: 757	max: 0.99998057/1.0	min: 1.9417665e-05	loss: 34409.515625	train_loss: 34437.403396158494	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_758
Epoch: 758	max: 0.99998224/1.0	min: 1.7778179e-05	loss: 34409.34375	train_loss: 34437.382838628764	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_759
Epoch: 759	max: 0.99998665/1.0	min: 1.335191e-05	loss: 34409.83984375	train_loss: 34437.36835652019	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_760
Epoch: 760	max: 0.9999881/1.0	min: 1.1947788e-05	loss: 34409.796875	train_loss: 34437.32378810929	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_761
Epoch: 761	max: 0.9999862/1.0	min: 1.3884762e-05	loss: 34409.6484375	train_loss: 34437.32166974405	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_762
Epoch: 762	max: 0.99997604/1.0	min: 2.3909e-05	loss: 34409.37890625	train_loss: 34437.27906002261	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_763
Epoch: 763	max: 0.9999654/1.0	min: 3.4524408e-05	loss: 34409.16796875	train_loss: 34437.22101207342	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_764
Epoch: 764	max: 0.9999486/1.0	min: 5.132466e-05	loss: 34409.2265625	train_loss: 34437.18299859485	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_765
Epoch: 765	max: 0.99996865/1.0	min: 3.1355947e-05	loss: 34409.44921875	train_loss: 34437.149062170975	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_766
Epoch: 766	max: 0.99998426/1.0	min: 1.5691914e-05	loss: 34409.42578125	train_loss: 34437.100537188	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_767
Epoch: 767	max: 0.99998546/1.0	min: 1.4489403e-05	loss: 34409.42578125	train_loss: 34437.077178074294	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_768
Epoch: 768	max: 0.99997354/1.0	min: 2.64764e-05	loss: 34409.30078125	train_loss: 34437.033336430075	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_769
Epoch: 769	max: 0.99998474/1.0	min: 1.5262107e-05	loss: 34409.11328125	train_loss: 34436.98580143689	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_770
Epoch: 770	max: 0.9999801/1.0	min: 1.9856132e-05	loss: 34409.3359375	train_loss: 34436.96535471247	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_771
Epoch: 771	max: 0.9999838/1.0	min: 1.6243903e-05	loss: 34409.1640625	train_loss: 34436.930481040195	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_772
Epoch: 772	max: 0.9999769/1.0	min: 2.3129702e-05	loss: 34408.953125	train_loss: 34436.89210466215	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_773
Epoch: 773	max: 0.99997675/1.0	min: 2.3227978e-05	loss: 34409.18359375	train_loss: 34436.85979693113	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_774
Epoch: 774	max: 0.9999882/1.0	min: 1.1858012e-05	loss: 34409.23828125	train_loss: 34436.83461993295	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_775
Epoch: 775	max: 0.9999831/1.0	min: 1.6909735e-05	loss: 34409.26171875	train_loss: 34436.80329686919	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_776
Epoch: 776	max: 0.9999864/1.0	min: 1.3571987e-05	loss: 34409.421875	train_loss: 34436.763211960395	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_777
Epoch: 777	max: 0.99999225/1.0	min: 7.757824e-06	loss: 34409.17578125	train_loss: 34436.83036046079	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_778
Epoch: 778	max: 0.99998415/1.0	min: 1.5847249e-05	loss: 34409.046875	train_loss: 34436.69682506503	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_779
Epoch: 779	max: 0.9999857/1.0	min: 1.4344165e-05	loss: 34408.94921875	train_loss: 34436.65224310588	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_780
Epoch: 780	max: 0.9999759/1.0	min: 2.4094132e-05	loss: 34408.87109375	train_loss: 34436.62757707017	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_781
Epoch: 781	max: 0.99998045/1.0	min: 1.9515794e-05	loss: 34408.87890625	train_loss: 34436.58783377075	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_782
Epoch: 782	max: 0.99996877/1.0	min: 3.1227333e-05	loss: 34408.8046875	train_loss: 34436.54568323811	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_783
Epoch: 783	max: 0.9999622/1.0	min: 3.774168e-05	loss: 34408.7890625	train_loss: 34436.53398771367	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_784
Epoch: 784	max: 0.99997425/1.0	min: 2.569748e-05	loss: 34408.80078125	train_loss: 34436.50692702527	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_785
Epoch: 785	max: 0.99997735/1.0	min: 2.2673434e-05	loss: 34408.85546875	train_loss: 34436.454940949	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_786
Epoch: 786	max: 0.9999758/1.0	min: 2.4248942e-05	loss: 34408.71875	train_loss: 34436.42540673773	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_787
Epoch: 787	max: 0.999977/1.0	min: 2.295586e-05	loss: 34408.90625	train_loss: 34436.387233583395	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_788
Epoch: 788	max: 0.9999759/1.0	min: 2.4042005e-05	loss: 34409.06640625	train_loss: 34436.35164427335	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_789
Epoch: 789	max: 0.99997234/1.0	min: 2.7659677e-05	loss: 34408.859375	train_loss: 34436.352854906014	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_790
Epoch: 790	max: 0.99997294/1.0	min: 2.7108443e-05	loss: 34408.6484375	train_loss: 34436.286690589	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_791
Epoch: 791	max: 0.99997675/1.0	min: 2.3193204e-05	loss: 34408.81640625	train_loss: 34436.294774053946	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_792
Epoch: 792	max: 0.999972/1.0	min: 2.8014818e-05	loss: 34408.63671875	train_loss: 34436.2285632858	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_793
Epoch: 793	max: 0.99997735/1.0	min: 2.2664268e-05	loss: 34408.75	train_loss: 34436.20757317989	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_794
Epoch: 794	max: 0.9999759/1.0	min: 2.4117717e-05	loss: 34408.578125	train_loss: 34436.167863751085	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_795
Epoch: 795	max: 0.9999821/1.0	min: 1.7880622e-05	loss: 34408.57421875	train_loss: 34436.156022582996	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_796
Epoch: 796	max: 0.99998605/1.0	min: 1.3989668e-05	loss: 34408.78125	train_loss: 34436.12029488728	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_797
Epoch: 797	max: 0.9999722/1.0	min: 2.7733236e-05	loss: 34408.75390625	train_loss: 34436.06932057475	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_798
Epoch: 798	max: 0.9999763/1.0	min: 2.3768192e-05	loss: 34408.8984375	train_loss: 34436.046453552735	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_799
Epoch: 799	max: 0.99997735/1.0	min: 2.2702881e-05	loss: 34408.50390625	train_loss: 34436.03005388332	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_800
Epoch: 800	max: 0.99997497/1.0	min: 2.5066742e-05	loss: 34408.59375	train_loss: 34436.02163267992	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_801
Epoch: 801	max: 0.99998236/1.0	min: 1.7637089e-05	loss: 34408.98046875	train_loss: 34435.96066363186	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_802
Epoch: 802	max: 0.9999845/1.0	min: 1.5481673e-05	loss: 34408.703125	train_loss: 34435.93086958457	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_803
Epoch: 803	max: 0.9999808/1.0	min: 1.924676e-05	loss: 34408.73046875	train_loss: 34435.8835591052	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_804
Epoch: 804	max: 0.99998593/1.0	min: 1.41036935e-05	loss: 34408.6796875	train_loss: 34435.847686733556	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_805
Epoch: 805	max: 0.9999738/1.0	min: 2.6175434e-05	loss: 34408.56640625	train_loss: 34435.830568039295	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_806
Epoch: 806	max: 0.9999827/1.0	min: 1.7244443e-05	loss: 34408.7734375	train_loss: 34435.7953890476	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_807
Epoch: 807	max: 0.9999895/1.0	min: 1.0482831e-05	loss: 34408.55078125	train_loss: 34435.77663295089	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_808
Epoch: 808	max: 0.99997854/1.0	min: 2.1448323e-05	loss: 34408.5234375	train_loss: 34435.761215045524	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_809
Epoch: 809	max: 0.9999821/1.0	min: 1.7922399e-05	loss: 34408.7890625	train_loss: 34435.708440267714	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_810
Epoch: 810	max: 0.99999106/1.0	min: 8.901489e-06	loss: 34408.6796875	train_loss: 34435.69274268782	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_811
Epoch: 811	max: 0.9999963/1.0	min: 3.6853942e-06	loss: 34408.8984375	train_loss: 34435.722144803665	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_812
Epoch: 812	max: 0.9999925/1.0	min: 7.5204553e-06	loss: 34408.63671875	train_loss: 34435.65638596634	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_813
Epoch: 813	max: 0.99999034/1.0	min: 9.682393e-06	loss: 34408.63671875	train_loss: 34435.6403008098	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_814
Epoch: 814	max: 0.99998045/1.0	min: 1.9513673e-05	loss: 34408.3203125	train_loss: 34435.57234280162	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_815
Epoch: 815	max: 0.99997926/1.0	min: 2.0788779e-05	loss: 34408.390625	train_loss: 34435.52093833225	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_816
Epoch: 816	max: 0.9999838/1.0	min: 1.617357e-05	loss: 34408.37109375	train_loss: 34435.51019892698	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_817
Epoch: 817	max: 0.9999708/1.0	min: 2.9182262e-05	loss: 34408.3046875	train_loss: 34435.473539789265	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_818
Epoch: 818	max: 0.9999789/1.0	min: 2.1078038e-05	loss: 34408.24609375	train_loss: 34435.44561878716	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_819
Epoch: 819	max: 0.99998426/1.0	min: 1.5748643e-05	loss: 34408.328125	train_loss: 34435.42483916295	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_820
Epoch: 820	max: 0.9999738/1.0	min: 2.6283795e-05	loss: 34408.23828125	train_loss: 34435.38586714589	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_821
Epoch: 821	max: 0.99998057/1.0	min: 1.9478162e-05	loss: 34408.34375	train_loss: 34435.36460075251	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_822
Epoch: 822	max: 0.9999932/1.0	min: 6.762108e-06	loss: 34408.4609375	train_loss: 34435.37240357519	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_823
Epoch: 823	max: 0.9999893/1.0	min: 1.073308e-05	loss: 34408.2890625	train_loss: 34435.33066868342	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_824
Epoch: 824	max: 0.9999858/1.0	min: 1.4156003e-05	loss: 34408.08203125	train_loss: 34435.281159517064	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_825
Epoch: 825	max: 0.99998426/1.0	min: 1.5776002e-05	loss: 34408.2578125	train_loss: 34435.2565583194	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_826
Epoch: 826	max: 0.9999865/1.0	min: 1.3439582e-05	loss: 34408.265625	train_loss: 34435.218127264496	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_827
Epoch: 827	max: 0.9999838/1.0	min: 1.619878e-05	loss: 34408.35546875	train_loss: 34435.20756688963	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_828
Epoch: 828	max: 0.9999752/1.0	min: 2.4764979e-05	loss: 34408.51171875	train_loss: 34435.16801471727	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_829
Epoch: 829	max: 0.99998236/1.0	min: 1.760422e-05	loss: 34408.328125	train_loss: 34435.16344169996	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_830
Epoch: 830	max: 0.99998367/1.0	min: 1.6363405e-05	loss: 34408.1015625	train_loss: 34435.12347049966	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_831
Epoch: 831	max: 0.99997497/1.0	min: 2.497604e-05	loss: 34408.31640625	train_loss: 34435.08899214589	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_832
Epoch: 832	max: 0.99998736/1.0	min: 1.2646442e-05	loss: 34408.28125	train_loss: 34435.0860342732	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_833
Epoch: 833	max: 0.99998164/1.0	min: 1.8335897e-05	loss: 34408.15625	train_loss: 34435.08801570436	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_834
Epoch: 834	max: 0.9999801/1.0	min: 1.9905066e-05	loss: 34408.40625	train_loss: 34435.00695315403	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_835
Epoch: 835	max: 0.99998367/1.0	min: 1.6372413e-05	loss: 34408.328125	train_loss: 34435.007759758606	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_836
Epoch: 836	max: 0.99998677/1.0	min: 1.3174991e-05	loss: 34408.37890625	train_loss: 34434.95478127323	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_837
Epoch: 837	max: 0.999984/1.0	min: 1.5929965e-05	loss: 34408.30078125	train_loss: 34434.940924803355	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_838
Epoch: 838	max: 0.99998295/1.0	min: 1.709461e-05	loss: 34408.05859375	train_loss: 34434.911359624675	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_839
Epoch: 839	max: 0.9999888/1.0	min: 1.1233962e-05	loss: 34407.91015625	train_loss: 34434.89318416713	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_840
Epoch: 840	max: 0.99998176/1.0	min: 1.8240184e-05	loss: 34407.953125	train_loss: 34434.86235513053	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_841
Epoch: 841	max: 0.9999763/1.0	min: 2.369048e-05	loss: 34407.96875	train_loss: 34434.83835150734	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_842
Epoch: 842	max: 0.999979/1.0	min: 2.1001835e-05	loss: 34407.92578125	train_loss: 34434.8038271863	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_843
Epoch: 843	max: 0.9999826/1.0	min: 1.7418835e-05	loss: 34407.88671875	train_loss: 34434.78900927474	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_844
Epoch: 844	max: 0.999992/1.0	min: 8.026617e-06	loss: 34408.2265625	train_loss: 34434.779241472344	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_845
Epoch: 845	max: 0.99998295/1.0	min: 1.7100283e-05	loss: 34408.140625	train_loss: 34434.75864233015	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_846
Epoch: 846	max: 0.9999924/1.0	min: 7.639299e-06	loss: 34408.25	train_loss: 34434.72788103478	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_847
Epoch: 847	max: 0.9999877/1.0	min: 1.2219087e-05	loss: 34407.96875	train_loss: 34434.695303306544	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_848
Epoch: 848	max: 0.9999949/1.0	min: 5.1565994e-06	loss: 34408.28515625	train_loss: 34434.67825186966	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_849
Epoch: 849	max: 0.9999925/1.0	min: 7.543225e-06	loss: 34408.23828125	train_loss: 34434.684719222256	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_850
Epoch: 850	max: 0.99998474/1.0	min: 1.5264202e-05	loss: 34408.23046875	train_loss: 34434.61995231017	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_851
Epoch: 851	max: 0.9999924/1.0	min: 7.5838125e-06	loss: 34408.17578125	train_loss: 34434.61068434132	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_852
Epoch: 852	max: 0.9999895/1.0	min: 1.04578285e-05	loss: 34408.15625	train_loss: 34434.56638399216	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_853
Epoch: 853	max: 0.9999901/1.0	min: 9.909214e-06	loss: 34408.015625	train_loss: 34434.58612717546	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_854
Epoch: 854	max: 0.9999937/1.0	min: 6.2629074e-06	loss: 34408.46875	train_loss: 34434.535868500716	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_855
Epoch: 855	max: 0.9999832/1.0	min: 1.6843249e-05	loss: 34408.17578125	train_loss: 34434.51804626533	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_856
Epoch: 856	max: 0.9999869/1.0	min: 1.3098559e-05	loss: 34408.05859375	train_loss: 34434.50664831847	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_857
Epoch: 857	max: 0.9999876/1.0	min: 1.2455606e-05	loss: 34408.19140625	train_loss: 34434.47296302103	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_858
Epoch: 858	max: 0.9999924/1.0	min: 7.681468e-06	loss: 34407.90625	train_loss: 34434.4480100528	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_859
Epoch: 859	max: 0.9999902/1.0	min: 9.733404e-06	loss: 34407.98046875	train_loss: 34434.424879807695	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_860
Epoch: 860	max: 0.9999809/1.0	min: 1.9057758e-05	loss: 34407.85546875	train_loss: 34434.38668391165	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_861
Epoch: 861	max: 0.99999154/1.0	min: 8.5082875e-06	loss: 34408.14453125	train_loss: 34434.368749903224	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_862
Epoch: 862	max: 0.9999931/1.0	min: 6.9069624e-06	loss: 34408.078125	train_loss: 34434.34680512975	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_863
Epoch: 863	max: 0.9999964/1.0	min: 3.573598e-06	loss: 34408.2890625	train_loss: 34434.40607193732	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_864
Epoch: 864	max: 0.9999939/1.0	min: 6.0228886e-06	loss: 34408.2265625	train_loss: 34434.367115887835	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_865
Epoch: 865	max: 0.9999926/1.0	min: 7.3314914e-06	loss: 34408.078125	train_loss: 34434.31517142404	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_866
Epoch: 866	max: 0.99998164/1.0	min: 1.8331491e-05	loss: 34407.75390625	train_loss: 34434.25710847501	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_867
Epoch: 867	max: 0.9999875/1.0	min: 1.2495092e-05	loss: 34407.62109375	train_loss: 34434.233555814906	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_868
Epoch: 868	max: 0.999985/1.0	min: 1.5019032e-05	loss: 34407.73828125	train_loss: 34434.240413163476	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_869
Epoch: 869	max: 0.99998/1.0	min: 2.0048748e-05	loss: 34408.0234375	train_loss: 34434.215690515455	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_870
Epoch: 870	max: 0.9999845/1.0	min: 1.5486265e-05	loss: 34407.703125	train_loss: 34434.18270101728	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_871
Epoch: 871	max: 0.9999876/1.0	min: 1.235639e-05	loss: 34407.71875	train_loss: 34434.17337450065	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_872
Epoch: 872	max: 0.9999896/1.0	min: 1.0330612e-05	loss: 34407.9609375	train_loss: 34434.14656590642	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_873
Epoch: 873	max: 0.99998736/1.0	min: 1.2690056e-05	loss: 34407.7109375	train_loss: 34434.137990833646	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_874
Epoch: 874	max: 0.9999863/1.0	min: 1.3742174e-05	loss: 34407.57421875	train_loss: 34434.098533015145	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_875
Epoch: 875	max: 0.9999882/1.0	min: 1.1818036e-05	loss: 34407.76953125	train_loss: 34434.10373360662	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_876
Epoch: 876	max: 0.99998736/1.0	min: 1.2630365e-05	loss: 34407.95703125	train_loss: 34434.0604295375	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_877
Epoch: 877	max: 0.99999344/1.0	min: 6.5155223e-06	loss: 34408.0234375	train_loss: 34434.062412904124	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_878
Epoch: 878	max: 0.999992/1.0	min: 7.974983e-06	loss: 34407.5390625	train_loss: 34434.01650031355	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_879
Epoch: 879	max: 0.99997044/1.0	min: 2.9535282e-05	loss: 34407.65625	train_loss: 34434.004651887466	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_880
Epoch: 880	max: 0.9999769/1.0	min: 2.3123746e-05	loss: 34407.55078125	train_loss: 34434.02664649914	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_881
Epoch: 881	max: 0.9999893/1.0	min: 1.0782531e-05	loss: 34407.59765625	train_loss: 34433.98588466184	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_882
Epoch: 882	max: 0.9999826/1.0	min: 1.7423521e-05	loss: 34407.53125	train_loss: 34433.97195174114	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_883
Epoch: 883	max: 0.99998045/1.0	min: 1.959935e-05	loss: 34407.484375	train_loss: 34433.95679222021	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_884
Epoch: 884	max: 0.9999895/1.0	min: 1.0490193e-05	loss: 34407.94140625	train_loss: 34433.94158189335	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_885
Epoch: 885	max: 0.9999902/1.0	min: 9.754211e-06	loss: 34407.89453125	train_loss: 34433.916250058064	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_886
Epoch: 886	max: 0.99998546/1.0	min: 1.451283e-05	loss: 34407.81640625	train_loss: 34433.87491580732	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_887
Epoch: 887	max: 0.9999914/1.0	min: 8.5994225e-06	loss: 34407.85546875	train_loss: 34433.855849068656	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_888
Epoch: 888	max: 0.99998987/1.0	min: 1.0186509e-05	loss: 34407.56640625	train_loss: 34433.875694831535	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_889
Epoch: 889	max: 0.99998856/1.0	min: 1.1460556e-05	loss: 34407.50390625	train_loss: 34433.82619485864	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_890
Epoch: 890	max: 0.999972/1.0	min: 2.799647e-05	loss: 34407.48828125	train_loss: 34433.81444272188	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_891
Epoch: 891	max: 0.9999869/1.0	min: 1.31253055e-05	loss: 34407.67578125	train_loss: 34433.79826321148	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_892
Epoch: 892	max: 0.9999893/1.0	min: 1.07218275e-05	loss: 34407.8515625	train_loss: 34433.76152520361	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_893
Epoch: 893	max: 0.999995/1.0	min: 5.064458e-06	loss: 34407.63671875	train_loss: 34433.760110863375	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_894
Epoch: 894	max: 0.9999937/1.0	min: 6.275307e-06	loss: 34407.68359375	train_loss: 34433.72757910241	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_895
Epoch: 895	max: 0.99996984/1.0	min: 3.0206362e-05	loss: 34407.63671875	train_loss: 34433.734931929735	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_896
Epoch: 896	max: 0.99998343/1.0	min: 1.6583943e-05	loss: 34407.55859375	train_loss: 34433.68534195776	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_897
Epoch: 897	max: 0.9999894/1.0	min: 1.0566258e-05	loss: 34407.48828125	train_loss: 34433.674330135946	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_898
Epoch: 898	max: 0.999982/1.0	min: 1.7944458e-05	loss: 34407.515625	train_loss: 34433.65441179317	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_899
Epoch: 899	max: 0.9999927/1.0	min: 7.2944867e-06	loss: 34407.55078125	train_loss: 34433.63688181283	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_900
Epoch: 900	max: 0.9999838/1.0	min: 1.6178323e-05	loss: 34407.25390625	train_loss: 34433.621084556544	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_901
Epoch: 901	max: 0.9999715/1.0	min: 2.8537801e-05	loss: 34407.39453125	train_loss: 34433.6201139214	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_902
Epoch: 902	max: 0.9999846/1.0	min: 1.5395588e-05	loss: 34407.43359375	train_loss: 34433.59710415892	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_903
Epoch: 903	max: 0.99999/1.0	min: 1.0007774e-05	loss: 34407.60546875	train_loss: 34433.57061007757	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_904
Epoch: 904	max: 0.99998844/1.0	min: 1.1594155e-05	loss: 34407.5703125	train_loss: 34433.56196436037	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_905
Epoch: 905	max: 0.9999877/1.0	min: 1.2276471e-05	loss: 34407.37890625	train_loss: 34433.539118628454	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_906
Epoch: 906	max: 0.99997807/1.0	min: 2.1928194e-05	loss: 34407.35546875	train_loss: 34433.53045694367	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_907
Epoch: 907	max: 0.99998677/1.0	min: 1.3229623e-05	loss: 34407.53125	train_loss: 34433.505737198844	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_908
Epoch: 908	max: 0.99997807/1.0	min: 2.189008e-05	loss: 34407.48828125	train_loss: 34433.47900457156	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_909
Epoch: 909	max: 0.99996305/1.0	min: 3.6931473e-05	loss: 34407.46875	train_loss: 34433.48025633284	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_910
Epoch: 910	max: 0.99998/1.0	min: 2.0080783e-05	loss: 34407.3203125	train_loss: 34433.47460332668	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_911
Epoch: 911	max: 0.9999881/1.0	min: 1.19119395e-05	loss: 34407.26953125	train_loss: 34433.444444444445	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_912
Epoch: 912	max: 0.9999893/1.0	min: 1.0763032e-05	loss: 34407.30859375	train_loss: 34433.41764359207	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_913
Epoch: 913	max: 0.99999166/1.0	min: 8.391699e-06	loss: 34407.33203125	train_loss: 34433.39086693298	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_914
Epoch: 914	max: 0.9999769/1.0	min: 2.3076296e-05	loss: 34407.1484375	train_loss: 34433.37468790645	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_915
Epoch: 915	max: 0.9999771/1.0	min: 2.289755e-05	loss: 34407.23828125	train_loss: 34433.41450233417	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_916
Epoch: 916	max: 0.9999949/1.0	min: 5.159969e-06	loss: 34407.5078125	train_loss: 34433.36233577589	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_917
Epoch: 917	max: 0.9999826/1.0	min: 1.7363705e-05	loss: 34407.12890625	train_loss: 34433.35036106079	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_918
Epoch: 918	max: 0.9999869/1.0	min: 1.3135825e-05	loss: 34407.265625	train_loss: 34433.327582586244	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_919
Epoch: 919	max: 0.9999846/1.0	min: 1.5402828e-05	loss: 34407.26171875	train_loss: 34433.33821989579	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_920
Epoch: 920	max: 0.9999927/1.0	min: 7.3110696e-06	loss: 34407.2109375	train_loss: 34433.2912239293	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_921
Epoch: 921	max: 0.9999912/1.0	min: 8.7813305e-06	loss: 34407.078125	train_loss: 34433.27608618233	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_922
Epoch: 922	max: 0.999985/1.0	min: 1.5010998e-05	loss: 34407.2109375	train_loss: 34433.2647675895	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_923
Epoch: 923	max: 0.9999894/1.0	min: 1.0606013e-05	loss: 34407.50390625	train_loss: 34433.25265642419	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_924
Epoch: 924	max: 0.9999932/1.0	min: 6.836958e-06	loss: 34407.5234375	train_loss: 34433.24619826505	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_925
Epoch: 925	max: 0.99999094/1.0	min: 9.0543945e-06	loss: 34407.03125	train_loss: 34433.22567412208	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_926
Epoch: 926	max: 0.9999889/1.0	min: 1.1045367e-05	loss: 34407.62890625	train_loss: 34433.23930123947	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_927
Epoch: 927	max: 0.99999344/1.0	min: 6.516616e-06	loss: 34407.734375	train_loss: 34433.2006137356	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_928
Epoch: 928	max: 0.99999/1.0	min: 1.00311845e-05	loss: 34407.45703125	train_loss: 34433.19921778227	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_929
Epoch: 929	max: 0.99999356/1.0	min: 6.435385e-06	loss: 34407.5390625	train_loss: 34433.155878390935	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_930
Epoch: 930	max: 0.9999943/1.0	min: 5.743992e-06	loss: 34407.57421875	train_loss: 34433.16049592391	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_931
Epoch: 931	max: 0.9999896/1.0	min: 1.0421759e-05	loss: 34407.84375	train_loss: 34433.14180611684	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_932
Epoch: 932	max: 0.99998426/1.0	min: 1.5742668e-05	loss: 34407.296875	train_loss: 34433.14454818531	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_933
Epoch: 933	max: 0.99998295/1.0	min: 1.7033224e-05	loss: 34407.296875	train_loss: 34433.09843237102	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_934
Epoch: 934	max: 0.9999856/1.0	min: 1.4366451e-05	loss: 34407.34375	train_loss: 34433.08731313096	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_935
Epoch: 935	max: 0.9999881/1.0	min: 1.1974447e-05	loss: 34407.1640625	train_loss: 34433.06028002292	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_936
Epoch: 936	max: 0.9999727/1.0	min: 2.7337546e-05	loss: 34407.05078125	train_loss: 34433.052625263226	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_937
Epoch: 937	max: 0.999977/1.0	min: 2.2962735e-05	loss: 34407.0	train_loss: 34433.06579464341	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_938
Epoch: 938	max: 0.99998534/1.0	min: 1.4699986e-05	loss: 34406.8046875	train_loss: 34433.093572905054	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_939
Epoch: 939	max: 0.99998784/1.0	min: 1.2213927e-05	loss: 34407.125	train_loss: 34433.04109376935	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_940
Epoch: 940	max: 0.99998426/1.0	min: 1.573638e-05	loss: 34407.13671875	train_loss: 34433.0010693438	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_941
Epoch: 941	max: 0.9999863/1.0	min: 1.3681133e-05	loss: 34407.1015625	train_loss: 34432.996036653814	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_942
Epoch: 942	max: 0.9999913/1.0	min: 8.680086e-06	loss: 34407.24609375	train_loss: 34432.96945402499	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_943
Epoch: 943	max: 0.9999871/1.0	min: 1.2875064e-05	loss: 34407.04296875	train_loss: 34432.96930838133	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_944
Epoch: 944	max: 0.99998367/1.0	min: 1.6296766e-05	loss: 34406.89453125	train_loss: 34432.969501443855	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_945
Epoch: 945	max: 0.9999796/1.0	min: 2.0346335e-05	loss: 34406.88671875	train_loss: 34432.942456239165	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_946
Epoch: 946	max: 0.99999464/1.0	min: 5.3291315e-06	loss: 34406.890625	train_loss: 34432.93522970085	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_947
Epoch: 947	max: 0.9999927/1.0	min: 7.32878e-06	loss: 34407.3515625	train_loss: 34432.9199680842	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_948
Epoch: 948	max: 0.99998474/1.0	min: 1.52037355e-05	loss: 34406.98046875	train_loss: 34432.89070967655	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_949
Epoch: 949	max: 0.99999666/1.0	min: 3.3410936e-06	loss: 34406.94921875	train_loss: 34432.8970894494	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_950
Epoch: 950	max: 0.999992/1.0	min: 8.043321e-06	loss: 34407.06640625	train_loss: 34432.87278195838	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_951
Epoch: 951	max: 0.9999852/1.0	min: 1.47616e-05	loss: 34407.1796875	train_loss: 34432.85636390205	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_952
Epoch: 952	max: 0.99999464/1.0	min: 5.3386443e-06	loss: 34407.03125	train_loss: 34432.83743506519	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_953
Epoch: 953	max: 0.9999944/1.0	min: 5.644342e-06	loss: 34407.17578125	train_loss: 34432.82681469095	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_954
Epoch: 954	max: 0.99999166/1.0	min: 8.291506e-06	loss: 34407.140625	train_loss: 34432.817208499786	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_955
Epoch: 955	max: 0.9999932/1.0	min: 6.7916894e-06	loss: 34406.80078125	train_loss: 34432.81014647591	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_956
Epoch: 956	max: 0.9999943/1.0	min: 5.765022e-06	loss: 34407.1796875	train_loss: 34432.8112883996	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_957
Epoch: 957	max: 0.99997175/1.0	min: 2.8274897e-05	loss: 34407.1796875	train_loss: 34432.785276732626	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_958
Epoch: 958	max: 0.99998534/1.0	min: 1.4710042e-05	loss: 34407.24609375	train_loss: 34432.80707731404	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_959
Epoch: 959	max: 0.99999034/1.0	min: 9.667658e-06	loss: 34406.96875	train_loss: 34432.74368361359	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_960
Epoch: 960	max: 0.99999166/1.0	min: 8.350657e-06	loss: 34406.97265625	train_loss: 34432.74240523969	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_961
Epoch: 961	max: 0.99999547/1.0	min: 4.5202437e-06	loss: 34406.9609375	train_loss: 34432.747808087144	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_962
Epoch: 962	max: 0.9999927/1.0	min: 7.2799626e-06	loss: 34406.8359375	train_loss: 34432.71554680726	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_963
Epoch: 963	max: 0.9999914/1.0	min: 8.619933e-06	loss: 34407.26953125	train_loss: 34432.702045011145	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_964
Epoch: 964	max: 0.99999213/1.0	min: 7.8314815e-06	loss: 34407.19921875	train_loss: 34432.70126259987	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_965
Epoch: 965	max: 0.9999949/1.0	min: 5.1448005e-06	loss: 34406.96484375	train_loss: 34432.680074592776	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_966
Epoch: 966	max: 0.9999963/1.0	min: 3.6368383e-06	loss: 34406.98828125	train_loss: 34432.661134627	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_967
Epoch: 967	max: 0.99999106/1.0	min: 8.993131e-06	loss: 34406.84375	train_loss: 34432.66182316828	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_968
Epoch: 968	max: 0.9999927/1.0	min: 7.2378866e-06	loss: 34406.875	train_loss: 34432.6376927722	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_969
Epoch: 969	max: 0.9999906/1.0	min: 9.377181e-06	loss: 34406.73046875	train_loss: 34432.614210272666	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_970
Epoch: 970	max: 0.9999938/1.0	min: 6.187193e-06	loss: 34406.8359375	train_loss: 34432.64163434442	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_971
Epoch: 971	max: 0.9999951/1.0	min: 4.9445753e-06	loss: 34407.25	train_loss: 34432.600618961354	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_972
Epoch: 972	max: 0.99999547/1.0	min: 4.584479e-06	loss: 34407.15625	train_loss: 34432.6282791597	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_973
Epoch: 973	max: 0.99998593/1.0	min: 1.4017846e-05	loss: 34406.8046875	train_loss: 34432.568950417284	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_974
Epoch: 974	max: 0.9999919/1.0	min: 8.095335e-06	loss: 34406.97265625	train_loss: 34432.562292905364	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_975
Epoch: 975	max: 0.9999958/1.0	min: 4.207983e-06	loss: 34407.046875	train_loss: 34432.539871523906	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_976
Epoch: 976	max: 0.9999963/1.0	min: 3.640482e-06	loss: 34406.90625	train_loss: 34432.55537120262	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_977
Epoch: 977	max: 0.99999547/1.0	min: 4.479048e-06	loss: 34406.96484375	train_loss: 34432.530576458565	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_978
Epoch: 978	max: 0.999995/1.0	min: 4.974125e-06	loss: 34406.6484375	train_loss: 34432.50647751378	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_979
Epoch: 979	max: 0.9999906/1.0	min: 9.3694935e-06	loss: 34406.6796875	train_loss: 34432.504576404375	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_980
Epoch: 980	max: 0.99999535/1.0	min: 4.618682e-06	loss: 34406.75	train_loss: 34432.50579235956	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_981
Epoch: 981	max: 0.999997/1.0	min: 3.0191586e-06	loss: 34406.87109375	train_loss: 34432.47208577202	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_982
Epoch: 982	max: 0.9999957/1.0	min: 4.2622814e-06	loss: 34407.08984375	train_loss: 34432.465110844016	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_983
Epoch: 983	max: 0.99999356/1.0	min: 6.393305e-06	loss: 34406.86328125	train_loss: 34432.44719425477	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_984
Epoch: 984	max: 0.99999344/1.0	min: 6.537818e-06	loss: 34406.8125	train_loss: 34432.43267537238	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_985
Epoch: 985	max: 0.99999416/1.0	min: 5.8782543e-06	loss: 34406.73046875	train_loss: 34432.428890572744	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_986
Epoch: 986	max: 0.999997/1.0	min: 2.9595774e-06	loss: 34406.69140625	train_loss: 34432.41647844281	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_987
Epoch: 987	max: 0.999995/1.0	min: 5.0662748e-06	loss: 34407.17578125	train_loss: 34432.397377349655	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_988
Epoch: 988	max: 0.99999356/1.0	min: 6.4273627e-06	loss: 34407.0546875	train_loss: 34432.43330246268	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_989
Epoch: 989	max: 0.9999932/1.0	min: 6.7577107e-06	loss: 34406.8203125	train_loss: 34432.39617978137	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_990
Epoch: 990	max: 0.9999919/1.0	min: 8.145804e-06	loss: 34406.67578125	train_loss: 34432.36854135699	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_991
Epoch: 991	max: 0.9999932/1.0	min: 6.7613146e-06	loss: 34406.6640625	train_loss: 34432.36789055726	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_992
Epoch: 992	max: 0.9999914/1.0	min: 8.534861e-06	loss: 34406.93359375	train_loss: 34432.35195201211	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_993
Epoch: 993	max: 0.9999981/1.0	min: 1.931405e-06	loss: 34407.0078125	train_loss: 34432.35912871222	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_994
Epoch: 994	max: 0.99999404/1.0	min: 5.9782074e-06	loss: 34406.796875	train_loss: 34432.37588402313	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_995
Epoch: 995	max: 0.99999344/1.0	min: 6.6054404e-06	loss: 34406.65625	train_loss: 34432.30827536619	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_996
Epoch: 996	max: 0.99999356/1.0	min: 6.4648248e-06	loss: 34406.55078125	train_loss: 34432.30777940357	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_997
Epoch: 997	max: 0.999985/1.0	min: 1.5031513e-05	loss: 34406.76171875	train_loss: 34432.30207172055	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_998
Epoch: 998	max: 0.99998975/1.0	min: 1.0292822e-05	loss: 34406.7109375	train_loss: 34432.28753396739	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_999
Epoch: 999	max: 0.9999937/1.0	min: 6.333156e-06	loss: 34406.5234375	train_loss: 34432.28160418989	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1000
Epoch: 1000	max: 0.9999925/1.0	min: 7.564354e-06	loss: 34406.515625	train_loss: 34432.27362814319	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1001
Epoch: 1001	max: 0.999992/1.0	min: 7.931855e-06	loss: 34406.55078125	train_loss: 34432.28906685479	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1002
Epoch: 1002	max: 0.9999887/1.0	min: 1.1308592e-05	loss: 34406.65234375	train_loss: 34432.254642210144	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1003
Epoch: 1003	max: 0.9999913/1.0	min: 8.740217e-06	loss: 34406.63671875	train_loss: 34432.22849989936	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1004
Epoch: 1004	max: 0.999997/1.0	min: 3.0275432e-06	loss: 34406.59765625	train_loss: 34432.21015750805	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1005
Epoch: 1005	max: 0.9999943/1.0	min: 5.7381553e-06	loss: 34406.98828125	train_loss: 34432.18933917456	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1006
Epoch: 1006	max: 0.99999654/1.0	min: 3.4894115e-06	loss: 34406.8359375	train_loss: 34432.198689400626	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1007
Epoch: 1007	max: 0.9999945/1.0	min: 5.4540933e-06	loss: 34406.50390625	train_loss: 34432.17794703409	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1008
Epoch: 1008	max: 0.9999894/1.0	min: 1.06185935e-05	loss: 34406.5	train_loss: 34432.173322726994	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1009
Epoch: 1009	max: 0.9999951/1.0	min: 4.91981e-06	loss: 34406.5703125	train_loss: 34432.221783839654	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1010
Epoch: 1010	max: 0.99999523/1.0	min: 4.7281014e-06	loss: 34406.453125	train_loss: 34432.13919033739	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1011
Epoch: 1011	max: 0.9999914/1.0	min: 8.575819e-06	loss: 34406.60546875	train_loss: 34432.13095445466	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1012
Epoch: 1012	max: 0.9999845/1.0	min: 1.5511452e-05	loss: 34406.67578125	train_loss: 34432.12417355692	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1013
Epoch: 1013	max: 0.9999927/1.0	min: 7.2959065e-06	loss: 34406.55078125	train_loss: 34432.15207568825	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1014
Epoch: 1014	max: 0.9999943/1.0	min: 5.750109e-06	loss: 34406.734375	train_loss: 34432.130061721946	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1015
Epoch: 1015	max: 0.99999595/1.0	min: 4.0593022e-06	loss: 34406.75	train_loss: 34432.126244503284	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1016
Epoch: 1016	max: 0.9999958/1.0	min: 4.1319804e-06	loss: 34406.71484375	train_loss: 34432.09561240013	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1017
Epoch: 1017	max: 0.999997/1.0	min: 2.9588323e-06	loss: 34406.65625	train_loss: 34432.08410703502	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1018
Epoch: 1018	max: 0.9999945/1.0	min: 5.522069e-06	loss: 34406.546875	train_loss: 34432.07679098151	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1019
Epoch: 1019	max: 0.9999939/1.0	min: 6.1056116e-06	loss: 34406.703125	train_loss: 34432.06212161681	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1020
Epoch: 1020	max: 0.9999944/1.0	min: 5.6405006e-06	loss: 34406.390625	train_loss: 34432.0466417766	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1021
Epoch: 1021	max: 0.99999595/1.0	min: 4.101319e-06	loss: 34406.3203125	train_loss: 34432.03236724653	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1022
Epoch: 1022	max: 0.9999932/1.0	min: 6.8272043e-06	loss: 34406.61328125	train_loss: 34432.026130698	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1023
Epoch: 1023	max: 0.9999944/1.0	min: 5.564965e-06	loss: 34406.46875	train_loss: 34432.03138209541	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1024
Epoch: 1024	max: 0.9999927/1.0	min: 7.2851294e-06	loss: 34406.30078125	train_loss: 34432.0476216052	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1025
Epoch: 1025	max: 0.9999926/1.0	min: 7.3365973e-06	loss: 34406.44921875	train_loss: 34432.02690488356	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1026
Epoch: 1026	max: 0.99999607/1.0	min: 3.97168e-06	loss: 34406.62109375	train_loss: 34431.98305017497	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1027
Epoch: 1027	max: 0.99999094/1.0	min: 9.115927e-06	loss: 34406.44140625	train_loss: 34431.98574676003	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1028
Epoch: 1028	max: 0.99998474/1.0	min: 1.5254656e-05	loss: 34406.34375	train_loss: 34431.982093088074	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1029
Epoch: 1029	max: 0.9999957/1.0	min: 4.280633e-06	loss: 34406.5234375	train_loss: 34431.9807232635	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1030
Epoch: 1030	max: 0.99998856/1.0	min: 1.1477017e-05	loss: 34406.30078125	train_loss: 34431.94148608788	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1031
Epoch: 1031	max: 0.99998796/1.0	min: 1.20392115e-05	loss: 34406.34375	train_loss: 34431.96077105011	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1032
Epoch: 1032	max: 0.9999926/1.0	min: 7.4230925e-06	loss: 34406.5234375	train_loss: 34431.957079636595	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1033
Epoch: 1033	max: 0.99999774/1.0	min: 2.2094553e-06	loss: 34406.5703125	train_loss: 34431.92468964837	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1034
Epoch: 1034	max: 0.9999964/1.0	min: 3.5783078e-06	loss: 34406.546875	train_loss: 34431.903648252664	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1035
Epoch: 1035	max: 0.9999846/1.0	min: 1.5404004e-05	loss: 34406.40625	train_loss: 34431.89370674238	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1036
Epoch: 1036	max: 0.99998987/1.0	min: 1.0168029e-05	loss: 34406.52734375	train_loss: 34431.931782639665	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1037
Epoch: 1037	max: 0.99999213/1.0	min: 7.811089e-06	loss: 34406.39453125	train_loss: 34431.87862076908	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1038
Epoch: 1038	max: 0.9999888/1.0	min: 1.1170535e-05	loss: 34406.4921875	train_loss: 34431.863652859065	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1039
Epoch: 1039	max: 0.9999957/1.0	min: 4.312055e-06	loss: 34406.40625	train_loss: 34431.864637042454	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1040
Epoch: 1040	max: 0.9999914/1.0	min: 8.622218e-06	loss: 34406.46875	train_loss: 34431.833783328686	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1041
Epoch: 1041	max: 0.99999535/1.0	min: 4.6053806e-06	loss: 34406.671875	train_loss: 34431.83667200855	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1042
Epoch: 1042	max: 0.99999285/1.0	min: 7.1915338e-06	loss: 34406.85546875	train_loss: 34431.82346053202	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1043
Epoch: 1043	max: 0.9999962/1.0	min: 3.7845668e-06	loss: 34406.5546875	train_loss: 34431.82192135436	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1044
Epoch: 1044	max: 0.99998546/1.0	min: 1.4587331e-05	loss: 34406.40625	train_loss: 34431.79825885668	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1045
Epoch: 1045	max: 0.99998796/1.0	min: 1.2009522e-05	loss: 34406.27734375	train_loss: 34431.79941626409	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1046
Epoch: 1046	max: 0.9999976/1.0	min: 2.3327684e-06	loss: 34406.171875	train_loss: 34431.8132678953	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1047
Epoch: 1047	max: 0.9999964/1.0	min: 3.5216387e-06	loss: 34406.453125	train_loss: 34431.7886444398	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1048
Epoch: 1048	max: 0.99999154/1.0	min: 8.48466e-06	loss: 34406.59765625	train_loss: 34431.779157763536	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1049
Epoch: 1049	max: 0.99999595/1.0	min: 4.04478e-06	loss: 34406.6015625	train_loss: 34431.77593908708	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1050
Epoch: 1050	max: 0.9999939/1.0	min: 6.050649e-06	loss: 34406.37109375	train_loss: 34431.749963710055	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1051
Epoch: 1051	max: 0.9999926/1.0	min: 7.4173745e-06	loss: 34406.484375	train_loss: 34431.7425373351	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1052
Epoch: 1052	max: 0.99999714/1.0	min: 2.8298666e-06	loss: 34406.578125	train_loss: 34431.733019207546	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1053
Epoch: 1053	max: 0.9999957/1.0	min: 4.3332025e-06	loss: 34406.4609375	train_loss: 34431.73440403196	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1054
Epoch: 1054	max: 0.99999654/1.0	min: 3.4677787e-06	loss: 34406.73046875	train_loss: 34431.74321039267	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1055
Epoch: 1055	max: 0.99999464/1.0	min: 5.3478875e-06	loss: 34406.4296875	train_loss: 34431.7196587003	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1056
Epoch: 1056	max: 0.999995/1.0	min: 5.0141657e-06	loss: 34406.46875	train_loss: 34431.67498287115	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1057
Epoch: 1057	max: 0.9999962/1.0	min: 3.8412886e-06	loss: 34406.36328125	train_loss: 34431.67107129862	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1058
Epoch: 1058	max: 0.99999046/1.0	min: 9.563853e-06	loss: 34406.23828125	train_loss: 34431.662998962594	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1059
Epoch: 1059	max: 0.9999956/1.0	min: 4.3559658e-06	loss: 34406.30859375	train_loss: 34431.64675896894	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1060
Epoch: 1060	max: 0.99999774/1.0	min: 2.264942e-06	loss: 34406.421875	train_loss: 34431.63410200282	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1061
Epoch: 1061	max: 0.9999931/1.0	min: 6.880015e-06	loss: 34406.13671875	train_loss: 34431.64831217871	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1062
Epoch: 1062	max: 0.99999166/1.0	min: 8.357978e-06	loss: 34406.0390625	train_loss: 34431.640556774895	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1063
Epoch: 1063	max: 0.99999475/1.0	min: 5.194238e-06	loss: 34406.30859375	train_loss: 34431.69785908661	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1064
Epoch: 1064	max: 0.99999523/1.0	min: 4.781199e-06	loss: 34406.296875	train_loss: 34431.60368715549	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1065
Epoch: 1065	max: 0.99999535/1.0	min: 4.6842265e-06	loss: 34406.44921875	train_loss: 34431.590851642824	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1066
Epoch: 1066	max: 0.9999976/1.0	min: 2.4410813e-06	loss: 34406.1640625	train_loss: 34431.61157610631	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1067
Epoch: 1067	max: 0.99999714/1.0	min: 2.9037792e-06	loss: 34406.39453125	train_loss: 34431.56565867707	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1068
Epoch: 1068	max: 0.99999523/1.0	min: 4.741544e-06	loss: 34406.30859375	train_loss: 34431.5590616484	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1069
Epoch: 1069	max: 0.999995/1.0	min: 5.0292274e-06	loss: 34406.296875	train_loss: 34431.55783746749	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1070
Epoch: 1070	max: 0.9999962/1.0	min: 3.767221e-06	loss: 34406.26171875	train_loss: 34431.53983910489	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1071
Epoch: 1071	max: 0.999997/1.0	min: 2.930995e-06	loss: 34406.30078125	train_loss: 34431.548940139975	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1072
Epoch: 1072	max: 0.9999956/1.0	min: 4.4315634e-06	loss: 34406.34375	train_loss: 34431.52264783073	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1073
Epoch: 1073	max: 0.999997/1.0	min: 2.996195e-06	loss: 34406.25390625	train_loss: 34431.515211294594	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1074
Epoch: 1074	max: 0.99999535/1.0	min: 4.7058843e-06	loss: 34406.41796875	train_loss: 34431.520828010805	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1075
Epoch: 1075	max: 0.99999297/1.0	min: 6.979187e-06	loss: 34406.40625	train_loss: 34431.585488472374	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1076
Epoch: 1076	max: 0.99999547/1.0	min: 4.5296424e-06	loss: 34406.265625	train_loss: 34431.49897807506	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1077
Epoch: 1077	max: 0.99999523/1.0	min: 4.7695767e-06	loss: 34406.24609375	train_loss: 34431.465277293915	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1078
Epoch: 1078	max: 0.99999404/1.0	min: 5.904605e-06	loss: 34406.01171875	train_loss: 34431.48238340765	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1079
Epoch: 1079	max: 0.99999285/1.0	min: 7.1940103e-06	loss: 34406.16015625	train_loss: 34431.45731576319	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1080
Epoch: 1080	max: 0.9999931/1.0	min: 6.8609484e-06	loss: 34406.14453125	train_loss: 34431.442620753594	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1081
Epoch: 1081	max: 0.9999927/1.0	min: 7.3098704e-06	loss: 34406.17578125	train_loss: 34431.454417406014	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1082
Epoch: 1082	max: 0.9999957/1.0	min: 4.333459e-06	loss: 34406.19921875	train_loss: 34431.436810974854	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1083
Epoch: 1083	max: 0.9999974/1.0	min: 2.568155e-06	loss: 34405.96875	train_loss: 34431.440271584295	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1084
Epoch: 1084	max: 0.9999924/1.0	min: 7.6480765e-06	loss: 34406.19921875	train_loss: 34431.42395320436	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1085
Epoch: 1085	max: 0.9999958/1.0	min: 4.183343e-06	loss: 34406.26171875	train_loss: 34431.39368835548	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1086
Epoch: 1086	max: 0.9999982/1.0	min: 1.8065934e-06	loss: 34406.0390625	train_loss: 34431.39708896553	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1087
Epoch: 1087	max: 0.9999956/1.0	min: 4.382625e-06	loss: 34406.23828125	train_loss: 34431.40321712808	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1088
Epoch: 1088	max: 0.9999895/1.0	min: 1.0448856e-05	loss: 34406.34765625	train_loss: 34431.365879610275	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1089
Epoch: 1089	max: 0.9999943/1.0	min: 5.692675e-06	loss: 34406.41015625	train_loss: 34431.397951698564	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1090
Epoch: 1090	max: 0.999997/1.0	min: 2.9214423e-06	loss: 34406.4609375	train_loss: 34431.35893323037	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1091
Epoch: 1091	max: 0.9999914/1.0	min: 8.632174e-06	loss: 34406.28125	train_loss: 34431.36344092577	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1092
Epoch: 1092	max: 0.99999297/1.0	min: 7.0785013e-06	loss: 34406.21875	train_loss: 34431.34005810263	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1093
Epoch: 1093	max: 0.9999951/1.0	min: 4.846904e-06	loss: 34406.1953125	train_loss: 34431.323366178156	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1094
Epoch: 1094	max: 0.999995/1.0	min: 4.9695113e-06	loss: 34405.99609375	train_loss: 34431.31677543974	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1095
Epoch: 1095	max: 0.9999962/1.0	min: 3.8418784e-06	loss: 34406.09375	train_loss: 34431.314194498635	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1096
Epoch: 1096	max: 0.9999906/1.0	min: 9.456724e-06	loss: 34406.0546875	train_loss: 34431.29133183142	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1097
Epoch: 1097	max: 0.9999958/1.0	min: 4.197514e-06	loss: 34406.37890625	train_loss: 34431.29031329354	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1098
Epoch: 1098	max: 0.9999974/1.0	min: 2.6296239e-06	loss: 34406.42578125	train_loss: 34431.30820036696	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1099
Epoch: 1099	max: 0.999995/1.0	min: 4.9484947e-06	loss: 34406.0703125	train_loss: 34431.26598935108	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1100
Epoch: 1100	max: 0.9999865/1.0	min: 1.349952e-05	loss: 34406.36328125	train_loss: 34431.27081930122	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1101
Epoch: 1101	max: 0.9999951/1.0	min: 4.85027e-06	loss: 34406.26953125	train_loss: 34431.31571674099	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1102
Epoch: 1102	max: 0.9999963/1.0	min: 3.6482256e-06	loss: 34406.125	train_loss: 34431.284157066766	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1103
Epoch: 1103	max: 0.9999963/1.0	min: 3.7378834e-06	loss: 34406.14453125	train_loss: 34431.23179067184	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1104
Epoch: 1104	max: 0.9999943/1.0	min: 5.747625e-06	loss: 34406.12890625	train_loss: 34431.224095267404	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1105
Epoch: 1105	max: 0.99998915/1.0	min: 1.0861244e-05	loss: 34406.05078125	train_loss: 34431.21510794082	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1106
Epoch: 1106	max: 0.9999957/1.0	min: 4.245401e-06	loss: 34406.12109375	train_loss: 34431.220351112504	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1107
Epoch: 1107	max: 0.9999945/1.0	min: 5.435877e-06	loss: 34406.23828125	train_loss: 34431.20887139229	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1108
Epoch: 1108	max: 0.9999907/1.0	min: 9.3156e-06	loss: 34406.18359375	train_loss: 34431.21963499086	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1109
Epoch: 1109	max: 0.99999213/1.0	min: 7.850625e-06	loss: 34406.1015625	train_loss: 34431.1742241693	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1110
Epoch: 1110	max: 0.9999962/1.0	min: 3.814999e-06	loss: 34406.375	train_loss: 34431.17545996299	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1111
Epoch: 1111	max: 0.9999938/1.0	min: 6.170975e-06	loss: 34406.14453125	train_loss: 34431.18813725148	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1112
Epoch: 1112	max: 0.9999912/1.0	min: 8.797391e-06	loss: 34406.16015625	train_loss: 34431.15680305881	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1113
Epoch: 1113	max: 0.9999933/1.0	min: 6.7254755e-06	loss: 34406.3125	train_loss: 34431.153745993586	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1114
Epoch: 1114	max: 0.99999595/1.0	min: 4.017109e-06	loss: 34406.00390625	train_loss: 34431.15106731156	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1115
Epoch: 1115	max: 0.9999982/1.0	min: 1.7644004e-06	loss: 34406.04296875	train_loss: 34431.13031139679	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1116
Epoch: 1116	max: 0.9999862/1.0	min: 1.3796379e-05	loss: 34406.0234375	train_loss: 34431.1115877191	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1117
Epoch: 1117	max: 0.99998987/1.0	min: 1.0085957e-05	loss: 34406.125	train_loss: 34431.113078510156	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1118
Epoch: 1118	max: 0.9999969/1.0	min: 3.062518e-06	loss: 34406.12109375	train_loss: 34431.10165782159	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1119
Epoch: 1119	max: 0.9999974/1.0	min: 2.5644397e-06	loss: 34406.234375	train_loss: 34431.116388153416	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1120
Epoch: 1120	max: 0.9999908/1.0	min: 9.216515e-06	loss: 34406.18359375	train_loss: 34431.12559612288	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1121
Epoch: 1121	max: 0.9999944/1.0	min: 5.6132135e-06	loss: 34406.05078125	train_loss: 34431.09356032454	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1122
Epoch: 1122	max: 0.9999927/1.0	min: 7.304316e-06	loss: 34406.0703125	train_loss: 34431.1171875	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1123
Epoch: 1123	max: 0.99999404/1.0	min: 5.9275226e-06	loss: 34405.99609375	train_loss: 34431.0634087003	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1124
Epoch: 1124	max: 0.99999845/1.0	min: 1.5947392e-06	loss: 34406.19140625	train_loss: 34431.07992304595	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1125
Epoch: 1125	max: 0.99998915/1.0	min: 1.0864093e-05	loss: 34406.10546875	train_loss: 34431.09472111901	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1126
Epoch: 1126	max: 0.99999046/1.0	min: 9.512912e-06	loss: 34406.234375	train_loss: 34431.03410142218	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1127
Epoch: 1127	max: 0.9999945/1.0	min: 5.515196e-06	loss: 34406.19921875	train_loss: 34431.030963067475	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1128
Epoch: 1128	max: 0.9999939/1.0	min: 6.0522248e-06	loss: 34406.14453125	train_loss: 34431.037769126255	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1129
Epoch: 1129	max: 0.99999404/1.0	min: 6.0095895e-06	loss: 34405.87109375	train_loss: 34431.01104375697	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1130
Epoch: 1130	max: 0.99999404/1.0	min: 5.9647223e-06	loss: 34405.89453125	train_loss: 34430.99691196736	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1131
Epoch: 1131	max: 0.9999908/1.0	min: 9.17555e-06	loss: 34406.0	train_loss: 34430.996324070205	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1132
Epoch: 1132	max: 0.99999225/1.0	min: 7.763212e-06	loss: 34405.96484375	train_loss: 34431.02474248653	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1133
Epoch: 1133	max: 0.999995/1.0	min: 4.9541372e-06	loss: 34406.1328125	train_loss: 34431.01643886256	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1134
Epoch: 1134	max: 0.9999958/1.0	min: 4.202761e-06	loss: 34405.9921875	train_loss: 34430.96608341462	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1135
Epoch: 1135	max: 0.99999607/1.0	min: 3.955298e-06	loss: 34405.890625	train_loss: 34430.95643803032	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1136
Epoch: 1136	max: 0.9999938/1.0	min: 6.1713404e-06	loss: 34405.7109375	train_loss: 34430.95086631364	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1137
Epoch: 1137	max: 0.9999895/1.0	min: 1.0503096e-05	loss: 34405.88671875	train_loss: 34430.9743570389	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1138
Epoch: 1138	max: 0.9999949/1.0	min: 5.107602e-06	loss: 34405.9609375	train_loss: 34430.93209521708	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1139
Epoch: 1139	max: 0.9999976/1.0	min: 2.4218882e-06	loss: 34406.078125	train_loss: 34430.92304402019	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1140
Epoch: 1140	max: 0.9999913/1.0	min: 8.67843e-06	loss: 34405.9765625	train_loss: 34430.93017620463	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1141
Epoch: 1141	max: 0.9999945/1.0	min: 5.4611405e-06	loss: 34405.9765625	train_loss: 34430.91783423526	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1142
Epoch: 1142	max: 0.9999964/1.0	min: 3.5309977e-06	loss: 34405.8984375	train_loss: 34430.90565049006	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1143
Epoch: 1143	max: 0.999992/1.0	min: 8.019524e-06	loss: 34405.9140625	train_loss: 34430.8918366004	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1144
Epoch: 1144	max: 0.9999877/1.0	min: 1.2225253e-05	loss: 34405.89453125	train_loss: 34430.877049656265	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1145
Epoch: 1145	max: 0.9999938/1.0	min: 6.2246795e-06	loss: 34405.81640625	train_loss: 34430.89118725226	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1146
Epoch: 1146	max: 0.99998283/1.0	min: 1.7221568e-05	loss: 34406.03515625	train_loss: 34430.86072014741	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1147
Epoch: 1147	max: 0.99999607/1.0	min: 3.9060346e-06	loss: 34405.81640625	train_loss: 34430.86451946302	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1148
Epoch: 1148	max: 0.99999356/1.0	min: 6.413084e-06	loss: 34405.98046875	train_loss: 34430.86775507479	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1149
Epoch: 1149	max: 0.99999034/1.0	min: 9.7104585e-06	loss: 34405.88671875	train_loss: 34430.836186690976	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1150
Epoch: 1150	max: 0.9999933/1.0	min: 6.6540474e-06	loss: 34405.765625	train_loss: 34430.84002036108	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1151
Epoch: 1151	max: 0.9999925/1.0	min: 7.504686e-06	loss: 34405.95703125	train_loss: 34430.83246431004	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1152
Epoch: 1152	max: 0.99998665/1.0	min: 1.3366038e-05	loss: 34405.8203125	train_loss: 34430.840580677876	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1153
Epoch: 1153	max: 0.9999858/1.0	min: 1.416424e-05	loss: 34405.796875	train_loss: 34430.89558511009	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1154
Epoch: 1154	max: 0.99999166/1.0	min: 8.325919e-06	loss: 34405.796875	train_loss: 34430.866469442895	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1155
Epoch: 1155	max: 0.99999416/1.0	min: 5.8545784e-06	loss: 34405.80078125	train_loss: 34430.792031985475	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1156
Epoch: 1156	max: 0.99999774/1.0	min: 2.2955512e-06	loss: 34405.7890625	train_loss: 34430.771252361264	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1157
Epoch: 1157	max: 0.9999938/1.0	min: 6.2124327e-06	loss: 34405.6640625	train_loss: 34430.75287561548	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1158
Epoch: 1158	max: 0.9999957/1.0	min: 4.3376267e-06	loss: 34406.2421875	train_loss: 34430.75569026384	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1159
Epoch: 1159	max: 0.99999523/1.0	min: 4.721766e-06	loss: 34406.00390625	train_loss: 34430.772731539546	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1160
Epoch: 1160	max: 0.99999523/1.0	min: 4.731336e-06	loss: 34405.74609375	train_loss: 34430.73908398365	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1161
Epoch: 1161	max: 0.9999926/1.0	min: 7.377129e-06	loss: 34405.71875	train_loss: 34430.719762247616	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1162
Epoch: 1162	max: 0.99998844/1.0	min: 1.1562399e-05	loss: 34406.04296875	train_loss: 34430.712264260495	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1163
Epoch: 1163	max: 0.99998546/1.0	min: 1.4503823e-05	loss: 34405.68359375	train_loss: 34430.72478090549	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1164
Epoch: 1164	max: 0.9999969/1.0	min: 3.0945694e-06	loss: 34405.640625	train_loss: 34430.72230980196	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1165
Epoch: 1165	max: 0.9999968/1.0	min: 3.2766432e-06	loss: 34406.109375	train_loss: 34430.693556066515	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1166
Epoch: 1166	max: 0.9999931/1.0	min: 6.863448e-06	loss: 34405.7734375	train_loss: 34430.680364428496	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1167
Epoch: 1167	max: 0.9999962/1.0	min: 3.8677845e-06	loss: 34405.68359375	train_loss: 34430.66846180943	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1168
Epoch: 1168	max: 0.99999154/1.0	min: 8.426456e-06	loss: 34405.703125	train_loss: 34430.64024032655	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1169
Epoch: 1169	max: 0.9999914/1.0	min: 8.530157e-06	loss: 34405.7265625	train_loss: 34430.63828502416	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1170
Epoch: 1170	max: 0.9999933/1.0	min: 6.6263237e-06	loss: 34405.58203125	train_loss: 34430.6265314358	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1171
Epoch: 1171	max: 0.99999535/1.0	min: 4.6845303e-06	loss: 34405.578125	train_loss: 34430.622566154154	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1172
Epoch: 1172	max: 0.9999913/1.0	min: 8.738759e-06	loss: 34405.640625	train_loss: 34430.60231200839	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1173
Epoch: 1173	max: 0.99998915/1.0	min: 1.0860944e-05	loss: 34405.609375	train_loss: 34430.58802102688	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1174
Epoch: 1174	max: 0.9999913/1.0	min: 8.728197e-06	loss: 34405.93359375	train_loss: 34430.587445226374	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1175
Epoch: 1175	max: 0.99999464/1.0	min: 5.3295635e-06	loss: 34405.953125	train_loss: 34430.571605873745	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1176
Epoch: 1176	max: 0.99999726/1.0	min: 2.7793542e-06	loss: 34405.8203125	train_loss: 34430.564352238944	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1177
Epoch: 1177	max: 0.99999475/1.0	min: 5.1960706e-06	loss: 34406.01171875	train_loss: 34430.564373045185	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1178
Epoch: 1178	max: 0.9999957/1.0	min: 4.270582e-06	loss: 34405.87109375	train_loss: 34430.61147497832	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1179
Epoch: 1179	max: 0.9999968/1.0	min: 3.1899492e-06	loss: 34405.68359375	train_loss: 34430.54095828688	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1180
Epoch: 1180	max: 0.99999523/1.0	min: 4.8013953e-06	loss: 34405.53515625	train_loss: 34430.52473522854	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1181
Epoch: 1181	max: 0.9999975/1.0	min: 2.462816e-06	loss: 34405.54296875	train_loss: 34430.50428511706	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1182
Epoch: 1182	max: 0.9999924/1.0	min: 7.661625e-06	loss: 34405.6015625	train_loss: 34430.4918845999	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1183
Epoch: 1183	max: 0.99998903/1.0	min: 1.094191e-05	loss: 34405.6796875	train_loss: 34430.512174551746	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1184
Epoch: 1184	max: 0.99999034/1.0	min: 9.67488e-06	loss: 34405.453125	train_loss: 34430.495818914125	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1185
Epoch: 1185	max: 0.9999918/1.0	min: 8.169959e-06	loss: 34405.55859375	train_loss: 34430.50594187415	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1186
Epoch: 1186	max: 0.9999938/1.0	min: 6.1504e-06	loss: 34405.68359375	train_loss: 34430.50244352316	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1187
Epoch: 1187	max: 0.9999939/1.0	min: 6.0529114e-06	loss: 34405.85546875	train_loss: 34430.43656371934	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1188
Epoch: 1188	max: 0.99999344/1.0	min: 6.613054e-06	loss: 34405.80078125	train_loss: 34430.47325043741	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1189
Epoch: 1189	max: 0.9999913/1.0	min: 8.672787e-06	loss: 34405.765625	train_loss: 34430.41098269308	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1190
Epoch: 1190	max: 0.9999939/1.0	min: 6.091851e-06	loss: 34405.65625	train_loss: 34430.417482948564	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1191
Epoch: 1191	max: 0.9999957/1.0	min: 4.3121245e-06	loss: 34405.48828125	train_loss: 34430.39393706259	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1192
Epoch: 1192	max: 0.99999166/1.0	min: 8.383292e-06	loss: 34405.5859375	train_loss: 34430.38908485461	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1193
Epoch: 1193	max: 0.99999/1.0	min: 1.0023247e-05	loss: 34405.69921875	train_loss: 34430.35571745711	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1194
Epoch: 1194	max: 0.9999958/1.0	min: 4.1355206e-06	loss: 34405.4765625	train_loss: 34430.35828678543	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1195
Epoch: 1195	max: 0.99999404/1.0	min: 5.931334e-06	loss: 34405.69140625	train_loss: 34430.35548471758	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1196
Epoch: 1196	max: 0.99999356/1.0	min: 6.4807327e-06	loss: 34405.63671875	train_loss: 34430.349930420074	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1197
Epoch: 1197	max: 0.9999968/1.0	min: 3.270808e-06	loss: 34405.80859375	train_loss: 34430.37178083968	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1198
Epoch: 1198	max: 0.99999666/1.0	min: 3.3291153e-06	loss: 34405.30078125	train_loss: 34430.33890166295	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1199
Epoch: 1199	max: 0.9999919/1.0	min: 8.1434655e-06	loss: 34405.46875	train_loss: 34430.3254003507	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1200
Epoch: 1200	max: 0.999995/1.0	min: 4.947523e-06	loss: 34406.05859375	train_loss: 34430.30034673835	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1201
Epoch: 1201	max: 0.9999913/1.0	min: 8.647564e-06	loss: 34405.4609375	train_loss: 34430.3148932011	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1202
Epoch: 1202	max: 0.9999901/1.0	min: 9.916266e-06	loss: 34405.42578125	train_loss: 34430.29484421451	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1203
Epoch: 1203	max: 0.99999535/1.0	min: 4.630484e-06	loss: 34405.39453125	train_loss: 34430.27719181609	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1204
Epoch: 1204	max: 0.9999957/1.0	min: 4.3326777e-06	loss: 34405.72265625	train_loss: 34430.27137623096	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1205
Epoch: 1205	max: 0.9999963/1.0	min: 3.639444e-06	loss: 34405.484375	train_loss: 34430.266884019264	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1206
Epoch: 1206	max: 0.99999094/1.0	min: 9.0791245e-06	loss: 34405.48046875	train_loss: 34430.24130783166	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1207
Epoch: 1207	max: 0.99999475/1.0	min: 5.20768e-06	loss: 34405.43359375	train_loss: 34430.238095445464	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1208
Epoch: 1208	max: 0.9999964/1.0	min: 3.5872256e-06	loss: 34405.515625	train_loss: 34430.212249744516	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1209
Epoch: 1209	max: 0.9999956/1.0	min: 4.409919e-06	loss: 34405.6484375	train_loss: 34430.26393534002	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1210
Epoch: 1210	max: 0.99999595/1.0	min: 4.060293e-06	loss: 34405.74609375	train_loss: 34430.21608341462	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1211
Epoch: 1211	max: 0.9999968/1.0	min: 3.1991865e-06	loss: 34405.671875	train_loss: 34430.22810603245	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1212
Epoch: 1212	max: 0.99999416/1.0	min: 5.885564e-06	loss: 34405.5234375	train_loss: 34430.1828940798	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1213
Epoch: 1213	max: 0.9999969/1.0	min: 3.0810438e-06	loss: 34405.25	train_loss: 34430.16823681175	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1214
Epoch: 1214	max: 0.9999982/1.0	min: 1.7833574e-06	loss: 34405.46875	train_loss: 34430.161371721326	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1215
Epoch: 1215	max: 0.9999943/1.0	min: 5.6685785e-06	loss: 34405.671875	train_loss: 34430.15021135266	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1216
Epoch: 1216	max: 0.9999976/1.0	min: 2.4251033e-06	loss: 34405.25390625	train_loss: 34430.15526146182	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1217
Epoch: 1217	max: 0.9999938/1.0	min: 6.1633295e-06	loss: 34405.4609375	train_loss: 34430.12546886613	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1218
Epoch: 1218	max: 0.9999937/1.0	min: 6.3705306e-06	loss: 34405.57421875	train_loss: 34430.106558900035	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1219
Epoch: 1219	max: 0.99999344/1.0	min: 6.5655468e-06	loss: 34405.421875	train_loss: 34430.09616255574	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1220
Epoch: 1220	max: 0.99999356/1.0	min: 6.4555593e-06	loss: 34405.35546875	train_loss: 34430.09570578626	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1221
Epoch: 1221	max: 0.9999925/1.0	min: 7.5297994e-06	loss: 34405.26171875	train_loss: 34430.08950262449	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1222
Epoch: 1222	max: 0.99999547/1.0	min: 4.4890294e-06	loss: 34405.36328125	train_loss: 34430.09505353493	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1223
Epoch: 1223	max: 0.9999893/1.0	min: 1.0684295e-05	loss: 34405.234375	train_loss: 34430.05910471247	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1224
Epoch: 1224	max: 0.999997/1.0	min: 2.9593007e-06	loss: 34405.37109375	train_loss: 34430.101421695	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1225
Epoch: 1225	max: 0.999995/1.0	min: 5.025258e-06	loss: 34405.296875	train_loss: 34430.074293749225	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1226
Epoch: 1226	max: 0.9999945/1.0	min: 5.5104692e-06	loss: 34405.30859375	train_loss: 34430.03272433962	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1227
Epoch: 1227	max: 0.9999924/1.0	min: 7.5861853e-06	loss: 34405.3359375	train_loss: 34430.04325181159	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1228
Epoch: 1228	max: 0.9999943/1.0	min: 5.7140733e-06	loss: 34405.4765625	train_loss: 34430.023922333705	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1229
Epoch: 1229	max: 0.99999547/1.0	min: 4.5381003e-06	loss: 34405.46484375	train_loss: 34430.01650128128	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1230
Epoch: 1230	max: 0.9999901/1.0	min: 9.851004e-06	loss: 34405.390625	train_loss: 34429.997739378174	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1231
Epoch: 1231	max: 0.9999969/1.0	min: 3.137273e-06	loss: 34405.19140625	train_loss: 34430.008477331845	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1232
Epoch: 1232	max: 0.9999956/1.0	min: 4.362809e-06	loss: 34405.49609375	train_loss: 34429.99294862118	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1233
Epoch: 1233	max: 0.99999666/1.0	min: 3.3199367e-06	loss: 34405.12109375	train_loss: 34429.98860350474	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1234
Epoch: 1234	max: 0.9999863/1.0	min: 1.3710508e-05	loss: 34405.28515625	train_loss: 34429.97469768054	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1235
Epoch: 1235	max: 0.9999956/1.0	min: 4.366547e-06	loss: 34405.19921875	train_loss: 34429.96502036108	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1236
Epoch: 1236	max: 0.9999919/1.0	min: 8.087787e-06	loss: 34405.1953125	train_loss: 34429.95766221123	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1237
Epoch: 1237	max: 0.9999937/1.0	min: 6.332431e-06	loss: 34405.18359375	train_loss: 34429.952325653416	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1238
Epoch: 1238	max: 0.9999937/1.0	min: 6.2998856e-06	loss: 34405.54296875	train_loss: 34429.93400261675	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1239
Epoch: 1239	max: 0.99999356/1.0	min: 6.4822902e-06	loss: 34405.3125	train_loss: 34430.002887228264	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1240
Epoch: 1240	max: 0.9999969/1.0	min: 3.1173e-06	loss: 34405.50390625	train_loss: 34429.92017904977	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1241
Epoch: 1241	max: 0.99999416/1.0	min: 5.8325877e-06	loss: 34405.12890625	train_loss: 34429.9210630729	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1242
Epoch: 1242	max: 0.9999924/1.0	min: 7.5946764e-06	loss: 34405.1953125	train_loss: 34429.90903029388	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1243
Epoch: 1243	max: 0.9999943/1.0	min: 5.672754e-06	loss: 34405.1640625	train_loss: 34429.88449490199	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1244
Epoch: 1244	max: 0.9999944/1.0	min: 5.6623494e-06	loss: 34404.9765625	train_loss: 34429.91117672333	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1245
Epoch: 1245	max: 0.99999285/1.0	min: 7.1379577e-06	loss: 34405.06640625	train_loss: 34429.90013925663	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1246
Epoch: 1246	max: 0.9999981/1.0	min: 1.864586e-06	loss: 34405.08984375	train_loss: 34429.89351609919	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1247
Epoch: 1247	max: 0.9999976/1.0	min: 2.4088758e-06	loss: 34405.4296875	train_loss: 34429.85674276911	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1248
Epoch: 1248	max: 0.99999607/1.0	min: 3.9824745e-06	loss: 34405.359375	train_loss: 34429.88498118729	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1249
Epoch: 1249	max: 0.9999944/1.0	min: 5.6120894e-06	loss: 34405.09375	train_loss: 34429.82988675601	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1250
Epoch: 1250	max: 0.9999926/1.0	min: 7.434116e-06	loss: 34405.14453125	train_loss: 34429.826951625015	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1251
Epoch: 1251	max: 0.9999974/1.0	min: 2.5737868e-06	loss: 34404.96484375	train_loss: 34429.80578055323	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1252
Epoch: 1252	max: 0.99999785/1.0	min: 2.1830315e-06	loss: 34405.25	train_loss: 34429.81730285365	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1253
Epoch: 1253	max: 0.99999654/1.0	min: 3.4097466e-06	loss: 34404.9921875	train_loss: 34429.86827232751	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1254
Epoch: 1254	max: 0.9999896/1.0	min: 1.0331833e-05	loss: 34405.13671875	train_loss: 34429.796886612785	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1255
Epoch: 1255	max: 0.99999404/1.0	min: 5.954963e-06	loss: 34405.06640625	train_loss: 34429.77921631132	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1256
Epoch: 1256	max: 0.99999654/1.0	min: 3.5071168e-06	loss: 34405.16796875	train_loss: 34429.77758907005	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1257
Epoch: 1257	max: 0.9999958/1.0	min: 4.1771405e-06	loss: 34405.0	train_loss: 34429.75930280719	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1258
Epoch: 1258	max: 0.99999595/1.0	min: 3.997828e-06	loss: 34405.10546875	train_loss: 34429.736472558994	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1259
Epoch: 1259	max: 0.9999964/1.0	min: 3.6338504e-06	loss: 34404.95703125	train_loss: 34429.73970768689	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1260
Epoch: 1260	max: 0.9999962/1.0	min: 3.8056382e-06	loss: 34405.13671875	train_loss: 34429.74403635188	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1261
Epoch: 1261	max: 0.9999919/1.0	min: 8.110998e-06	loss: 34405.1953125	train_loss: 34429.713544569866	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1262
Epoch: 1262	max: 0.99999654/1.0	min: 3.4648695e-06	loss: 34404.890625	train_loss: 34429.71054798789	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1263
Epoch: 1263	max: 0.99999607/1.0	min: 3.969749e-06	loss: 34404.96484375	train_loss: 34429.73531321612	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1264
Epoch: 1264	max: 0.99999213/1.0	min: 7.889533e-06	loss: 34405.30859375	train_loss: 34429.70109469838	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1265
Epoch: 1265	max: 0.9999964/1.0	min: 3.618665e-06	loss: 34404.92578125	train_loss: 34429.68824854066	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1266
Epoch: 1266	max: 0.9999969/1.0	min: 3.0417066e-06	loss: 34405.12109375	train_loss: 34429.68021394618	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1267
Epoch: 1267	max: 0.9999943/1.0	min: 5.7526972e-06	loss: 34404.8984375	train_loss: 34429.72046046621	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1268
Epoch: 1268	max: 0.99999714/1.0	min: 2.8049328e-06	loss: 34405.0546875	train_loss: 34429.64903217128	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1269
Epoch: 1269	max: 0.9999956/1.0	min: 4.3931577e-06	loss: 34405.05078125	train_loss: 34429.649335555245	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1270
Epoch: 1270	max: 0.99999607/1.0	min: 3.9856586e-06	loss: 34405.0859375	train_loss: 34429.62811658073	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1271
Epoch: 1271	max: 0.99999726/1.0	min: 2.7757676e-06	loss: 34404.9609375	train_loss: 34429.63665971835	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1272
Epoch: 1272	max: 0.999997/1.0	min: 2.965833e-06	loss: 34404.86328125	train_loss: 34429.60757888951	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1273
Epoch: 1273	max: 0.9999975/1.0	min: 2.5273562e-06	loss: 34405.06640625	train_loss: 34429.624876130314	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1274
Epoch: 1274	max: 0.9999962/1.0	min: 3.7603618e-06	loss: 34405.18359375	train_loss: 34429.59613255605	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1275
Epoch: 1275	max: 0.9999975/1.0	min: 2.4543306e-06	loss: 34404.87109375	train_loss: 34429.5889805331	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1276
Epoch: 1276	max: 0.9999964/1.0	min: 3.580192e-06	loss: 34405.1953125	train_loss: 34429.57061346463	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1277
Epoch: 1277	max: 0.9999968/1.0	min: 3.2655312e-06	loss: 34404.91796875	train_loss: 34429.583426719466	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1278
Epoch: 1278	max: 0.9999943/1.0	min: 5.77697e-06	loss: 34404.90625	train_loss: 34429.55993309101	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1279
Epoch: 1279	max: 0.9999956/1.0	min: 4.4235157e-06	loss: 34404.88671875	train_loss: 34429.56999363232	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1280
Epoch: 1280	max: 0.999997/1.0	min: 2.9491778e-06	loss: 34404.90625	train_loss: 34429.539409431905	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1281
Epoch: 1281	max: 0.99999356/1.0	min: 6.4386204e-06	loss: 34404.9921875	train_loss: 34429.521256716056	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1282
Epoch: 1282	max: 0.99999464/1.0	min: 5.3466433e-06	loss: 34404.94140625	train_loss: 34429.51885238604	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1283
Epoch: 1283	max: 0.99999726/1.0	min: 2.7057324e-06	loss: 34404.9921875	train_loss: 34429.51156149356	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1284
Epoch: 1284	max: 0.9999987/1.0	min: 1.3564836e-06	loss: 34405.01953125	train_loss: 34429.52496506488	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1285
Epoch: 1285	max: 0.9999919/1.0	min: 8.095752e-06	loss: 34405.08984375	train_loss: 34429.50345335145	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1286
Epoch: 1286	max: 0.9999962/1.0	min: 3.7663588e-06	loss: 34404.87890625	train_loss: 34429.48645126889	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1287
Epoch: 1287	max: 0.99999607/1.0	min: 3.893167e-06	loss: 34404.88671875	train_loss: 34429.457410600924	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1288
Epoch: 1288	max: 0.9999974/1.0	min: 2.656326e-06	loss: 34404.81640625	train_loss: 34429.453944185094	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1289
Epoch: 1289	max: 0.9999944/1.0	min: 5.56558e-06	loss: 34405.0703125	train_loss: 34429.44690393518	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1290
Epoch: 1290	max: 0.9999976/1.0	min: 2.3450518e-06	loss: 34404.71484375	train_loss: 34429.46036557042	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1291
Epoch: 1291	max: 0.99999714/1.0	min: 2.91401e-06	loss: 34404.65625	train_loss: 34429.45412805416	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1292
Epoch: 1292	max: 0.999992/1.0	min: 7.95965e-06	loss: 34404.74609375	train_loss: 34429.44174640778	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1293
Epoch: 1293	max: 0.9999951/1.0	min: 4.8466363e-06	loss: 34404.74609375	train_loss: 34429.47332446891	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1294
Epoch: 1294	max: 0.999998/1.0	min: 1.9787685e-06	loss: 34404.73828125	train_loss: 34429.396455584974	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1295
Epoch: 1295	max: 0.9999969/1.0	min: 3.1163786e-06	loss: 34404.80859375	train_loss: 34429.373260985696	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1296
Epoch: 1296	max: 0.99999774/1.0	min: 2.271158e-06	loss: 34404.76171875	train_loss: 34429.386240690415	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1297
Epoch: 1297	max: 0.9999976/1.0	min: 2.419912e-06	loss: 34404.765625	train_loss: 34429.36371624551	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1298
Epoch: 1298	max: 0.9999974/1.0	min: 2.610621e-06	loss: 34404.66015625	train_loss: 34429.371996160036	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1299
Epoch: 1299	max: 0.9999957/1.0	min: 4.2459396e-06	loss: 34404.62109375	train_loss: 34429.353378449	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1300
Epoch: 1300	max: 0.99999356/1.0	min: 6.377837e-06	loss: 34404.8671875	train_loss: 34429.333425751734	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1301
Epoch: 1301	max: 0.9999982/1.0	min: 1.8062248e-06	loss: 34404.6015625	train_loss: 34429.315402711974	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1302
Epoch: 1302	max: 0.99999416/1.0	min: 5.859997e-06	loss: 34404.78515625	train_loss: 34429.32741323316	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1303
Epoch: 1303	max: 0.999998/1.0	min: 2.0581238e-06	loss: 34404.58203125	train_loss: 34429.31179694274	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1304
Epoch: 1304	max: 0.9999925/1.0	min: 7.4764903e-06	loss: 34404.7265625	train_loss: 34429.333903327446	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1305
Epoch: 1305	max: 0.9999974/1.0	min: 2.6297541e-06	loss: 34404.74609375	train_loss: 34429.28295514369	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1306
Epoch: 1306	max: 0.9999908/1.0	min: 9.159674e-06	loss: 34404.80859375	train_loss: 34429.26055069754	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1307
Epoch: 1307	max: 0.9999982/1.0	min: 1.8299716e-06	loss: 34404.546875	train_loss: 34429.265688870306	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1308
Epoch: 1308	max: 0.999995/1.0	min: 5.0573058e-06	loss: 34404.74609375	train_loss: 34429.24979822789	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1309
Epoch: 1309	max: 0.9999976/1.0	min: 2.3836697e-06	loss: 34404.98828125	train_loss: 34429.236413527346	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1310
Epoch: 1310	max: 0.9999988/1.0	min: 1.2234048e-06	loss: 34404.734375	train_loss: 34429.26241938793	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1311
Epoch: 1311	max: 0.9999968/1.0	min: 3.277959e-06	loss: 34404.5234375	train_loss: 34429.232528567445	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1312
Epoch: 1312	max: 0.9999943/1.0	min: 5.6677786e-06	loss: 34404.65625	train_loss: 34429.21445714109	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1313
Epoch: 1313	max: 0.99999857/1.0	min: 1.4038044e-06	loss: 34404.5625	train_loss: 34429.18728855057	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1314
Epoch: 1314	max: 0.9999949/1.0	min: 5.079298e-06	loss: 34404.96484375	train_loss: 34429.21476778304	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1315
Epoch: 1315	max: 0.9999987/1.0	min: 1.3014495e-06	loss: 34404.58984375	train_loss: 34429.253508028305	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1316
Epoch: 1316	max: 0.99999785/1.0	min: 2.1090855e-06	loss: 34404.89453125	train_loss: 34429.202512425676	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1317
Epoch: 1317	max: 0.9999976/1.0	min: 2.3754683e-06	loss: 34404.671875	train_loss: 34429.143569808315	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1318
Epoch: 1318	max: 0.99999857/1.0	min: 1.4641132e-06	loss: 34404.41015625	train_loss: 34429.1498324856	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1319
Epoch: 1319	max: 0.9999974/1.0	min: 2.6036093e-06	loss: 34404.62109375	train_loss: 34429.15030377106	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1320
Epoch: 1320	max: 0.99999714/1.0	min: 2.847368e-06	loss: 34404.61328125	train_loss: 34429.158151109405	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1321
Epoch: 1321	max: 0.9999968/1.0	min: 3.2127004e-06	loss: 34404.44140625	train_loss: 34429.20300500124	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1322
Epoch: 1322	max: 0.99999404/1.0	min: 5.9185973e-06	loss: 34404.59375	train_loss: 34429.10790066038	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1323
Epoch: 1323	max: 0.9999969/1.0	min: 3.1490083e-06	loss: 34404.4765625	train_loss: 34429.08824892775	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1324
Epoch: 1324	max: 0.9999957/1.0	min: 4.2398865e-06	loss: 34404.58203125	train_loss: 34429.07645469466	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1325
Epoch: 1325	max: 0.99999917/1.0	min: 8.561352e-07	loss: 34404.62890625	train_loss: 34429.076549532394	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1326
Epoch: 1326	max: 0.99999714/1.0	min: 2.8759332e-06	loss: 34404.37890625	train_loss: 34429.08328881767	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1327
Epoch: 1327	max: 0.999997/1.0	min: 2.9983246e-06	loss: 34404.546875	train_loss: 34429.05179833627	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1328
Epoch: 1328	max: 0.9999969/1.0	min: 3.12178e-06	loss: 34404.5546875	train_loss: 34429.033437558064	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1329
Epoch: 1329	max: 0.99999726/1.0	min: 2.694413e-06	loss: 34404.4765625	train_loss: 34429.016981760185	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1330
Epoch: 1330	max: 0.99999034/1.0	min: 9.665611e-06	loss: 34404.56640625	train_loss: 34429.038882017994	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1331
Epoch: 1331	max: 0.99999726/1.0	min: 2.7981387e-06	loss: 34404.39453125	train_loss: 34429.002433845846	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1332
Epoch: 1332	max: 0.9999958/1.0	min: 4.1223925e-06	loss: 34404.28515625	train_loss: 34428.992223789945	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1333
Epoch: 1333	max: 0.9999989/1.0	min: 1.1154301e-06	loss: 34404.38671875	train_loss: 34428.984326613405	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1334
Epoch: 1334	max: 0.99999607/1.0	min: 3.9521756e-06	loss: 34404.5390625	train_loss: 34428.980453750155	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1335
Epoch: 1335	max: 0.9999974/1.0	min: 2.6601538e-06	loss: 34404.328125	train_loss: 34428.95530239688	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1336
Epoch: 1336	max: 0.99999774/1.0	min: 2.23993e-06	loss: 34404.6015625	train_loss: 34428.961933296174	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1337
Epoch: 1337	max: 0.9999989/1.0	min: 1.0703433e-06	loss: 34404.68359375	train_loss: 34428.95265661774	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1338
Epoch: 1338	max: 0.9999993/1.0	min: 7.694207e-07	loss: 34404.5859375	train_loss: 34428.94658603524	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1339
Epoch: 1339	max: 0.9999974/1.0	min: 2.6655632e-06	loss: 34404.76171875	train_loss: 34428.92783961585	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1340
Epoch: 1340	max: 0.9999989/1.0	min: 1.0142084e-06	loss: 34404.61328125	train_loss: 34428.96976031215	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1341
Epoch: 1341	max: 0.9999963/1.0	min: 3.7004536e-06	loss: 34404.42578125	train_loss: 34428.92480093754	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1342
Epoch: 1342	max: 0.99999845/1.0	min: 1.5362587e-06	loss: 34404.13671875	train_loss: 34428.89614978168	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1343
Epoch: 1343	max: 0.99999535/1.0	min: 4.656478e-06	loss: 34404.328125	train_loss: 34428.898613627214	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1344
Epoch: 1344	max: 0.9999989/1.0	min: 1.1301285e-06	loss: 34404.2734375	train_loss: 34428.87036311238	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1345
Epoch: 1345	max: 0.99999666/1.0	min: 3.2962032e-06	loss: 34404.44140625	train_loss: 34428.86326915335	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1346
Epoch: 1346	max: 0.99999297/1.0	min: 6.9754215e-06	loss: 34404.65625	train_loss: 34428.88213363604	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1347
Epoch: 1347	max: 0.9999989/1.0	min: 1.0787011e-06	loss: 34404.2109375	train_loss: 34428.85503327062	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1348
Epoch: 1348	max: 0.99999857/1.0	min: 1.4723505e-06	loss: 34404.140625	train_loss: 34428.82395746237	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1349
Epoch: 1349	max: 0.99999654/1.0	min: 3.5109654e-06	loss: 34404.3515625	train_loss: 34428.83420671141	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1350
Epoch: 1350	max: 0.999997/1.0	min: 2.9761688e-06	loss: 34404.17578125	train_loss: 34428.80176204633	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1351
Epoch: 1351	max: 0.9999988/1.0	min: 1.2133182e-06	loss: 34404.11328125	train_loss: 34428.78022226867	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1352
Epoch: 1352	max: 0.999992/1.0	min: 7.936206e-06	loss: 34404.328125	train_loss: 34428.80063705794	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1353
Epoch: 1353	max: 0.99999785/1.0	min: 2.1520912e-06	loss: 34404.19140625	train_loss: 34428.787709126875	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1354
Epoch: 1354	max: 0.99999857/1.0	min: 1.4802108e-06	loss: 34404.07421875	train_loss: 34428.73630514136	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1355
Epoch: 1355	max: 0.9999964/1.0	min: 3.62787e-06	loss: 34404.19140625	train_loss: 34428.73465467453	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1356
Epoch: 1356	max: 0.99999595/1.0	min: 4.034278e-06	loss: 34404.0703125	train_loss: 34428.72769087545	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1357
Epoch: 1357	max: 0.99999845/1.0	min: 1.4972362e-06	loss: 34404.1484375	train_loss: 34428.730361331756	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1358
Epoch: 1358	max: 0.9999981/1.0	min: 1.8790398e-06	loss: 34404.078125	train_loss: 34428.70972493187	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1359
Epoch: 1359	max: 0.99999845/1.0	min: 1.5843718e-06	loss: 34404.04296875	train_loss: 34428.67239515592	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1360
Epoch: 1360	max: 0.9999943/1.0	min: 5.753416e-06	loss: 34404.34375	train_loss: 34428.65530259042	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1361
Epoch: 1361	max: 0.99999905/1.0	min: 1.0028373e-06	loss: 34404.0	train_loss: 34428.643744483925	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1362
Epoch: 1362	max: 0.9999987/1.0	min: 1.2551012e-06	loss: 34404.16015625	train_loss: 34428.61477252493	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1363
Epoch: 1363	max: 0.99999917/1.0	min: 8.421639e-07	loss: 34403.9765625	train_loss: 34428.59470176437	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1364
Epoch: 1364	max: 0.99999833/1.0	min: 1.6323672e-06	loss: 34404.12109375	train_loss: 34428.58232785984	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1365
Epoch: 1365	max: 0.9999988/1.0	min: 1.2291797e-06	loss: 34404.2109375	train_loss: 34428.56985282733	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1366
Epoch: 1366	max: 0.99999785/1.0	min: 2.1002218e-06	loss: 34404.4921875	train_loss: 34428.564154337764	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1367
Epoch: 1367	max: 0.99999905/1.0	min: 8.952313e-07	loss: 34404.09765625	train_loss: 34428.54683532299	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1368
Epoch: 1368	max: 0.9999988/1.0	min: 1.2119535e-06	loss: 34404.14453125	train_loss: 34428.51921044686	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1369
Epoch: 1369	max: 0.99999595/1.0	min: 4.028269e-06	loss: 34404.16796875	train_loss: 34428.502831583675	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1370
Epoch: 1370	max: 0.9999969/1.0	min: 3.1145335e-06	loss: 34404.171875	train_loss: 34428.48741367831	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1371
Epoch: 1371	max: 0.9999943/1.0	min: 5.7251023e-06	loss: 34403.96484375	train_loss: 34428.47099465425	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1372
Epoch: 1372	max: 0.9999981/1.0	min: 1.9227434e-06	loss: 34403.9453125	train_loss: 34428.5002772552	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1373
Epoch: 1373	max: 0.9999969/1.0	min: 3.0842368e-06	loss: 34404.13671875	train_loss: 34428.452099204136	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1374
Epoch: 1374	max: 0.9999976/1.0	min: 2.384222e-06	loss: 34403.84375	train_loss: 34428.496804065246	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1375
Epoch: 1375	max: 0.99999595/1.0	min: 4.0284804e-06	loss: 34403.9140625	train_loss: 34428.42459819769	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1376
Epoch: 1376	max: 0.99999726/1.0	min: 2.7273752e-06	loss: 34404.015625	train_loss: 34428.43232844048	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1377
Epoch: 1377	max: 0.9999989/1.0	min: 1.0495659e-06	loss: 34404.05078125	train_loss: 34428.40000764508	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1378
Epoch: 1378	max: 0.9999981/1.0	min: 1.9403442e-06	loss: 34403.8515625	train_loss: 34428.38917582141	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1379
Epoch: 1379	max: 0.9999975/1.0	min: 2.4880972e-06	loss: 34403.81640625	train_loss: 34428.36685653567	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1380
Epoch: 1380	max: 0.9999981/1.0	min: 1.8483139e-06	loss: 34404.00390625	train_loss: 34428.351475404124	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1381
Epoch: 1381	max: 0.9999968/1.0	min: 3.2163973e-06	loss: 34403.890625	train_loss: 34428.35106944057	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1382
Epoch: 1382	max: 0.99999905/1.0	min: 9.683322e-07	loss: 34403.90625	train_loss: 34428.333513331476	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1383
Epoch: 1383	max: 0.9999987/1.0	min: 1.2879799e-06	loss: 34403.9609375	train_loss: 34428.30006367676	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1384
Epoch: 1384	max: 0.9999988/1.0	min: 1.192859e-06	loss: 34403.89453125	train_loss: 34428.287890092746	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1385
Epoch: 1385	max: 0.9999994/1.0	min: 6.006834e-07	loss: 34403.96875	train_loss: 34428.296863387215	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1386
Epoch: 1386	max: 0.9999982/1.0	min: 1.812421e-06	loss: 34403.984375	train_loss: 34428.27084688158	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1387
Epoch: 1387	max: 0.9999969/1.0	min: 3.1492216e-06	loss: 34403.85546875	train_loss: 34428.23498709046	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1388
Epoch: 1388	max: 0.9999969/1.0	min: 3.1403204e-06	loss: 34403.7734375	train_loss: 34428.2194695087	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1389
Epoch: 1389	max: 0.99999917/1.0	min: 8.1397945e-07	loss: 34404.03125	train_loss: 34428.208854456985	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1390
Epoch: 1390	max: 0.9999988/1.0	min: 1.2109276e-06	loss: 34403.51171875	train_loss: 34428.19898117181	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1391
Epoch: 1391	max: 0.99999654/1.0	min: 3.478779e-06	loss: 34403.83984375	train_loss: 34428.18355165366	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1392
Epoch: 1392	max: 0.9999981/1.0	min: 1.8572122e-06	loss: 34403.82421875	train_loss: 34428.180424427876	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1393
Epoch: 1393	max: 0.99999833/1.0	min: 1.6327658e-06	loss: 34403.80078125	train_loss: 34428.14296449198	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1394
Epoch: 1394	max: 0.9999982/1.0	min: 1.8056047e-06	loss: 34403.77734375	train_loss: 34428.13315894804	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1395
Epoch: 1395	max: 0.99999857/1.0	min: 1.4031499e-06	loss: 34403.7578125	train_loss: 34428.149076686954	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1396
Epoch: 1396	max: 0.9999993/1.0	min: 7.446338e-07	loss: 34403.69921875	train_loss: 34428.1322294415	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1397
Epoch: 1397	max: 0.99999833/1.0	min: 1.660276e-06	loss: 34403.78125	train_loss: 34428.088813599345	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1398
Epoch: 1398	max: 0.99999905/1.0	min: 9.3397887e-07	loss: 34403.78125	train_loss: 34428.07995885204	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1399
Epoch: 1399	max: 0.9999993/1.0	min: 7.358933e-07	loss: 34403.984375	train_loss: 34428.10481359547	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1400
Epoch: 1400	max: 0.9999975/1.0	min: 2.4996368e-06	loss: 34403.75390625	train_loss: 34428.12603934411	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1401
Epoch: 1401	max: 0.99999714/1.0	min: 2.8550821e-06	loss: 34403.73046875	train_loss: 34428.07490874288	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1402
Epoch: 1402	max: 0.99999917/1.0	min: 7.924e-07	loss: 34403.5234375	train_loss: 34428.024344264835	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1403
Epoch: 1403	max: 0.99999774/1.0	min: 2.3242637e-06	loss: 34403.69921875	train_loss: 34428.03323578595	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1404
Epoch: 1404	max: 0.99999857/1.0	min: 1.3736767e-06	loss: 34403.5234375	train_loss: 34427.993214263595	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1405
Epoch: 1405	max: 0.9999988/1.0	min: 1.156838e-06	loss: 34404.0234375	train_loss: 34427.99091444862	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1406
Epoch: 1406	max: 0.99999905/1.0	min: 9.384673e-07	loss: 34403.59375	train_loss: 34428.0294611475	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1407
Epoch: 1407	max: 0.99999726/1.0	min: 2.7266365e-06	loss: 34403.6484375	train_loss: 34427.96627018689	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1408
Epoch: 1408	max: 0.999998/1.0	min: 2.016596e-06	loss: 34403.5390625	train_loss: 34427.94587910706	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1409
Epoch: 1409	max: 0.999997/1.0	min: 3.0260885e-06	loss: 34403.78125	train_loss: 34427.952525973924	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1410
Epoch: 1410	max: 0.99999917/1.0	min: 8.4710405e-07	loss: 34403.57421875	train_loss: 34427.97094820312	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1411
Epoch: 1411	max: 0.9999976/1.0	min: 2.4047442e-06	loss: 34403.62109375	train_loss: 34427.932908111914	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1412
Epoch: 1412	max: 0.99999964/1.0	min: 3.0482266e-07	loss: 34403.703125	train_loss: 34427.982513083734	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1413
Epoch: 1413	max: 0.9999969/1.0	min: 3.0768158e-06	loss: 34403.63671875	train_loss: 34427.89436044531	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1414
Epoch: 1414	max: 0.9999989/1.0	min: 1.0413773e-06	loss: 34403.61328125	train_loss: 34427.86620476821	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1415
Epoch: 1415	max: 0.999998/1.0	min: 2.0294103e-06	loss: 34403.61328125	train_loss: 34427.8637491484	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1416
Epoch: 1416	max: 0.9999981/1.0	min: 1.8701761e-06	loss: 34403.5546875	train_loss: 34427.913359926606	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1417
Epoch: 1417	max: 0.9999994/1.0	min: 6.4695774e-07	loss: 34403.359375	train_loss: 34427.860154024216	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1418
Epoch: 1418	max: 0.9999987/1.0	min: 1.2563371e-06	loss: 34403.5234375	train_loss: 34427.824903420355	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1419
Epoch: 1419	max: 0.99999905/1.0	min: 9.756487e-07	loss: 34403.484375	train_loss: 34427.81466868729	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1420
Epoch: 1420	max: 0.9999988/1.0	min: 1.2316051e-06	loss: 34403.328125	train_loss: 34427.80367476852	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1421
Epoch: 1421	max: 0.99999857/1.0	min: 1.3977356e-06	loss: 34403.578125	train_loss: 34427.79140150811	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1422
Epoch: 1422	max: 0.9999988/1.0	min: 1.1987881e-06	loss: 34403.64453125	train_loss: 34427.78396013332	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1423
Epoch: 1423	max: 0.9999989/1.0	min: 1.0757076e-06	loss: 34403.4296875	train_loss: 34427.77633198625	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1424
Epoch: 1424	max: 0.9999994/1.0	min: 6.0821696e-07	loss: 34403.38671875	train_loss: 34427.76241164607	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1425
Epoch: 1425	max: 0.999998/1.0	min: 1.9716517e-06	loss: 34403.55859375	train_loss: 34427.766851600245	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1426
Epoch: 1426	max: 0.99999726/1.0	min: 2.7235803e-06	loss: 34403.5078125	train_loss: 34427.726515081136	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1427
Epoch: 1427	max: 0.9999968/1.0	min: 3.1985765e-06	loss: 34403.4609375	train_loss: 34427.699514875974	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1428
Epoch: 1428	max: 0.99999774/1.0	min: 2.2090508e-06	loss: 34403.3359375	train_loss: 34427.69676216246	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1429
Epoch: 1429	max: 0.9999975/1.0	min: 2.467299e-06	loss: 34403.3671875	train_loss: 34427.69806182646	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1430
Epoch: 1430	max: 0.9999974/1.0	min: 2.5932115e-06	loss: 34403.30859375	train_loss: 34427.69159060294	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1431
Epoch: 1431	max: 0.99999833/1.0	min: 1.6603742e-06	loss: 34403.32421875	train_loss: 34427.68893079168	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1432
Epoch: 1432	max: 0.99999833/1.0	min: 1.7078405e-06	loss: 34403.35546875	train_loss: 34427.64473592531	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1433
Epoch: 1433	max: 0.99999857/1.0	min: 1.4660693e-06	loss: 34403.4375	train_loss: 34427.63456748189	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1434
Epoch: 1434	max: 0.99999857/1.0	min: 1.4716752e-06	loss: 34403.4765625	train_loss: 34427.61507881209	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1435
Epoch: 1435	max: 0.9999968/1.0	min: 3.2112423e-06	loss: 34403.30078125	train_loss: 34427.61035918339	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1436
Epoch: 1436	max: 0.9999993/1.0	min: 6.619437e-07	loss: 34403.234375	train_loss: 34427.60780243559	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1437
Epoch: 1437	max: 0.9999988/1.0	min: 1.2150307e-06	loss: 34403.4453125	train_loss: 34427.59363919469	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1438
Epoch: 1438	max: 0.99999845/1.0	min: 1.553917e-06	loss: 34403.46875	train_loss: 34427.59334452031	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1439
Epoch: 1439	max: 0.9999989/1.0	min: 1.0665782e-06	loss: 34403.4921875	train_loss: 34427.57254602533	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1440
Epoch: 1440	max: 0.99999785/1.0	min: 2.0931495e-06	loss: 34403.5	train_loss: 34427.557950208255	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1441
Epoch: 1441	max: 0.9999994/1.0	min: 6.1399766e-07	loss: 34403.26171875	train_loss: 34427.57381327031	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1442
Epoch: 1442	max: 0.9999994/1.0	min: 5.671812e-07	loss: 34403.2890625	train_loss: 34427.52056188452	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1443
Epoch: 1443	max: 0.99999917/1.0	min: 8.19641e-07	loss: 34403.3828125	train_loss: 34427.49905936455	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1444
Epoch: 1444	max: 0.999998/1.0	min: 2.0204113e-06	loss: 34403.3203125	train_loss: 34427.48898333953	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1445
Epoch: 1445	max: 0.9999982/1.0	min: 1.837232e-06	loss: 34403.203125	train_loss: 34427.47555218785	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1446
Epoch: 1446	max: 0.99999726/1.0	min: 2.7101537e-06	loss: 34403.17578125	train_loss: 34427.4776134569	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1447
Epoch: 1447	max: 0.9999982/1.0	min: 1.8217283e-06	loss: 34403.46875	train_loss: 34427.44235801437	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1448
Epoch: 1448	max: 0.999998/1.0	min: 1.9727918e-06	loss: 34403.44140625	train_loss: 34427.45017196597	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1449
Epoch: 1449	max: 0.99999845/1.0	min: 1.4948137e-06	loss: 34403.265625	train_loss: 34427.44931310386	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1450
Epoch: 1450	max: 0.99999845/1.0	min: 1.4968208e-06	loss: 34403.23828125	train_loss: 34427.46145475272	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1451
Epoch: 1451	max: 0.99999714/1.0	min: 2.8275842e-06	loss: 34403.20703125	train_loss: 34427.42406642899	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1452
Epoch: 1452	max: 0.99999833/1.0	min: 1.697837e-06	loss: 34403.109375	train_loss: 34427.431412966056	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1453
Epoch: 1453	max: 0.999997/1.0	min: 3.0044987e-06	loss: 34403.25390625	train_loss: 34427.37263776632	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1454
Epoch: 1454	max: 0.9999968/1.0	min: 3.2260186e-06	loss: 34403.14453125	train_loss: 34427.37827432104	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1455
Epoch: 1455	max: 0.9999989/1.0	min: 1.063025e-06	loss: 34403.1015625	train_loss: 34427.36463752632	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1456
Epoch: 1456	max: 0.99999833/1.0	min: 1.7277166e-06	loss: 34403.21484375	train_loss: 34427.348102374424	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1457
Epoch: 1457	max: 0.99999917/1.0	min: 8.8107055e-07	loss: 34403.27734375	train_loss: 34427.33451396631	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1458
Epoch: 1458	max: 0.99999857/1.0	min: 1.4110914e-06	loss: 34403.22265625	train_loss: 34427.31931815542	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1459
Epoch: 1459	max: 0.99999905/1.0	min: 9.649527e-07	loss: 34403.1640625	train_loss: 34427.29712612644	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1460
Epoch: 1460	max: 0.99999714/1.0	min: 2.8684005e-06	loss: 34403.4140625	train_loss: 34427.28323820528	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1461
Epoch: 1461	max: 0.99999785/1.0	min: 2.1885346e-06	loss: 34403.09375	train_loss: 34427.28361320141	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1462
Epoch: 1462	max: 0.99999607/1.0	min: 3.9116635e-06	loss: 34403.125	train_loss: 34427.31317063824	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1463
Epoch: 1463	max: 0.9999976/1.0	min: 2.3539405e-06	loss: 34403.0859375	train_loss: 34427.28890137263	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1464
Epoch: 1464	max: 0.9999964/1.0	min: 3.5800213e-06	loss: 34403.171875	train_loss: 34427.278682607146	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1465
Epoch: 1465	max: 0.99999905/1.0	min: 9.839181e-07	loss: 34403.21484375	train_loss: 34427.24873372275	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1466
Epoch: 1466	max: 0.9999982/1.0	min: 1.8109162e-06	loss: 34403.15625	train_loss: 34427.22188254831	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1467
Epoch: 1467	max: 0.99999905/1.0	min: 9.83904e-07	loss: 34403.1015625	train_loss: 34427.198497305835	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1468
Epoch: 1468	max: 0.99999523/1.0	min: 4.7154754e-06	loss: 34403.2578125	train_loss: 34427.195597497055	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1469
Epoch: 1469	max: 0.99999726/1.0	min: 2.7519243e-06	loss: 34403.0078125	train_loss: 34427.209775253934	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1470
Epoch: 1470	max: 0.9999995/1.0	min: 4.8084155e-07	loss: 34403.11328125	train_loss: 34427.196392488855	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1471
Epoch: 1471	max: 0.9999981/1.0	min: 1.9660213e-06	loss: 34403.19140625	train_loss: 34427.17352014431	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1472
Epoch: 1472	max: 0.9999987/1.0	min: 1.3500938e-06	loss: 34402.96484375	train_loss: 34427.14746638099	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1473
Epoch: 1473	max: 0.99999917/1.0	min: 7.944323e-07	loss: 34403.1875	train_loss: 34427.13238524635	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1474
Epoch: 1474	max: 0.9999968/1.0	min: 3.1924144e-06	loss: 34403.21875	train_loss: 34427.22099320265	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1475
Epoch: 1475	max: 0.99999857/1.0	min: 1.490077e-06	loss: 34402.890625	train_loss: 34427.12538999598	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1476
Epoch: 1476	max: 0.99999857/1.0	min: 1.47011e-06	loss: 34403.03515625	train_loss: 34427.10950951474	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1477
Epoch: 1477	max: 0.999997/1.0	min: 2.9883815e-06	loss: 34403.12890625	train_loss: 34427.0808907779	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1478
Epoch: 1478	max: 0.99999046/1.0	min: 9.487182e-06	loss: 34403.05859375	train_loss: 34427.08081723027	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1479
Epoch: 1479	max: 0.9999988/1.0	min: 1.2482924e-06	loss: 34402.828125	train_loss: 34427.109252098046	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1480
Epoch: 1480	max: 0.99999607/1.0	min: 3.8876683e-06	loss: 34402.8984375	train_loss: 34427.0920492111	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1481
Epoch: 1481	max: 0.9999968/1.0	min: 3.2550781e-06	loss: 34402.93359375	train_loss: 34427.07558857457	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1482
Epoch: 1482	max: 0.99999845/1.0	min: 1.6050582e-06	loss: 34403.07421875	train_loss: 34427.03446674099	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1483
Epoch: 1483	max: 0.99999857/1.0	min: 1.3971319e-06	loss: 34402.94140625	train_loss: 34427.008764748236	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1484
Epoch: 1484	max: 0.99999774/1.0	min: 2.297439e-06	loss: 34403.01171875	train_loss: 34427.008452654685	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1485
Epoch: 1485	max: 0.99999845/1.0	min: 1.6070018e-06	loss: 34403.28125	train_loss: 34427.0150917797	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1486
Epoch: 1486	max: 0.9999993/1.0	min: 7.58831e-07	loss: 34403.05859375	train_loss: 34427.009314903844	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1487
Epoch: 1487	max: 0.9999994/1.0	min: 6.3163e-07	loss: 34403.4296875	train_loss: 34427.000795959524	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1488
Epoch: 1488	max: 0.99999726/1.0	min: 2.7963301e-06	loss: 34403.1875	train_loss: 34427.03056000712	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1489
Epoch: 1489	max: 0.9999987/1.0	min: 1.3585744e-06	loss: 34402.78515625	train_loss: 34427.01384243776	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1490
Epoch: 1490	max: 0.9999987/1.0	min: 1.2773231e-06	loss: 34403.0859375	train_loss: 34426.94175511737	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1491
Epoch: 1491	max: 0.9999993/1.0	min: 7.1530735e-07	loss: 34402.76953125	train_loss: 34426.93384052165	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1492
Epoch: 1492	max: 0.99999654/1.0	min: 3.4901473e-06	loss: 34402.67578125	train_loss: 34427.03060355506	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1493
Epoch: 1493	max: 0.9999981/1.0	min: 1.933908e-06	loss: 34402.87109375	train_loss: 34426.908274011366	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1494
Epoch: 1494	max: 0.99999857/1.0	min: 1.4850054e-06	loss: 34403.03515625	train_loss: 34426.885225539605	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1495
Epoch: 1495	max: 0.99999845/1.0	min: 1.526404e-06	loss: 34403.08203125	train_loss: 34426.8738851728	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1496
Epoch: 1496	max: 0.99999607/1.0	min: 3.8915637e-06	loss: 34403.00390625	train_loss: 34426.85776033925	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1497
Epoch: 1497	max: 0.99999857/1.0	min: 1.400897e-06	loss: 34402.984375	train_loss: 34426.844171447265	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1498
Epoch: 1498	max: 0.99999595/1.0	min: 3.999037e-06	loss: 34402.81640625	train_loss: 34426.84006052196	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1499
Epoch: 1499	max: 0.99999213/1.0	min: 7.875559e-06	loss: 34403.03515625	train_loss: 34426.81480658909	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1500
Epoch: 1500	max: 0.9999968/1.0	min: 3.2355642e-06	loss: 34402.8828125	train_loss: 34426.817222048034	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1501
Epoch: 1501	max: 0.99999726/1.0	min: 2.7583776e-06	loss: 34402.796875	train_loss: 34426.792863751085	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1502
Epoch: 1502	max: 0.9999968/1.0	min: 3.2409564e-06	loss: 34402.74609375	train_loss: 34426.791387959864	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1503
Epoch: 1503	max: 0.99999726/1.0	min: 2.7854464e-06	loss: 34402.796875	train_loss: 34426.78369884569	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1504
Epoch: 1504	max: 0.9999981/1.0	min: 1.927074e-06	loss: 34402.85546875	train_loss: 34426.770793656324	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1505
Epoch: 1505	max: 0.99999654/1.0	min: 3.4777804e-06	loss: 34402.91015625	train_loss: 34426.74953597253	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1506
Epoch: 1506	max: 0.99999726/1.0	min: 2.7152191e-06	loss: 34402.78515625	train_loss: 34426.74613487861	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1507
Epoch: 1507	max: 0.99999595/1.0	min: 3.9962e-06	loss: 34402.87890625	train_loss: 34426.72139335981	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1508
Epoch: 1508	max: 0.9999963/1.0	min: 3.7164498e-06	loss: 34402.75	train_loss: 34426.742127016754	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1509
Epoch: 1509	max: 0.9999976/1.0	min: 2.3589612e-06	loss: 34402.7890625	train_loss: 34426.70927058172	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1510
Epoch: 1510	max: 0.999997/1.0	min: 3.028323e-06	loss: 34402.8671875	train_loss: 34426.71292570528	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1511
Epoch: 1511	max: 0.99999785/1.0	min: 2.1263875e-06	loss: 34402.93359375	train_loss: 34426.67751203859	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1512
Epoch: 1512	max: 0.9999987/1.0	min: 1.257441e-06	loss: 34402.7109375	train_loss: 34426.66605167301	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1513
Epoch: 1513	max: 0.9999974/1.0	min: 2.587389e-06	loss: 34402.85546875	train_loss: 34426.64560494859	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1514
Epoch: 1514	max: 0.99999833/1.0	min: 1.612699e-06	loss: 34402.87109375	train_loss: 34426.65103344095	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1515
Epoch: 1515	max: 0.9999964/1.0	min: 3.5423575e-06	loss: 34402.671875	train_loss: 34426.623173405955	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1516
Epoch: 1516	max: 0.99999833/1.0	min: 1.6525545e-06	loss: 34402.6640625	train_loss: 34426.60591390669	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1517
Epoch: 1517	max: 0.9999988/1.0	min: 1.1803332e-06	loss: 34402.60546875	train_loss: 34426.60012638579	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1518
Epoch: 1518	max: 0.9999974/1.0	min: 2.641024e-06	loss: 34402.74609375	train_loss: 34426.59638803729	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1519
Epoch: 1519	max: 0.9999987/1.0	min: 1.2759632e-06	loss: 34403.03125	train_loss: 34426.57432229732	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1520
Epoch: 1520	max: 0.9999982/1.0	min: 1.8375036e-06	loss: 34403.078125	train_loss: 34426.59427160752	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1521
Epoch: 1521	max: 0.9999989/1.0	min: 1.1175853e-06	loss: 34402.6015625	train_loss: 34426.58982487923	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1522
Epoch: 1522	max: 0.99999774/1.0	min: 2.3179239e-06	loss: 34402.98046875	train_loss: 34426.5432218119	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1523
Epoch: 1523	max: 0.9999974/1.0	min: 2.5999495e-06	loss: 34402.78515625	train_loss: 34426.53242047179	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1524
Epoch: 1524	max: 0.99999475/1.0	min: 5.229947e-06	loss: 34402.7734375	train_loss: 34426.50958635266	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1525
Epoch: 1525	max: 0.9999988/1.0	min: 1.2124264e-06	loss: 34402.9609375	train_loss: 34426.50310641955	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1526
Epoch: 1526	max: 0.9999989/1.0	min: 1.1269083e-06	loss: 34402.90625	train_loss: 34426.524324426326	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1527
Epoch: 1527	max: 0.99999785/1.0	min: 2.1667538e-06	loss: 34402.75390625	train_loss: 34426.479420696305	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1528
Epoch: 1528	max: 0.99999857/1.0	min: 1.4531821e-06	loss: 34402.80078125	train_loss: 34426.48992542658	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1529
Epoch: 1529	max: 0.99999535/1.0	min: 4.6994846e-06	loss: 34402.7734375	train_loss: 34426.48306856187	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1530
Epoch: 1530	max: 0.9999949/1.0	min: 5.1064476e-06	loss: 34402.671875	train_loss: 34426.438975791214	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1531
Epoch: 1531	max: 0.9999962/1.0	min: 3.838831e-06	loss: 34402.58984375	train_loss: 34426.42508351526	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1532
Epoch: 1532	max: 0.9999945/1.0	min: 5.5062196e-06	loss: 34402.71875	train_loss: 34426.46014008888	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1533
Epoch: 1533	max: 0.999995/1.0	min: 5.014668e-06	loss: 34402.63671875	train_loss: 34426.442698656014	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1534
Epoch: 1534	max: 0.999998/1.0	min: 2.0458324e-06	loss: 34402.53515625	train_loss: 34426.413439764496	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1535
Epoch: 1535	max: 0.9999982/1.0	min: 1.7997236e-06	loss: 34402.546875	train_loss: 34426.3683279721	saved as: categorical_crossentropy_hidden-softmax_output-softmax_above_1536
