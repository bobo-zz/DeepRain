import matplotlib.pyplot as plt
import numpy as np
import sample_bundle
from eval_stored_network import load_model
from evaluate_realData import display_one_img



#Alle Netze laden und lernkurve (auf ein bsp Bild) anzeigen
#letztes Bild auf alle testdaten laufen lassen und MSE berechnen für letztes Bild und für ausgabe
    # Schlechteste Werte anschauen und auswerten.
def load_and_eval_network(testdata, testlabel, learncurvesample, learncurvelabel, network_path_prefix, networkpath_postfix = "", max_number_networks=100, plotit=True):
    learncurve = []
    for i in range(1, max_number_networks+1):
        net_model = load_model(network_path_prefix+str(i)+networkpath_postfix+".h5", verbose=True)
        prediction = net_model.predict(np.expand_dims(learncurvesample, axis=0))
        MSE = (np.square(learncurvelabel.flatten() - prediction)).mean(axis=1)
        learncurve.append(MSE)

    lbl, base = compare_mse(net_model, testdata, testlabel)

    if plotit:
        plt.plot(learncurve)
        plt.xlabel("epoch")
        plt.ylabel("mse")
        plt.title("learning curve")
        plt.show()
    print("learningcurve =",learncurve)
    print("prediction_loss =",lbl)
    print("baseline_loss =",base)

    return net_model, (learncurve, lbl, base)

def compare_mse(net_model, testdata, testlabel):
    values_on_label = []
    values_baseline = []
    for i in range(len(testdata)):
        prediction = net_model.predict(np.expand_dims(testdata[i], axis=0))
        MSE = (np.square(testlabel[i].flatten() - prediction)).mean(axis=1)
        Baseline = (np.square(testlabel[i].flatten() - testdata[i][..., 4].flatten())).mean(axis=0)
        values_on_label.append(MSE)
        values_baseline.append(Baseline)
    return values_on_label, values_baseline

def default_values_UNet64_output_2016():
    learningcurve = [0.0115894, 0.00958822, 0.00796455, 0.00732153, 0.00727009, 0.00711318, 0.00692073, 0.00675846,
                     0.00665379, 0.00645629, 0.00637198, 0.00650981, 0.0064181, 0.00635487, 0.00624361, 0.00618663,
                     0.00612047, 0.00611733, 0.00620965, 0.00614361, 0.00616507, 0.00612534, 0.00606998, 0.00603275,
                     0.00605507, 0.00602762, 0.00608261, 0.00606057, 0.00606904, 0.00604447, 0.00601669, 0.00601813,
                     0.00598835, 0.00599038, 0.00603436, 0.00598364, 0.00598707, 0.00600294, 0.00601596, 0.00600256,
                     0.0059786, 0.00595138, 0.00595035, 0.00595839, 0.00597264, 0.00595936, 0.00598617, 0.00596159,
                     0.00599627, 0.00592671, 0.00591463, 0.00597174, 0.00601303, 0.00591218, 0.00599138, 0.00586511,
                     0.00585967, 0.0058672, 0.00586569, 0.00587476, 0.00590325, 0.00586857, 0.00587302, 0.00583622,
                     0.00586059, 0.00585119, 0.00583102, 0.00580262, 0.00583791, 0.00588642, 0.00589478, 0.00580198,
                     0.00578195, 0.00577411, 0.00583903, 0.00592595, 0.00573809, 0.00575651, 0.00580867, 0.0057976,
                     0.00574949, 0.00574277, 0.00572543, 0.0057714, 0.00575325, 0.00593839, 0.00577013, 0.00578963,
                     0.00575294, 0.005784, 0.00582843, 0.0057558, 0.00588208, 0.00589379, 0.00601915, 0.00569832,
                     0.00571483, 0.00572478, 0.00578767, 0.00569442]

    prediction_loss = [1.86470236e-06, 2.8264612e-06, 2.57799939e-06, 2.24289355e-05, 0.00015157, 0.00026531,
                       0.00033583, 0.00037115, 0.0004648, 0.0007185, 0.00069467, 0.00075835, 0.00068323, 0.00084506,
                       0.00081046, 0.00067252, 0.00044094, 0.00037288, 0.00024517, 0.00016385, 0.00019954, 0.00014589,
                       9.01579817e-05, 2.38962804e-09, 8.98763642e-07, 1.22362092e-05, 3.10096528e-05, 3.37138407e-06,
                       2.8856611e-06, 5.61989257e-05, 1.71629722e-05, 5.08496547e-09, 4.94259982e-06, 3.37298162e-05,
                       8.39688232e-05, 0.00017017, 0.00014647, 0.00017797, 0.00022459, 0.00023736, 0.0002829,
                       0.00024595, 0.00019492, 5.99015221e-05, 3.99775451e-05, 4.63488214e-05, 9.46813496e-06,
                       2.8748552e-05, 7.44204943e-05, 5.18611243e-06]

    baseline_loss = [7.396494136870434e-07, 2.2677575932333715e-06, 3.161344194540561e-06, 3.26459474721261e-05,
                     0.0002704300929930796, 0.0005964502835447904, 0.0006755326977604766, 0.0008103178465013457,
                     0.001028285395040369, 0.0014358960495963091, 0.0013702099252691272, 0.0013215620194156094,
                     0.0014910693903787005, 0.0014552545895809305, 0.0016509913554882737, 0.001446596561418685,
                     0.0009419228782199154, 0.0006850129757785468, 0.0004638991013071895, 0.000308084630911188,
                     0.0003598450716070742, 0.000374457840734333, 0.00034752258746635915, 0.0, 4.8997080449827e-06,
                     1.4049584294502115e-05, 8.270181540753557e-05, 7.411512399077278e-06, 3.195135284505959e-06,
                     4.742391748366013e-05, 5.453881920415225e-05, 1.87728277585544e-06, 9.476523452518261e-06,
                     5.482041162053057e-05, 0.00013154871323529412, 0.0002496222907054979, 0.00020320459678969626,
                     0.00028636822376009233, 0.00028379259179161864, 0.0003579677888312187, 0.0004275173611111111,
                     0.00031476400302768166, 0.00024243229767397157, 8.324622741253364e-05, 5.39718798058439e-05,
                     8.502964604959632e-05, 1.7590139609765473e-05, 5.9633764657823906e-05, 0.00017642328070934256,
                     8.902074923106497e-06]
    statistical_evaluation_lr_baseline(baseline_loss, prediction_loss, learningcurve)
    samplebundle = sample_bundle.load_Sample_Bundle("RegenTage2016")
    samplebundle.normalize()
    blul = (([0, 63]), ([35, 35], "blueviolet"))
    purl = (([0, 63]), ([41, 41], "purple"))
    skyl = (([3, 32]), ([35, 17], "skyblue"))
    orl = (([32, 32]), ([0, 63], "orange"))

    net_model = load_model("C:\\Users\\TopSecret!\\Documents\\aMSI1\\Teamprojekt\\DeepRain\\NetworkTypes\\UNet64_output3x3\\UNet64_outputexpansed_2016_100.h5", verbose=False)
    data, label = samplebundle.get_all_data_label(channels_Last=True)
    prediction = net_model.predict(np.expand_dims(data[14], axis=0))
    plt.imshow(prediction.reshape((64, 64)).T, cmap="gray", vmax=0.85)
    plt.plot(blul[0], *blul[1])
    plt.plot(purl[0], *purl[1])
    plt.plot(skyl[0], *skyl[1])
    plt.plot(orl[0], *orl[1])
    plt.title("prediction")
    plt.show()

    return

def default_values_UNet64_2016():
    learningcurve = [0.0125825, 0.01090752, 0.00996938, 0.00877155, 0.00785926, 0.00749076, 0.00738954, 0.00710216,
                     0.00695553, 0.00685954, 0.00685263, 0.00683551, 0.0067013, 0.00669573, 0.00663494, 0.0065361,
                     0.00656253, 0.00655892, 0.00641627, 0.00643257, 0.00642143, 0.00643228, 0.00638859, 0.00635681,
                     0.00639316, 0.00631695, 0.0062926, 0.00633417, 0.00622689, 0.00616801, 0.00625138, 0.00621941,
                     0.00615199, 0.00620083, 0.00616311, 0.00617193, 0.00621265, 0.00614376, 0.0061507, 0.00614031,
                     0.00610141, 0.00613152, 0.00613031, 0.00610272, 0.00609479, 0.0061553, 0.0061067, 0.00605778,
                     0.00606069, 0.00603255, 0.00605208, 0.00601227, 0.00600995, 0.00601041, 0.00601996, 0.0060082,
                     0.00602065, 0.00619004, 0.00603388, 0.00603091, 0.00607781, 0.00611581, 0.00606192, 0.00599001,
                     0.00598812, 0.00596377, 0.00595005, 0.00597897, 0.00595829, 0.00594891, 0.00595861, 0.00597969,
                     0.00591869, 0.00593133, 0.00592642, 0.00592538, 0.00590671, 0.00598633, 0.0060014, 0.00590481,
                     0.00590337, 0.00598106, 0.00590425, 0.00589903, 0.00587542, 0.00588902, 0.0059049, 0.00590722,
                     0.00590535, 0.00589348, 0.00586809, 0.00586199, 0.00587707, 0.00585575, 0.00584643, 0.00583368,
                     0.00580768, 0.00581735, 0.00581284, 0.00581762]

    prediction_loss = [2.05482041e-06, 2.16494586e-06, 2.3332747e-06, 2.07652893e-05, 0.00015295, 0.00028465,
                       0.00031767, 0.00037503, 0.00047629, 0.00070817, 0.00069556, 0.00071058, 0.00068717, 0.00085751,
                       0.00080836, 0.00068803, 0.0004593, 0.00038036, 0.00023775, 0.00016827, 0.00018715, 0.0001683,
                       9.01244588e-05, 1.11477099e-08, 6.33360328e-07, 1.02075804e-05, 3.32653464e-05, 3.32339511e-06,
                       2.88497277e-06, 5.62943246e-05, 1.4668768e-05, 5.08214763e-08, 5.38758653e-06, 3.22183944e-05,
                       8.69566071e-05, 0.00017487, 0.00013233, 0.00017856, 0.00021881, 0.0002324, 0.00027731,
                       0.00024965, 0.00020651, 5.31775661e-05, 4.04651739e-05, 4.03603105e-05, 1.04818476e-05,
                       2.91035737e-05, 7.37178008e-05, 5.13091154e-06]

    baseline_loss = [7.396494136870434e-07, 2.2677575932333715e-06, 3.161344194540561e-06, 3.26459474721261e-05,
                     0.0002704300929930796, 0.0005964502835447904, 0.0006755326977604766, 0.0008103178465013457,
                     0.001028285395040369, 0.0014358960495963091, 0.0013702099252691272, 0.0013215620194156094,
                     0.0014910693903787005, 0.0014552545895809305, 0.0016509913554882737, 0.001446596561418685,
                     0.0009419228782199154, 0.0006850129757785468, 0.0004638991013071895, 0.000308084630911188,
                     0.0003598450716070742, 0.000374457840734333, 0.00034752258746635915, 0.0, 4.8997080449827e-06,
                     1.4049584294502115e-05, 8.270181540753557e-05, 7.411512399077278e-06, 3.195135284505959e-06,
                     4.742391748366013e-05, 5.453881920415225e-05, 1.87728277585544e-06, 9.476523452518261e-06,
                     5.482041162053057e-05, 0.00013154871323529412, 0.0002496222907054979, 0.00020320459678969626,
                     0.00028636822376009233, 0.00028379259179161864, 0.0003579677888312187, 0.0004275173611111111,
                     0.00031476400302768166, 0.00024243229767397157, 8.324622741253364e-05, 5.39718798058439e-05,
                     8.502964604959632e-05, 1.7590139609765473e-05, 5.9633764657823906e-05, 0.00017642328070934256,
                     8.902074923106497e-06]

    learningcurve = [0.00876916, 0.00763574, 0.00775013, 0.00728725, 0.00706771, 0.00690446, 0.00679859, 0.00685016,
                     0.0083208, 0.00674477, 0.00669052, 0.0065954, 0.00673142, 0.00698619, 0.00660383, 0.00655915,
                     0.00652131, 0.00663586, 0.00654554, 0.00680054, 0.00727, 0.00677988, 0.00748705, 0.00646014,
                     0.00644975, 0.00646124, 0.00648091, 0.00649791, 0.0063754, 0.0064263, 0.00636619, 0.00636916,
                     0.00642287, 0.00659642, 0.00636527, 0.006555, 0.00633962, 0.00630069, 0.00631354, 0.0062959,
                     0.00634053, 0.00628647, 0.00631652, 0.00621621, 0.00622429, 0.00662466, 0.00626726, 0.00645528,
                     0.00620124, 0.00660065, 0.00620791, 0.00617543, 0.00616647, 0.00620594, 0.00616584, 0.00615409,
                     0.0061273, 0.0061772, 0.00614339, 0.0061334, 0.00616816, 0.00613709, 0.00609759, 0.00638806,
                     0.00613235, 0.00612941, 0.00612209, 0.00615991, 0.006145, 0.00615401, 0.00635393, 0.00611096,
                     0.00615352, 0.0060822, 0.00610717, 0.00606298, 0.00606257, 0.00604071, 0.00606661, 0.00603798]
    prediction_loss = [1.71875397e-06, 1.65552961e-06, 2.51839882e-06, 2.19947249e-05, 0.00014833, 0.00027089,
                       0.00031949, 0.00036634, 0.00046509, 0.00072178, 0.00068672, 0.00071651, 0.00068261, 0.00081278,
                       0.0008001, 0.00070923, 0.00047983, 0.00037889, 0.00024699, 0.00016343, 0.00020333, 0.00018502,
                       0.00010807, 4.36043915e-07, 6.65378881e-07, 1.43982297e-05, 3.11619439e-05, 3.33887501e-06,
                       2.96609177e-06, 5.79021047e-05, 1.96858796e-05, 1.84167894e-07, 4.46581796e-06, 2.94263092e-05,
                       8.62778783e-05, 0.00016357, 0.0001413, 0.00017918, 0.00021462, 0.00023868, 0.00028542,
                       0.00024291, 0.00019439, 5.60679626e-05, 4.105311e-05, 4.99470187e-05, 1.29807418e-05,
                       3.14061303e-05, 8.14463202e-05, 5.68513118e-06]
    baseline_loss = [7.396494136870434e-07, 2.2677575932333715e-06, 3.161344194540561e-06, 3.26459474721261e-05,
                     0.0002704300929930796, 0.0005964502835447904, 0.0006755326977604766, 0.0008103178465013457,
                     0.001028285395040369, 0.0014358960495963091, 0.0013702099252691272, 0.0013215620194156094,
                     0.0014910693903787005, 0.0014552545895809305, 0.0016509913554882737, 0.001446596561418685,
                     0.0009419228782199154, 0.0006850129757785468, 0.0004638991013071895, 0.000308084630911188,
                     0.0003598450716070742, 0.000374457840734333, 0.00034752258746635915, 0.0, 4.8997080449827e-06,
                     1.4049584294502115e-05, 8.270181540753557e-05, 7.411512399077278e-06, 3.195135284505959e-06,
                     4.742391748366013e-05, 5.453881920415225e-05, 1.87728277585544e-06, 9.476523452518261e-06,
                     5.482041162053057e-05, 0.00013154871323529412, 0.0002496222907054979, 0.00020320459678969626,
                     0.00028636822376009233, 0.00028379259179161864, 0.0003579677888312187, 0.0004275173611111111,
                     0.00031476400302768166, 0.00024243229767397157, 8.324622741253364e-05, 5.39718798058439e-05,
                     8.502964604959632e-05, 1.7590139609765473e-05, 5.9633764657823906e-05, 0.00017642328070934256,
                     8.902074923106497e-06]

    statistical_evaluation_lr_baseline(baseline_loss, prediction_loss, learningcurve)
    samplebundle = sample_bundle.load_Sample_Bundle("RegenTage2016")
    samplebundle.normalize()
    blul = (([0, 63]), ([35, 35], "blueviolet"))
    purl = (([0, 63]), ([41, 41], "purple"))
    skyl = (([3, 32]), ([35, 17], "skyblue"))
    orl = (([32, 32]), ([0, 63], "orange"))
    display_one_img(samplebundle, 14, [[],[],[],[],[skyl,purl,blul,orl],[skyl,purl,blul,orl]], vmax=0.85)

    #net_model = load_model("C:\\Users\\TopSecret!\\Documents\\aMSI1\\Teamprojekt\\DeepRain\\NetworkTypes\\UNet64\\UNet64_2016_100.h5", verbose=False)
    net_model = load_model(
        "C:\\Users\\TopSecret!\\Documents\\aMSI1\\Teamprojekt\\DeepRain\\NetworkTypes\\UNet64_sigmoid_tanh_2016_80.h5",
        verbose=False)

    data, label = samplebundle.get_all_data_label(channels_Last=True)
    prediction = net_model.predict(np.expand_dims(data[14], axis=0))
    plt.imshow(prediction.reshape((64, 64)).T, cmap="gray", vmax=0.85)
    plt.plot(blul[0], *blul[1])
    plt.plot(purl[0], *purl[1])
    plt.plot(skyl[0], *skyl[1])
    plt.plot(orl[0], *orl[1])
    plt.title("prediction")
    plt.show()
    return

def all_learnrates_all_loss():
    learningcurve_UNET64 = [0.0125825, 0.01090752, 0.00996938, 0.00877155, 0.00785926, 0.00749076, 0.00738954, 0.00710216,
                     0.00695553, 0.00685954, 0.00685263, 0.00683551, 0.0067013, 0.00669573, 0.00663494, 0.0065361,
                     0.00656253, 0.00655892, 0.00641627, 0.00643257, 0.00642143, 0.00643228, 0.00638859, 0.00635681,
                     0.00639316, 0.00631695, 0.0062926, 0.00633417, 0.00622689, 0.00616801, 0.00625138, 0.00621941,
                     0.00615199, 0.00620083, 0.00616311, 0.00617193, 0.00621265, 0.00614376, 0.0061507, 0.00614031,
                     0.00610141, 0.00613152, 0.00613031, 0.00610272, 0.00609479, 0.0061553, 0.0061067, 0.00605778,
                     0.00606069, 0.00603255, 0.00605208, 0.00601227, 0.00600995, 0.00601041, 0.00601996, 0.0060082,
                     0.00602065, 0.00619004, 0.00603388, 0.00603091, 0.00607781, 0.00611581, 0.00606192, 0.00599001,
                     0.00598812, 0.00596377, 0.00595005, 0.00597897, 0.00595829, 0.00594891, 0.00595861, 0.00597969,
                     0.00591869, 0.00593133, 0.00592642, 0.00592538, 0.00590671, 0.00598633, 0.0060014, 0.00590481,
                     0.00590337, 0.00598106, 0.00590425, 0.00589903, 0.00587542, 0.00588902, 0.0059049, 0.00590722,
                     0.00590535, 0.00589348, 0.00586809, 0.00586199, 0.00587707, 0.00585575, 0.00584643, 0.00583368,
                     0.00580768, 0.00581735, 0.00581284, 0.00581762]
    prediction_loss_UNET64 = [2.05482041e-06, 2.16494586e-06, 2.3332747e-06, 2.07652893e-05, 0.00015295, 0.00028465,
                       0.00031767, 0.00037503, 0.00047629, 0.00070817, 0.00069556, 0.00071058, 0.00068717, 0.00085751,
                       0.00080836, 0.00068803, 0.0004593, 0.00038036, 0.00023775, 0.00016827, 0.00018715, 0.0001683,
                       9.01244588e-05, 1.11477099e-08, 6.33360328e-07, 1.02075804e-05, 3.32653464e-05, 3.32339511e-06,
                       2.88497277e-06, 5.62943246e-05, 1.4668768e-05, 5.08214763e-08, 5.38758653e-06, 3.22183944e-05,
                       8.69566071e-05, 0.00017487, 0.00013233, 0.00017856, 0.00021881, 0.0002324, 0.00027731,
                       0.00024965, 0.00020651, 5.31775661e-05, 4.04651739e-05, 4.03603105e-05, 1.04818476e-05,
                       2.91035737e-05, 7.37178008e-05, 5.13091154e-06]
    learningcurve_UNET64OUT = [0.0115894, 0.00958822, 0.00796455, 0.00732153, 0.00727009, 0.00711318, 0.00692073, 0.00675846,
                     0.00665379, 0.00645629, 0.00637198, 0.00650981, 0.0064181, 0.00635487, 0.00624361, 0.00618663,
                     0.00612047, 0.00611733, 0.00620965, 0.00614361, 0.00616507, 0.00612534, 0.00606998, 0.00603275,
                     0.00605507, 0.00602762, 0.00608261, 0.00606057, 0.00606904, 0.00604447, 0.00601669, 0.00601813,
                     0.00598835, 0.00599038, 0.00603436, 0.00598364, 0.00598707, 0.00600294, 0.00601596, 0.00600256,
                     0.0059786, 0.00595138, 0.00595035, 0.00595839, 0.00597264, 0.00595936, 0.00598617, 0.00596159,
                     0.00599627, 0.00592671, 0.00591463, 0.00597174, 0.00601303, 0.00591218, 0.00599138, 0.00586511,
                     0.00585967, 0.0058672, 0.00586569, 0.00587476, 0.00590325, 0.00586857, 0.00587302, 0.00583622,
                     0.00586059, 0.00585119, 0.00583102, 0.00580262, 0.00583791, 0.00588642, 0.00589478, 0.00580198,
                     0.00578195, 0.00577411, 0.00583903, 0.00592595, 0.00573809, 0.00575651, 0.00580867, 0.0057976,
                     0.00574949, 0.00574277, 0.00572543, 0.0057714, 0.00575325, 0.00593839, 0.00577013, 0.00578963,
                     0.00575294, 0.005784, 0.00582843, 0.0057558, 0.00588208, 0.00589379, 0.00601915, 0.00569832,
                     0.00571483, 0.00572478, 0.00578767, 0.00569442]
    prediction_loss_UNET64OUT = [1.86470236e-06, 2.8264612e-06, 2.57799939e-06, 2.24289355e-05, 0.00015157, 0.00026531,
                       0.00033583, 0.00037115, 0.0004648, 0.0007185, 0.00069467, 0.00075835, 0.00068323, 0.00084506,
                       0.00081046, 0.00067252, 0.00044094, 0.00037288, 0.00024517, 0.00016385, 0.00019954, 0.00014589,
                       9.01579817e-05, 2.38962804e-09, 8.98763642e-07, 1.22362092e-05, 3.10096528e-05, 3.37138407e-06,
                       2.8856611e-06, 5.61989257e-05, 1.71629722e-05, 5.08496547e-09, 4.94259982e-06, 3.37298162e-05,
                       8.39688232e-05, 0.00017017, 0.00014647, 0.00017797, 0.00022459, 0.00023736, 0.0002829,
                       0.00024595, 0.00019492, 5.99015221e-05, 3.99775451e-05, 4.63488214e-05, 9.46813496e-06,
                       2.8748552e-05, 7.44204943e-05, 5.18611243e-06]
    baseline_loss = [7.396494136870434e-07, 2.2677575932333715e-06, 3.161344194540561e-06, 3.26459474721261e-05,
                     0.0002704300929930796, 0.0005964502835447904, 0.0006755326977604766, 0.0008103178465013457,
                     0.001028285395040369, 0.0014358960495963091, 0.0013702099252691272, 0.0013215620194156094,
                     0.0014910693903787005, 0.0014552545895809305, 0.0016509913554882737, 0.001446596561418685,
                     0.0009419228782199154, 0.0006850129757785468, 0.0004638991013071895, 0.000308084630911188,
                     0.0003598450716070742, 0.000374457840734333, 0.00034752258746635915, 0.0, 4.8997080449827e-06,
                     1.4049584294502115e-05, 8.270181540753557e-05, 7.411512399077278e-06, 3.195135284505959e-06,
                     4.742391748366013e-05, 5.453881920415225e-05, 1.87728277585544e-06, 9.476523452518261e-06,
                     5.482041162053057e-05, 0.00013154871323529412, 0.0002496222907054979, 0.00020320459678969626,
                     0.00028636822376009233, 0.00028379259179161864, 0.0003579677888312187, 0.0004275173611111111,
                     0.00031476400302768166, 0.00024243229767397157, 8.324622741253364e-05, 5.39718798058439e-05,
                     8.502964604959632e-05, 1.7590139609765473e-05, 5.9633764657823906e-05, 0.00017642328070934256,
                     8.902074923106497e-06]
    learningcurve_UNET642x2 = [0.00967205, 0.00896119, 0.00926007, 0.00798338, 0.00723953, 0.00690768, 0.00678629, 0.00665248,
                     0.0066625, 0.0066672, 0.00660023, 0.00659717, 0.00655708, 0.00656867, 0.00650326, 0.00645401,
                     0.00649371, 0.00640632, 0.00652234, 0.00643106, 0.00632002, 0.00636248, 0.00626922, 0.0062742,
                     0.00629147, 0.00627027, 0.0061941, 0.0061659, 0.00628205, 0.00625928, 0.00616971, 0.00614939,
                     0.00615451, 0.00615132, 0.00610609, 0.00611994, 0.00614144, 0.00622396, 0.00618354, 0.00616882,
                     0.00612461, 0.00617566, 0.00608759, 0.00605491, 0.00605445, 0.00612416, 0.00610076, 0.0060088,
                     0.00602393, 0.00606507, 0.00604228, 0.00604735, 0.00601087, 0.00600468, 0.00595286]
    prediction_loss_UNET642x2 = [1.57250867e-06, 1.61311602e-06, 2.53408344e-06, 2.22041847e-05, 0.00016465, 0.00025573,
                       0.00032877, 0.00036987, 0.00047564, 0.0007192, 0.00068206, 0.0007475, 0.00070098, 0.00083317,
                       0.00080548, 0.00068472, 0.00046304, 0.00037621, 0.00023368, 0.00015603, 0.00019727, 0.00018637,
                       8.90839827e-05, 2.60804133e-08, 5.62206454e-07, 1.19926273e-05, 3.41343549e-05, 3.49273355e-06,
                       2.886474e-06, 5.88146232e-05, 1.68414924e-05, 1.42535049e-08, 5.18690792e-06, 3.14320126e-05,
                       8.76532116e-05, 0.00017009, 0.00014126, 0.00017007, 0.00022906, 0.00022927, 0.00026855,
                       0.00023144, 0.00019113, 4.95220344e-05, 4.10555509e-05, 4.67487905e-05, 1.05572088e-05,
                       3.12320396e-05, 7.47326402e-05, 5.23922092e-06]
    baseline_loss = [7.396494136870434e-07, 2.2677575932333715e-06, 3.161344194540561e-06, 3.26459474721261e-05,
                     0.0002704300929930796, 0.0005964502835447904, 0.0006755326977604766, 0.0008103178465013457,
                     0.001028285395040369, 0.0014358960495963091, 0.0013702099252691272, 0.0013215620194156094,
                     0.0014910693903787005, 0.0014552545895809305, 0.0016509913554882737, 0.001446596561418685,
                     0.0009419228782199154, 0.0006850129757785468, 0.0004638991013071895, 0.000308084630911188,
                     0.0003598450716070742, 0.000374457840734333, 0.00034752258746635915, 0.0, 4.8997080449827e-06,
                     1.4049584294502115e-05, 8.270181540753557e-05, 7.411512399077278e-06, 3.195135284505959e-06,
                     4.742391748366013e-05, 5.453881920415225e-05, 1.87728277585544e-06, 9.476523452518261e-06,
                     5.482041162053057e-05, 0.00013154871323529412, 0.0002496222907054979, 0.00020320459678969626,
                     0.00028636822376009233, 0.00028379259179161864, 0.0003579677888312187, 0.0004275173611111111,
                     0.00031476400302768166, 0.00024243229767397157, 8.324622741253364e-05, 5.39718798058439e-05,
                     8.502964604959632e-05, 1.7590139609765473e-05, 5.9633764657823906e-05, 0.00017642328070934256,
                     8.902074923106497e-06]
    learningcurve_UNET642x2_large = [0.01542483, 0.01227555, 0.00981303, 0.00818568, 0.00740627, 0.00711809, 0.00700379, 0.00715189,
                     0.00677377, 0.00660352, 0.00669556, 0.0065976, 0.00659692, 0.0064024, 0.00641401, 0.00648576,
                     0.00636847, 0.00636155, 0.00643306, 0.00636485, 0.00636642, 0.00633127, 0.00627284, 0.00628594,
                     0.00629091, 0.00632065, 0.00632428, 0.00631177, 0.00619673, 0.00621804, 0.00620855, 0.00616797,
                     0.0062412, 0.00618077, 0.00614712, 0.00613959, 0.00612926, 0.00611515, 0.00611796, 0.00610146,
                     0.00617018, 0.00612249, 0.00623661, 0.00609106, 0.00606342, 0.00607256, 0.00603054, 0.00608614,
                     0.00602226, 0.00605981, 0.00603306, 0.00598655, 0.00598702, 0.00599127, 0.00596831, 0.0059811,
                     0.00597755, 0.00601305, 0.00607358, 0.00596205, 0.00594779, 0.00595126, 0.00597063, 0.00593439,
                     0.00592356, 0.00592215, 0.00590449, 0.00592326, 0.0059263, 0.00592401, 0.00585606, 0.0058964,
                     0.00589807, 0.00585516, 0.00590217, 0.00584977, 0.00588519, 0.00584241, 0.00583705, 0.00585597,
                     0.00583819, 0.00584314, 0.00581423, 0.00579654, 0.00587496, 0.00586305, 0.00582215, 0.00582177,
                     0.00581443, 0.00585569, 0.00577262, 0.00580513, 0.00582252, 0.00578813, 0.00578235, 0.00586007,
                     0.0058004, 0.00576819, 0.00578031, 0.00577764]
    prediction_loss_UNET642x2_large = [1.31047711e-06, 1.53569706e-06, 2.50793617e-06, 2.11630696e-05, 0.00015503, 0.00026431,
                       0.00031837, 0.00037304, 0.0004756, 0.00070924, 0.00067321, 0.00073358, 0.00069937, 0.0008887,
                       0.00078647, 0.00069735, 0.00044085, 0.00036539, 0.00024498, 0.00015391, 0.00020252, 0.00014822,
                       8.27105574e-05, 4.10841264e-08, 7.33987924e-07, 1.1790818e-05, 2.78940519e-05, 3.28412773e-06,
                       2.88757483e-06, 6.74543335e-05, 1.77510291e-05, 8.29847486e-08, 6.24734309e-06, 2.97679309e-05,
                       8.35397343e-05, 0.0001654, 0.00014769, 0.00017264, 0.00021209, 0.0002259, 0.0002788, 0.00025078,
                       0.00018615, 5.83757484e-05, 3.95376869e-05, 4.75069076e-05, 1.14763468e-05, 2.81398489e-05,
                       7.93913108e-05, 5.19459894e-06]
    learningcurve_UNET64sigmoid = [0.00982844, 0.00878599, 0.00824287, 0.00771291, 0.00744927, 0.00732471, 0.00705596, 0.00696323,
                     0.00701433, 0.00682966, 0.00687483, 0.00683185, 0.00669307, 0.00671589, 0.0065955, 0.00666528,
                     0.00670716, 0.00665558, 0.00655827, 0.00650041, 0.00646621, 0.00646823, 0.00647997, 0.00648563,
                     0.00646231, 0.00646207, 0.00637724, 0.00632952, 0.00634701, 0.00630382, 0.00630471, 0.00636425,
                     0.00629142, 0.00631192, 0.00624759, 0.00626162, 0.00638368, 0.00619384, 0.0062545, 0.0062667,
                     0.00620004, 0.00626341, 0.00622057, 0.00623036, 0.00628663, 0.0061771, 0.00618046, 0.00618628,
                     0.0061676, 0.00624647, 0.0061238, 0.00621325, 0.0063063, 0.00616356, 0.00616948, 0.00616828,
                     0.0061396, 0.00614306, 0.00613632, 0.00613263, 0.00614555, 0.00618109, 0.00616281, 0.00611652,
                     0.00612557, 0.0061305, 0.00609776, 0.00613571, 0.0061458, 0.00612819, 0.00608748, 0.00614194,
                     0.00607371, 0.00615936, 0.00624318, 0.00618301, 0.00615314, 0.00609191, 0.00616171, 0.00609152]
    prediction_loss_UNET64sigmoid = [1.4933168e-06, 1.81379595e-06, 2.17330885e-06, 2.23154319e-05, 0.00015958, 0.00026198,
                       0.00033735, 0.00037312, 0.00047565, 0.00068286, 0.00066576, 0.00069603, 0.00068443, 0.00080416,
                       0.00083447, 0.00068359, 0.00042336, 0.00036242, 0.00024852, 0.0001773, 0.00019519, 0.00019157,
                       0.00010788, 2.6429718e-07, 4.03897084e-07, 1.42469078e-05, 3.21058498e-05, 3.38017061e-06,
                       2.92932402e-06, 5.68885183e-05, 1.96190529e-05, 1.40434829e-07, 4.494141e-06, 2.96298311e-05,
                       8.73379384e-05, 0.00017712, 0.00014105, 0.0001767, 0.00021731, 0.00024272, 0.00027987,
                       0.00024056, 0.00020625, 5.5080914e-05, 3.86812005e-05, 4.88754585e-05, 1.03890689e-05,
                       2.96272102e-05, 7.77282237e-05, 5.32380286e-06]
    learningcurve_UNET64abs = [0.01876365, 0.01804537, 0.0138086, 0.01120751,
                     0.00962751, 0.00883819, 0.00809668, 0.00776966,
                     0.00753878, 0.00745495, 0.00739281, 0.00730355,
                     0.00718399, 0.00705692, 0.00695429, 0.00697871,
                     0.00685577, 0.00682552, 0.00677058, 0.00673312,
                     0.00671106, 0.00665919, 0.00664624, 0.00657408,
                     0.0065602, 0.00655582, 0.00654878, 0.00651724,
                     0.00651851, 0.00645462, 0.00671196, 0.00657295,
                     0.00650106, 0.00645785, 0.00646155, 0.00638427,
                     0.00655668, 0.0064565, 0.00644147, 0.00641295,
                     0.0063659, 0.00651105, 0.006403, 0.00637619,
                     0.00641359, 0.00636702, 0.00645244, 0.00648253,
                     0.00641384, 0.00638066, 0.00639105, 0.00638307,
                     0.00637118, 0.00639529, 0.00637691, 0.00637244,
                     0.0063676, 0.00638332, 0.00642277, 0.00638963,
                     0.00633171, 0.00636245, 0.00638066, 0.00647259,
                     0.00629492, 0.00638388, 0.00649466, 0.00637656,
                     0.00641266, 0.00633436, 0.00641047, 0.00634483,
                     0.00638659, 0.0063926, 0.00636098, 0.00637719,
                     0.00640723, 0.0064749, 0.00653293, 0.00646053]
    prediction_loss_UNET64abs = [2.49586301e-06, 2.56322924e-06, 2.50137539e-06,
                       2.72384373e-05, 0.00017864, 0.00032337, 0.00036838,
                       0.0004084, 0.00053091, 0.00077848, 0.00074009,
                       0.00075646, 0.00072697, 0.00080821, 0.00085557,
                       0.00074673, 0.00049115, 0.00040762, 0.00027681,
                       0.00020864, 0.00017849, 0.00021863, 0.00014134,
                       3.95688288e-08, 5.97470602e-07, 1.86084622e-05,
                       4.10281868e-05, 3.24394464e-06, 2.88350634e-06,
                       6.80294394e-05, 2.69211415e-05, 0., 4.14964918e-06,
                       3.57997681e-05, 0.0001022, 0.00022452, 0.00015141,
                       0.00021423, 0.00025182, 0.00030474, 0.00030555,
                       0.00028362, 0.00025831, 7.41289769e-05, 5.2787585e-05,
                       5.78577182e-05, 9.4277141e-06, 3.53924981e-05,
                       8.52235501e-05, 5.18505503e-06]
    learningcurve_nesterov = [0.00876916, 0.00763574, 0.00775013, 0.00728725, 0.00706771, 0.00690446, 0.00679859, 0.00685016,
                     0.0083208, 0.00674477, 0.00669052, 0.0065954, 0.00673142, 0.00698619, 0.00660383, 0.00655915,
                     0.00652131, 0.00663586, 0.00654554, 0.00680054, 0.00727, 0.00677988, 0.00748705, 0.00646014,
                     0.00644975, 0.00646124, 0.00648091, 0.00649791, 0.0063754, 0.0064263, 0.00636619, 0.00636916,
                     0.00642287, 0.00659642, 0.00636527, 0.006555, 0.00633962, 0.00630069, 0.00631354, 0.0062959,
                     0.00634053, 0.00628647, 0.00631652, 0.00621621, 0.00622429, 0.00662466, 0.00626726, 0.00645528,
                     0.00620124, 0.00660065, 0.00620791, 0.00617543, 0.00616647, 0.00620594, 0.00616584, 0.00615409,
                     0.0061273, 0.0061772, 0.00614339, 0.0061334, 0.00616816, 0.00613709, 0.00609759, 0.00638806,
                     0.00613235, 0.00612941, 0.00612209, 0.00615991, 0.006145, 0.00615401, 0.00635393, 0.00611096,
                     0.00615352, 0.0060822, 0.00610717, 0.00606298, 0.00606257, 0.00604071, 0.00606661, 0.00603798]
    prediction_loss_nesterov = [1.71875397e-06, 1.65552961e-06, 2.51839882e-06, 2.19947249e-05, 0.00014833, 0.00027089,
                       0.00031949, 0.00036634, 0.00046509, 0.00072178, 0.00068672, 0.00071651, 0.00068261, 0.00081278,
                       0.0008001, 0.00070923, 0.00047983, 0.00037889, 0.00024699, 0.00016343, 0.00020333, 0.00018502,
                       0.00010807, 4.36043915e-07, 6.65378881e-07, 1.43982297e-05, 3.11619439e-05, 3.33887501e-06,
                       2.96609177e-06, 5.79021047e-05, 1.96858796e-05, 1.84167894e-07, 4.46581796e-06, 2.94263092e-05,
                       8.62778783e-05, 0.00016357, 0.0001413, 0.00017918, 0.00021462, 0.00023868, 0.00028542,
                       0.00024291, 0.00019439, 5.60679626e-05, 4.105311e-05, 4.99470187e-05, 1.29807418e-05,
                       3.14061303e-05, 8.14463202e-05, 5.68513118e-06]

    ###Lernkurven:
    plt.plot(learningcurve_UNET64, label="UNet64")
    plt.plot(learningcurve_UNET64OUT, label="UNet64 3x3 output")
    plt.plot(learningcurve_UNET642x2, label="Unet64 2x2 core")
    plt.plot(learningcurve_UNET642x2_large, label="Unet64 2x2 core large")
    plt.plot(learningcurve_UNET64sigmoid, label="Unet64 sigmoid")
    plt.plot(learningcurve_UNET64abs, label="Unet64 MAE")
    plt.plot(learningcurve_nesterov, label="Unet64 nesterov")
    plt.xlabel("epoch")
    plt.ylabel("mse")
    plt.title("learning curve")
    plt.legend()
    plt.show()
###Baselinevgl:
    plt.plot(baseline_loss, "g+", label="baseline")
    plt.plot(prediction_loss_UNET64, "r+", label="prediction UNet64")
    plt.plot(prediction_loss_UNET64OUT, "b+", label="prediction UNet64 3x3 output")
    plt.plot(prediction_loss_UNET642x2, "c+", label="prediction UNet64 2x2 core")
    plt.plot(prediction_loss_UNET642x2_large, "m+", label="prediction UNet64 2x2 core large")
    plt.plot(prediction_loss_UNET64sigmoid, "k+", label="prediction UNet64 sigmoid")
    plt.plot(prediction_loss_UNET64abs, "y+", label="prediction UNet64 MAE")
    plt.plot(prediction_loss_nesterov, "c+", label="prediction UNet64 nesterov")
    plt.plot(prediction_loss_nesterov, "c", alpha=0.1)
    plt.plot(prediction_loss_UNET64abs, "y", alpha=0.1)
    plt.plot(prediction_loss_UNET64sigmoid, "k", alpha=0.1)
    plt.plot(prediction_loss_UNET642x2_large, "m", alpha=0.1)
    plt.plot(prediction_loss_UNET642x2, "c", alpha=0.1)
    plt.plot(prediction_loss_UNET64OUT, "b", alpha=0.1)
    plt.plot(baseline_loss, "g", alpha=0.1)
    plt.plot(prediction_loss_UNET64, "r", alpha=0.1)
    plt.legend()
    plt.show()
    return
def statistical_evaluation_lr_baseline(baseline_loss, prediction_loss, learningcurve=None):
    assert len(baseline_loss) == len(prediction_loss)

    mean_bl = np.mean(np.array(baseline_loss))
    mean_pr = np.mean(np.array(prediction_loss))

    if learningcurve is not None:
        plt.plot(learningcurve, "orange")
        plt.xlabel("epoch")
        plt.ylabel("mse")
        plt.title("learning curve")
        plt.show()


    plt.plot(baseline_loss, "g+", label="baseline")
    plt.plot(prediction_loss, "r+", label="prediction")
    plt.plot(baseline_loss, "g", alpha=0.1)
    plt.plot(prediction_loss, "r", alpha=0.1)
    plt.plot([0,49], [mean_pr,mean_pr], "r", linewidth=2, alpha=0.5)
    plt.plot([0,49], [mean_bl,mean_bl], "g", linewidth=2, alpha=0.5)
    plt.legend()
    plt.show()
    return


if __name__ == '__main__':
    loadAndEval = False

    if loadAndEval:
        sb = sample_bundle.load_Sample_Bundle("RegenTage2016")
        sb.normalize()
        data, label = sb.get_all_data_label(channels_Last=True)
        test_samples = data[:50]
        test_labels = label[:50]
        lcd = data[896]
        lcl = label[896]
        path = "C:\\Users\\TopSecret!\\Documents\\aMSI1\\Teamprojekt\\DeepRain\\NetworkTypes\\UNet64_sigmoid_tanh_2016_"
        load_and_eval_network(plotit= False, testdata=test_samples, testlabel=test_labels, learncurvesample=lcd, learncurvelabel=lcl, network_path_prefix=path,max_number_networks=80)
    if not loadAndEval:
        default_values_UNet64_2016()
        #default_values_UNet64_output_2016()
        all_learnrates_all_loss()
